---
title: "Prior Distributions for rstanarm Models"
author: "Jonah Gabry and Ben Goodrich"
date: "`r Sys.Date()`"
output: 
  html_vignette: 
    toc: yes
params:
  EVAL: !r identical(Sys.getenv("NOT_CRAN"), "true")
---
<!--
%\VignetteEngine{knitr::rmarkdown}
%\VignetteIndexEntry{Prior Distributions}
-->
```{r, child="children/SETTINGS-knitr.txt"}
```
```{r, child="children/SETTINGS-gg.txt"}
```
```{r, child="children/SETTINGS-rstan.txt"}
```
```{r, child="children/SETTINGS-loo.txt"}
```

# Introduction

This vignette provides an overview of how the specification of prior
distributions works in the __rstanarm__ package. Before reading this vignette it
is important to first go over the 
[How to Use the __rstanarm__ Package](rstanarm.html) 
vignette, which provides a general overview of the package.

Every modeling function in __rstanarm__ offers a subset of the following 
arguments for specifying priors:

| Argument       | Used in  | Applies to |
| ------------- | ------------- | ------------- |
| `prior_intercept` | All modeling functions except `stan_polr`| Model intercept, after centering predictors.|
| `prior` |  All modeling functions| Regression coefficients. Does _not_ include coefficients that vary by group in a multilevel model (see `prior_covariance`).|
| `prior_aux` | `stan_glm`\*, `stan_glmer`\*, `stan_gamm4`| Auxiliary parameter, e.g. error SD (interpretation depends on the GLM).|
| `prior_covariance` | `stan_glmer`\*, `stan_gamm4`| Covariance matrices in multilevel models with varying slopes and intercepts.|
\* `stan_glm` also implies `stan_glm.nb`. `stan_glmer` implies `stan_lmer` and
`stan_glmer.nb`.

<br> 

The `stan_polr` and `stan_betareg` functions also provide additional arguments 
specific only to those models:

| Argument       | Used only in  | Applies to |
| ------------- | ------------- | ------------- |
| `prior_counts` | `stan_polr` | Prior counts of an _ordinal_ outcome (when predictors at sample means). |
| `prior_z`  |  `stan_betareg`| Coefficients in the model for `phi`.|
| `prior_intercept_z` | `stan_betareg`| Intercept in the model for `phi`. |
| `prior_phi` | `stan_betareg`| `phi`, if not modeled as function of predictors. |


<br> 
The __rstanarm__ documentation and the other [vignettes](index.html) provide 
many examples of using these arguments to specify priors. The documentation 
for these arguments on the help pages for the various __rstanarm__ modeling 
functions also explains which distributions can be used when specifying 
each of the prior-related arguments.


# Default (Weakly Informative) Prior Distributions

With very few exceptions, the default priors in __rstanarm__ ---the priors used 
if the arguments in the tables above are untouched--- are _not flat priors_. 
Rather, the defaults are intended to be _weakly informative_. That is, they are 
designed to provide moderate regularlization and help stabilize computation. For
many (if not most) applications the defaults will perform well, but this is 
not guaranteed. It would be impossible to have default priors that work well 
with every possible model specification.

The way __rstanarm__ attempts to make priors weakly informative by default is to
internally adjust the scales of the priors. How this works (and how to turn it 
off) is explained below, but first let's see the default priors in action by 
fitting a basic linear regression model with the `stan_glm` function. The 
`stan_glm` function accepts the arguments `prior_intercept`, `prior`, and 
`prior_aux` To use the default priors we just leave those arguments at their
defaults (i.e., we don't specify them):

```{r, default-prior-1, results="hide"}
library("rstanarm")
default_prior_test <- stan_glm(mpg ~ wt + am, data = mtcars)
```

The `prior_summary` function provides a concise summary of the priors used: 

```{r, default-prior-summary}
prior_summary(default_prior_test)
```
```{r, echo=FALSE}
priors <- prior_summary(default_prior_test)
fr2 <- function(x) format(round(x, 2), nsmall = 2)
```

Starting from the bottom up, we can see that:

* __Auxiliary__: `sigma`, the error standard deviation, has a default prior that
is $\mathsf{halfCauchy}(0, 5)$. However, as a result of the automatic rescaling,
the actual scale used was `r fr2(priors$prior_aux$adjusted_scale)`.

* __Coefficients__: By default the regression coefficients (in this case the 
coefficients on the `wt` and `am` variables) are treated as a priori independent
with normal priors centered at 0 and with scale (standard deviation) $2.5$. Like
for `sigma`, in order for the default to be weakly informative __rstanarm__ will
adjust the scales of the priors on the coefficients. As a result, the prior
scales actually used were
`r fr2(priors$prior$adjusted_scale[1])` and 
`r fr2(priors$prior$adjusted_scale[2])`. 

* __Intercept__: For the intercept, the default prior is normal with mean $0$ 
and standard deviation $10$, but in this case the standard deviation was 
adjusted to `r fr2(priors$prior_intercept$adjusted_scale[1])`. There is also a
note in parentheses informing you that the prior applies to the intercept after
all predictors have been centered (a similar note can be found in the
documentation of the `prior_intercept` argument). In many cases the value of $y$
when $x=0$ is not meaningful and it is easier to think about the value when $x =
\bar{x}$. Therefore placing a prior on the intercept after centering the
predictors typically makes it easier to specify a reasonable prior for the
intercept. (Note: the user does _not_ need to manually center the predictors.)

The next two subsections describe how this rescaling works and how to easily
disable it if desired.


### Automatic Prior Scale Adjustments

For distributions that take an `autoscale` argument (see `help("priors")` for a
list), if `autoscale` is left at `TRUE` (the default) then, in certain cases,
the prior scales will be adjusted internally by __rstanarm__.

First, if the __outcome__ $y$ is Gaussian, the prior scales for the intercept,
coefficients, and error standard deviation are multiplied by a factor of
$\mathrm{sd}(y)$.

Additionally (not only for Gaussian models), if the `QR` argument to the model
fitting function (e.g. `stan_glm`) is `FALSE` (the default) then:

* For a __predictor__ $x$ with only one value nothing is changed.
* For a __predictor__ $x$ with exactly two unique values, we take the
user-specified (or default) scale(s) for the selected priors and divide by the
range of $x$.
* For a __predictor__ $x$ with more than two unique values, we divide the prior 
scale(s) by $\mathrm{sd}(x)$.

These are technically data-dependent priors since the scaling is based on scales
of the predictors (and possibly the outcome). However, since these priors are
quite wide (and in most cases rather conservative), the amount of information
used is weak and mainly takes into account the order of magnitude of the
variables. This enables __rstanarm__ to offer defaults that are reasonable for
many models.

### Disabling Prior Scale Adjustments

To disable automatic rescaling, the `autoscale` argument can be set
to `FALSE`. For example:

```{r, no-autoscale, results="hide"}
test_no_autoscale <-
  update(
    default_prior_test,
    prior = normal(0, 5, autoscale = FALSE),
    prior_intercept = student_t(4, 0, 10, autoscale = FALSE),
    prior_aux = exponential(1/10, autoscale=FALSE)
  )
```

We can verify that the prior scales weren't adjusted by checking
`prior_summary`:

```{r, no-autoscale-prior-summary}
prior_summary(test_no_autoscale)
```

# How to Specify Flat Priors (and why you shouldn't)

### Uninformative is Unrealistic

When "noninformative" or "uninformative" is used in the context of prior 
distributions, it typically refers to a flat (uniform) distribution or a nearly 
flat distribution. Sometimes it may also be used to refer to the 
parameterization-invariant Jeffreys prior. Although in most cases __rstanarm__ 
does not prevent you from using flat (or very diffuse) priors, unless the data 
is very strong it is wise to avoid them. Rarely is it approrpriate is any 
applied setting to use a prior that gives the same (or nearly the same) 
probability mass to values near zero as it gives values bigger than the age of
the universe in nanoseconds.

Even when you know very little, a flat or very wide prior will almost never be 
the best approximation to your beliefs about the parameters in your model that 
you can express using __rstanarm__ (or other software). _Some_ amount of prior 
information will be available. For example, even if there is nothing to suggest 
a priori that a particular coefficient will be positive or negative, there is 
almost always enough information to suggest that $1$ and $4.3\times 10^{26}$ are
not equally likely. Making use of this information when setting a prior scale 
parameter is simple ---a useful heuristic is to set the scale an 
order of magnitude bigger than you suspect it to be--- and has the added 
benefit of helping to stabilize computations.

### Specifying Flat Priors

__rstanarm__ will use flat priors if `NULL` is specified rather than a
distribution. For example, to use a flat prior on regression coefficients you
would specify `prior=NULL`:

```{r, flat-prior-1, echo=FALSE, results="hide"}
flat_prior_test <- stan_glm(mpg ~ wt, data = mtcars, prior = NULL, iter = 10, chains = 1)
```
```{r, flat-prior-2, eval=FALSE}
flat_prior_test <- stan_glm(mpg ~ wt, data = mtcars, prior = NULL)
```

In this case we let __rstanarm__ use the default priors for the intercept and
error standard deviation (we could change that if we wanted), but the 
coefficient on the `wt` variable will have a flat prior. To double check that
indeed a flat prior was used for the coefficient on `wt` we can call
`prior_summary`:

```{r, flat-prior-summary}
prior_summary(flat_prior_test)
```


# Informative Prior Distributions

Although the default priors tend to work well, prudent use of more informative
priors is encouraged. For example, suppose we have a linear regression model 
$$y \sim \mathsf{Normal}\left(\alpha + \beta_1 x_1 + \beta_2 x_2, \, \sigma\right)$$ 
and we have a strong reason to believe (perhaps from previous research on the
same topic) that $\beta_1 \in (-15, -5)$ and $\beta_2 \in (-1, 1)$. An example 
of an informative prior for $\boldsymbol{\beta} = (\beta_1, \beta_2)$ could be 

$$
\begin{pmatrix} \beta_1 \\ \beta_2 \end{pmatrix}
\sim \mathsf{Normal} \left( 
\begin{pmatrix} -10 \\ 0 \end{pmatrix},
\begin{pmatrix} 5^2 & 0 \\ 0 & 2^2 \end{pmatrix}
\right),
$$
which sets the prior means at the midpoints of the intervals and then allows
for some wiggle room on either side.

If the variables `y`, `x1`, and `x2` are in the data frame `dat` then this
model can be specified with __rstanarm__ 
```{r, eval=FALSE}
my_prior <- normal(location = c(-10, 0), scale = c(5, 2), autoscale = FALSE)
stan_glm(y ~ x1 + x2, data = dat, prior = my_prior)
```

