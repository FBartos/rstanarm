/*
    rstanarm is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    rstanarm is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with rstanarm.  If not, see <http://www.gnu.org/licenses/>.
*/
#ifndef MODELS_HPP
#define MODELS_HPP
#define STAN__SERVICES__COMMAND_HPP
#include <rstan/rstaninc.hpp>
// Code generated by Stan version 2.16.0

#include <stan/model/model_header.hpp>

namespace model_bernoulli_namespace {

using std::istream;
using std::string;
using std::stringstream;
using std::vector;
using stan::io::dump;
using stan::math::lgamma;
using stan::model::prob_grad;
using namespace stan::math;

typedef Eigen::Matrix<double,Eigen::Dynamic,1> vector_d;
typedef Eigen::Matrix<double,1,Eigen::Dynamic> row_vector_d;
typedef Eigen::Matrix<double,Eigen::Dynamic,Eigen::Dynamic> matrix_d;

static int current_statement_begin__;

stan::io::program_reader prog_reader__() {
    stan::io::program_reader reader;
    reader.add_event(0, 0, "start", "model_bernoulli");
    reader.add_event(760, 760, "end", "model_bernoulli");
    return reader;
}

template <typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T7__>
Eigen::Matrix<typename boost::math::tools::promote_args<T2__, T3__, T4__, T5__, typename boost::math::tools::promote_args<T6__, T7__>::type>::type, Eigen::Dynamic,1>
make_theta_L(const int& len_theta_L,
                 const std::vector<int>& p,
                 const T2__& dispersion,
                 const Eigen::Matrix<T3__, Eigen::Dynamic,1>& tau,
                 const Eigen::Matrix<T4__, Eigen::Dynamic,1>& scale,
                 const Eigen::Matrix<T5__, Eigen::Dynamic,1>& zeta,
                 const Eigen::Matrix<T6__, Eigen::Dynamic,1>& rho,
                 const Eigen::Matrix<T7__, Eigen::Dynamic,1>& z_T, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T2__, T3__, T4__, T5__, typename boost::math::tools::promote_args<T6__, T7__>::type>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            validate_non_negative_index("theta_L", "len_theta_L", len_theta_L);
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  theta_L(static_cast<Eigen::VectorXd::Index>(len_theta_L));
            (void) theta_L;  // dummy to suppress unused var warning

            stan::math::initialize(theta_L, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(theta_L,DUMMY_VAR__);
            int zeta_mark(0);
            (void) zeta_mark;  // dummy to suppress unused var warning

            stan::math::fill(zeta_mark, std::numeric_limits<int>::min());
            stan::math::assign(zeta_mark,1);
            int rho_mark(0);
            (void) rho_mark;  // dummy to suppress unused var warning

            stan::math::fill(rho_mark, std::numeric_limits<int>::min());
            stan::math::assign(rho_mark,1);
            int z_T_mark(0);
            (void) z_T_mark;  // dummy to suppress unused var warning

            stan::math::fill(z_T_mark, std::numeric_limits<int>::min());
            stan::math::assign(z_T_mark,1);
            int theta_L_mark(0);
            (void) theta_L_mark;  // dummy to suppress unused var warning

            stan::math::fill(theta_L_mark, std::numeric_limits<int>::min());
            stan::math::assign(theta_L_mark,1);


            current_statement_begin__ = 52;
            for (int i = 1; i <= size(p); ++i) {
                {
                    int nc(0);
                    (void) nc;  // dummy to suppress unused var warning

                    stan::math::fill(nc, std::numeric_limits<int>::min());
                    stan::math::assign(nc,get_base1(p,i,"p",1));


                    current_statement_begin__ = 54;
                    if (as_bool(logical_eq(nc,1))) {

                        current_statement_begin__ = 55;
                        stan::math::assign(get_base1_lhs(theta_L,theta_L_mark,"theta_L",1), ((get_base1(tau,i,"tau",1) * get_base1(scale,i,"scale",1)) * dispersion));
                        current_statement_begin__ = 57;
                        stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                    } else {
                        {
                            validate_non_negative_index("T_i", "nc", nc);
                            validate_non_negative_index("T_i", "nc", nc);
                            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,Eigen::Dynamic>  T_i(static_cast<Eigen::VectorXd::Index>(nc),static_cast<Eigen::VectorXd::Index>(nc));
                            (void) T_i;  // dummy to suppress unused var warning

                            stan::math::initialize(T_i, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(T_i,DUMMY_VAR__);
                            fun_scalar_t__ std_dev;
                            (void) std_dev;  // dummy to suppress unused var warning

                            stan::math::initialize(std_dev, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(std_dev,DUMMY_VAR__);
                            fun_scalar_t__ T21;
                            (void) T21;  // dummy to suppress unused var warning

                            stan::math::initialize(T21, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(T21,DUMMY_VAR__);
                            fun_scalar_t__ trace_T_i;
                            (void) trace_T_i;  // dummy to suppress unused var warning

                            stan::math::initialize(trace_T_i, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(trace_T_i,DUMMY_VAR__);
                            stan::math::assign(trace_T_i,(square(((get_base1(tau,i,"tau",1) * get_base1(scale,i,"scale",1)) * dispersion)) * nc));
                            validate_non_negative_index("pi", "nc", nc);
                            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  pi(static_cast<Eigen::VectorXd::Index>(nc));
                            (void) pi;  // dummy to suppress unused var warning

                            stan::math::initialize(pi, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(pi,DUMMY_VAR__);
                            stan::math::assign(pi,segment(zeta,zeta_mark,nc));


                            current_statement_begin__ = 65;
                            stan::math::assign(pi, divide(pi,sum(pi)));
                            current_statement_begin__ = 68;
                            stan::math::assign(zeta_mark, (zeta_mark + nc));
                            current_statement_begin__ = 69;
                            stan::math::assign(std_dev, sqrt((get_base1(pi,1,"pi",1) * trace_T_i)));
                            current_statement_begin__ = 70;
                            stan::math::assign(get_base1_lhs(T_i,1,1,"T_i",1), std_dev);
                            current_statement_begin__ = 73;
                            stan::math::assign(std_dev, sqrt((get_base1(pi,2,"pi",1) * trace_T_i)));
                            current_statement_begin__ = 74;
                            stan::math::assign(T21, ((2.0 * get_base1(rho,rho_mark,"rho",1)) - 1.0));
                            current_statement_begin__ = 75;
                            stan::math::assign(rho_mark, (rho_mark + 1));
                            current_statement_begin__ = 76;
                            stan::math::assign(get_base1_lhs(T_i,2,2,"T_i",1), (std_dev * sqrt((1.0 - square(T21)))));
                            current_statement_begin__ = 77;
                            stan::math::assign(get_base1_lhs(T_i,2,1,"T_i",1), (std_dev * T21));
                            current_statement_begin__ = 79;
                            for (int r = 2; r <= (nc - 1); ++r) {
                                {
                                    int rp1(0);
                                    (void) rp1;  // dummy to suppress unused var warning

                                    stan::math::fill(rp1, std::numeric_limits<int>::min());
                                    stan::math::assign(rp1,(r + 1));
                                    validate_non_negative_index("T_row", "r", r);
                                    Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  T_row(static_cast<Eigen::VectorXd::Index>(r));
                                    (void) T_row;  // dummy to suppress unused var warning

                                    stan::math::initialize(T_row, std::numeric_limits<double>::quiet_NaN());
                                    stan::math::fill(T_row,DUMMY_VAR__);
                                    stan::math::assign(T_row,segment(z_T,z_T_mark,r));
                                    fun_scalar_t__ scale_factor;
                                    (void) scale_factor;  // dummy to suppress unused var warning

                                    stan::math::initialize(scale_factor, std::numeric_limits<double>::quiet_NaN());
                                    stan::math::fill(scale_factor,DUMMY_VAR__);
                                    stan::math::assign(scale_factor,(sqrt((get_base1(rho,rho_mark,"rho",1) / dot_self(T_row))) * std_dev));


                                    current_statement_begin__ = 83;
                                    stan::math::assign(z_T_mark, (z_T_mark + r));
                                    current_statement_begin__ = 84;
                                    stan::math::assign(std_dev, sqrt((get_base1(pi,rp1,"pi",1) * trace_T_i)));
                                    current_statement_begin__ = 85;
                                    for (int c = 1; c <= r; ++c) {
                                        current_statement_begin__ = 85;
                                        stan::math::assign(get_base1_lhs(T_i,rp1,c,"T_i",1), (get_base1(T_row,c,"T_row",1) * scale_factor));
                                    }
                                    current_statement_begin__ = 86;
                                    stan::math::assign(get_base1_lhs(T_i,rp1,rp1,"T_i",1), (sqrt((1.0 - get_base1(rho,rho_mark,"rho",1))) * std_dev));
                                    current_statement_begin__ = 87;
                                    stan::math::assign(rho_mark, (rho_mark + 1));
                                }
                            }
                            current_statement_begin__ = 91;
                            for (int c = 1; c <= nc; ++c) {
                                current_statement_begin__ = 91;
                                for (int r = c; r <= nc; ++r) {

                                    current_statement_begin__ = 92;
                                    stan::math::assign(get_base1_lhs(theta_L,theta_L_mark,"theta_L",1), get_base1(T_i,r,c,"T_i",1));
                                    current_statement_begin__ = 93;
                                    stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                                }
                            }
                        }
                    }
                }
            }
            current_statement_begin__ = 97;
            return stan::math::promote_scalar<fun_return_scalar_t__>(theta_L);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct make_theta_L_functor__ {
    template <typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T7__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T2__, T3__, T4__, T5__, typename boost::math::tools::promote_args<T6__, T7__>::type>::type, Eigen::Dynamic,1>
    operator()(const int& len_theta_L,
                 const std::vector<int>& p,
                 const T2__& dispersion,
                 const Eigen::Matrix<T3__, Eigen::Dynamic,1>& tau,
                 const Eigen::Matrix<T4__, Eigen::Dynamic,1>& scale,
                 const Eigen::Matrix<T5__, Eigen::Dynamic,1>& zeta,
                 const Eigen::Matrix<T6__, Eigen::Dynamic,1>& rho,
                 const Eigen::Matrix<T7__, Eigen::Dynamic,1>& z_T, std::ostream* pstream__) const {
        return make_theta_L(len_theta_L, p, dispersion, tau, scale, zeta, rho, z_T, pstream__);
    }
};

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
make_b(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_b,
           const Eigen::Matrix<T1__, Eigen::Dynamic,1>& theta_L,
           const std::vector<int>& p,
           const std::vector<int>& l, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            validate_non_negative_index("b", "rows(z_b)", rows(z_b));
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  b(static_cast<Eigen::VectorXd::Index>(rows(z_b)));
            (void) b;  // dummy to suppress unused var warning

            stan::math::initialize(b, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(b,DUMMY_VAR__);
            int b_mark(0);
            (void) b_mark;  // dummy to suppress unused var warning

            stan::math::fill(b_mark, std::numeric_limits<int>::min());
            stan::math::assign(b_mark,1);
            int theta_L_mark(0);
            (void) theta_L_mark;  // dummy to suppress unused var warning

            stan::math::fill(theta_L_mark, std::numeric_limits<int>::min());
            stan::math::assign(theta_L_mark,1);


            current_statement_begin__ = 115;
            for (int i = 1; i <= size(p); ++i) {
                {
                    int nc(0);
                    (void) nc;  // dummy to suppress unused var warning

                    stan::math::fill(nc, std::numeric_limits<int>::min());
                    stan::math::assign(nc,get_base1(p,i,"p",1));


                    current_statement_begin__ = 117;
                    if (as_bool(logical_eq(nc,1))) {
                        {
                            fun_scalar_t__ theta_L_start;
                            (void) theta_L_start;  // dummy to suppress unused var warning

                            stan::math::initialize(theta_L_start, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(theta_L_start,DUMMY_VAR__);
                            stan::math::assign(theta_L_start,get_base1(theta_L,theta_L_mark,"theta_L",1));


                            current_statement_begin__ = 119;
                            for (int s = b_mark; s <= ((b_mark + get_base1(l,i,"l",1)) - 1); ++s) {
                                current_statement_begin__ = 120;
                                stan::math::assign(get_base1_lhs(b,s,"b",1), (theta_L_start * get_base1(z_b,s,"z_b",1)));
                            }
                            current_statement_begin__ = 121;
                            stan::math::assign(b_mark, (b_mark + get_base1(l,i,"l",1)));
                            current_statement_begin__ = 122;
                            stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                        }
                    } else {
                        {
                            validate_non_negative_index("T_i", "nc", nc);
                            validate_non_negative_index("T_i", "nc", nc);
                            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,Eigen::Dynamic>  T_i(static_cast<Eigen::VectorXd::Index>(nc),static_cast<Eigen::VectorXd::Index>(nc));
                            (void) T_i;  // dummy to suppress unused var warning

                            stan::math::initialize(T_i, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(T_i,DUMMY_VAR__);
                            stan::math::assign(T_i,rep_matrix(0,nc,nc));


                            current_statement_begin__ = 126;
                            for (int c = 1; c <= nc; ++c) {

                                current_statement_begin__ = 127;
                                stan::math::assign(get_base1_lhs(T_i,c,c,"T_i",1), get_base1(theta_L,theta_L_mark,"theta_L",1));
                                current_statement_begin__ = 128;
                                stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                                current_statement_begin__ = 129;
                                for (int r = (c + 1); r <= nc; ++r) {

                                    current_statement_begin__ = 130;
                                    stan::math::assign(get_base1_lhs(T_i,r,c,"T_i",1), get_base1(theta_L,theta_L_mark,"theta_L",1));
                                    current_statement_begin__ = 131;
                                    stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                                }
                            }
                            current_statement_begin__ = 134;
                            for (int j = 1; j <= get_base1(l,i,"l",1); ++j) {
                                {
                                    validate_non_negative_index("temp", "nc", nc);
                                    Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  temp(static_cast<Eigen::VectorXd::Index>(nc));
                                    (void) temp;  // dummy to suppress unused var warning

                                    stan::math::initialize(temp, std::numeric_limits<double>::quiet_NaN());
                                    stan::math::fill(temp,DUMMY_VAR__);
                                    stan::math::assign(temp,multiply(T_i,segment(z_b,b_mark,nc)));


                                    current_statement_begin__ = 136;
                                    stan::math::assign(b_mark, (b_mark - 1));
                                    current_statement_begin__ = 137;
                                    for (int s = 1; s <= nc; ++s) {
                                        current_statement_begin__ = 137;
                                        stan::math::assign(get_base1_lhs(b,(b_mark + s),"b",1), get_base1(temp,s,"temp",1));
                                    }
                                    current_statement_begin__ = 138;
                                    stan::math::assign(b_mark, ((b_mark + nc) + 1));
                                }
                            }
                        }
                    }
                }
            }
            current_statement_begin__ = 142;
            return stan::math::promote_scalar<fun_return_scalar_t__>(b);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct make_b_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_b,
           const Eigen::Matrix<T1__, Eigen::Dynamic,1>& theta_L,
           const std::vector<int>& p,
           const std::vector<int>& l, std::ostream* pstream__) const {
        return make_b(z_b, theta_L, p, l, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T7__, typename T_lp__, typename T_lp_accum__>
void
decov_lp(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_b,
             const Eigen::Matrix<T1__, Eigen::Dynamic,1>& z_T,
             const Eigen::Matrix<T2__, Eigen::Dynamic,1>& rho,
             const Eigen::Matrix<T3__, Eigen::Dynamic,1>& zeta,
             const Eigen::Matrix<T4__, Eigen::Dynamic,1>& tau,
             const std::vector<T5__>& regularization,
             const std::vector<T6__>& delta,
             const Eigen::Matrix<T7__, Eigen::Dynamic,1>& shape,
             const int& t,
             const std::vector<int>& p, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__, T6__, T7__, T_lp__>::type>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            int pos_reg(0);
            (void) pos_reg;  // dummy to suppress unused var warning

            stan::math::fill(pos_reg, std::numeric_limits<int>::min());
            stan::math::assign(pos_reg,1);
            int pos_rho(0);
            (void) pos_rho;  // dummy to suppress unused var warning

            stan::math::fill(pos_rho, std::numeric_limits<int>::min());
            stan::math::assign(pos_rho,1);


            current_statement_begin__ = 165;
            lp_accum__.add(normal_log(z_b,0,1));
            current_statement_begin__ = 166;
            lp_accum__.add(normal_log(z_T,0,1));
            current_statement_begin__ = 167;
            for (int i = 1; i <= t; ++i) {
                current_statement_begin__ = 167;
                if (as_bool(logical_gt(get_base1(p,i,"p",1),1))) {
                    {
                        validate_non_negative_index("shape1", "(get_base1(p,i,\"p\",1) - 1)", (get_base1(p,i,"p",1) - 1));
                        Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  shape1(static_cast<Eigen::VectorXd::Index>((get_base1(p,i,"p",1) - 1)));
                        (void) shape1;  // dummy to suppress unused var warning

                        stan::math::initialize(shape1, std::numeric_limits<double>::quiet_NaN());
                        stan::math::fill(shape1,DUMMY_VAR__);
                        validate_non_negative_index("shape2", "(get_base1(p,i,\"p\",1) - 1)", (get_base1(p,i,"p",1) - 1));
                        Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  shape2(static_cast<Eigen::VectorXd::Index>((get_base1(p,i,"p",1) - 1)));
                        (void) shape2;  // dummy to suppress unused var warning

                        stan::math::initialize(shape2, std::numeric_limits<double>::quiet_NaN());
                        stan::math::fill(shape2,DUMMY_VAR__);
                        fun_scalar_t__ nu;
                        (void) nu;  // dummy to suppress unused var warning

                        stan::math::initialize(nu, std::numeric_limits<double>::quiet_NaN());
                        stan::math::fill(nu,DUMMY_VAR__);
                        stan::math::assign(nu,(get_base1(regularization,pos_reg,"regularization",1) + (0.5 * (get_base1(p,i,"p",1) - 2))));


                        current_statement_begin__ = 171;
                        stan::math::assign(pos_reg, (pos_reg + 1));
                        current_statement_begin__ = 172;
                        stan::math::assign(get_base1_lhs(shape1,1,"shape1",1), nu);
                        current_statement_begin__ = 173;
                        stan::math::assign(get_base1_lhs(shape2,1,"shape2",1), nu);
                        current_statement_begin__ = 174;
                        for (int j = 2; j <= (get_base1(p,i,"p",1) - 1); ++j) {

                            current_statement_begin__ = 175;
                            stan::math::assign(nu, (nu - 0.5));
                            current_statement_begin__ = 176;
                            stan::math::assign(get_base1_lhs(shape1,j,"shape1",1), (0.5 * j));
                            current_statement_begin__ = 177;
                            stan::math::assign(get_base1_lhs(shape2,j,"shape2",1), nu);
                        }
                        current_statement_begin__ = 179;
                        lp_accum__.add(beta_log(stan::model::rvalue(rho, stan::model::cons_list(stan::model::index_min_max(pos_rho, ((pos_rho + get_base1(p,i,"p",1)) - 2)), stan::model::nil_index_list()), "rho"),shape1,shape2));
                        current_statement_begin__ = 180;
                        stan::math::assign(pos_rho, ((pos_rho + get_base1(p,i,"p",1)) - 1));
                    }
                }
            }
            current_statement_begin__ = 182;
            lp_accum__.add(gamma_log(zeta,delta,1));
            current_statement_begin__ = 183;
            lp_accum__.add(gamma_log(tau,shape,1));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct decov_lp_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T7__, typename T_lp__, typename T_lp_accum__>
        void
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_b,
             const Eigen::Matrix<T1__, Eigen::Dynamic,1>& z_T,
             const Eigen::Matrix<T2__, Eigen::Dynamic,1>& rho,
             const Eigen::Matrix<T3__, Eigen::Dynamic,1>& zeta,
             const Eigen::Matrix<T4__, Eigen::Dynamic,1>& tau,
             const std::vector<T5__>& regularization,
             const std::vector<T6__>& delta,
             const Eigen::Matrix<T7__, Eigen::Dynamic,1>& shape,
             const int& t,
             const std::vector<int>& p, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) const {
        return decov_lp(z_b, z_T, rho, zeta, tau, regularization, delta, shape, t, p, lp__, lp_accum__, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type, Eigen::Dynamic,1>
hs_prior(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_beta,
             const std::vector<T1__>& global,
             const std::vector<Eigen::Matrix<T2__, Eigen::Dynamic,1> >& local,
             const T3__& global_prior_scale,
             const T4__& error_scale, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            validate_non_negative_index("lambda", "rows(z_beta)", rows(z_beta));
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  lambda(static_cast<Eigen::VectorXd::Index>(rows(z_beta)));
            (void) lambda;  // dummy to suppress unused var warning

            stan::math::initialize(lambda, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(lambda,DUMMY_VAR__);
            int K(0);
            (void) K;  // dummy to suppress unused var warning

            stan::math::fill(K, std::numeric_limits<int>::min());


            current_statement_begin__ = 200;
            stan::math::assign(K, rows(z_beta));
            current_statement_begin__ = 201;
            for (int k = 1; k <= K; ++k) {
                current_statement_begin__ = 201;
                stan::math::assign(get_base1_lhs(lambda,k,"lambda",1), (get_base1(get_base1(local,1,"local",1),k,"local",2) * sqrt(get_base1(get_base1(local,2,"local",1),k,"local",2))));
            }
            current_statement_begin__ = 202;
            return stan::math::promote_scalar<fun_return_scalar_t__>(multiply(multiply(multiply(multiply(elt_multiply(z_beta,lambda),get_base1(global,1,"global",1)),sqrt(get_base1(global,2,"global",1))),global_prior_scale),error_scale));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct hs_prior_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_beta,
             const std::vector<T1__>& global,
             const std::vector<Eigen::Matrix<T2__, Eigen::Dynamic,1> >& local,
             const T3__& global_prior_scale,
             const T4__& error_scale, std::ostream* pstream__) const {
        return hs_prior(z_beta, global, local, global_prior_scale, error_scale, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type, Eigen::Dynamic,1>
hsplus_prior(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_beta,
                 const std::vector<T1__>& global,
                 const std::vector<Eigen::Matrix<T2__, Eigen::Dynamic,1> >& local,
                 const T3__& global_prior_scale,
                 const T4__& error_scale, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 218;
        return stan::math::promote_scalar<fun_return_scalar_t__>(multiply(multiply(multiply(multiply(elt_multiply(elt_multiply(z_beta,elt_multiply(get_base1(local,1,"local",1),sqrt(get_base1(local,2,"local",1)))),elt_multiply(get_base1(local,3,"local",1),sqrt(get_base1(local,4,"local",1)))),get_base1(global,1,"global",1)),sqrt(get_base1(global,2,"global",1))),global_prior_scale),error_scale));
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct hsplus_prior_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_beta,
                 const std::vector<T1__>& global,
                 const std::vector<Eigen::Matrix<T2__, Eigen::Dynamic,1> >& local,
                 const T3__& global_prior_scale,
                 const T4__& error_scale, std::ostream* pstream__) const {
        return hsplus_prior(z_beta, global, local, global_prior_scale, error_scale, pstream__);
    }
};

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
divide_real_by_vector(const T0__& x,
                          const Eigen::Matrix<T1__, Eigen::Dynamic,1>& y, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            int K(0);
            (void) K;  // dummy to suppress unused var warning

            stan::math::fill(K, std::numeric_limits<int>::min());
            stan::math::assign(K,rows(y));
            validate_non_negative_index("ret", "K", K);
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  ret(static_cast<Eigen::VectorXd::Index>(K));
            (void) ret;  // dummy to suppress unused var warning

            stan::math::initialize(ret, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(ret,DUMMY_VAR__);


            current_statement_begin__ = 233;
            for (int k = 1; k <= K; ++k) {
                current_statement_begin__ = 233;
                stan::math::assign(get_base1_lhs(ret,k,"ret",1), (x / get_base1(y,k,"y",1)));
            }
            current_statement_begin__ = 234;
            return stan::math::promote_scalar<fun_return_scalar_t__>(ret);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct divide_real_by_vector_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
    operator()(const T0__& x,
                          const Eigen::Matrix<T1__, Eigen::Dynamic,1>& y, std::ostream* pstream__) const {
        return divide_real_by_vector(x, y, pstream__);
    }
};

template <typename T0__, typename T1__>
typename boost::math::tools::promote_args<T0__, T1__>::type
CFt(const T0__& z,
        const T1__& df, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            fun_scalar_t__ z2;
            (void) z2;  // dummy to suppress unused var warning

            stan::math::initialize(z2, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(z2,DUMMY_VAR__);
            stan::math::assign(z2,square(z));
            fun_scalar_t__ z3;
            (void) z3;  // dummy to suppress unused var warning

            stan::math::initialize(z3, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(z3,DUMMY_VAR__);
            stan::math::assign(z3,(z2 * z));
            fun_scalar_t__ z5;
            (void) z5;  // dummy to suppress unused var warning

            stan::math::initialize(z5, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(z5,DUMMY_VAR__);
            stan::math::assign(z5,(z2 * z3));
            fun_scalar_t__ z7;
            (void) z7;  // dummy to suppress unused var warning

            stan::math::initialize(z7, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(z7,DUMMY_VAR__);
            stan::math::assign(z7,(z2 * z5));
            fun_scalar_t__ z9;
            (void) z9;  // dummy to suppress unused var warning

            stan::math::initialize(z9, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(z9,DUMMY_VAR__);
            stan::math::assign(z9,(z2 * z7));
            fun_scalar_t__ df2;
            (void) df2;  // dummy to suppress unused var warning

            stan::math::initialize(df2, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(df2,DUMMY_VAR__);
            stan::math::assign(df2,square(df));
            fun_scalar_t__ df3;
            (void) df3;  // dummy to suppress unused var warning

            stan::math::initialize(df3, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(df3,DUMMY_VAR__);
            stan::math::assign(df3,(df2 * df));
            fun_scalar_t__ df4;
            (void) df4;  // dummy to suppress unused var warning

            stan::math::initialize(df4, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(df4,DUMMY_VAR__);
            stan::math::assign(df4,(df2 * df2));


            current_statement_begin__ = 256;
            return stan::math::promote_scalar<fun_return_scalar_t__>(((((z + ((z3 + z) / (4 * df))) + ((((5 * z5) + (16 * z3)) + (3 * z)) / (96 * df2))) + (((((3 * z7) + (19 * z5)) + (17 * z3)) - (15 * z)) / (384 * df3))) + ((((((79 * z9) + (776 * z7)) + (1482 * z5)) - (1920 * z3)) - (945 * z)) / (92160 * df4))));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct CFt_functor__ {
    template <typename T0__, typename T1__>
        typename boost::math::tools::promote_args<T0__, T1__>::type
    operator()(const T0__& z,
        const T1__& df, std::ostream* pstream__) const {
        return CFt(z, df, pstream__);
    }
};

std::vector<std::vector<int> >
make_V(const int& N,
           const int& t,
           const std::vector<int>& v, std::ostream* pstream__) {
    typedef double fun_scalar_t__;
    typedef int fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            validate_non_negative_index("V", "t", t);
            validate_non_negative_index("V", "N", N);
            vector<vector<int> > V(t, (vector<int>(N, 0)));
            stan::math::fill(V, std::numeric_limits<int>::min());
            int pos(0);
            (void) pos;  // dummy to suppress unused var warning

            stan::math::fill(pos, std::numeric_limits<int>::min());
            stan::math::assign(pos,1);


            current_statement_begin__ = 271;
            if (as_bool(logical_gt(t,0))) {
                current_statement_begin__ = 271;
                for (int j = 1; j <= N; ++j) {
                    current_statement_begin__ = 271;
                    for (int i = 1; i <= t; ++i) {

                        current_statement_begin__ = 272;
                        stan::math::assign(get_base1_lhs(get_base1_lhs(V,i,"V",1),j,"V",2), get_base1(v,pos,"v",1));
                        current_statement_begin__ = 273;
                        stan::math::assign(pos, (pos + 1));
                    }
                }
            }
            current_statement_begin__ = 275;
            return stan::math::promote_scalar<fun_return_scalar_t__>(V);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct make_V_functor__ {
            std::vector<std::vector<int> >
    operator()(const int& N,
           const int& t,
           const std::vector<int>& v, std::ostream* pstream__) const {
        return make_V(N, t, v, pstream__);
    }
};

template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
linkinv_bern(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                 const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 288;
        if (as_bool(logical_eq(link,1))) {
            current_statement_begin__ = 288;
            return stan::math::promote_scalar<fun_return_scalar_t__>(inv_logit(eta));
        } else if (as_bool(logical_eq(link,2))) {
            current_statement_begin__ = 289;
            return stan::math::promote_scalar<fun_return_scalar_t__>(Phi(eta));
        } else if (as_bool(logical_eq(link,3))) {
            current_statement_begin__ = 290;
            return stan::math::promote_scalar<fun_return_scalar_t__>(add(divide(atan(eta),stan::math::pi()),0.5));
        } else if (as_bool(logical_eq(link,4))) {
            current_statement_begin__ = 291;
            return stan::math::promote_scalar<fun_return_scalar_t__>(exp(eta));
        } else if (as_bool(logical_eq(link,5))) {
            current_statement_begin__ = 292;
            return stan::math::promote_scalar<fun_return_scalar_t__>(inv_cloglog(eta));
        } else {
            current_statement_begin__ = 293;
            std::stringstream errmsg_stream__;
            errmsg_stream__ << "Invalid link";
            throw std::domain_error(errmsg_stream__.str());
        }
        current_statement_begin__ = 293;
        current_statement_begin__ = 294;
        return stan::math::promote_scalar<fun_return_scalar_t__>(eta);
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct linkinv_bern_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                 const int& link, std::ostream* pstream__) const {
        return linkinv_bern(eta, link, pstream__);
    }
};

template <typename T0__, typename T1__, typename T_lp__, typename T_lp_accum__>
typename boost::math::tools::promote_args<T0__, T1__, T_lp__>::type
ll_bern_lp(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta0,
               const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta1,
               const int& link,
               const std::vector<int>& N, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T_lp__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 307;
        if (as_bool(logical_eq(link,1))) {

            current_statement_begin__ = 308;
            lp_accum__.add(logistic_ccdf_log(eta0,0,1));
            current_statement_begin__ = 309;
            lp_accum__.add(logistic_cdf_log(eta1,0,1));
        } else if (as_bool(logical_eq(link,2))) {

            current_statement_begin__ = 312;
            lp_accum__.add(normal_ccdf_log(eta0,0,1));
            current_statement_begin__ = 313;
            lp_accum__.add(normal_cdf_log(eta1,0,1));
        } else if (as_bool(logical_eq(link,3))) {

            current_statement_begin__ = 316;
            lp_accum__.add(cauchy_ccdf_log(eta0,0,1));
            current_statement_begin__ = 317;
            lp_accum__.add(cauchy_cdf_log(eta1,0,1));
        } else if (as_bool(logical_eq(link,4))) {

            current_statement_begin__ = 320;
            lp_accum__.add(log1m_exp(eta0));
            current_statement_begin__ = 321;
            lp_accum__.add(eta1);
        } else if (as_bool(logical_eq(link,5))) {

            current_statement_begin__ = 324;
            lp_accum__.add(log1m_exp(minus(exp(eta1))));
            current_statement_begin__ = 325;
            lp_accum__.add(minus(exp(eta0)));
        } else {
            current_statement_begin__ = 327;
            std::stringstream errmsg_stream__;
            errmsg_stream__ << "Invalid link";
            throw std::domain_error(errmsg_stream__.str());
        }
        current_statement_begin__ = 327;
        current_statement_begin__ = 328;
        return stan::math::promote_scalar<fun_return_scalar_t__>(get_lp(lp__, lp_accum__));
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct ll_bern_lp_functor__ {
    template <typename T0__, typename T1__, typename T_lp__, typename T_lp_accum__>
        typename boost::math::tools::promote_args<T0__, T1__, T_lp__>::type
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta0,
               const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta1,
               const int& link,
               const std::vector<int>& N, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) const {
        return ll_bern_lp(eta0, eta1, link, N, lp__, lp_accum__, pstream__);
    }
};

template <typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T1__>::type, Eigen::Dynamic,1>
pw_bern(const int& y,
            const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
            const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T1__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            int N(0);
            (void) N;  // dummy to suppress unused var warning

            stan::math::fill(N, std::numeric_limits<int>::min());
            stan::math::assign(N,rows(eta));
            validate_non_negative_index("ll", "N", N);
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  ll(static_cast<Eigen::VectorXd::Index>(N));
            (void) ll;  // dummy to suppress unused var warning

            stan::math::initialize(ll, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(ll,DUMMY_VAR__);


            current_statement_begin__ = 343;
            if (as_bool(logical_eq(link,1))) {

                current_statement_begin__ = 344;
                for (int n = 1; n <= N; ++n) {
                    current_statement_begin__ = 344;
                    stan::math::assign(get_base1_lhs(ll,n,"ll",1), bernoulli_logit_log(y,get_base1(eta,n,"eta",1)));
                }
            } else if (as_bool(logical_lte(link,5))) {
                {
                    validate_non_negative_index("pi", "N", N);
                    Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  pi(static_cast<Eigen::VectorXd::Index>(N));
                    (void) pi;  // dummy to suppress unused var warning

                    stan::math::initialize(pi, std::numeric_limits<double>::quiet_NaN());
                    stan::math::fill(pi,DUMMY_VAR__);
                    stan::math::assign(pi,linkinv_bern(eta,link, pstream__));


                    current_statement_begin__ = 348;
                    for (int n = 1; n <= N; ++n) {
                        current_statement_begin__ = 348;
                        stan::math::assign(get_base1_lhs(ll,n,"ll",1), bernoulli_log(y,get_base1(pi,n,"pi",1)));
                    }
                }
            } else {
                current_statement_begin__ = 350;
                std::stringstream errmsg_stream__;
                errmsg_stream__ << "Invalid link";
                throw std::domain_error(errmsg_stream__.str());
            }
            current_statement_begin__ = 350;
            current_statement_begin__ = 351;
            return stan::math::promote_scalar<fun_return_scalar_t__>(ll);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct pw_bern_functor__ {
    template <typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T1__>::type, Eigen::Dynamic,1>
    operator()(const int& y,
            const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
            const int& link, std::ostream* pstream__) const {
        return pw_bern(y, eta, link, pstream__);
    }
};

class model_bernoulli : public prob_grad {
private:
    int K;
    vector<int> N;
    vector_d xbar;
    int dense_X;
    vector<matrix_d> X0;
    vector<matrix_d> X1;
    int nnz_X0;
    vector_d w_X0;
    vector<int> v_X0;
    vector<int> u_X0;
    int nnz_X1;
    vector_d w_X1;
    vector<int> v_X1;
    vector<int> u_X1;
    int K_smooth;
    matrix_d S0;
    matrix_d S1;
    vector<int> smooth_map;
    int prior_PD;
    int has_intercept;
    int family;
    int link;
    int prior_dist;
    int prior_dist_for_intercept;
    int prior_dist_for_aux;
    int prior_dist_for_smooth;
    int has_weights;
    vector_d weights0;
    vector_d weights1;
    int has_offset;
    vector_d offset0;
    vector_d offset1;
    vector_d prior_scale;
    double prior_scale_for_intercept;
    double prior_scale_for_aux;
    vector_d prior_scale_for_smooth;
    vector_d prior_mean;
    double prior_mean_for_intercept;
    double prior_mean_for_aux;
    vector_d prior_mean_for_smooth;
    vector_d prior_df;
    double prior_df_for_intercept;
    double prior_df_for_aux;
    vector_d prior_df_for_smooth;
    double global_prior_df;
    double global_prior_scale;
    vector<int> num_normals;
    int t;
    vector<int> p;
    vector<int> l;
    int q;
    int len_theta_L;
    vector_d shape;
    vector_d scale;
    int len_concentration;
    vector<double> concentration;
    int len_regularization;
    vector<double> regularization;
    vector<int> num_non_zero;
    vector_d w0;
    vector_d w1;
    vector<int> v0;
    vector<int> v1;
    vector<int> u0;
    vector<int> u1;
    int special_case;
    int NN;
    double aux;
    vector<vector<int> > V0;
    vector<vector<int> > V1;
    int len_z_T;
    int len_var_group;
    int len_rho;
    int is_continuous;
    int pos;
    vector<double> delta;
    int hs;
public:
    model_bernoulli(stan::io::var_context& context__,
        std::ostream* pstream__ = 0)
        : prob_grad(0) {
        ctor_body(context__, 0, pstream__);
    }

    model_bernoulli(stan::io::var_context& context__,
        unsigned int random_seed__,
        std::ostream* pstream__ = 0)
        : prob_grad(0) {
        ctor_body(context__, random_seed__, pstream__);
    }

    void ctor_body(stan::io::var_context& context__,
                   unsigned int random_seed__,
                   std::ostream* pstream__) {
        boost::ecuyer1988 base_rng__ =
          stan::services::util::create_rng(random_seed__, 0);
        (void) base_rng__;  // suppress unused var warning

        current_statement_begin__ = -1;

        static const char* function__ = "model_bernoulli_namespace::model_bernoulli";
        (void) function__;  // dummy to suppress unused var warning
        size_t pos__;
        (void) pos__;  // dummy to suppress unused var warning
        std::vector<int> vals_i__;
        std::vector<double> vals_r__;
        double DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

        // initialize member variables
        context__.validate_dims("data initialization", "K", "int", context__.to_vec());
        K = int(0);
        vals_i__ = context__.vals_i("K");
        pos__ = 0;
        K = vals_i__[pos__++];
        validate_non_negative_index("N", "2", 2);
        context__.validate_dims("data initialization", "N", "int", context__.to_vec(2));
        validate_non_negative_index("N", "2", 2);
        N = std::vector<int>(2,int(0));
        vals_i__ = context__.vals_i("N");
        pos__ = 0;
        size_t N_limit_0__ = 2;
        for (size_t i_0__ = 0; i_0__ < N_limit_0__; ++i_0__) {
            N[i_0__] = vals_i__[pos__++];
        }
        validate_non_negative_index("xbar", "K", K);
        context__.validate_dims("data initialization", "xbar", "vector_d", context__.to_vec(K));
        validate_non_negative_index("xbar", "K", K);
        xbar = vector_d(static_cast<Eigen::VectorXd::Index>(K));
        vals_r__ = context__.vals_r("xbar");
        pos__ = 0;
        size_t xbar_i_vec_lim__ = K;
        for (size_t i_vec__ = 0; i_vec__ < xbar_i_vec_lim__; ++i_vec__) {
            xbar[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "dense_X", "int", context__.to_vec());
        dense_X = int(0);
        vals_i__ = context__.vals_i("dense_X");
        pos__ = 0;
        dense_X = vals_i__[pos__++];
        validate_non_negative_index("X0", "dense_X", dense_X);
        validate_non_negative_index("X0", "get_base1(N,1,\"N\",1)", get_base1(N,1,"N",1));
        validate_non_negative_index("X0", "K", K);
        context__.validate_dims("data initialization", "X0", "matrix_d", context__.to_vec(dense_X,get_base1(N,1,"N",1),K));
        validate_non_negative_index("X0", "dense_X", dense_X);
        validate_non_negative_index("X0", "get_base1(N,1,\"N\",1)", get_base1(N,1,"N",1));
        validate_non_negative_index("X0", "K", K);
        X0 = std::vector<matrix_d>(dense_X,matrix_d(static_cast<Eigen::VectorXd::Index>(get_base1(N,1,"N",1)),static_cast<Eigen::VectorXd::Index>(K)));
        vals_r__ = context__.vals_r("X0");
        pos__ = 0;
        size_t X0_m_mat_lim__ = get_base1(N,1,"N",1);
        size_t X0_n_mat_lim__ = K;
        for (size_t n_mat__ = 0; n_mat__ < X0_n_mat_lim__; ++n_mat__) {
            for (size_t m_mat__ = 0; m_mat__ < X0_m_mat_lim__; ++m_mat__) {
                size_t X0_limit_0__ = dense_X;
                for (size_t i_0__ = 0; i_0__ < X0_limit_0__; ++i_0__) {
                    X0[i_0__](m_mat__,n_mat__) = vals_r__[pos__++];
            }
            }
        }
        validate_non_negative_index("X1", "dense_X", dense_X);
        validate_non_negative_index("X1", "get_base1(N,2,\"N\",1)", get_base1(N,2,"N",1));
        validate_non_negative_index("X1", "K", K);
        context__.validate_dims("data initialization", "X1", "matrix_d", context__.to_vec(dense_X,get_base1(N,2,"N",1),K));
        validate_non_negative_index("X1", "dense_X", dense_X);
        validate_non_negative_index("X1", "get_base1(N,2,\"N\",1)", get_base1(N,2,"N",1));
        validate_non_negative_index("X1", "K", K);
        X1 = std::vector<matrix_d>(dense_X,matrix_d(static_cast<Eigen::VectorXd::Index>(get_base1(N,2,"N",1)),static_cast<Eigen::VectorXd::Index>(K)));
        vals_r__ = context__.vals_r("X1");
        pos__ = 0;
        size_t X1_m_mat_lim__ = get_base1(N,2,"N",1);
        size_t X1_n_mat_lim__ = K;
        for (size_t n_mat__ = 0; n_mat__ < X1_n_mat_lim__; ++n_mat__) {
            for (size_t m_mat__ = 0; m_mat__ < X1_m_mat_lim__; ++m_mat__) {
                size_t X1_limit_0__ = dense_X;
                for (size_t i_0__ = 0; i_0__ < X1_limit_0__; ++i_0__) {
                    X1[i_0__](m_mat__,n_mat__) = vals_r__[pos__++];
            }
            }
        }
        context__.validate_dims("data initialization", "nnz_X0", "int", context__.to_vec());
        nnz_X0 = int(0);
        vals_i__ = context__.vals_i("nnz_X0");
        pos__ = 0;
        nnz_X0 = vals_i__[pos__++];
        validate_non_negative_index("w_X0", "nnz_X0", nnz_X0);
        context__.validate_dims("data initialization", "w_X0", "vector_d", context__.to_vec(nnz_X0));
        validate_non_negative_index("w_X0", "nnz_X0", nnz_X0);
        w_X0 = vector_d(static_cast<Eigen::VectorXd::Index>(nnz_X0));
        vals_r__ = context__.vals_r("w_X0");
        pos__ = 0;
        size_t w_X0_i_vec_lim__ = nnz_X0;
        for (size_t i_vec__ = 0; i_vec__ < w_X0_i_vec_lim__; ++i_vec__) {
            w_X0[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("v_X0", "nnz_X0", nnz_X0);
        context__.validate_dims("data initialization", "v_X0", "int", context__.to_vec(nnz_X0));
        validate_non_negative_index("v_X0", "nnz_X0", nnz_X0);
        v_X0 = std::vector<int>(nnz_X0,int(0));
        vals_i__ = context__.vals_i("v_X0");
        pos__ = 0;
        size_t v_X0_limit_0__ = nnz_X0;
        for (size_t i_0__ = 0; i_0__ < v_X0_limit_0__; ++i_0__) {
            v_X0[i_0__] = vals_i__[pos__++];
        }
        validate_non_negative_index("u_X0", "(dense_X ? 0 : (get_base1(N,1,\"N\",1) + 1) )", (dense_X ? 0 : (get_base1(N,1,"N",1) + 1) ));
        context__.validate_dims("data initialization", "u_X0", "int", context__.to_vec((dense_X ? 0 : (get_base1(N,1,"N",1) + 1) )));
        validate_non_negative_index("u_X0", "(dense_X ? 0 : (get_base1(N,1,\"N\",1) + 1) )", (dense_X ? 0 : (get_base1(N,1,"N",1) + 1) ));
        u_X0 = std::vector<int>((dense_X ? 0 : (get_base1(N,1,"N",1) + 1) ),int(0));
        vals_i__ = context__.vals_i("u_X0");
        pos__ = 0;
        size_t u_X0_limit_0__ = (dense_X ? 0 : (get_base1(N,1,"N",1) + 1) );
        for (size_t i_0__ = 0; i_0__ < u_X0_limit_0__; ++i_0__) {
            u_X0[i_0__] = vals_i__[pos__++];
        }
        context__.validate_dims("data initialization", "nnz_X1", "int", context__.to_vec());
        nnz_X1 = int(0);
        vals_i__ = context__.vals_i("nnz_X1");
        pos__ = 0;
        nnz_X1 = vals_i__[pos__++];
        validate_non_negative_index("w_X1", "nnz_X1", nnz_X1);
        context__.validate_dims("data initialization", "w_X1", "vector_d", context__.to_vec(nnz_X1));
        validate_non_negative_index("w_X1", "nnz_X1", nnz_X1);
        w_X1 = vector_d(static_cast<Eigen::VectorXd::Index>(nnz_X1));
        vals_r__ = context__.vals_r("w_X1");
        pos__ = 0;
        size_t w_X1_i_vec_lim__ = nnz_X1;
        for (size_t i_vec__ = 0; i_vec__ < w_X1_i_vec_lim__; ++i_vec__) {
            w_X1[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("v_X1", "nnz_X1", nnz_X1);
        context__.validate_dims("data initialization", "v_X1", "int", context__.to_vec(nnz_X1));
        validate_non_negative_index("v_X1", "nnz_X1", nnz_X1);
        v_X1 = std::vector<int>(nnz_X1,int(0));
        vals_i__ = context__.vals_i("v_X1");
        pos__ = 0;
        size_t v_X1_limit_0__ = nnz_X1;
        for (size_t i_0__ = 0; i_0__ < v_X1_limit_0__; ++i_0__) {
            v_X1[i_0__] = vals_i__[pos__++];
        }
        validate_non_negative_index("u_X1", "(dense_X ? 0 : (get_base1(N,2,\"N\",1) + 1) )", (dense_X ? 0 : (get_base1(N,2,"N",1) + 1) ));
        context__.validate_dims("data initialization", "u_X1", "int", context__.to_vec((dense_X ? 0 : (get_base1(N,2,"N",1) + 1) )));
        validate_non_negative_index("u_X1", "(dense_X ? 0 : (get_base1(N,2,\"N\",1) + 1) )", (dense_X ? 0 : (get_base1(N,2,"N",1) + 1) ));
        u_X1 = std::vector<int>((dense_X ? 0 : (get_base1(N,2,"N",1) + 1) ),int(0));
        vals_i__ = context__.vals_i("u_X1");
        pos__ = 0;
        size_t u_X1_limit_0__ = (dense_X ? 0 : (get_base1(N,2,"N",1) + 1) );
        for (size_t i_0__ = 0; i_0__ < u_X1_limit_0__; ++i_0__) {
            u_X1[i_0__] = vals_i__[pos__++];
        }
        context__.validate_dims("data initialization", "K_smooth", "int", context__.to_vec());
        K_smooth = int(0);
        vals_i__ = context__.vals_i("K_smooth");
        pos__ = 0;
        K_smooth = vals_i__[pos__++];
        validate_non_negative_index("S0", "get_base1(N,1,\"N\",1)", get_base1(N,1,"N",1));
        validate_non_negative_index("S0", "K_smooth", K_smooth);
        context__.validate_dims("data initialization", "S0", "matrix_d", context__.to_vec(get_base1(N,1,"N",1),K_smooth));
        validate_non_negative_index("S0", "get_base1(N,1,\"N\",1)", get_base1(N,1,"N",1));
        validate_non_negative_index("S0", "K_smooth", K_smooth);
        S0 = matrix_d(static_cast<Eigen::VectorXd::Index>(get_base1(N,1,"N",1)),static_cast<Eigen::VectorXd::Index>(K_smooth));
        vals_r__ = context__.vals_r("S0");
        pos__ = 0;
        size_t S0_m_mat_lim__ = get_base1(N,1,"N",1);
        size_t S0_n_mat_lim__ = K_smooth;
        for (size_t n_mat__ = 0; n_mat__ < S0_n_mat_lim__; ++n_mat__) {
            for (size_t m_mat__ = 0; m_mat__ < S0_m_mat_lim__; ++m_mat__) {
                S0(m_mat__,n_mat__) = vals_r__[pos__++];
            }
        }
        validate_non_negative_index("S1", "get_base1(N,2,\"N\",1)", get_base1(N,2,"N",1));
        validate_non_negative_index("S1", "K_smooth", K_smooth);
        context__.validate_dims("data initialization", "S1", "matrix_d", context__.to_vec(get_base1(N,2,"N",1),K_smooth));
        validate_non_negative_index("S1", "get_base1(N,2,\"N\",1)", get_base1(N,2,"N",1));
        validate_non_negative_index("S1", "K_smooth", K_smooth);
        S1 = matrix_d(static_cast<Eigen::VectorXd::Index>(get_base1(N,2,"N",1)),static_cast<Eigen::VectorXd::Index>(K_smooth));
        vals_r__ = context__.vals_r("S1");
        pos__ = 0;
        size_t S1_m_mat_lim__ = get_base1(N,2,"N",1);
        size_t S1_n_mat_lim__ = K_smooth;
        for (size_t n_mat__ = 0; n_mat__ < S1_n_mat_lim__; ++n_mat__) {
            for (size_t m_mat__ = 0; m_mat__ < S1_m_mat_lim__; ++m_mat__) {
                S1(m_mat__,n_mat__) = vals_r__[pos__++];
            }
        }
        validate_non_negative_index("smooth_map", "K_smooth", K_smooth);
        context__.validate_dims("data initialization", "smooth_map", "int", context__.to_vec(K_smooth));
        validate_non_negative_index("smooth_map", "K_smooth", K_smooth);
        smooth_map = std::vector<int>(K_smooth,int(0));
        vals_i__ = context__.vals_i("smooth_map");
        pos__ = 0;
        size_t smooth_map_limit_0__ = K_smooth;
        for (size_t i_0__ = 0; i_0__ < smooth_map_limit_0__; ++i_0__) {
            smooth_map[i_0__] = vals_i__[pos__++];
        }
        context__.validate_dims("data initialization", "prior_PD", "int", context__.to_vec());
        prior_PD = int(0);
        vals_i__ = context__.vals_i("prior_PD");
        pos__ = 0;
        prior_PD = vals_i__[pos__++];
        context__.validate_dims("data initialization", "has_intercept", "int", context__.to_vec());
        has_intercept = int(0);
        vals_i__ = context__.vals_i("has_intercept");
        pos__ = 0;
        has_intercept = vals_i__[pos__++];
        context__.validate_dims("data initialization", "family", "int", context__.to_vec());
        family = int(0);
        vals_i__ = context__.vals_i("family");
        pos__ = 0;
        family = vals_i__[pos__++];
        context__.validate_dims("data initialization", "link", "int", context__.to_vec());
        link = int(0);
        vals_i__ = context__.vals_i("link");
        pos__ = 0;
        link = vals_i__[pos__++];
        context__.validate_dims("data initialization", "prior_dist", "int", context__.to_vec());
        prior_dist = int(0);
        vals_i__ = context__.vals_i("prior_dist");
        pos__ = 0;
        prior_dist = vals_i__[pos__++];
        context__.validate_dims("data initialization", "prior_dist_for_intercept", "int", context__.to_vec());
        prior_dist_for_intercept = int(0);
        vals_i__ = context__.vals_i("prior_dist_for_intercept");
        pos__ = 0;
        prior_dist_for_intercept = vals_i__[pos__++];
        context__.validate_dims("data initialization", "prior_dist_for_aux", "int", context__.to_vec());
        prior_dist_for_aux = int(0);
        vals_i__ = context__.vals_i("prior_dist_for_aux");
        pos__ = 0;
        prior_dist_for_aux = vals_i__[pos__++];
        context__.validate_dims("data initialization", "prior_dist_for_smooth", "int", context__.to_vec());
        prior_dist_for_smooth = int(0);
        vals_i__ = context__.vals_i("prior_dist_for_smooth");
        pos__ = 0;
        prior_dist_for_smooth = vals_i__[pos__++];
        context__.validate_dims("data initialization", "has_weights", "int", context__.to_vec());
        has_weights = int(0);
        vals_i__ = context__.vals_i("has_weights");
        pos__ = 0;
        has_weights = vals_i__[pos__++];
        validate_non_negative_index("weights0", "(has_weights ? get_base1(N,1,\"N\",1) : 0 )", (has_weights ? get_base1(N,1,"N",1) : 0 ));
        context__.validate_dims("data initialization", "weights0", "vector_d", context__.to_vec((has_weights ? get_base1(N,1,"N",1) : 0 )));
        validate_non_negative_index("weights0", "(has_weights ? get_base1(N,1,\"N\",1) : 0 )", (has_weights ? get_base1(N,1,"N",1) : 0 ));
        weights0 = vector_d(static_cast<Eigen::VectorXd::Index>((has_weights ? get_base1(N,1,"N",1) : 0 )));
        vals_r__ = context__.vals_r("weights0");
        pos__ = 0;
        size_t weights0_i_vec_lim__ = (has_weights ? get_base1(N,1,"N",1) : 0 );
        for (size_t i_vec__ = 0; i_vec__ < weights0_i_vec_lim__; ++i_vec__) {
            weights0[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("weights1", "(has_weights ? get_base1(N,2,\"N\",1) : 0 )", (has_weights ? get_base1(N,2,"N",1) : 0 ));
        context__.validate_dims("data initialization", "weights1", "vector_d", context__.to_vec((has_weights ? get_base1(N,2,"N",1) : 0 )));
        validate_non_negative_index("weights1", "(has_weights ? get_base1(N,2,\"N\",1) : 0 )", (has_weights ? get_base1(N,2,"N",1) : 0 ));
        weights1 = vector_d(static_cast<Eigen::VectorXd::Index>((has_weights ? get_base1(N,2,"N",1) : 0 )));
        vals_r__ = context__.vals_r("weights1");
        pos__ = 0;
        size_t weights1_i_vec_lim__ = (has_weights ? get_base1(N,2,"N",1) : 0 );
        for (size_t i_vec__ = 0; i_vec__ < weights1_i_vec_lim__; ++i_vec__) {
            weights1[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "has_offset", "int", context__.to_vec());
        has_offset = int(0);
        vals_i__ = context__.vals_i("has_offset");
        pos__ = 0;
        has_offset = vals_i__[pos__++];
        validate_non_negative_index("offset0", "(has_offset ? get_base1(N,1,\"N\",1) : 0 )", (has_offset ? get_base1(N,1,"N",1) : 0 ));
        context__.validate_dims("data initialization", "offset0", "vector_d", context__.to_vec((has_offset ? get_base1(N,1,"N",1) : 0 )));
        validate_non_negative_index("offset0", "(has_offset ? get_base1(N,1,\"N\",1) : 0 )", (has_offset ? get_base1(N,1,"N",1) : 0 ));
        offset0 = vector_d(static_cast<Eigen::VectorXd::Index>((has_offset ? get_base1(N,1,"N",1) : 0 )));
        vals_r__ = context__.vals_r("offset0");
        pos__ = 0;
        size_t offset0_i_vec_lim__ = (has_offset ? get_base1(N,1,"N",1) : 0 );
        for (size_t i_vec__ = 0; i_vec__ < offset0_i_vec_lim__; ++i_vec__) {
            offset0[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("offset1", "(has_offset ? get_base1(N,2,\"N\",1) : 0 )", (has_offset ? get_base1(N,2,"N",1) : 0 ));
        context__.validate_dims("data initialization", "offset1", "vector_d", context__.to_vec((has_offset ? get_base1(N,2,"N",1) : 0 )));
        validate_non_negative_index("offset1", "(has_offset ? get_base1(N,2,\"N\",1) : 0 )", (has_offset ? get_base1(N,2,"N",1) : 0 ));
        offset1 = vector_d(static_cast<Eigen::VectorXd::Index>((has_offset ? get_base1(N,2,"N",1) : 0 )));
        vals_r__ = context__.vals_r("offset1");
        pos__ = 0;
        size_t offset1_i_vec_lim__ = (has_offset ? get_base1(N,2,"N",1) : 0 );
        for (size_t i_vec__ = 0; i_vec__ < offset1_i_vec_lim__; ++i_vec__) {
            offset1[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("prior_scale", "K", K);
        context__.validate_dims("data initialization", "prior_scale", "vector_d", context__.to_vec(K));
        validate_non_negative_index("prior_scale", "K", K);
        prior_scale = vector_d(static_cast<Eigen::VectorXd::Index>(K));
        vals_r__ = context__.vals_r("prior_scale");
        pos__ = 0;
        size_t prior_scale_i_vec_lim__ = K;
        for (size_t i_vec__ = 0; i_vec__ < prior_scale_i_vec_lim__; ++i_vec__) {
            prior_scale[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "prior_scale_for_intercept", "double", context__.to_vec());
        prior_scale_for_intercept = double(0);
        vals_r__ = context__.vals_r("prior_scale_for_intercept");
        pos__ = 0;
        prior_scale_for_intercept = vals_r__[pos__++];
        context__.validate_dims("data initialization", "prior_scale_for_aux", "double", context__.to_vec());
        prior_scale_for_aux = double(0);
        vals_r__ = context__.vals_r("prior_scale_for_aux");
        pos__ = 0;
        prior_scale_for_aux = vals_r__[pos__++];
        validate_non_negative_index("prior_scale_for_smooth", "(logical_gt(K_smooth,0) ? max(smooth_map) : 0 )", (logical_gt(K_smooth,0) ? max(smooth_map) : 0 ));
        context__.validate_dims("data initialization", "prior_scale_for_smooth", "vector_d", context__.to_vec((logical_gt(K_smooth,0) ? max(smooth_map) : 0 )));
        validate_non_negative_index("prior_scale_for_smooth", "(logical_gt(K_smooth,0) ? max(smooth_map) : 0 )", (logical_gt(K_smooth,0) ? max(smooth_map) : 0 ));
        prior_scale_for_smooth = vector_d(static_cast<Eigen::VectorXd::Index>((logical_gt(K_smooth,0) ? max(smooth_map) : 0 )));
        vals_r__ = context__.vals_r("prior_scale_for_smooth");
        pos__ = 0;
        size_t prior_scale_for_smooth_i_vec_lim__ = (logical_gt(K_smooth,0) ? max(smooth_map) : 0 );
        for (size_t i_vec__ = 0; i_vec__ < prior_scale_for_smooth_i_vec_lim__; ++i_vec__) {
            prior_scale_for_smooth[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("prior_mean", "K", K);
        context__.validate_dims("data initialization", "prior_mean", "vector_d", context__.to_vec(K));
        validate_non_negative_index("prior_mean", "K", K);
        prior_mean = vector_d(static_cast<Eigen::VectorXd::Index>(K));
        vals_r__ = context__.vals_r("prior_mean");
        pos__ = 0;
        size_t prior_mean_i_vec_lim__ = K;
        for (size_t i_vec__ = 0; i_vec__ < prior_mean_i_vec_lim__; ++i_vec__) {
            prior_mean[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "prior_mean_for_intercept", "double", context__.to_vec());
        prior_mean_for_intercept = double(0);
        vals_r__ = context__.vals_r("prior_mean_for_intercept");
        pos__ = 0;
        prior_mean_for_intercept = vals_r__[pos__++];
        context__.validate_dims("data initialization", "prior_mean_for_aux", "double", context__.to_vec());
        prior_mean_for_aux = double(0);
        vals_r__ = context__.vals_r("prior_mean_for_aux");
        pos__ = 0;
        prior_mean_for_aux = vals_r__[pos__++];
        validate_non_negative_index("prior_mean_for_smooth", "(logical_gt(K_smooth,0) ? max(smooth_map) : 0 )", (logical_gt(K_smooth,0) ? max(smooth_map) : 0 ));
        context__.validate_dims("data initialization", "prior_mean_for_smooth", "vector_d", context__.to_vec((logical_gt(K_smooth,0) ? max(smooth_map) : 0 )));
        validate_non_negative_index("prior_mean_for_smooth", "(logical_gt(K_smooth,0) ? max(smooth_map) : 0 )", (logical_gt(K_smooth,0) ? max(smooth_map) : 0 ));
        prior_mean_for_smooth = vector_d(static_cast<Eigen::VectorXd::Index>((logical_gt(K_smooth,0) ? max(smooth_map) : 0 )));
        vals_r__ = context__.vals_r("prior_mean_for_smooth");
        pos__ = 0;
        size_t prior_mean_for_smooth_i_vec_lim__ = (logical_gt(K_smooth,0) ? max(smooth_map) : 0 );
        for (size_t i_vec__ = 0; i_vec__ < prior_mean_for_smooth_i_vec_lim__; ++i_vec__) {
            prior_mean_for_smooth[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("prior_df", "K", K);
        context__.validate_dims("data initialization", "prior_df", "vector_d", context__.to_vec(K));
        validate_non_negative_index("prior_df", "K", K);
        prior_df = vector_d(static_cast<Eigen::VectorXd::Index>(K));
        vals_r__ = context__.vals_r("prior_df");
        pos__ = 0;
        size_t prior_df_i_vec_lim__ = K;
        for (size_t i_vec__ = 0; i_vec__ < prior_df_i_vec_lim__; ++i_vec__) {
            prior_df[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "prior_df_for_intercept", "double", context__.to_vec());
        prior_df_for_intercept = double(0);
        vals_r__ = context__.vals_r("prior_df_for_intercept");
        pos__ = 0;
        prior_df_for_intercept = vals_r__[pos__++];
        context__.validate_dims("data initialization", "prior_df_for_aux", "double", context__.to_vec());
        prior_df_for_aux = double(0);
        vals_r__ = context__.vals_r("prior_df_for_aux");
        pos__ = 0;
        prior_df_for_aux = vals_r__[pos__++];
        validate_non_negative_index("prior_df_for_smooth", "(logical_gt(K_smooth,0) ? max(smooth_map) : 0 )", (logical_gt(K_smooth,0) ? max(smooth_map) : 0 ));
        context__.validate_dims("data initialization", "prior_df_for_smooth", "vector_d", context__.to_vec((logical_gt(K_smooth,0) ? max(smooth_map) : 0 )));
        validate_non_negative_index("prior_df_for_smooth", "(logical_gt(K_smooth,0) ? max(smooth_map) : 0 )", (logical_gt(K_smooth,0) ? max(smooth_map) : 0 ));
        prior_df_for_smooth = vector_d(static_cast<Eigen::VectorXd::Index>((logical_gt(K_smooth,0) ? max(smooth_map) : 0 )));
        vals_r__ = context__.vals_r("prior_df_for_smooth");
        pos__ = 0;
        size_t prior_df_for_smooth_i_vec_lim__ = (logical_gt(K_smooth,0) ? max(smooth_map) : 0 );
        for (size_t i_vec__ = 0; i_vec__ < prior_df_for_smooth_i_vec_lim__; ++i_vec__) {
            prior_df_for_smooth[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "global_prior_df", "double", context__.to_vec());
        global_prior_df = double(0);
        vals_r__ = context__.vals_r("global_prior_df");
        pos__ = 0;
        global_prior_df = vals_r__[pos__++];
        context__.validate_dims("data initialization", "global_prior_scale", "double", context__.to_vec());
        global_prior_scale = double(0);
        vals_r__ = context__.vals_r("global_prior_scale");
        pos__ = 0;
        global_prior_scale = vals_r__[pos__++];
        validate_non_negative_index("num_normals", "(logical_eq(prior_dist,7) ? K : 0 )", (logical_eq(prior_dist,7) ? K : 0 ));
        context__.validate_dims("data initialization", "num_normals", "int", context__.to_vec((logical_eq(prior_dist,7) ? K : 0 )));
        validate_non_negative_index("num_normals", "(logical_eq(prior_dist,7) ? K : 0 )", (logical_eq(prior_dist,7) ? K : 0 ));
        num_normals = std::vector<int>((logical_eq(prior_dist,7) ? K : 0 ),int(0));
        vals_i__ = context__.vals_i("num_normals");
        pos__ = 0;
        size_t num_normals_limit_0__ = (logical_eq(prior_dist,7) ? K : 0 );
        for (size_t i_0__ = 0; i_0__ < num_normals_limit_0__; ++i_0__) {
            num_normals[i_0__] = vals_i__[pos__++];
        }
        context__.validate_dims("data initialization", "t", "int", context__.to_vec());
        t = int(0);
        vals_i__ = context__.vals_i("t");
        pos__ = 0;
        t = vals_i__[pos__++];
        validate_non_negative_index("p", "t", t);
        context__.validate_dims("data initialization", "p", "int", context__.to_vec(t));
        validate_non_negative_index("p", "t", t);
        p = std::vector<int>(t,int(0));
        vals_i__ = context__.vals_i("p");
        pos__ = 0;
        size_t p_limit_0__ = t;
        for (size_t i_0__ = 0; i_0__ < p_limit_0__; ++i_0__) {
            p[i_0__] = vals_i__[pos__++];
        }
        validate_non_negative_index("l", "t", t);
        context__.validate_dims("data initialization", "l", "int", context__.to_vec(t));
        validate_non_negative_index("l", "t", t);
        l = std::vector<int>(t,int(0));
        vals_i__ = context__.vals_i("l");
        pos__ = 0;
        size_t l_limit_0__ = t;
        for (size_t i_0__ = 0; i_0__ < l_limit_0__; ++i_0__) {
            l[i_0__] = vals_i__[pos__++];
        }
        context__.validate_dims("data initialization", "q", "int", context__.to_vec());
        q = int(0);
        vals_i__ = context__.vals_i("q");
        pos__ = 0;
        q = vals_i__[pos__++];
        context__.validate_dims("data initialization", "len_theta_L", "int", context__.to_vec());
        len_theta_L = int(0);
        vals_i__ = context__.vals_i("len_theta_L");
        pos__ = 0;
        len_theta_L = vals_i__[pos__++];
        validate_non_negative_index("shape", "t", t);
        context__.validate_dims("data initialization", "shape", "vector_d", context__.to_vec(t));
        validate_non_negative_index("shape", "t", t);
        shape = vector_d(static_cast<Eigen::VectorXd::Index>(t));
        vals_r__ = context__.vals_r("shape");
        pos__ = 0;
        size_t shape_i_vec_lim__ = t;
        for (size_t i_vec__ = 0; i_vec__ < shape_i_vec_lim__; ++i_vec__) {
            shape[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("scale", "t", t);
        context__.validate_dims("data initialization", "scale", "vector_d", context__.to_vec(t));
        validate_non_negative_index("scale", "t", t);
        scale = vector_d(static_cast<Eigen::VectorXd::Index>(t));
        vals_r__ = context__.vals_r("scale");
        pos__ = 0;
        size_t scale_i_vec_lim__ = t;
        for (size_t i_vec__ = 0; i_vec__ < scale_i_vec_lim__; ++i_vec__) {
            scale[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "len_concentration", "int", context__.to_vec());
        len_concentration = int(0);
        vals_i__ = context__.vals_i("len_concentration");
        pos__ = 0;
        len_concentration = vals_i__[pos__++];
        validate_non_negative_index("concentration", "len_concentration", len_concentration);
        context__.validate_dims("data initialization", "concentration", "double", context__.to_vec(len_concentration));
        validate_non_negative_index("concentration", "len_concentration", len_concentration);
        concentration = std::vector<double>(len_concentration,double(0));
        vals_r__ = context__.vals_r("concentration");
        pos__ = 0;
        size_t concentration_limit_0__ = len_concentration;
        for (size_t i_0__ = 0; i_0__ < concentration_limit_0__; ++i_0__) {
            concentration[i_0__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "len_regularization", "int", context__.to_vec());
        len_regularization = int(0);
        vals_i__ = context__.vals_i("len_regularization");
        pos__ = 0;
        len_regularization = vals_i__[pos__++];
        validate_non_negative_index("regularization", "len_regularization", len_regularization);
        context__.validate_dims("data initialization", "regularization", "double", context__.to_vec(len_regularization));
        validate_non_negative_index("regularization", "len_regularization", len_regularization);
        regularization = std::vector<double>(len_regularization,double(0));
        vals_r__ = context__.vals_r("regularization");
        pos__ = 0;
        size_t regularization_limit_0__ = len_regularization;
        for (size_t i_0__ = 0; i_0__ < regularization_limit_0__; ++i_0__) {
            regularization[i_0__] = vals_r__[pos__++];
        }
        validate_non_negative_index("num_non_zero", "2", 2);
        context__.validate_dims("data initialization", "num_non_zero", "int", context__.to_vec(2));
        validate_non_negative_index("num_non_zero", "2", 2);
        num_non_zero = std::vector<int>(2,int(0));
        vals_i__ = context__.vals_i("num_non_zero");
        pos__ = 0;
        size_t num_non_zero_limit_0__ = 2;
        for (size_t i_0__ = 0; i_0__ < num_non_zero_limit_0__; ++i_0__) {
            num_non_zero[i_0__] = vals_i__[pos__++];
        }
        validate_non_negative_index("w0", "get_base1(num_non_zero,1,\"num_non_zero\",1)", get_base1(num_non_zero,1,"num_non_zero",1));
        context__.validate_dims("data initialization", "w0", "vector_d", context__.to_vec(get_base1(num_non_zero,1,"num_non_zero",1)));
        validate_non_negative_index("w0", "get_base1(num_non_zero,1,\"num_non_zero\",1)", get_base1(num_non_zero,1,"num_non_zero",1));
        w0 = vector_d(static_cast<Eigen::VectorXd::Index>(get_base1(num_non_zero,1,"num_non_zero",1)));
        vals_r__ = context__.vals_r("w0");
        pos__ = 0;
        size_t w0_i_vec_lim__ = get_base1(num_non_zero,1,"num_non_zero",1);
        for (size_t i_vec__ = 0; i_vec__ < w0_i_vec_lim__; ++i_vec__) {
            w0[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("w1", "get_base1(num_non_zero,2,\"num_non_zero\",1)", get_base1(num_non_zero,2,"num_non_zero",1));
        context__.validate_dims("data initialization", "w1", "vector_d", context__.to_vec(get_base1(num_non_zero,2,"num_non_zero",1)));
        validate_non_negative_index("w1", "get_base1(num_non_zero,2,\"num_non_zero\",1)", get_base1(num_non_zero,2,"num_non_zero",1));
        w1 = vector_d(static_cast<Eigen::VectorXd::Index>(get_base1(num_non_zero,2,"num_non_zero",1)));
        vals_r__ = context__.vals_r("w1");
        pos__ = 0;
        size_t w1_i_vec_lim__ = get_base1(num_non_zero,2,"num_non_zero",1);
        for (size_t i_vec__ = 0; i_vec__ < w1_i_vec_lim__; ++i_vec__) {
            w1[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("v0", "get_base1(num_non_zero,1,\"num_non_zero\",1)", get_base1(num_non_zero,1,"num_non_zero",1));
        context__.validate_dims("data initialization", "v0", "int", context__.to_vec(get_base1(num_non_zero,1,"num_non_zero",1)));
        validate_non_negative_index("v0", "get_base1(num_non_zero,1,\"num_non_zero\",1)", get_base1(num_non_zero,1,"num_non_zero",1));
        v0 = std::vector<int>(get_base1(num_non_zero,1,"num_non_zero",1),int(0));
        vals_i__ = context__.vals_i("v0");
        pos__ = 0;
        size_t v0_limit_0__ = get_base1(num_non_zero,1,"num_non_zero",1);
        for (size_t i_0__ = 0; i_0__ < v0_limit_0__; ++i_0__) {
            v0[i_0__] = vals_i__[pos__++];
        }
        validate_non_negative_index("v1", "get_base1(num_non_zero,2,\"num_non_zero\",1)", get_base1(num_non_zero,2,"num_non_zero",1));
        context__.validate_dims("data initialization", "v1", "int", context__.to_vec(get_base1(num_non_zero,2,"num_non_zero",1)));
        validate_non_negative_index("v1", "get_base1(num_non_zero,2,\"num_non_zero\",1)", get_base1(num_non_zero,2,"num_non_zero",1));
        v1 = std::vector<int>(get_base1(num_non_zero,2,"num_non_zero",1),int(0));
        vals_i__ = context__.vals_i("v1");
        pos__ = 0;
        size_t v1_limit_0__ = get_base1(num_non_zero,2,"num_non_zero",1);
        for (size_t i_0__ = 0; i_0__ < v1_limit_0__; ++i_0__) {
            v1[i_0__] = vals_i__[pos__++];
        }
        validate_non_negative_index("u0", "(logical_gt(t,0) ? (get_base1(N,1,\"N\",1) + 1) : 0 )", (logical_gt(t,0) ? (get_base1(N,1,"N",1) + 1) : 0 ));
        context__.validate_dims("data initialization", "u0", "int", context__.to_vec((logical_gt(t,0) ? (get_base1(N,1,"N",1) + 1) : 0 )));
        validate_non_negative_index("u0", "(logical_gt(t,0) ? (get_base1(N,1,\"N\",1) + 1) : 0 )", (logical_gt(t,0) ? (get_base1(N,1,"N",1) + 1) : 0 ));
        u0 = std::vector<int>((logical_gt(t,0) ? (get_base1(N,1,"N",1) + 1) : 0 ),int(0));
        vals_i__ = context__.vals_i("u0");
        pos__ = 0;
        size_t u0_limit_0__ = (logical_gt(t,0) ? (get_base1(N,1,"N",1) + 1) : 0 );
        for (size_t i_0__ = 0; i_0__ < u0_limit_0__; ++i_0__) {
            u0[i_0__] = vals_i__[pos__++];
        }
        validate_non_negative_index("u1", "(logical_gt(t,0) ? (get_base1(N,2,\"N\",1) + 1) : 0 )", (logical_gt(t,0) ? (get_base1(N,2,"N",1) + 1) : 0 ));
        context__.validate_dims("data initialization", "u1", "int", context__.to_vec((logical_gt(t,0) ? (get_base1(N,2,"N",1) + 1) : 0 )));
        validate_non_negative_index("u1", "(logical_gt(t,0) ? (get_base1(N,2,\"N\",1) + 1) : 0 )", (logical_gt(t,0) ? (get_base1(N,2,"N",1) + 1) : 0 ));
        u1 = std::vector<int>((logical_gt(t,0) ? (get_base1(N,2,"N",1) + 1) : 0 ),int(0));
        vals_i__ = context__.vals_i("u1");
        pos__ = 0;
        size_t u1_limit_0__ = (logical_gt(t,0) ? (get_base1(N,2,"N",1) + 1) : 0 );
        for (size_t i_0__ = 0; i_0__ < u1_limit_0__; ++i_0__) {
            u1[i_0__] = vals_i__[pos__++];
        }
        context__.validate_dims("data initialization", "special_case", "int", context__.to_vec());
        special_case = int(0);
        vals_i__ = context__.vals_i("special_case");
        pos__ = 0;
        special_case = vals_i__[pos__++];

        // validate, data variables
        check_greater_or_equal(function__,"K",K,0);
        for (int k0__ = 0; k0__ < 2; ++k0__) {
            check_greater_or_equal(function__,"N[k0__]",N[k0__],1);
        }
        check_greater_or_equal(function__,"dense_X",dense_X,0);
        check_less_or_equal(function__,"dense_X",dense_X,1);
        check_greater_or_equal(function__,"nnz_X0",nnz_X0,0);
        for (int k0__ = 0; k0__ < nnz_X0; ++k0__) {
            check_greater_or_equal(function__,"v_X0[k0__]",v_X0[k0__],0);
        }
        for (int k0__ = 0; k0__ < (dense_X ? 0 : (get_base1(N,1,"N",1) + 1) ); ++k0__) {
            check_greater_or_equal(function__,"u_X0[k0__]",u_X0[k0__],0);
        }
        check_greater_or_equal(function__,"nnz_X1",nnz_X1,0);
        for (int k0__ = 0; k0__ < nnz_X1; ++k0__) {
            check_greater_or_equal(function__,"v_X1[k0__]",v_X1[k0__],0);
        }
        for (int k0__ = 0; k0__ < (dense_X ? 0 : (get_base1(N,2,"N",1) + 1) ); ++k0__) {
            check_greater_or_equal(function__,"u_X1[k0__]",u_X1[k0__],0);
        }
        check_greater_or_equal(function__,"K_smooth",K_smooth,0);
        for (int k0__ = 0; k0__ < K_smooth; ++k0__) {
            check_greater_or_equal(function__,"smooth_map[k0__]",smooth_map[k0__],1);
        }
        check_greater_or_equal(function__,"prior_PD",prior_PD,0);
        check_less_or_equal(function__,"prior_PD",prior_PD,1);
        check_greater_or_equal(function__,"has_intercept",has_intercept,0);
        check_less_or_equal(function__,"has_intercept",has_intercept,1);
        check_greater_or_equal(function__,"family",family,1);
        check_greater_or_equal(function__,"link",link,1);
        check_greater_or_equal(function__,"prior_dist",prior_dist,0);
        check_less_or_equal(function__,"prior_dist",prior_dist,7);
        check_greater_or_equal(function__,"prior_dist_for_intercept",prior_dist_for_intercept,0);
        check_less_or_equal(function__,"prior_dist_for_intercept",prior_dist_for_intercept,2);
        check_greater_or_equal(function__,"prior_dist_for_aux",prior_dist_for_aux,0);
        check_less_or_equal(function__,"prior_dist_for_aux",prior_dist_for_aux,3);
        check_greater_or_equal(function__,"prior_dist_for_smooth",prior_dist_for_smooth,0);
        check_less_or_equal(function__,"prior_dist_for_smooth",prior_dist_for_smooth,3);
        check_greater_or_equal(function__,"has_weights",has_weights,0);
        check_less_or_equal(function__,"has_weights",has_weights,1);
        check_greater_or_equal(function__,"has_offset",has_offset,0);
        check_less_or_equal(function__,"has_offset",has_offset,1);
        check_greater_or_equal(function__,"prior_scale",prior_scale,0);
        check_greater_or_equal(function__,"prior_scale_for_intercept",prior_scale_for_intercept,0);
        check_greater_or_equal(function__,"prior_scale_for_aux",prior_scale_for_aux,0);
        check_greater_or_equal(function__,"prior_scale_for_smooth",prior_scale_for_smooth,0);
        check_greater_or_equal(function__,"prior_mean_for_aux",prior_mean_for_aux,0);
        check_greater_or_equal(function__,"prior_mean_for_smooth",prior_mean_for_smooth,0);
        check_greater_or_equal(function__,"prior_df",prior_df,0);
        check_greater_or_equal(function__,"prior_df_for_intercept",prior_df_for_intercept,0);
        check_greater_or_equal(function__,"prior_df_for_aux",prior_df_for_aux,0);
        check_greater_or_equal(function__,"prior_df_for_smooth",prior_df_for_smooth,0);
        check_greater_or_equal(function__,"global_prior_df",global_prior_df,0);
        check_greater_or_equal(function__,"global_prior_scale",global_prior_scale,0);
        for (int k0__ = 0; k0__ < (logical_eq(prior_dist,7) ? K : 0 ); ++k0__) {
            check_greater_or_equal(function__,"num_normals[k0__]",num_normals[k0__],2);
        }
        check_greater_or_equal(function__,"t",t,0);
        for (int k0__ = 0; k0__ < t; ++k0__) {
            check_greater_or_equal(function__,"p[k0__]",p[k0__],1);
        }
        for (int k0__ = 0; k0__ < t; ++k0__) {
            check_greater_or_equal(function__,"l[k0__]",l[k0__],1);
        }
        check_greater_or_equal(function__,"q",q,0);
        check_greater_or_equal(function__,"len_theta_L",len_theta_L,0);
        check_greater_or_equal(function__,"shape",shape,0);
        check_greater_or_equal(function__,"scale",scale,0);
        check_greater_or_equal(function__,"len_concentration",len_concentration,0);
        for (int k0__ = 0; k0__ < len_concentration; ++k0__) {
            check_greater_or_equal(function__,"concentration[k0__]",concentration[k0__],0);
        }
        check_greater_or_equal(function__,"len_regularization",len_regularization,0);
        for (int k0__ = 0; k0__ < len_regularization; ++k0__) {
            check_greater_or_equal(function__,"regularization[k0__]",regularization[k0__],0);
        }
        for (int k0__ = 0; k0__ < 2; ++k0__) {
            check_greater_or_equal(function__,"num_non_zero[k0__]",num_non_zero[k0__],0);
        }
        for (int k0__ = 0; k0__ < get_base1(num_non_zero,1,"num_non_zero",1); ++k0__) {
            check_greater_or_equal(function__,"v0[k0__]",v0[k0__],0);
        }
        for (int k0__ = 0; k0__ < get_base1(num_non_zero,2,"num_non_zero",1); ++k0__) {
            check_greater_or_equal(function__,"v1[k0__]",v1[k0__],0);
        }
        for (int k0__ = 0; k0__ < (logical_gt(t,0) ? (get_base1(N,1,"N",1) + 1) : 0 ); ++k0__) {
            check_greater_or_equal(function__,"u0[k0__]",u0[k0__],0);
        }
        for (int k0__ = 0; k0__ < (logical_gt(t,0) ? (get_base1(N,2,"N",1) + 1) : 0 ); ++k0__) {
            check_greater_or_equal(function__,"u1[k0__]",u1[k0__],0);
        }
        check_greater_or_equal(function__,"special_case",special_case,0);
        check_less_or_equal(function__,"special_case",special_case,1);
        // initialize data variables
        NN = int(0);
        stan::math::fill(NN, std::numeric_limits<int>::min());
        stan::math::assign(NN,(get_base1(N,1,"N",1) + get_base1(N,2,"N",1)));
        aux = double(0);
        stan::math::fill(aux,DUMMY_VAR__);
        stan::math::assign(aux,stan::math::not_a_number());
        validate_non_negative_index("V0", "(special_case ? t : 0 )", (special_case ? t : 0 ));
        validate_non_negative_index("V0", "get_base1(N,1,\"N\",1)", get_base1(N,1,"N",1));
        V0 = std::vector<std::vector<int> >((special_case ? t : 0 ),std::vector<int>(get_base1(N,1,"N",1),int(0)));
        stan::math::fill(V0, std::numeric_limits<int>::min());
        stan::math::assign(V0,make_V(get_base1(N,1,"N",1),(special_case ? t : 0 ),v0, pstream__));
        validate_non_negative_index("V1", "(special_case ? t : 0 )", (special_case ? t : 0 ));
        validate_non_negative_index("V1", "get_base1(N,2,\"N\",1)", get_base1(N,2,"N",1));
        V1 = std::vector<std::vector<int> >((special_case ? t : 0 ),std::vector<int>(get_base1(N,2,"N",1),int(0)));
        stan::math::fill(V1, std::numeric_limits<int>::min());
        stan::math::assign(V1,make_V(get_base1(N,2,"N",1),(special_case ? t : 0 ),v1, pstream__));
        len_z_T = int(0);
        stan::math::fill(len_z_T, std::numeric_limits<int>::min());
        stan::math::assign(len_z_T,0);
        len_var_group = int(0);
        stan::math::fill(len_var_group, std::numeric_limits<int>::min());
        stan::math::assign(len_var_group,(sum(p) * logical_gt(t,0)));
        len_rho = int(0);
        stan::math::fill(len_rho, std::numeric_limits<int>::min());
        stan::math::assign(len_rho,(sum(p) - t));
        is_continuous = int(0);
        stan::math::fill(is_continuous, std::numeric_limits<int>::min());
        stan::math::assign(is_continuous,0);
        pos = int(0);
        stan::math::fill(pos, std::numeric_limits<int>::min());
        stan::math::assign(pos,1);
        validate_non_negative_index("delta", "len_concentration", len_concentration);
        delta = std::vector<double>(len_concentration,double(0));
        stan::math::fill(delta,DUMMY_VAR__);
        hs = int(0);
        stan::math::fill(hs, std::numeric_limits<int>::min());

        try {
            current_statement_begin__ = 471;
            if (as_bool(logical_lte(prior_dist,2))) {
                current_statement_begin__ = 471;
                stan::math::assign(hs, 0);
            } else if (as_bool(logical_eq(prior_dist,3))) {
                current_statement_begin__ = 472;
                stan::math::assign(hs, 2);
            } else if (as_bool(logical_eq(prior_dist,4))) {
                current_statement_begin__ = 473;
                stan::math::assign(hs, 4);
            } else {
                current_statement_begin__ = 474;
                stan::math::assign(hs, 0);
            }
            current_statement_begin__ = 476;
            stan::math::assign(pos, 1);
            current_statement_begin__ = 477;
            for (int i = 1; i <= t; ++i) {

                current_statement_begin__ = 478;
                if (as_bool(logical_gt(get_base1(p,i,"p",1),1))) {

                    current_statement_begin__ = 479;
                    for (int j = 1; j <= get_base1(p,i,"p",1); ++j) {

                        current_statement_begin__ = 480;
                        stan::math::assign(get_base1_lhs(delta,pos,"delta",1), get_base1(concentration,j,"concentration",1));
                        current_statement_begin__ = 481;
                        stan::math::assign(pos, (pos + 1));
                    }
                }
                current_statement_begin__ = 484;
                for (int j = 3; j <= get_base1(p,i,"p",1); ++j) {
                    current_statement_begin__ = 484;
                    stan::math::assign(len_z_T, ((len_z_T + get_base1(p,i,"p",1)) - 1));
                }
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        // validate transformed data
        for (int k0__ = 0; k0__ < (special_case ? t : 0 ); ++k0__) {
            for (int k1__ = 0; k1__ < get_base1(N,1,"N",1); ++k1__) {
                check_greater_or_equal(function__,"V0[k0__][k1__]",V0[k0__][k1__],1);
            }
        }
        for (int k0__ = 0; k0__ < (special_case ? t : 0 ); ++k0__) {
            for (int k1__ = 0; k1__ < get_base1(N,2,"N",1); ++k1__) {
                check_greater_or_equal(function__,"V1[k0__][k1__]",V1[k0__][k1__],1);
            }
        }
        check_greater_or_equal(function__,"len_z_T",len_z_T,0);
        check_greater_or_equal(function__,"len_var_group",len_var_group,0);
        check_greater_or_equal(function__,"len_rho",len_rho,0);
        check_greater_or_equal(function__,"is_continuous",is_continuous,0);
        check_less_or_equal(function__,"is_continuous",is_continuous,1);
        check_greater_or_equal(function__,"pos",pos,1);
        for (int k0__ = 0; k0__ < len_concentration; ++k0__) {
            check_greater_or_equal(function__,"delta[k0__]",delta[k0__],0);
        }
        check_greater_or_equal(function__,"hs",hs,0);

        // validate, set parameter ranges
        num_params_r__ = 0U;
        param_ranges_i__.clear();
        validate_non_negative_index("gamma", "has_intercept", has_intercept);
        num_params_r__ += has_intercept;
        validate_non_negative_index("z_beta", "(logical_eq(prior_dist,7) ? sum(num_normals) : K )", (logical_eq(prior_dist,7) ? sum(num_normals) : K ));
        num_params_r__ += (logical_eq(prior_dist,7) ? sum(num_normals) : K );
        validate_non_negative_index("z_beta_smooth", "K_smooth", K_smooth);
        num_params_r__ += K_smooth;
        validate_non_negative_index("smooth_sd_raw", "(logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,\"smooth_map\",1) : 0 )", (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));
        num_params_r__ += (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 );
        validate_non_negative_index("global", "hs", hs);
        num_params_r__ += hs;
        validate_non_negative_index("local", "K", K);
        validate_non_negative_index("local", "hs", hs);
        num_params_r__ += K * hs;
        validate_non_negative_index("mix", "K", K);
        validate_non_negative_index("mix", "(primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6)))", (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))));
        num_params_r__ += K * (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6)));
        validate_non_negative_index("one_over_lambda", "logical_eq(prior_dist,6)", logical_eq(prior_dist,6));
        num_params_r__ += logical_eq(prior_dist,6);
        validate_non_negative_index("z_b", "q", q);
        num_params_r__ += q;
        validate_non_negative_index("z_T", "len_z_T", len_z_T);
        num_params_r__ += len_z_T;
        validate_non_negative_index("rho", "len_rho", len_rho);
        num_params_r__ += len_rho;
        validate_non_negative_index("zeta", "len_concentration", len_concentration);
        num_params_r__ += len_concentration;
        validate_non_negative_index("tau", "t", t);
        num_params_r__ += t;
    }

    ~model_bernoulli() { }


    void transform_inits(const stan::io::var_context& context__,
                         std::vector<int>& params_i__,
                         std::vector<double>& params_r__,
                         std::ostream* pstream__) const {
        stan::io::writer<double> writer__(params_r__,params_i__);
        size_t pos__;
        (void) pos__; // dummy call to supress warning
        std::vector<double> vals_r__;
        std::vector<int> vals_i__;

        if (!(context__.contains_r("gamma")))
            throw std::runtime_error("variable gamma missing");
        vals_r__ = context__.vals_r("gamma");
        pos__ = 0U;
        validate_non_negative_index("gamma", "has_intercept", has_intercept);
        context__.validate_dims("initialization", "gamma", "double", context__.to_vec(has_intercept));
        // generate_declaration gamma
        std::vector<double> gamma(has_intercept,double(0));
        for (int i0__ = 0U; i0__ < has_intercept; ++i0__)
            gamma[i0__] = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < has_intercept; ++i0__)
            try {
            writer__.scalar_ub_unconstrain((logical_eq(link,4) ? 0.0 : stan::math::positive_infinity() ),gamma[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable gamma: ") + e.what());
        }

        if (!(context__.contains_r("z_beta")))
            throw std::runtime_error("variable z_beta missing");
        vals_r__ = context__.vals_r("z_beta");
        pos__ = 0U;
        validate_non_negative_index("z_beta", "(logical_eq(prior_dist,7) ? sum(num_normals) : K )", (logical_eq(prior_dist,7) ? sum(num_normals) : K ));
        context__.validate_dims("initialization", "z_beta", "vector_d", context__.to_vec((logical_eq(prior_dist,7) ? sum(num_normals) : K )));
        // generate_declaration z_beta
        vector_d z_beta(static_cast<Eigen::VectorXd::Index>((logical_eq(prior_dist,7) ? sum(num_normals) : K )));
        for (int j1__ = 0U; j1__ < (logical_eq(prior_dist,7) ? sum(num_normals) : K ); ++j1__)
            z_beta(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_unconstrain(z_beta);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable z_beta: ") + e.what());
        }

        if (!(context__.contains_r("z_beta_smooth")))
            throw std::runtime_error("variable z_beta_smooth missing");
        vals_r__ = context__.vals_r("z_beta_smooth");
        pos__ = 0U;
        validate_non_negative_index("z_beta_smooth", "K_smooth", K_smooth);
        context__.validate_dims("initialization", "z_beta_smooth", "vector_d", context__.to_vec(K_smooth));
        // generate_declaration z_beta_smooth
        vector_d z_beta_smooth(static_cast<Eigen::VectorXd::Index>(K_smooth));
        for (int j1__ = 0U; j1__ < K_smooth; ++j1__)
            z_beta_smooth(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_unconstrain(z_beta_smooth);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable z_beta_smooth: ") + e.what());
        }

        if (!(context__.contains_r("smooth_sd_raw")))
            throw std::runtime_error("variable smooth_sd_raw missing");
        vals_r__ = context__.vals_r("smooth_sd_raw");
        pos__ = 0U;
        validate_non_negative_index("smooth_sd_raw", "(logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,\"smooth_map\",1) : 0 )", (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));
        context__.validate_dims("initialization", "smooth_sd_raw", "vector_d", context__.to_vec((logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 )));
        // generate_declaration smooth_sd_raw
        vector_d smooth_sd_raw(static_cast<Eigen::VectorXd::Index>((logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 )));
        for (int j1__ = 0U; j1__ < (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++j1__)
            smooth_sd_raw(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_lb_unconstrain(0,smooth_sd_raw);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable smooth_sd_raw: ") + e.what());
        }

        if (!(context__.contains_r("global")))
            throw std::runtime_error("variable global missing");
        vals_r__ = context__.vals_r("global");
        pos__ = 0U;
        validate_non_negative_index("global", "hs", hs);
        context__.validate_dims("initialization", "global", "double", context__.to_vec(hs));
        // generate_declaration global
        std::vector<double> global(hs,double(0));
        for (int i0__ = 0U; i0__ < hs; ++i0__)
            global[i0__] = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < hs; ++i0__)
            try {
            writer__.scalar_lb_unconstrain(0,global[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable global: ") + e.what());
        }

        if (!(context__.contains_r("local")))
            throw std::runtime_error("variable local missing");
        vals_r__ = context__.vals_r("local");
        pos__ = 0U;
        validate_non_negative_index("local", "hs", hs);
        validate_non_negative_index("local", "K", K);
        context__.validate_dims("initialization", "local", "vector_d", context__.to_vec(hs,K));
        // generate_declaration local
        std::vector<vector_d> local(hs,vector_d(static_cast<Eigen::VectorXd::Index>(K)));
        for (int j1__ = 0U; j1__ < K; ++j1__)
            for (int i0__ = 0U; i0__ < hs; ++i0__)
                local[i0__](j1__) = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < hs; ++i0__)
            try {
            writer__.vector_lb_unconstrain(0,local[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable local: ") + e.what());
        }

        if (!(context__.contains_r("mix")))
            throw std::runtime_error("variable mix missing");
        vals_r__ = context__.vals_r("mix");
        pos__ = 0U;
        validate_non_negative_index("mix", "(primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6)))", (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))));
        validate_non_negative_index("mix", "K", K);
        context__.validate_dims("initialization", "mix", "vector_d", context__.to_vec((primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))),K));
        // generate_declaration mix
        std::vector<vector_d> mix((primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))),vector_d(static_cast<Eigen::VectorXd::Index>(K)));
        for (int j1__ = 0U; j1__ < K; ++j1__)
            for (int i0__ = 0U; i0__ < (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))); ++i0__)
                mix[i0__](j1__) = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))); ++i0__)
            try {
            writer__.vector_lb_unconstrain(0,mix[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable mix: ") + e.what());
        }

        if (!(context__.contains_r("one_over_lambda")))
            throw std::runtime_error("variable one_over_lambda missing");
        vals_r__ = context__.vals_r("one_over_lambda");
        pos__ = 0U;
        validate_non_negative_index("one_over_lambda", "logical_eq(prior_dist,6)", logical_eq(prior_dist,6));
        context__.validate_dims("initialization", "one_over_lambda", "double", context__.to_vec(logical_eq(prior_dist,6)));
        // generate_declaration one_over_lambda
        std::vector<double> one_over_lambda(logical_eq(prior_dist,6),double(0));
        for (int i0__ = 0U; i0__ < logical_eq(prior_dist,6); ++i0__)
            one_over_lambda[i0__] = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < logical_eq(prior_dist,6); ++i0__)
            try {
            writer__.scalar_lb_unconstrain(0,one_over_lambda[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable one_over_lambda: ") + e.what());
        }

        if (!(context__.contains_r("z_b")))
            throw std::runtime_error("variable z_b missing");
        vals_r__ = context__.vals_r("z_b");
        pos__ = 0U;
        validate_non_negative_index("z_b", "q", q);
        context__.validate_dims("initialization", "z_b", "vector_d", context__.to_vec(q));
        // generate_declaration z_b
        vector_d z_b(static_cast<Eigen::VectorXd::Index>(q));
        for (int j1__ = 0U; j1__ < q; ++j1__)
            z_b(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_unconstrain(z_b);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable z_b: ") + e.what());
        }

        if (!(context__.contains_r("z_T")))
            throw std::runtime_error("variable z_T missing");
        vals_r__ = context__.vals_r("z_T");
        pos__ = 0U;
        validate_non_negative_index("z_T", "len_z_T", len_z_T);
        context__.validate_dims("initialization", "z_T", "vector_d", context__.to_vec(len_z_T));
        // generate_declaration z_T
        vector_d z_T(static_cast<Eigen::VectorXd::Index>(len_z_T));
        for (int j1__ = 0U; j1__ < len_z_T; ++j1__)
            z_T(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_unconstrain(z_T);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable z_T: ") + e.what());
        }

        if (!(context__.contains_r("rho")))
            throw std::runtime_error("variable rho missing");
        vals_r__ = context__.vals_r("rho");
        pos__ = 0U;
        validate_non_negative_index("rho", "len_rho", len_rho);
        context__.validate_dims("initialization", "rho", "vector_d", context__.to_vec(len_rho));
        // generate_declaration rho
        vector_d rho(static_cast<Eigen::VectorXd::Index>(len_rho));
        for (int j1__ = 0U; j1__ < len_rho; ++j1__)
            rho(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_lub_unconstrain(0,1,rho);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable rho: ") + e.what());
        }

        if (!(context__.contains_r("zeta")))
            throw std::runtime_error("variable zeta missing");
        vals_r__ = context__.vals_r("zeta");
        pos__ = 0U;
        validate_non_negative_index("zeta", "len_concentration", len_concentration);
        context__.validate_dims("initialization", "zeta", "vector_d", context__.to_vec(len_concentration));
        // generate_declaration zeta
        vector_d zeta(static_cast<Eigen::VectorXd::Index>(len_concentration));
        for (int j1__ = 0U; j1__ < len_concentration; ++j1__)
            zeta(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_lb_unconstrain(0,zeta);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable zeta: ") + e.what());
        }

        if (!(context__.contains_r("tau")))
            throw std::runtime_error("variable tau missing");
        vals_r__ = context__.vals_r("tau");
        pos__ = 0U;
        validate_non_negative_index("tau", "t", t);
        context__.validate_dims("initialization", "tau", "vector_d", context__.to_vec(t));
        // generate_declaration tau
        vector_d tau(static_cast<Eigen::VectorXd::Index>(t));
        for (int j1__ = 0U; j1__ < t; ++j1__)
            tau(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_lb_unconstrain(0,tau);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable tau: ") + e.what());
        }

        params_r__ = writer__.data_r();
        params_i__ = writer__.data_i();
    }

    void transform_inits(const stan::io::var_context& context,
                         Eigen::Matrix<double,Eigen::Dynamic,1>& params_r,
                         std::ostream* pstream__) const {
      std::vector<double> params_r_vec;
      std::vector<int> params_i_vec;
      transform_inits(context, params_i_vec, params_r_vec, pstream__);
      params_r.resize(params_r_vec.size());
      for (int i = 0; i < params_r.size(); ++i)
        params_r(i) = params_r_vec[i];
    }


    template <bool propto__, bool jacobian__, typename T__>
    T__ log_prob(vector<T__>& params_r__,
                 vector<int>& params_i__,
                 std::ostream* pstream__ = 0) const {

        T__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

        T__ lp__(0.0);
        stan::math::accumulator<T__> lp_accum__;

        // model parameters
        stan::io::reader<T__> in__(params_r__,params_i__);

        vector<T__> gamma;
        size_t dim_gamma_0__ = has_intercept;
        gamma.reserve(dim_gamma_0__);
        for (size_t k_0__ = 0; k_0__ < dim_gamma_0__; ++k_0__) {
            if (jacobian__)
                gamma.push_back(in__.scalar_ub_constrain((logical_eq(link,4) ? 0.0 : stan::math::positive_infinity() ),lp__));
            else
                gamma.push_back(in__.scalar_ub_constrain((logical_eq(link,4) ? 0.0 : stan::math::positive_infinity() )));
        }

        Eigen::Matrix<T__,Eigen::Dynamic,1>  z_beta;
        (void) z_beta;  // dummy to suppress unused var warning
        if (jacobian__)
            z_beta = in__.vector_constrain((logical_eq(prior_dist,7) ? sum(num_normals) : K ),lp__);
        else
            z_beta = in__.vector_constrain((logical_eq(prior_dist,7) ? sum(num_normals) : K ));

        Eigen::Matrix<T__,Eigen::Dynamic,1>  z_beta_smooth;
        (void) z_beta_smooth;  // dummy to suppress unused var warning
        if (jacobian__)
            z_beta_smooth = in__.vector_constrain(K_smooth,lp__);
        else
            z_beta_smooth = in__.vector_constrain(K_smooth);

        Eigen::Matrix<T__,Eigen::Dynamic,1>  smooth_sd_raw;
        (void) smooth_sd_raw;  // dummy to suppress unused var warning
        if (jacobian__)
            smooth_sd_raw = in__.vector_lb_constrain(0,(logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ),lp__);
        else
            smooth_sd_raw = in__.vector_lb_constrain(0,(logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));

        vector<T__> global;
        size_t dim_global_0__ = hs;
        global.reserve(dim_global_0__);
        for (size_t k_0__ = 0; k_0__ < dim_global_0__; ++k_0__) {
            if (jacobian__)
                global.push_back(in__.scalar_lb_constrain(0,lp__));
            else
                global.push_back(in__.scalar_lb_constrain(0));
        }

        vector<Eigen::Matrix<T__,Eigen::Dynamic,1> > local;
        size_t dim_local_0__ = hs;
        local.reserve(dim_local_0__);
        for (size_t k_0__ = 0; k_0__ < dim_local_0__; ++k_0__) {
            if (jacobian__)
                local.push_back(in__.vector_lb_constrain(0,K,lp__));
            else
                local.push_back(in__.vector_lb_constrain(0,K));
        }

        vector<Eigen::Matrix<T__,Eigen::Dynamic,1> > mix;
        size_t dim_mix_0__ = (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6)));
        mix.reserve(dim_mix_0__);
        for (size_t k_0__ = 0; k_0__ < dim_mix_0__; ++k_0__) {
            if (jacobian__)
                mix.push_back(in__.vector_lb_constrain(0,K,lp__));
            else
                mix.push_back(in__.vector_lb_constrain(0,K));
        }

        vector<T__> one_over_lambda;
        size_t dim_one_over_lambda_0__ = logical_eq(prior_dist,6);
        one_over_lambda.reserve(dim_one_over_lambda_0__);
        for (size_t k_0__ = 0; k_0__ < dim_one_over_lambda_0__; ++k_0__) {
            if (jacobian__)
                one_over_lambda.push_back(in__.scalar_lb_constrain(0,lp__));
            else
                one_over_lambda.push_back(in__.scalar_lb_constrain(0));
        }

        Eigen::Matrix<T__,Eigen::Dynamic,1>  z_b;
        (void) z_b;  // dummy to suppress unused var warning
        if (jacobian__)
            z_b = in__.vector_constrain(q,lp__);
        else
            z_b = in__.vector_constrain(q);

        Eigen::Matrix<T__,Eigen::Dynamic,1>  z_T;
        (void) z_T;  // dummy to suppress unused var warning
        if (jacobian__)
            z_T = in__.vector_constrain(len_z_T,lp__);
        else
            z_T = in__.vector_constrain(len_z_T);

        Eigen::Matrix<T__,Eigen::Dynamic,1>  rho;
        (void) rho;  // dummy to suppress unused var warning
        if (jacobian__)
            rho = in__.vector_lub_constrain(0,1,len_rho,lp__);
        else
            rho = in__.vector_lub_constrain(0,1,len_rho);

        Eigen::Matrix<T__,Eigen::Dynamic,1>  zeta;
        (void) zeta;  // dummy to suppress unused var warning
        if (jacobian__)
            zeta = in__.vector_lb_constrain(0,len_concentration,lp__);
        else
            zeta = in__.vector_lb_constrain(0,len_concentration);

        Eigen::Matrix<T__,Eigen::Dynamic,1>  tau;
        (void) tau;  // dummy to suppress unused var warning
        if (jacobian__)
            tau = in__.vector_lb_constrain(0,t,lp__);
        else
            tau = in__.vector_lb_constrain(0,t);


        // transformed parameters
        validate_non_negative_index("beta", "K", K);
        Eigen::Matrix<T__,Eigen::Dynamic,1>  beta(static_cast<Eigen::VectorXd::Index>(K));
        (void) beta;  // dummy to suppress unused var warning

        stan::math::initialize(beta, DUMMY_VAR__);
        stan::math::fill(beta,DUMMY_VAR__);
        validate_non_negative_index("beta_smooth", "K_smooth", K_smooth);
        Eigen::Matrix<T__,Eigen::Dynamic,1>  beta_smooth(static_cast<Eigen::VectorXd::Index>(K_smooth));
        (void) beta_smooth;  // dummy to suppress unused var warning

        stan::math::initialize(beta_smooth, DUMMY_VAR__);
        stan::math::fill(beta_smooth,DUMMY_VAR__);
        validate_non_negative_index("smooth_sd", "(logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,\"smooth_map\",1) : 0 )", (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));
        Eigen::Matrix<T__,Eigen::Dynamic,1>  smooth_sd(static_cast<Eigen::VectorXd::Index>((logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 )));
        (void) smooth_sd;  // dummy to suppress unused var warning

        stan::math::initialize(smooth_sd, DUMMY_VAR__);
        stan::math::fill(smooth_sd,DUMMY_VAR__);
        validate_non_negative_index("b", "q", q);
        Eigen::Matrix<T__,Eigen::Dynamic,1>  b(static_cast<Eigen::VectorXd::Index>(q));
        (void) b;  // dummy to suppress unused var warning

        stan::math::initialize(b, DUMMY_VAR__);
        stan::math::fill(b,DUMMY_VAR__);
        validate_non_negative_index("theta_L", "len_theta_L", len_theta_L);
        Eigen::Matrix<T__,Eigen::Dynamic,1>  theta_L(static_cast<Eigen::VectorXd::Index>(len_theta_L));
        (void) theta_L;  // dummy to suppress unused var warning

        stan::math::initialize(theta_L, DUMMY_VAR__);
        stan::math::fill(theta_L,DUMMY_VAR__);


        try {
            current_statement_begin__ = 512;
            if (as_bool(logical_eq(prior_dist,0))) {
                current_statement_begin__ = 512;
                stan::math::assign(beta, z_beta);
            } else if (as_bool(logical_eq(prior_dist,1))) {
                current_statement_begin__ = 513;
                stan::math::assign(beta, add(elt_multiply(z_beta,prior_scale),prior_mean));
            } else if (as_bool(logical_eq(prior_dist,2))) {
                current_statement_begin__ = 514;
                for (int k = 1; k <= K; ++k) {

                    current_statement_begin__ = 515;
                    stan::math::assign(get_base1_lhs(beta,k,"beta",1), ((CFt(get_base1(z_beta,k,"z_beta",1),get_base1(prior_df,k,"prior_df",1), pstream__) * get_base1(prior_scale,k,"prior_scale",1)) + get_base1(prior_mean,k,"prior_mean",1)));
                }
            } else if (as_bool(logical_eq(prior_dist,3))) {

                current_statement_begin__ = 518;
                if (as_bool((primitive_value(logical_eq(is_continuous,1)) && primitive_value(logical_eq(family,1))))) {
                    current_statement_begin__ = 519;
                    stan::math::assign(beta, hs_prior(z_beta,global,local,global_prior_scale,aux, pstream__));
                } else {
                    current_statement_begin__ = 520;
                    stan::math::assign(beta, hs_prior(z_beta,global,local,global_prior_scale,1, pstream__));
                }
            } else if (as_bool(logical_eq(prior_dist,4))) {

                current_statement_begin__ = 523;
                if (as_bool((primitive_value(logical_eq(is_continuous,1)) && primitive_value(logical_eq(family,1))))) {
                    current_statement_begin__ = 524;
                    stan::math::assign(beta, hsplus_prior(z_beta,global,local,global_prior_scale,aux, pstream__));
                } else {
                    current_statement_begin__ = 525;
                    stan::math::assign(beta, hsplus_prior(z_beta,global,local,global_prior_scale,1, pstream__));
                }
            } else if (as_bool(logical_eq(prior_dist,5))) {
                current_statement_begin__ = 528;
                stan::math::assign(beta, add(prior_mean,elt_multiply(elt_multiply(prior_scale,sqrt(multiply(2,get_base1(mix,1,"mix",1)))),z_beta)));
            } else if (as_bool(logical_eq(prior_dist,6))) {
                current_statement_begin__ = 530;
                stan::math::assign(beta, add(prior_mean,elt_multiply(elt_multiply(multiply(get_base1(one_over_lambda,1,"one_over_lambda",1),prior_scale),sqrt(multiply(2,get_base1(mix,1,"mix",1)))),z_beta)));
            } else if (as_bool(logical_eq(prior_dist,7))) {
                {
                    int z_pos(0);
                    (void) z_pos;  // dummy to suppress unused var warning

                    stan::math::fill(z_pos, std::numeric_limits<int>::min());
                    stan::math::assign(z_pos,1);


                    current_statement_begin__ = 533;
                    for (int k = 1; k <= K; ++k) {

                        current_statement_begin__ = 534;
                        stan::math::assign(get_base1_lhs(beta,k,"beta",1), get_base1(z_beta,z_pos,"z_beta",1));
                        current_statement_begin__ = 535;
                        stan::math::assign(z_pos, (z_pos + 1));
                        current_statement_begin__ = 536;
                        for (int n = 2; n <= get_base1(num_normals,k,"num_normals",1); ++n) {

                            current_statement_begin__ = 537;
                            stan::math::assign(get_base1_lhs(beta,k,"beta",1), (get_base1(beta,k,"beta",1) * get_base1(z_beta,z_pos,"z_beta",1)));
                            current_statement_begin__ = 538;
                            stan::math::assign(z_pos, (z_pos + 1));
                        }
                        current_statement_begin__ = 540;
                        stan::math::assign(get_base1_lhs(beta,k,"beta",1), ((get_base1(beta,k,"beta",1) * pow(get_base1(prior_scale,k,"prior_scale",1),get_base1(num_normals,k,"num_normals",1))) + get_base1(prior_mean,k,"prior_mean",1)));
                    }
                }
            }
            current_statement_begin__ = 544;
            if (as_bool(K_smooth)) {

                current_statement_begin__ = 545;
                stan::math::assign(smooth_sd, add(prior_mean_for_smooth,elt_multiply(prior_scale_for_smooth,smooth_sd_raw)));
                current_statement_begin__ = 546;
                if (as_bool((primitive_value(is_continuous) && primitive_value(logical_eq(family,1))))) {
                    current_statement_begin__ = 546;
                    stan::math::assign(smooth_sd, multiply(smooth_sd,aux));
                }
                current_statement_begin__ = 547;
                stan::math::assign(beta_smooth, elt_multiply(z_beta_smooth,stan::model::rvalue(smooth_sd, stan::model::cons_list(stan::model::index_multi(smooth_map), stan::model::nil_index_list()), "smooth_sd")));
            }
            current_statement_begin__ = 549;
            if (as_bool(logical_gt(t,0))) {

                current_statement_begin__ = 550;
                if (as_bool(special_case)) {
                    {
                        int start(0);
                        (void) start;  // dummy to suppress unused var warning

                        stan::math::fill(start, std::numeric_limits<int>::min());
                        stan::math::assign(start,1);


                        current_statement_begin__ = 552;
                        stan::math::assign(theta_L, elt_multiply(scale,tau));
                        current_statement_begin__ = 553;
                        if (as_bool(logical_eq(t,1))) {
                            current_statement_begin__ = 553;
                            stan::math::assign(b, multiply(get_base1(theta_L,1,"theta_L",1),z_b));
                        } else {
                            current_statement_begin__ = 554;
                            for (int i = 1; i <= t; ++i) {
                                {
                                    int end(0);
                                    (void) end;  // dummy to suppress unused var warning

                                    stan::math::fill(end, std::numeric_limits<int>::min());
                                    stan::math::assign(end,((start + get_base1(l,i,"l",1)) - 1));


                                    current_statement_begin__ = 556;
                                    stan::model::assign(b, 
                                                stan::model::cons_list(stan::model::index_min_max(start, end), stan::model::nil_index_list()), 
                                                multiply(get_base1(theta_L,i,"theta_L",1),stan::model::rvalue(z_b, stan::model::cons_list(stan::model::index_min_max(start, end), stan::model::nil_index_list()), "z_b")), 
                                                "assigning variable b");
                                    current_statement_begin__ = 557;
                                    stan::math::assign(start, (end + 1));
                                }
                            }
                        }
                    }
                } else {

                    current_statement_begin__ = 561;
                    stan::math::assign(theta_L, make_theta_L(len_theta_L,p,1.0,tau,scale,zeta,rho,z_T, pstream__));
                    current_statement_begin__ = 563;
                    stan::math::assign(b, make_b(z_b,theta_L,p,l, pstream__));
                }
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        // validate transformed parameters
        for (int i0__ = 0; i0__ < K; ++i0__) {
            if (stan::math::is_uninitialized(beta(i0__))) {
                std::stringstream msg__;
                msg__ << "Undefined transformed parameter: beta" << '[' << i0__ << ']';
                throw std::runtime_error(msg__.str());
            }
        }
        for (int i0__ = 0; i0__ < K_smooth; ++i0__) {
            if (stan::math::is_uninitialized(beta_smooth(i0__))) {
                std::stringstream msg__;
                msg__ << "Undefined transformed parameter: beta_smooth" << '[' << i0__ << ']';
                throw std::runtime_error(msg__.str());
            }
        }
        for (int i0__ = 0; i0__ < (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++i0__) {
            if (stan::math::is_uninitialized(smooth_sd(i0__))) {
                std::stringstream msg__;
                msg__ << "Undefined transformed parameter: smooth_sd" << '[' << i0__ << ']';
                throw std::runtime_error(msg__.str());
            }
        }
        for (int i0__ = 0; i0__ < q; ++i0__) {
            if (stan::math::is_uninitialized(b(i0__))) {
                std::stringstream msg__;
                msg__ << "Undefined transformed parameter: b" << '[' << i0__ << ']';
                throw std::runtime_error(msg__.str());
            }
        }
        for (int i0__ = 0; i0__ < len_theta_L; ++i0__) {
            if (stan::math::is_uninitialized(theta_L(i0__))) {
                std::stringstream msg__;
                msg__ << "Undefined transformed parameter: theta_L" << '[' << i0__ << ']';
                throw std::runtime_error(msg__.str());
            }
        }

        const char* function__ = "validate transformed params";
        (void) function__;  // dummy to suppress unused var warning

        // model body
        try {
            {
                validate_non_negative_index("eta0", "get_base1(N,1,\"N\",1)", get_base1(N,1,"N",1));
                Eigen::Matrix<T__,Eigen::Dynamic,1>  eta0(static_cast<Eigen::VectorXd::Index>(get_base1(N,1,"N",1)));
                (void) eta0;  // dummy to suppress unused var warning

                stan::math::initialize(eta0, DUMMY_VAR__);
                stan::math::fill(eta0,DUMMY_VAR__);
                validate_non_negative_index("eta1", "get_base1(N,2,\"N\",1)", get_base1(N,2,"N",1));
                Eigen::Matrix<T__,Eigen::Dynamic,1>  eta1(static_cast<Eigen::VectorXd::Index>(get_base1(N,2,"N",1)));
                (void) eta1;  // dummy to suppress unused var warning

                stan::math::initialize(eta1, DUMMY_VAR__);
                stan::math::fill(eta1,DUMMY_VAR__);


                current_statement_begin__ = 571;
                if (as_bool(logical_gt(K,0))) {

                    current_statement_begin__ = 572;
                    if (as_bool(dense_X)) {

                        current_statement_begin__ = 573;
                        stan::math::assign(eta0, multiply(get_base1(X0,1,"X0",1),beta));
                        current_statement_begin__ = 574;
                        stan::math::assign(eta1, multiply(get_base1(X1,1,"X1",1),beta));
                    } else {

                        current_statement_begin__ = 577;
                        stan::math::assign(eta0, csr_matrix_times_vector(get_base1(N,1,"N",1),K,w_X0,v_X0,u_X0,beta));
                        current_statement_begin__ = 578;
                        stan::math::assign(eta1, csr_matrix_times_vector(get_base1(N,2,"N",1),K,w_X1,v_X1,u_X1,beta));
                    }
                } else {

                    current_statement_begin__ = 582;
                    stan::math::assign(eta0, rep_vector(0.0,get_base1(N,1,"N",1)));
                    current_statement_begin__ = 583;
                    stan::math::assign(eta1, rep_vector(0.0,get_base1(N,2,"N",1)));
                }
                current_statement_begin__ = 585;
                if (as_bool((primitive_value(logical_eq(has_intercept,0)) && primitive_value(dense_X)))) {
                    {
                        T__ tmp;
                        (void) tmp;  // dummy to suppress unused var warning

                        stan::math::initialize(tmp, DUMMY_VAR__);
                        stan::math::fill(tmp,DUMMY_VAR__);


                        current_statement_begin__ = 587;
                        stan::math::assign(tmp, dot_product(xbar,beta));
                        current_statement_begin__ = 588;
                        stan::math::assign(eta0, add(eta0,tmp));
                        current_statement_begin__ = 589;
                        stan::math::assign(eta1, add(eta1,tmp));
                    }
                }
                current_statement_begin__ = 591;
                if (as_bool(logical_eq(has_offset,1))) {

                    current_statement_begin__ = 592;
                    stan::math::assign(eta0, add(eta0,offset0));
                    current_statement_begin__ = 593;
                    stan::math::assign(eta1, add(eta1,offset1));
                }
                current_statement_begin__ = 595;
                if (as_bool(K_smooth)) {

                    current_statement_begin__ = 596;
                    stan::math::assign(eta0, add(eta0,multiply(S0,beta_smooth)));
                    current_statement_begin__ = 597;
                    stan::math::assign(eta1, add(eta1,multiply(S1,beta_smooth)));
                }
                current_statement_begin__ = 599;
                if (as_bool(special_case)) {
                    current_statement_begin__ = 599;
                    for (int i = 1; i <= t; ++i) {

                        current_statement_begin__ = 600;
                        stan::math::assign(eta0, add(eta0,stan::model::rvalue(b, stan::model::cons_list(stan::model::index_multi(get_base1(V0,i,"V0",1)), stan::model::nil_index_list()), "b")));
                        current_statement_begin__ = 601;
                        stan::math::assign(eta1, add(eta1,stan::model::rvalue(b, stan::model::cons_list(stan::model::index_multi(get_base1(V1,i,"V1",1)), stan::model::nil_index_list()), "b")));
                    }
                } else if (as_bool(logical_gt(t,0))) {

                    current_statement_begin__ = 604;
                    stan::math::assign(eta0, add(eta0,csr_matrix_times_vector(get_base1(N,1,"N",1),q,w0,v0,u0,b)));
                    current_statement_begin__ = 605;
                    stan::math::assign(eta1, add(eta1,csr_matrix_times_vector(get_base1(N,2,"N",1),q,w1,v1,u1,b)));
                }
                current_statement_begin__ = 607;
                if (as_bool(logical_eq(has_intercept,1))) {

                    current_statement_begin__ = 608;
                    if (as_bool(logical_neq(link,4))) {

                        current_statement_begin__ = 609;
                        stan::math::assign(eta0, add(get_base1(gamma,1,"gamma",1),eta0));
                        current_statement_begin__ = 610;
                        stan::math::assign(eta1, add(get_base1(gamma,1,"gamma",1),eta1));
                    } else {
                        {
                            T__ shift;
                            (void) shift;  // dummy to suppress unused var warning

                            stan::math::initialize(shift, DUMMY_VAR__);
                            stan::math::fill(shift,DUMMY_VAR__);


                            current_statement_begin__ = 614;
                            stan::math::assign(shift, stan::math::fmax(max(eta0),max(eta1)));
                            current_statement_begin__ = 615;
                            stan::math::assign(eta0, subtract(add(get_base1(gamma,1,"gamma",1),eta0),shift));
                            current_statement_begin__ = 616;
                            stan::math::assign(eta1, subtract(add(get_base1(gamma,1,"gamma",1),eta1),shift));
                        }
                    }
                }
                current_statement_begin__ = 620;
                if (as_bool((primitive_value(logical_eq(has_weights,0)) && primitive_value(logical_eq(prior_PD,0))))) {
                    {
                        T__ dummy;
                        (void) dummy;  // dummy to suppress unused var warning

                        stan::math::initialize(dummy, DUMMY_VAR__);
                        stan::math::fill(dummy,DUMMY_VAR__);


                        current_statement_begin__ = 622;
                        stan::math::assign(dummy, ll_bern_lp(eta0,eta1,link,N, lp__, lp_accum__, pstream__));
                    }
                } else if (as_bool(logical_eq(prior_PD,0))) {

                    current_statement_begin__ = 625;
                    lp_accum__.add(dot_product(weights0,pw_bern(0,eta0,link, pstream__)));
                    current_statement_begin__ = 626;
                    lp_accum__.add(dot_product(weights1,pw_bern(1,eta1,link, pstream__)));
                }
                current_statement_begin__ = 632;
                if (as_bool(logical_eq(prior_dist,1))) {
                    current_statement_begin__ = 632;
                    lp_accum__.add(normal_log(z_beta,0,1));
                } else if (as_bool(logical_eq(prior_dist,2))) {
                    current_statement_begin__ = 633;
                    lp_accum__.add(normal_log(z_beta,0,1));
                } else if (as_bool(logical_eq(prior_dist,3))) {
                    {
                        T__ log_half;
                        (void) log_half;  // dummy to suppress unused var warning

                        stan::math::initialize(log_half, DUMMY_VAR__);
                        stan::math::fill(log_half,DUMMY_VAR__);
                        stan::math::assign(log_half,-(0.6931471805599454));


                        current_statement_begin__ = 636;
                        lp_accum__.add(normal_log(z_beta,0,1));
                        current_statement_begin__ = 637;
                        lp_accum__.add((normal_log(get_base1(local,1,"local",1),0,1) - log_half));
                        current_statement_begin__ = 638;
                        lp_accum__.add(inv_gamma_log(get_base1(local,2,"local",1),multiply(0.5,prior_df),multiply(0.5,prior_df)));
                        current_statement_begin__ = 639;
                        lp_accum__.add((normal_log(get_base1(global,1,"global",1),0,1) - log_half));
                        current_statement_begin__ = 640;
                        lp_accum__.add(inv_gamma_log(get_base1(global,2,"global",1),(0.5 * global_prior_df),(0.5 * global_prior_df)));
                    }
                } else if (as_bool(logical_eq(prior_dist,4))) {
                    {
                        T__ log_half;
                        (void) log_half;  // dummy to suppress unused var warning

                        stan::math::initialize(log_half, DUMMY_VAR__);
                        stan::math::fill(log_half,DUMMY_VAR__);
                        stan::math::assign(log_half,-(0.6931471805599454));


                        current_statement_begin__ = 644;
                        lp_accum__.add(normal_log(z_beta,0,1));
                        current_statement_begin__ = 645;
                        lp_accum__.add((normal_log(get_base1(local,1,"local",1),0,1) - log_half));
                        current_statement_begin__ = 646;
                        lp_accum__.add(inv_gamma_log(get_base1(local,2,"local",1),multiply(0.5,prior_df),multiply(0.5,prior_df)));
                        current_statement_begin__ = 647;
                        lp_accum__.add((normal_log(get_base1(local,3,"local",1),0,1) - log_half));
                        current_statement_begin__ = 649;
                        lp_accum__.add(inv_gamma_log(get_base1(local,4,"local",1),multiply(0.5,prior_scale),multiply(0.5,prior_scale)));
                        current_statement_begin__ = 650;
                        lp_accum__.add((normal_log(get_base1(global,1,"global",1),0,1) - log_half));
                        current_statement_begin__ = 651;
                        lp_accum__.add(inv_gamma_log(get_base1(global,2,"global",1),(0.5 * global_prior_df),(0.5 * global_prior_df)));
                    }
                } else if (as_bool(logical_eq(prior_dist,5))) {

                    current_statement_begin__ = 654;
                    lp_accum__.add(normal_log(z_beta,0,1));
                    current_statement_begin__ = 655;
                    lp_accum__.add(exponential_log(get_base1(mix,1,"mix",1),1));
                } else if (as_bool(logical_eq(prior_dist,6))) {

                    current_statement_begin__ = 658;
                    lp_accum__.add(normal_log(z_beta,0,1));
                    current_statement_begin__ = 659;
                    lp_accum__.add(exponential_log(get_base1(mix,1,"mix",1),1));
                    current_statement_begin__ = 660;
                    lp_accum__.add(chi_square_log(get_base1(one_over_lambda,1,"one_over_lambda",1),get_base1(prior_df,1,"prior_df",1)));
                } else if (as_bool(logical_eq(prior_dist,7))) {

                    current_statement_begin__ = 663;
                    lp_accum__.add(normal_log(z_beta,0,1));
                }
                current_statement_begin__ = 668;
                if (as_bool(logical_eq(has_intercept,1))) {

                    current_statement_begin__ = 669;
                    if (as_bool(logical_eq(prior_dist_for_intercept,1))) {
                        current_statement_begin__ = 670;
                        lp_accum__.add(normal_log(gamma,prior_mean_for_intercept,prior_scale_for_intercept));
                    } else if (as_bool(logical_eq(prior_dist_for_intercept,2))) {
                        current_statement_begin__ = 672;
                        lp_accum__.add(student_t_log(gamma,prior_df_for_intercept,prior_mean_for_intercept,prior_scale_for_intercept));
                    }
                }
                current_statement_begin__ = 677;
                if (as_bool(K_smooth)) {

                    current_statement_begin__ = 678;
                    lp_accum__.add(normal_log(z_beta_smooth,0,1));
                    current_statement_begin__ = 679;
                    if (as_bool(logical_gt(prior_dist_for_smooth,0))) {
                        {
                            T__ log_half;
                            (void) log_half;  // dummy to suppress unused var warning

                            stan::math::initialize(log_half, DUMMY_VAR__);
                            stan::math::fill(log_half,DUMMY_VAR__);
                            stan::math::assign(log_half,-(0.6931471805599454));


                            current_statement_begin__ = 681;
                            if (as_bool(logical_eq(prior_dist_for_smooth,1))) {
                                current_statement_begin__ = 682;
                                lp_accum__.add((normal_log(smooth_sd_raw,0,1) - log_half));
                            } else if (as_bool(logical_eq(prior_dist_for_smooth,2))) {
                                current_statement_begin__ = 684;
                                lp_accum__.add((student_t_log(smooth_sd_raw,prior_df_for_smooth,0,1) - log_half));
                            } else if (as_bool(logical_eq(prior_dist_for_smooth,3))) {
                                current_statement_begin__ = 686;
                                lp_accum__.add(exponential_log(smooth_sd_raw,1));
                            }
                        }
                    }
                }
                current_statement_begin__ = 689;
                if (as_bool(logical_gt(t,0))) {
                    current_statement_begin__ = 689;
                    decov_lp(z_b,z_T,rho,zeta,tau,regularization,delta,shape,t,p, lp__, lp_accum__, pstream__);
                }
                current_statement_begin__ = 690;
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        lp_accum__.add(lp__);
        return lp_accum__.sum();

    } // log_prob()

    template <bool propto, bool jacobian, typename T_>
    T_ log_prob(Eigen::Matrix<T_,Eigen::Dynamic,1>& params_r,
               std::ostream* pstream = 0) const {
      std::vector<T_> vec_params_r;
      vec_params_r.reserve(params_r.size());
      for (int i = 0; i < params_r.size(); ++i)
        vec_params_r.push_back(params_r(i));
      std::vector<int> vec_params_i;
      return log_prob<propto,jacobian,T_>(vec_params_r, vec_params_i, pstream);
    }


    void get_param_names(std::vector<std::string>& names__) const {
        names__.resize(0);
        names__.push_back("gamma");
        names__.push_back("z_beta");
        names__.push_back("z_beta_smooth");
        names__.push_back("smooth_sd_raw");
        names__.push_back("global");
        names__.push_back("local");
        names__.push_back("mix");
        names__.push_back("one_over_lambda");
        names__.push_back("z_b");
        names__.push_back("z_T");
        names__.push_back("rho");
        names__.push_back("zeta");
        names__.push_back("tau");
        names__.push_back("beta");
        names__.push_back("beta_smooth");
        names__.push_back("smooth_sd");
        names__.push_back("b");
        names__.push_back("theta_L");
        names__.push_back("alpha");
        names__.push_back("mean_PPD");
    }


    void get_dims(std::vector<std::vector<size_t> >& dimss__) const {
        dimss__.resize(0);
        std::vector<size_t> dims__;
        dims__.resize(0);
        dims__.push_back(has_intercept);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((logical_eq(prior_dist,7) ? sum(num_normals) : K ));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(K_smooth);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(hs);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(hs);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))));
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(logical_eq(prior_dist,6));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(q);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(len_z_T);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(len_rho);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(len_concentration);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(t);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(K_smooth);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(q);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(len_theta_L);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(has_intercept);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dimss__.push_back(dims__);
    }

    template <typename RNG>
    void write_array(RNG& base_rng__,
                     std::vector<double>& params_r__,
                     std::vector<int>& params_i__,
                     std::vector<double>& vars__,
                     bool include_tparams__ = true,
                     bool include_gqs__ = true,
                     std::ostream* pstream__ = 0) const {
        vars__.resize(0);
        stan::io::reader<double> in__(params_r__,params_i__);
        static const char* function__ = "model_bernoulli_namespace::write_array";
        (void) function__;  // dummy to suppress unused var warning
        // read-transform, write parameters
        vector<double> gamma;
        size_t dim_gamma_0__ = has_intercept;
        for (size_t k_0__ = 0; k_0__ < dim_gamma_0__; ++k_0__) {
            gamma.push_back(in__.scalar_ub_constrain((logical_eq(link,4) ? 0.0 : stan::math::positive_infinity() )));
        }
        vector_d z_beta = in__.vector_constrain((logical_eq(prior_dist,7) ? sum(num_normals) : K ));
        vector_d z_beta_smooth = in__.vector_constrain(K_smooth);
        vector_d smooth_sd_raw = in__.vector_lb_constrain(0,(logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));
        vector<double> global;
        size_t dim_global_0__ = hs;
        for (size_t k_0__ = 0; k_0__ < dim_global_0__; ++k_0__) {
            global.push_back(in__.scalar_lb_constrain(0));
        }
        vector<vector_d> local;
        size_t dim_local_0__ = hs;
        for (size_t k_0__ = 0; k_0__ < dim_local_0__; ++k_0__) {
            local.push_back(in__.vector_lb_constrain(0,K));
        }
        vector<vector_d> mix;
        size_t dim_mix_0__ = (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6)));
        for (size_t k_0__ = 0; k_0__ < dim_mix_0__; ++k_0__) {
            mix.push_back(in__.vector_lb_constrain(0,K));
        }
        vector<double> one_over_lambda;
        size_t dim_one_over_lambda_0__ = logical_eq(prior_dist,6);
        for (size_t k_0__ = 0; k_0__ < dim_one_over_lambda_0__; ++k_0__) {
            one_over_lambda.push_back(in__.scalar_lb_constrain(0));
        }
        vector_d z_b = in__.vector_constrain(q);
        vector_d z_T = in__.vector_constrain(len_z_T);
        vector_d rho = in__.vector_lub_constrain(0,1,len_rho);
        vector_d zeta = in__.vector_lb_constrain(0,len_concentration);
        vector_d tau = in__.vector_lb_constrain(0,t);
        for (int k_0__ = 0; k_0__ < has_intercept; ++k_0__) {
            vars__.push_back(gamma[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < (logical_eq(prior_dist,7) ? sum(num_normals) : K ); ++k_0__) {
            vars__.push_back(z_beta[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < K_smooth; ++k_0__) {
            vars__.push_back(z_beta_smooth[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++k_0__) {
            vars__.push_back(smooth_sd_raw[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < hs; ++k_0__) {
            vars__.push_back(global[k_0__]);
        }
        for (int k_1__ = 0; k_1__ < K; ++k_1__) {
            for (int k_0__ = 0; k_0__ < hs; ++k_0__) {
                vars__.push_back(local[k_0__][k_1__]);
            }
        }
        for (int k_1__ = 0; k_1__ < K; ++k_1__) {
            for (int k_0__ = 0; k_0__ < (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))); ++k_0__) {
                vars__.push_back(mix[k_0__][k_1__]);
            }
        }
        for (int k_0__ = 0; k_0__ < logical_eq(prior_dist,6); ++k_0__) {
            vars__.push_back(one_over_lambda[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < q; ++k_0__) {
            vars__.push_back(z_b[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < len_z_T; ++k_0__) {
            vars__.push_back(z_T[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < len_rho; ++k_0__) {
            vars__.push_back(rho[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < len_concentration; ++k_0__) {
            vars__.push_back(zeta[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < t; ++k_0__) {
            vars__.push_back(tau[k_0__]);
        }

        if (!include_tparams__) return;
        // declare and define transformed parameters
        double lp__ = 0.0;
        (void) lp__;  // dummy to suppress unused var warning
        stan::math::accumulator<double> lp_accum__;

        double DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

        validate_non_negative_index("beta", "K", K);
        vector_d beta(static_cast<Eigen::VectorXd::Index>(K));
        (void) beta;  // dummy to suppress unused var warning

        stan::math::initialize(beta, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(beta,DUMMY_VAR__);
        validate_non_negative_index("beta_smooth", "K_smooth", K_smooth);
        vector_d beta_smooth(static_cast<Eigen::VectorXd::Index>(K_smooth));
        (void) beta_smooth;  // dummy to suppress unused var warning

        stan::math::initialize(beta_smooth, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(beta_smooth,DUMMY_VAR__);
        validate_non_negative_index("smooth_sd", "(logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,\"smooth_map\",1) : 0 )", (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));
        vector_d smooth_sd(static_cast<Eigen::VectorXd::Index>((logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 )));
        (void) smooth_sd;  // dummy to suppress unused var warning

        stan::math::initialize(smooth_sd, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(smooth_sd,DUMMY_VAR__);
        validate_non_negative_index("b", "q", q);
        vector_d b(static_cast<Eigen::VectorXd::Index>(q));
        (void) b;  // dummy to suppress unused var warning

        stan::math::initialize(b, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(b,DUMMY_VAR__);
        validate_non_negative_index("theta_L", "len_theta_L", len_theta_L);
        vector_d theta_L(static_cast<Eigen::VectorXd::Index>(len_theta_L));
        (void) theta_L;  // dummy to suppress unused var warning

        stan::math::initialize(theta_L, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(theta_L,DUMMY_VAR__);


        try {
            current_statement_begin__ = 512;
            if (as_bool(logical_eq(prior_dist,0))) {
                current_statement_begin__ = 512;
                stan::math::assign(beta, z_beta);
            } else if (as_bool(logical_eq(prior_dist,1))) {
                current_statement_begin__ = 513;
                stan::math::assign(beta, add(elt_multiply(z_beta,prior_scale),prior_mean));
            } else if (as_bool(logical_eq(prior_dist,2))) {
                current_statement_begin__ = 514;
                for (int k = 1; k <= K; ++k) {

                    current_statement_begin__ = 515;
                    stan::math::assign(get_base1_lhs(beta,k,"beta",1), ((CFt(get_base1(z_beta,k,"z_beta",1),get_base1(prior_df,k,"prior_df",1), pstream__) * get_base1(prior_scale,k,"prior_scale",1)) + get_base1(prior_mean,k,"prior_mean",1)));
                }
            } else if (as_bool(logical_eq(prior_dist,3))) {

                current_statement_begin__ = 518;
                if (as_bool((primitive_value(logical_eq(is_continuous,1)) && primitive_value(logical_eq(family,1))))) {
                    current_statement_begin__ = 519;
                    stan::math::assign(beta, hs_prior(z_beta,global,local,global_prior_scale,aux, pstream__));
                } else {
                    current_statement_begin__ = 520;
                    stan::math::assign(beta, hs_prior(z_beta,global,local,global_prior_scale,1, pstream__));
                }
            } else if (as_bool(logical_eq(prior_dist,4))) {

                current_statement_begin__ = 523;
                if (as_bool((primitive_value(logical_eq(is_continuous,1)) && primitive_value(logical_eq(family,1))))) {
                    current_statement_begin__ = 524;
                    stan::math::assign(beta, hsplus_prior(z_beta,global,local,global_prior_scale,aux, pstream__));
                } else {
                    current_statement_begin__ = 525;
                    stan::math::assign(beta, hsplus_prior(z_beta,global,local,global_prior_scale,1, pstream__));
                }
            } else if (as_bool(logical_eq(prior_dist,5))) {
                current_statement_begin__ = 528;
                stan::math::assign(beta, add(prior_mean,elt_multiply(elt_multiply(prior_scale,sqrt(multiply(2,get_base1(mix,1,"mix",1)))),z_beta)));
            } else if (as_bool(logical_eq(prior_dist,6))) {
                current_statement_begin__ = 530;
                stan::math::assign(beta, add(prior_mean,elt_multiply(elt_multiply(multiply(get_base1(one_over_lambda,1,"one_over_lambda",1),prior_scale),sqrt(multiply(2,get_base1(mix,1,"mix",1)))),z_beta)));
            } else if (as_bool(logical_eq(prior_dist,7))) {
                {
                    int z_pos(0);
                    (void) z_pos;  // dummy to suppress unused var warning

                    stan::math::fill(z_pos, std::numeric_limits<int>::min());
                    stan::math::assign(z_pos,1);


                    current_statement_begin__ = 533;
                    for (int k = 1; k <= K; ++k) {

                        current_statement_begin__ = 534;
                        stan::math::assign(get_base1_lhs(beta,k,"beta",1), get_base1(z_beta,z_pos,"z_beta",1));
                        current_statement_begin__ = 535;
                        stan::math::assign(z_pos, (z_pos + 1));
                        current_statement_begin__ = 536;
                        for (int n = 2; n <= get_base1(num_normals,k,"num_normals",1); ++n) {

                            current_statement_begin__ = 537;
                            stan::math::assign(get_base1_lhs(beta,k,"beta",1), (get_base1(beta,k,"beta",1) * get_base1(z_beta,z_pos,"z_beta",1)));
                            current_statement_begin__ = 538;
                            stan::math::assign(z_pos, (z_pos + 1));
                        }
                        current_statement_begin__ = 540;
                        stan::math::assign(get_base1_lhs(beta,k,"beta",1), ((get_base1(beta,k,"beta",1) * pow(get_base1(prior_scale,k,"prior_scale",1),get_base1(num_normals,k,"num_normals",1))) + get_base1(prior_mean,k,"prior_mean",1)));
                    }
                }
            }
            current_statement_begin__ = 544;
            if (as_bool(K_smooth)) {

                current_statement_begin__ = 545;
                stan::math::assign(smooth_sd, add(prior_mean_for_smooth,elt_multiply(prior_scale_for_smooth,smooth_sd_raw)));
                current_statement_begin__ = 546;
                if (as_bool((primitive_value(is_continuous) && primitive_value(logical_eq(family,1))))) {
                    current_statement_begin__ = 546;
                    stan::math::assign(smooth_sd, multiply(smooth_sd,aux));
                }
                current_statement_begin__ = 547;
                stan::math::assign(beta_smooth, elt_multiply(z_beta_smooth,stan::model::rvalue(smooth_sd, stan::model::cons_list(stan::model::index_multi(smooth_map), stan::model::nil_index_list()), "smooth_sd")));
            }
            current_statement_begin__ = 549;
            if (as_bool(logical_gt(t,0))) {

                current_statement_begin__ = 550;
                if (as_bool(special_case)) {
                    {
                        int start(0);
                        (void) start;  // dummy to suppress unused var warning

                        stan::math::fill(start, std::numeric_limits<int>::min());
                        stan::math::assign(start,1);


                        current_statement_begin__ = 552;
                        stan::math::assign(theta_L, elt_multiply(scale,tau));
                        current_statement_begin__ = 553;
                        if (as_bool(logical_eq(t,1))) {
                            current_statement_begin__ = 553;
                            stan::math::assign(b, multiply(get_base1(theta_L,1,"theta_L",1),z_b));
                        } else {
                            current_statement_begin__ = 554;
                            for (int i = 1; i <= t; ++i) {
                                {
                                    int end(0);
                                    (void) end;  // dummy to suppress unused var warning

                                    stan::math::fill(end, std::numeric_limits<int>::min());
                                    stan::math::assign(end,((start + get_base1(l,i,"l",1)) - 1));


                                    current_statement_begin__ = 556;
                                    stan::model::assign(b, 
                                                stan::model::cons_list(stan::model::index_min_max(start, end), stan::model::nil_index_list()), 
                                                multiply(get_base1(theta_L,i,"theta_L",1),stan::model::rvalue(z_b, stan::model::cons_list(stan::model::index_min_max(start, end), stan::model::nil_index_list()), "z_b")), 
                                                "assigning variable b");
                                    current_statement_begin__ = 557;
                                    stan::math::assign(start, (end + 1));
                                }
                            }
                        }
                    }
                } else {

                    current_statement_begin__ = 561;
                    stan::math::assign(theta_L, make_theta_L(len_theta_L,p,1.0,tau,scale,zeta,rho,z_T, pstream__));
                    current_statement_begin__ = 563;
                    stan::math::assign(b, make_b(z_b,theta_L,p,l, pstream__));
                }
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        // validate transformed parameters

        // write transformed parameters
        for (int k_0__ = 0; k_0__ < K; ++k_0__) {
            vars__.push_back(beta[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < K_smooth; ++k_0__) {
            vars__.push_back(beta_smooth[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++k_0__) {
            vars__.push_back(smooth_sd[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < q; ++k_0__) {
            vars__.push_back(b[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < len_theta_L; ++k_0__) {
            vars__.push_back(theta_L[k_0__]);
        }

        if (!include_gqs__) return;
        // declare and define generated quantities
        validate_non_negative_index("alpha", "has_intercept", has_intercept);
        vector<double> alpha(has_intercept, 0.0);
        stan::math::initialize(alpha, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(alpha,DUMMY_VAR__);
        double mean_PPD(0.0);
        (void) mean_PPD;  // dummy to suppress unused var warning

        stan::math::initialize(mean_PPD, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(mean_PPD,DUMMY_VAR__);
        stan::math::assign(mean_PPD,0);


        try {
            current_statement_begin__ = 695;
            if (as_bool(logical_eq(has_intercept,1))) {

                current_statement_begin__ = 696;
                if (as_bool(dense_X)) {
                    current_statement_begin__ = 696;
                    stan::math::assign(get_base1_lhs(alpha,1,"alpha",1), (get_base1(gamma,1,"gamma",1) - dot_product(xbar,beta)));
                } else {
                    current_statement_begin__ = 697;
                    stan::math::assign(get_base1_lhs(alpha,1,"alpha",1), get_base1(gamma,1,"gamma",1));
                }
            }
            {
                validate_non_negative_index("pi0", "get_base1(N,1,\"N\",1)", get_base1(N,1,"N",1));
                vector_d pi0(static_cast<Eigen::VectorXd::Index>(get_base1(N,1,"N",1)));
                (void) pi0;  // dummy to suppress unused var warning

                stan::math::initialize(pi0, std::numeric_limits<double>::quiet_NaN());
                stan::math::fill(pi0,DUMMY_VAR__);
                validate_non_negative_index("pi1", "get_base1(N,2,\"N\",1)", get_base1(N,2,"N",1));
                vector_d pi1(static_cast<Eigen::VectorXd::Index>(get_base1(N,2,"N",1)));
                (void) pi1;  // dummy to suppress unused var warning

                stan::math::initialize(pi1, std::numeric_limits<double>::quiet_NaN());
                stan::math::fill(pi1,DUMMY_VAR__);
                validate_non_negative_index("eta0", "get_base1(N,1,\"N\",1)", get_base1(N,1,"N",1));
                vector_d eta0(static_cast<Eigen::VectorXd::Index>(get_base1(N,1,"N",1)));
                (void) eta0;  // dummy to suppress unused var warning

                stan::math::initialize(eta0, std::numeric_limits<double>::quiet_NaN());
                stan::math::fill(eta0,DUMMY_VAR__);
                validate_non_negative_index("eta1", "get_base1(N,2,\"N\",1)", get_base1(N,2,"N",1));
                vector_d eta1(static_cast<Eigen::VectorXd::Index>(get_base1(N,2,"N",1)));
                (void) eta1;  // dummy to suppress unused var warning

                stan::math::initialize(eta1, std::numeric_limits<double>::quiet_NaN());
                stan::math::fill(eta1,DUMMY_VAR__);


                current_statement_begin__ = 705;
                if (as_bool(logical_gt(K,0))) {

                    current_statement_begin__ = 706;
                    if (as_bool(dense_X)) {

                        current_statement_begin__ = 707;
                        stan::math::assign(eta0, multiply(get_base1(X0,1,"X0",1),beta));
                        current_statement_begin__ = 708;
                        stan::math::assign(eta1, multiply(get_base1(X1,1,"X1",1),beta));
                    } else {

                        current_statement_begin__ = 711;
                        stan::math::assign(eta0, csr_matrix_times_vector(get_base1(N,1,"N",1),K,w_X0,v_X0,u_X0,beta));
                        current_statement_begin__ = 712;
                        stan::math::assign(eta1, csr_matrix_times_vector(get_base1(N,2,"N",1),K,w_X1,v_X1,u_X1,beta));
                    }
                } else {

                    current_statement_begin__ = 716;
                    stan::math::assign(eta0, rep_vector(0.0,get_base1(N,1,"N",1)));
                    current_statement_begin__ = 717;
                    stan::math::assign(eta1, rep_vector(0.0,get_base1(N,2,"N",1)));
                }
                current_statement_begin__ = 719;
                if (as_bool((primitive_value(logical_eq(has_intercept,0)) && primitive_value(dense_X)))) {
                    {
                        double tmp(0.0);
                        (void) tmp;  // dummy to suppress unused var warning

                        stan::math::initialize(tmp, std::numeric_limits<double>::quiet_NaN());
                        stan::math::fill(tmp,DUMMY_VAR__);


                        current_statement_begin__ = 721;
                        stan::math::assign(tmp, dot_product(xbar,beta));
                        current_statement_begin__ = 722;
                        stan::math::assign(eta0, add(eta0,tmp));
                        current_statement_begin__ = 723;
                        stan::math::assign(eta1, add(eta1,tmp));
                    }
                }
                current_statement_begin__ = 725;
                if (as_bool(logical_eq(has_offset,1))) {

                    current_statement_begin__ = 726;
                    stan::math::assign(eta0, add(eta0,offset0));
                    current_statement_begin__ = 727;
                    stan::math::assign(eta1, add(eta1,offset1));
                }
                current_statement_begin__ = 729;
                if (as_bool(K_smooth)) {

                    current_statement_begin__ = 730;
                    stan::math::assign(eta0, add(eta0,multiply(S0,beta_smooth)));
                    current_statement_begin__ = 731;
                    stan::math::assign(eta1, add(eta1,multiply(S1,beta_smooth)));
                }
                current_statement_begin__ = 733;
                if (as_bool(special_case)) {
                    current_statement_begin__ = 733;
                    for (int i = 1; i <= t; ++i) {

                        current_statement_begin__ = 734;
                        stan::math::assign(eta0, add(eta0,stan::model::rvalue(b, stan::model::cons_list(stan::model::index_multi(get_base1(V0,i,"V0",1)), stan::model::nil_index_list()), "b")));
                        current_statement_begin__ = 735;
                        stan::math::assign(eta1, add(eta1,stan::model::rvalue(b, stan::model::cons_list(stan::model::index_multi(get_base1(V1,i,"V1",1)), stan::model::nil_index_list()), "b")));
                    }
                } else if (as_bool(logical_gt(t,0))) {

                    current_statement_begin__ = 738;
                    stan::math::assign(eta0, add(eta0,csr_matrix_times_vector(get_base1(N,1,"N",1),q,w0,v0,u0,b)));
                    current_statement_begin__ = 739;
                    stan::math::assign(eta1, add(eta1,csr_matrix_times_vector(get_base1(N,2,"N",1),q,w1,v1,u1,b)));
                }
                current_statement_begin__ = 741;
                if (as_bool(logical_eq(has_intercept,1))) {

                    current_statement_begin__ = 742;
                    if (as_bool(logical_neq(link,4))) {

                        current_statement_begin__ = 743;
                        stan::math::assign(eta0, add(get_base1(gamma,1,"gamma",1),eta0));
                        current_statement_begin__ = 744;
                        stan::math::assign(eta1, add(get_base1(gamma,1,"gamma",1),eta1));
                    } else {
                        {
                            double shift(0.0);
                            (void) shift;  // dummy to suppress unused var warning

                            stan::math::initialize(shift, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(shift,DUMMY_VAR__);


                            current_statement_begin__ = 748;
                            stan::math::assign(shift, stan::math::fmax(max(eta0),max(eta1)));
                            current_statement_begin__ = 749;
                            stan::math::assign(eta0, subtract(add(get_base1(gamma,1,"gamma",1),eta0),shift));
                            current_statement_begin__ = 750;
                            stan::math::assign(eta1, subtract(add(get_base1(gamma,1,"gamma",1),eta1),shift));
                            current_statement_begin__ = 751;
                            stan::math::assign(get_base1_lhs(alpha,1,"alpha",1), (get_base1(alpha,1,"alpha",1) - shift));
                        }
                    }
                }
                current_statement_begin__ = 754;
                stan::math::assign(pi0, linkinv_bern(eta0,link, pstream__));
                current_statement_begin__ = 755;
                stan::math::assign(pi1, linkinv_bern(eta1,link, pstream__));
                current_statement_begin__ = 756;
                for (int n = 1; n <= get_base1(N,1,"N",1); ++n) {
                    current_statement_begin__ = 756;
                    stan::math::assign(mean_PPD, (mean_PPD + bernoulli_rng(get_base1(pi0,n,"pi0",1), base_rng__)));
                }
                current_statement_begin__ = 757;
                for (int n = 1; n <= get_base1(N,2,"N",1); ++n) {
                    current_statement_begin__ = 757;
                    stan::math::assign(mean_PPD, (mean_PPD + bernoulli_rng(get_base1(pi1,n,"pi1",1), base_rng__)));
                }
                current_statement_begin__ = 758;
                stan::math::assign(mean_PPD, (mean_PPD / NN));
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        // validate generated quantities

        // write generated quantities
        for (int k_0__ = 0; k_0__ < has_intercept; ++k_0__) {
            vars__.push_back(alpha[k_0__]);
        }
        vars__.push_back(mean_PPD);

    }

    template <typename RNG>
    void write_array(RNG& base_rng,
                     Eigen::Matrix<double,Eigen::Dynamic,1>& params_r,
                     Eigen::Matrix<double,Eigen::Dynamic,1>& vars,
                     bool include_tparams = true,
                     bool include_gqs = true,
                     std::ostream* pstream = 0) const {
      std::vector<double> params_r_vec(params_r.size());
      for (int i = 0; i < params_r.size(); ++i)
        params_r_vec[i] = params_r(i);
      std::vector<double> vars_vec;
      std::vector<int> params_i_vec;
      write_array(base_rng,params_r_vec,params_i_vec,vars_vec,include_tparams,include_gqs,pstream);
      vars.resize(vars_vec.size());
      for (int i = 0; i < vars.size(); ++i)
        vars(i) = vars_vec[i];
    }

    static std::string model_name() {
        return "model_bernoulli";
    }


    void constrained_param_names(std::vector<std::string>& param_names__,
                                 bool include_tparams__ = true,
                                 bool include_gqs__ = true) const {
        std::stringstream param_name_stream__;
        for (int k_0__ = 1; k_0__ <= has_intercept; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "gamma" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (logical_eq(prior_dist,7) ? sum(num_normals) : K ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_beta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= K_smooth; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_beta_smooth" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "smooth_sd_raw" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= hs; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "global" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_1__ = 1; k_1__ <= K; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= hs; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "local" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        for (int k_1__ = 1; k_1__ <= K; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))); ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "mix" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        for (int k_0__ = 1; k_0__ <= logical_eq(prior_dist,6); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "one_over_lambda" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= q; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_b" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_z_T; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_T" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_rho; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "rho" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_concentration; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "zeta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= t; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "tau" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__ && !include_tparams__) return;
        for (int k_0__ = 1; k_0__ <= K; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "beta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= K_smooth; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "beta_smooth" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "smooth_sd" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= q; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "b" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_theta_L; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "theta_L" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__) return;
        for (int k_0__ = 1; k_0__ <= has_intercept; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "alpha" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        param_name_stream__.str(std::string());
        param_name_stream__ << "mean_PPD";
        param_names__.push_back(param_name_stream__.str());
    }


    void unconstrained_param_names(std::vector<std::string>& param_names__,
                                   bool include_tparams__ = true,
                                   bool include_gqs__ = true) const {
        std::stringstream param_name_stream__;
        for (int k_0__ = 1; k_0__ <= has_intercept; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "gamma" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (logical_eq(prior_dist,7) ? sum(num_normals) : K ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_beta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= K_smooth; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_beta_smooth" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "smooth_sd_raw" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= hs; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "global" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_1__ = 1; k_1__ <= K; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= hs; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "local" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        for (int k_1__ = 1; k_1__ <= K; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))); ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "mix" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        for (int k_0__ = 1; k_0__ <= logical_eq(prior_dist,6); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "one_over_lambda" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= q; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_b" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_z_T; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_T" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_rho; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "rho" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_concentration; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "zeta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= t; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "tau" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__ && !include_tparams__) return;
        for (int k_0__ = 1; k_0__ <= K; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "beta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= K_smooth; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "beta_smooth" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "smooth_sd" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= q; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "b" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_theta_L; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "theta_L" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__) return;
        for (int k_0__ = 1; k_0__ <= has_intercept; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "alpha" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        param_name_stream__.str(std::string());
        param_name_stream__ << "mean_PPD";
        param_names__.push_back(param_name_stream__.str());
    }

}; // model

}




// Code generated by Stan version 2.16.0

#include <stan/model/model_header.hpp>

namespace model_binomial_namespace {

using std::istream;
using std::string;
using std::stringstream;
using std::vector;
using stan::io::dump;
using stan::math::lgamma;
using stan::model::prob_grad;
using namespace stan::math;

typedef Eigen::Matrix<double,Eigen::Dynamic,1> vector_d;
typedef Eigen::Matrix<double,1,Eigen::Dynamic> row_vector_d;
typedef Eigen::Matrix<double,Eigen::Dynamic,Eigen::Dynamic> matrix_d;

static int current_statement_begin__;

stan::io::program_reader prog_reader__() {
    stan::io::program_reader reader;
    reader.add_event(0, 0, "start", "model_binomial");
    reader.add_event(690, 690, "end", "model_binomial");
    return reader;
}

template <typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T7__>
Eigen::Matrix<typename boost::math::tools::promote_args<T2__, T3__, T4__, T5__, typename boost::math::tools::promote_args<T6__, T7__>::type>::type, Eigen::Dynamic,1>
make_theta_L(const int& len_theta_L,
                 const std::vector<int>& p,
                 const T2__& dispersion,
                 const Eigen::Matrix<T3__, Eigen::Dynamic,1>& tau,
                 const Eigen::Matrix<T4__, Eigen::Dynamic,1>& scale,
                 const Eigen::Matrix<T5__, Eigen::Dynamic,1>& zeta,
                 const Eigen::Matrix<T6__, Eigen::Dynamic,1>& rho,
                 const Eigen::Matrix<T7__, Eigen::Dynamic,1>& z_T, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T2__, T3__, T4__, T5__, typename boost::math::tools::promote_args<T6__, T7__>::type>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            validate_non_negative_index("theta_L", "len_theta_L", len_theta_L);
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  theta_L(static_cast<Eigen::VectorXd::Index>(len_theta_L));
            (void) theta_L;  // dummy to suppress unused var warning

            stan::math::initialize(theta_L, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(theta_L,DUMMY_VAR__);
            int zeta_mark(0);
            (void) zeta_mark;  // dummy to suppress unused var warning

            stan::math::fill(zeta_mark, std::numeric_limits<int>::min());
            stan::math::assign(zeta_mark,1);
            int rho_mark(0);
            (void) rho_mark;  // dummy to suppress unused var warning

            stan::math::fill(rho_mark, std::numeric_limits<int>::min());
            stan::math::assign(rho_mark,1);
            int z_T_mark(0);
            (void) z_T_mark;  // dummy to suppress unused var warning

            stan::math::fill(z_T_mark, std::numeric_limits<int>::min());
            stan::math::assign(z_T_mark,1);
            int theta_L_mark(0);
            (void) theta_L_mark;  // dummy to suppress unused var warning

            stan::math::fill(theta_L_mark, std::numeric_limits<int>::min());
            stan::math::assign(theta_L_mark,1);


            current_statement_begin__ = 52;
            for (int i = 1; i <= size(p); ++i) {
                {
                    int nc(0);
                    (void) nc;  // dummy to suppress unused var warning

                    stan::math::fill(nc, std::numeric_limits<int>::min());
                    stan::math::assign(nc,get_base1(p,i,"p",1));


                    current_statement_begin__ = 54;
                    if (as_bool(logical_eq(nc,1))) {

                        current_statement_begin__ = 55;
                        stan::math::assign(get_base1_lhs(theta_L,theta_L_mark,"theta_L",1), ((get_base1(tau,i,"tau",1) * get_base1(scale,i,"scale",1)) * dispersion));
                        current_statement_begin__ = 57;
                        stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                    } else {
                        {
                            validate_non_negative_index("T_i", "nc", nc);
                            validate_non_negative_index("T_i", "nc", nc);
                            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,Eigen::Dynamic>  T_i(static_cast<Eigen::VectorXd::Index>(nc),static_cast<Eigen::VectorXd::Index>(nc));
                            (void) T_i;  // dummy to suppress unused var warning

                            stan::math::initialize(T_i, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(T_i,DUMMY_VAR__);
                            fun_scalar_t__ std_dev;
                            (void) std_dev;  // dummy to suppress unused var warning

                            stan::math::initialize(std_dev, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(std_dev,DUMMY_VAR__);
                            fun_scalar_t__ T21;
                            (void) T21;  // dummy to suppress unused var warning

                            stan::math::initialize(T21, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(T21,DUMMY_VAR__);
                            fun_scalar_t__ trace_T_i;
                            (void) trace_T_i;  // dummy to suppress unused var warning

                            stan::math::initialize(trace_T_i, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(trace_T_i,DUMMY_VAR__);
                            stan::math::assign(trace_T_i,(square(((get_base1(tau,i,"tau",1) * get_base1(scale,i,"scale",1)) * dispersion)) * nc));
                            validate_non_negative_index("pi", "nc", nc);
                            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  pi(static_cast<Eigen::VectorXd::Index>(nc));
                            (void) pi;  // dummy to suppress unused var warning

                            stan::math::initialize(pi, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(pi,DUMMY_VAR__);
                            stan::math::assign(pi,segment(zeta,zeta_mark,nc));


                            current_statement_begin__ = 65;
                            stan::math::assign(pi, divide(pi,sum(pi)));
                            current_statement_begin__ = 68;
                            stan::math::assign(zeta_mark, (zeta_mark + nc));
                            current_statement_begin__ = 69;
                            stan::math::assign(std_dev, sqrt((get_base1(pi,1,"pi",1) * trace_T_i)));
                            current_statement_begin__ = 70;
                            stan::math::assign(get_base1_lhs(T_i,1,1,"T_i",1), std_dev);
                            current_statement_begin__ = 73;
                            stan::math::assign(std_dev, sqrt((get_base1(pi,2,"pi",1) * trace_T_i)));
                            current_statement_begin__ = 74;
                            stan::math::assign(T21, ((2.0 * get_base1(rho,rho_mark,"rho",1)) - 1.0));
                            current_statement_begin__ = 75;
                            stan::math::assign(rho_mark, (rho_mark + 1));
                            current_statement_begin__ = 76;
                            stan::math::assign(get_base1_lhs(T_i,2,2,"T_i",1), (std_dev * sqrt((1.0 - square(T21)))));
                            current_statement_begin__ = 77;
                            stan::math::assign(get_base1_lhs(T_i,2,1,"T_i",1), (std_dev * T21));
                            current_statement_begin__ = 79;
                            for (int r = 2; r <= (nc - 1); ++r) {
                                {
                                    int rp1(0);
                                    (void) rp1;  // dummy to suppress unused var warning

                                    stan::math::fill(rp1, std::numeric_limits<int>::min());
                                    stan::math::assign(rp1,(r + 1));
                                    validate_non_negative_index("T_row", "r", r);
                                    Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  T_row(static_cast<Eigen::VectorXd::Index>(r));
                                    (void) T_row;  // dummy to suppress unused var warning

                                    stan::math::initialize(T_row, std::numeric_limits<double>::quiet_NaN());
                                    stan::math::fill(T_row,DUMMY_VAR__);
                                    stan::math::assign(T_row,segment(z_T,z_T_mark,r));
                                    fun_scalar_t__ scale_factor;
                                    (void) scale_factor;  // dummy to suppress unused var warning

                                    stan::math::initialize(scale_factor, std::numeric_limits<double>::quiet_NaN());
                                    stan::math::fill(scale_factor,DUMMY_VAR__);
                                    stan::math::assign(scale_factor,(sqrt((get_base1(rho,rho_mark,"rho",1) / dot_self(T_row))) * std_dev));


                                    current_statement_begin__ = 83;
                                    stan::math::assign(z_T_mark, (z_T_mark + r));
                                    current_statement_begin__ = 84;
                                    stan::math::assign(std_dev, sqrt((get_base1(pi,rp1,"pi",1) * trace_T_i)));
                                    current_statement_begin__ = 85;
                                    for (int c = 1; c <= r; ++c) {
                                        current_statement_begin__ = 85;
                                        stan::math::assign(get_base1_lhs(T_i,rp1,c,"T_i",1), (get_base1(T_row,c,"T_row",1) * scale_factor));
                                    }
                                    current_statement_begin__ = 86;
                                    stan::math::assign(get_base1_lhs(T_i,rp1,rp1,"T_i",1), (sqrt((1.0 - get_base1(rho,rho_mark,"rho",1))) * std_dev));
                                    current_statement_begin__ = 87;
                                    stan::math::assign(rho_mark, (rho_mark + 1));
                                }
                            }
                            current_statement_begin__ = 91;
                            for (int c = 1; c <= nc; ++c) {
                                current_statement_begin__ = 91;
                                for (int r = c; r <= nc; ++r) {

                                    current_statement_begin__ = 92;
                                    stan::math::assign(get_base1_lhs(theta_L,theta_L_mark,"theta_L",1), get_base1(T_i,r,c,"T_i",1));
                                    current_statement_begin__ = 93;
                                    stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                                }
                            }
                        }
                    }
                }
            }
            current_statement_begin__ = 97;
            return stan::math::promote_scalar<fun_return_scalar_t__>(theta_L);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct make_theta_L_functor__ {
    template <typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T7__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T2__, T3__, T4__, T5__, typename boost::math::tools::promote_args<T6__, T7__>::type>::type, Eigen::Dynamic,1>
    operator()(const int& len_theta_L,
                 const std::vector<int>& p,
                 const T2__& dispersion,
                 const Eigen::Matrix<T3__, Eigen::Dynamic,1>& tau,
                 const Eigen::Matrix<T4__, Eigen::Dynamic,1>& scale,
                 const Eigen::Matrix<T5__, Eigen::Dynamic,1>& zeta,
                 const Eigen::Matrix<T6__, Eigen::Dynamic,1>& rho,
                 const Eigen::Matrix<T7__, Eigen::Dynamic,1>& z_T, std::ostream* pstream__) const {
        return make_theta_L(len_theta_L, p, dispersion, tau, scale, zeta, rho, z_T, pstream__);
    }
};

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
make_b(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_b,
           const Eigen::Matrix<T1__, Eigen::Dynamic,1>& theta_L,
           const std::vector<int>& p,
           const std::vector<int>& l, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            validate_non_negative_index("b", "rows(z_b)", rows(z_b));
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  b(static_cast<Eigen::VectorXd::Index>(rows(z_b)));
            (void) b;  // dummy to suppress unused var warning

            stan::math::initialize(b, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(b,DUMMY_VAR__);
            int b_mark(0);
            (void) b_mark;  // dummy to suppress unused var warning

            stan::math::fill(b_mark, std::numeric_limits<int>::min());
            stan::math::assign(b_mark,1);
            int theta_L_mark(0);
            (void) theta_L_mark;  // dummy to suppress unused var warning

            stan::math::fill(theta_L_mark, std::numeric_limits<int>::min());
            stan::math::assign(theta_L_mark,1);


            current_statement_begin__ = 115;
            for (int i = 1; i <= size(p); ++i) {
                {
                    int nc(0);
                    (void) nc;  // dummy to suppress unused var warning

                    stan::math::fill(nc, std::numeric_limits<int>::min());
                    stan::math::assign(nc,get_base1(p,i,"p",1));


                    current_statement_begin__ = 117;
                    if (as_bool(logical_eq(nc,1))) {
                        {
                            fun_scalar_t__ theta_L_start;
                            (void) theta_L_start;  // dummy to suppress unused var warning

                            stan::math::initialize(theta_L_start, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(theta_L_start,DUMMY_VAR__);
                            stan::math::assign(theta_L_start,get_base1(theta_L,theta_L_mark,"theta_L",1));


                            current_statement_begin__ = 119;
                            for (int s = b_mark; s <= ((b_mark + get_base1(l,i,"l",1)) - 1); ++s) {
                                current_statement_begin__ = 120;
                                stan::math::assign(get_base1_lhs(b,s,"b",1), (theta_L_start * get_base1(z_b,s,"z_b",1)));
                            }
                            current_statement_begin__ = 121;
                            stan::math::assign(b_mark, (b_mark + get_base1(l,i,"l",1)));
                            current_statement_begin__ = 122;
                            stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                        }
                    } else {
                        {
                            validate_non_negative_index("T_i", "nc", nc);
                            validate_non_negative_index("T_i", "nc", nc);
                            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,Eigen::Dynamic>  T_i(static_cast<Eigen::VectorXd::Index>(nc),static_cast<Eigen::VectorXd::Index>(nc));
                            (void) T_i;  // dummy to suppress unused var warning

                            stan::math::initialize(T_i, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(T_i,DUMMY_VAR__);
                            stan::math::assign(T_i,rep_matrix(0,nc,nc));


                            current_statement_begin__ = 126;
                            for (int c = 1; c <= nc; ++c) {

                                current_statement_begin__ = 127;
                                stan::math::assign(get_base1_lhs(T_i,c,c,"T_i",1), get_base1(theta_L,theta_L_mark,"theta_L",1));
                                current_statement_begin__ = 128;
                                stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                                current_statement_begin__ = 129;
                                for (int r = (c + 1); r <= nc; ++r) {

                                    current_statement_begin__ = 130;
                                    stan::math::assign(get_base1_lhs(T_i,r,c,"T_i",1), get_base1(theta_L,theta_L_mark,"theta_L",1));
                                    current_statement_begin__ = 131;
                                    stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                                }
                            }
                            current_statement_begin__ = 134;
                            for (int j = 1; j <= get_base1(l,i,"l",1); ++j) {
                                {
                                    validate_non_negative_index("temp", "nc", nc);
                                    Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  temp(static_cast<Eigen::VectorXd::Index>(nc));
                                    (void) temp;  // dummy to suppress unused var warning

                                    stan::math::initialize(temp, std::numeric_limits<double>::quiet_NaN());
                                    stan::math::fill(temp,DUMMY_VAR__);
                                    stan::math::assign(temp,multiply(T_i,segment(z_b,b_mark,nc)));


                                    current_statement_begin__ = 136;
                                    stan::math::assign(b_mark, (b_mark - 1));
                                    current_statement_begin__ = 137;
                                    for (int s = 1; s <= nc; ++s) {
                                        current_statement_begin__ = 137;
                                        stan::math::assign(get_base1_lhs(b,(b_mark + s),"b",1), get_base1(temp,s,"temp",1));
                                    }
                                    current_statement_begin__ = 138;
                                    stan::math::assign(b_mark, ((b_mark + nc) + 1));
                                }
                            }
                        }
                    }
                }
            }
            current_statement_begin__ = 142;
            return stan::math::promote_scalar<fun_return_scalar_t__>(b);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct make_b_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_b,
           const Eigen::Matrix<T1__, Eigen::Dynamic,1>& theta_L,
           const std::vector<int>& p,
           const std::vector<int>& l, std::ostream* pstream__) const {
        return make_b(z_b, theta_L, p, l, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T7__, typename T_lp__, typename T_lp_accum__>
void
decov_lp(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_b,
             const Eigen::Matrix<T1__, Eigen::Dynamic,1>& z_T,
             const Eigen::Matrix<T2__, Eigen::Dynamic,1>& rho,
             const Eigen::Matrix<T3__, Eigen::Dynamic,1>& zeta,
             const Eigen::Matrix<T4__, Eigen::Dynamic,1>& tau,
             const std::vector<T5__>& regularization,
             const std::vector<T6__>& delta,
             const Eigen::Matrix<T7__, Eigen::Dynamic,1>& shape,
             const int& t,
             const std::vector<int>& p, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__, T6__, T7__, T_lp__>::type>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            int pos_reg(0);
            (void) pos_reg;  // dummy to suppress unused var warning

            stan::math::fill(pos_reg, std::numeric_limits<int>::min());
            stan::math::assign(pos_reg,1);
            int pos_rho(0);
            (void) pos_rho;  // dummy to suppress unused var warning

            stan::math::fill(pos_rho, std::numeric_limits<int>::min());
            stan::math::assign(pos_rho,1);


            current_statement_begin__ = 165;
            lp_accum__.add(normal_log(z_b,0,1));
            current_statement_begin__ = 166;
            lp_accum__.add(normal_log(z_T,0,1));
            current_statement_begin__ = 167;
            for (int i = 1; i <= t; ++i) {
                current_statement_begin__ = 167;
                if (as_bool(logical_gt(get_base1(p,i,"p",1),1))) {
                    {
                        validate_non_negative_index("shape1", "(get_base1(p,i,\"p\",1) - 1)", (get_base1(p,i,"p",1) - 1));
                        Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  shape1(static_cast<Eigen::VectorXd::Index>((get_base1(p,i,"p",1) - 1)));
                        (void) shape1;  // dummy to suppress unused var warning

                        stan::math::initialize(shape1, std::numeric_limits<double>::quiet_NaN());
                        stan::math::fill(shape1,DUMMY_VAR__);
                        validate_non_negative_index("shape2", "(get_base1(p,i,\"p\",1) - 1)", (get_base1(p,i,"p",1) - 1));
                        Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  shape2(static_cast<Eigen::VectorXd::Index>((get_base1(p,i,"p",1) - 1)));
                        (void) shape2;  // dummy to suppress unused var warning

                        stan::math::initialize(shape2, std::numeric_limits<double>::quiet_NaN());
                        stan::math::fill(shape2,DUMMY_VAR__);
                        fun_scalar_t__ nu;
                        (void) nu;  // dummy to suppress unused var warning

                        stan::math::initialize(nu, std::numeric_limits<double>::quiet_NaN());
                        stan::math::fill(nu,DUMMY_VAR__);
                        stan::math::assign(nu,(get_base1(regularization,pos_reg,"regularization",1) + (0.5 * (get_base1(p,i,"p",1) - 2))));


                        current_statement_begin__ = 171;
                        stan::math::assign(pos_reg, (pos_reg + 1));
                        current_statement_begin__ = 172;
                        stan::math::assign(get_base1_lhs(shape1,1,"shape1",1), nu);
                        current_statement_begin__ = 173;
                        stan::math::assign(get_base1_lhs(shape2,1,"shape2",1), nu);
                        current_statement_begin__ = 174;
                        for (int j = 2; j <= (get_base1(p,i,"p",1) - 1); ++j) {

                            current_statement_begin__ = 175;
                            stan::math::assign(nu, (nu - 0.5));
                            current_statement_begin__ = 176;
                            stan::math::assign(get_base1_lhs(shape1,j,"shape1",1), (0.5 * j));
                            current_statement_begin__ = 177;
                            stan::math::assign(get_base1_lhs(shape2,j,"shape2",1), nu);
                        }
                        current_statement_begin__ = 179;
                        lp_accum__.add(beta_log(stan::model::rvalue(rho, stan::model::cons_list(stan::model::index_min_max(pos_rho, ((pos_rho + get_base1(p,i,"p",1)) - 2)), stan::model::nil_index_list()), "rho"),shape1,shape2));
                        current_statement_begin__ = 180;
                        stan::math::assign(pos_rho, ((pos_rho + get_base1(p,i,"p",1)) - 1));
                    }
                }
            }
            current_statement_begin__ = 182;
            lp_accum__.add(gamma_log(zeta,delta,1));
            current_statement_begin__ = 183;
            lp_accum__.add(gamma_log(tau,shape,1));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct decov_lp_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T7__, typename T_lp__, typename T_lp_accum__>
        void
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_b,
             const Eigen::Matrix<T1__, Eigen::Dynamic,1>& z_T,
             const Eigen::Matrix<T2__, Eigen::Dynamic,1>& rho,
             const Eigen::Matrix<T3__, Eigen::Dynamic,1>& zeta,
             const Eigen::Matrix<T4__, Eigen::Dynamic,1>& tau,
             const std::vector<T5__>& regularization,
             const std::vector<T6__>& delta,
             const Eigen::Matrix<T7__, Eigen::Dynamic,1>& shape,
             const int& t,
             const std::vector<int>& p, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) const {
        return decov_lp(z_b, z_T, rho, zeta, tau, regularization, delta, shape, t, p, lp__, lp_accum__, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type, Eigen::Dynamic,1>
hs_prior(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_beta,
             const std::vector<T1__>& global,
             const std::vector<Eigen::Matrix<T2__, Eigen::Dynamic,1> >& local,
             const T3__& global_prior_scale,
             const T4__& error_scale, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            validate_non_negative_index("lambda", "rows(z_beta)", rows(z_beta));
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  lambda(static_cast<Eigen::VectorXd::Index>(rows(z_beta)));
            (void) lambda;  // dummy to suppress unused var warning

            stan::math::initialize(lambda, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(lambda,DUMMY_VAR__);
            int K(0);
            (void) K;  // dummy to suppress unused var warning

            stan::math::fill(K, std::numeric_limits<int>::min());


            current_statement_begin__ = 200;
            stan::math::assign(K, rows(z_beta));
            current_statement_begin__ = 201;
            for (int k = 1; k <= K; ++k) {
                current_statement_begin__ = 201;
                stan::math::assign(get_base1_lhs(lambda,k,"lambda",1), (get_base1(get_base1(local,1,"local",1),k,"local",2) * sqrt(get_base1(get_base1(local,2,"local",1),k,"local",2))));
            }
            current_statement_begin__ = 202;
            return stan::math::promote_scalar<fun_return_scalar_t__>(multiply(multiply(multiply(multiply(elt_multiply(z_beta,lambda),get_base1(global,1,"global",1)),sqrt(get_base1(global,2,"global",1))),global_prior_scale),error_scale));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct hs_prior_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_beta,
             const std::vector<T1__>& global,
             const std::vector<Eigen::Matrix<T2__, Eigen::Dynamic,1> >& local,
             const T3__& global_prior_scale,
             const T4__& error_scale, std::ostream* pstream__) const {
        return hs_prior(z_beta, global, local, global_prior_scale, error_scale, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type, Eigen::Dynamic,1>
hsplus_prior(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_beta,
                 const std::vector<T1__>& global,
                 const std::vector<Eigen::Matrix<T2__, Eigen::Dynamic,1> >& local,
                 const T3__& global_prior_scale,
                 const T4__& error_scale, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 218;
        return stan::math::promote_scalar<fun_return_scalar_t__>(multiply(multiply(multiply(multiply(elt_multiply(elt_multiply(z_beta,elt_multiply(get_base1(local,1,"local",1),sqrt(get_base1(local,2,"local",1)))),elt_multiply(get_base1(local,3,"local",1),sqrt(get_base1(local,4,"local",1)))),get_base1(global,1,"global",1)),sqrt(get_base1(global,2,"global",1))),global_prior_scale),error_scale));
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct hsplus_prior_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_beta,
                 const std::vector<T1__>& global,
                 const std::vector<Eigen::Matrix<T2__, Eigen::Dynamic,1> >& local,
                 const T3__& global_prior_scale,
                 const T4__& error_scale, std::ostream* pstream__) const {
        return hsplus_prior(z_beta, global, local, global_prior_scale, error_scale, pstream__);
    }
};

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
divide_real_by_vector(const T0__& x,
                          const Eigen::Matrix<T1__, Eigen::Dynamic,1>& y, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            int K(0);
            (void) K;  // dummy to suppress unused var warning

            stan::math::fill(K, std::numeric_limits<int>::min());
            stan::math::assign(K,rows(y));
            validate_non_negative_index("ret", "K", K);
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  ret(static_cast<Eigen::VectorXd::Index>(K));
            (void) ret;  // dummy to suppress unused var warning

            stan::math::initialize(ret, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(ret,DUMMY_VAR__);


            current_statement_begin__ = 233;
            for (int k = 1; k <= K; ++k) {
                current_statement_begin__ = 233;
                stan::math::assign(get_base1_lhs(ret,k,"ret",1), (x / get_base1(y,k,"y",1)));
            }
            current_statement_begin__ = 234;
            return stan::math::promote_scalar<fun_return_scalar_t__>(ret);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct divide_real_by_vector_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
    operator()(const T0__& x,
                          const Eigen::Matrix<T1__, Eigen::Dynamic,1>& y, std::ostream* pstream__) const {
        return divide_real_by_vector(x, y, pstream__);
    }
};

template <typename T0__, typename T1__>
typename boost::math::tools::promote_args<T0__, T1__>::type
CFt(const T0__& z,
        const T1__& df, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            fun_scalar_t__ z2;
            (void) z2;  // dummy to suppress unused var warning

            stan::math::initialize(z2, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(z2,DUMMY_VAR__);
            stan::math::assign(z2,square(z));
            fun_scalar_t__ z3;
            (void) z3;  // dummy to suppress unused var warning

            stan::math::initialize(z3, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(z3,DUMMY_VAR__);
            stan::math::assign(z3,(z2 * z));
            fun_scalar_t__ z5;
            (void) z5;  // dummy to suppress unused var warning

            stan::math::initialize(z5, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(z5,DUMMY_VAR__);
            stan::math::assign(z5,(z2 * z3));
            fun_scalar_t__ z7;
            (void) z7;  // dummy to suppress unused var warning

            stan::math::initialize(z7, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(z7,DUMMY_VAR__);
            stan::math::assign(z7,(z2 * z5));
            fun_scalar_t__ z9;
            (void) z9;  // dummy to suppress unused var warning

            stan::math::initialize(z9, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(z9,DUMMY_VAR__);
            stan::math::assign(z9,(z2 * z7));
            fun_scalar_t__ df2;
            (void) df2;  // dummy to suppress unused var warning

            stan::math::initialize(df2, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(df2,DUMMY_VAR__);
            stan::math::assign(df2,square(df));
            fun_scalar_t__ df3;
            (void) df3;  // dummy to suppress unused var warning

            stan::math::initialize(df3, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(df3,DUMMY_VAR__);
            stan::math::assign(df3,(df2 * df));
            fun_scalar_t__ df4;
            (void) df4;  // dummy to suppress unused var warning

            stan::math::initialize(df4, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(df4,DUMMY_VAR__);
            stan::math::assign(df4,(df2 * df2));


            current_statement_begin__ = 256;
            return stan::math::promote_scalar<fun_return_scalar_t__>(((((z + ((z3 + z) / (4 * df))) + ((((5 * z5) + (16 * z3)) + (3 * z)) / (96 * df2))) + (((((3 * z7) + (19 * z5)) + (17 * z3)) - (15 * z)) / (384 * df3))) + ((((((79 * z9) + (776 * z7)) + (1482 * z5)) - (1920 * z3)) - (945 * z)) / (92160 * df4))));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct CFt_functor__ {
    template <typename T0__, typename T1__>
        typename boost::math::tools::promote_args<T0__, T1__>::type
    operator()(const T0__& z,
        const T1__& df, std::ostream* pstream__) const {
        return CFt(z, df, pstream__);
    }
};

std::vector<std::vector<int> >
make_V(const int& N,
           const int& t,
           const std::vector<int>& v, std::ostream* pstream__) {
    typedef double fun_scalar_t__;
    typedef int fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            validate_non_negative_index("V", "t", t);
            validate_non_negative_index("V", "N", N);
            vector<vector<int> > V(t, (vector<int>(N, 0)));
            stan::math::fill(V, std::numeric_limits<int>::min());
            int pos(0);
            (void) pos;  // dummy to suppress unused var warning

            stan::math::fill(pos, std::numeric_limits<int>::min());
            stan::math::assign(pos,1);


            current_statement_begin__ = 271;
            if (as_bool(logical_gt(t,0))) {
                current_statement_begin__ = 271;
                for (int j = 1; j <= N; ++j) {
                    current_statement_begin__ = 271;
                    for (int i = 1; i <= t; ++i) {

                        current_statement_begin__ = 272;
                        stan::math::assign(get_base1_lhs(get_base1_lhs(V,i,"V",1),j,"V",2), get_base1(v,pos,"v",1));
                        current_statement_begin__ = 273;
                        stan::math::assign(pos, (pos + 1));
                    }
                }
            }
            current_statement_begin__ = 275;
            return stan::math::promote_scalar<fun_return_scalar_t__>(V);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct make_V_functor__ {
            std::vector<std::vector<int> >
    operator()(const int& N,
           const int& t,
           const std::vector<int>& v, std::ostream* pstream__) const {
        return make_V(N, t, v, pstream__);
    }
};

template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
linkinv_binom(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                  const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 287;
        if (as_bool(logical_eq(link,1))) {
            current_statement_begin__ = 287;
            return stan::math::promote_scalar<fun_return_scalar_t__>(inv_logit(eta));
        } else if (as_bool(logical_eq(link,2))) {
            current_statement_begin__ = 288;
            return stan::math::promote_scalar<fun_return_scalar_t__>(Phi(eta));
        } else if (as_bool(logical_eq(link,3))) {
            current_statement_begin__ = 289;
            return stan::math::promote_scalar<fun_return_scalar_t__>(add(divide(atan(eta),stan::math::pi()),0.5));
        } else if (as_bool(logical_eq(link,4))) {
            current_statement_begin__ = 290;
            return stan::math::promote_scalar<fun_return_scalar_t__>(exp(eta));
        } else if (as_bool(logical_eq(link,5))) {
            current_statement_begin__ = 291;
            return stan::math::promote_scalar<fun_return_scalar_t__>(inv_cloglog(eta));
        } else {
            current_statement_begin__ = 292;
            std::stringstream errmsg_stream__;
            errmsg_stream__ << "Invalid link";
            throw std::domain_error(errmsg_stream__.str());
        }
        current_statement_begin__ = 292;
        current_statement_begin__ = 293;
        return stan::math::promote_scalar<fun_return_scalar_t__>(eta);
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct linkinv_binom_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                  const int& link, std::ostream* pstream__) const {
        return linkinv_binom(eta, link, pstream__);
    }
};

template <typename T2__, typename T_lp__, typename T_lp_accum__>
typename boost::math::tools::promote_args<T2__, T_lp__>::type
ll_binom_lp(const std::vector<int>& y,
                const std::vector<int>& trials,
                const Eigen::Matrix<T2__, Eigen::Dynamic,1>& eta,
                const int& link, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T2__, T_lp__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 305;
        if (as_bool(logical_eq(link,1))) {
            current_statement_begin__ = 305;
            lp_accum__.add(binomial_logit_log(y,trials,eta));
        } else if (as_bool(logical_lt(link,4))) {
            current_statement_begin__ = 306;
            lp_accum__.add(binomial_log(y,trials,linkinv_binom(eta,link, pstream__)));
        } else if (as_bool(logical_eq(link,4))) {

            current_statement_begin__ = 308;
            for (int n = 1; n <= num_elements(y); ++n) {

                current_statement_begin__ = 309;
                lp_accum__.add((get_base1(y,n,"y",1) * get_base1(eta,n,"eta",1)));
                current_statement_begin__ = 310;
                lp_accum__.add(((get_base1(trials,n,"trials",1) - get_base1(y,n,"y",1)) * log1m_exp(get_base1(eta,n,"eta",1))));
                current_statement_begin__ = 311;
                lp_accum__.add(binomial_coefficient_log(get_base1(trials,n,"trials",1),get_base1(y,n,"y",1)));
            }
        } else if (as_bool(logical_eq(link,5))) {

            current_statement_begin__ = 315;
            for (int n = 1; n <= num_elements(y); ++n) {
                {
                    fun_scalar_t__ neg_exp_eta;
                    (void) neg_exp_eta;  // dummy to suppress unused var warning

                    stan::math::initialize(neg_exp_eta, std::numeric_limits<double>::quiet_NaN());
                    stan::math::fill(neg_exp_eta,DUMMY_VAR__);
                    stan::math::assign(neg_exp_eta,-(exp(get_base1(eta,n,"eta",1))));


                    current_statement_begin__ = 317;
                    lp_accum__.add((get_base1(y,n,"y",1) * log1m_exp(neg_exp_eta)));
                    current_statement_begin__ = 318;
                    lp_accum__.add(((get_base1(trials,n,"trials",1) - get_base1(y,n,"y",1)) * neg_exp_eta));
                    current_statement_begin__ = 319;
                    lp_accum__.add(binomial_coefficient_log(get_base1(trials,n,"trials",1),get_base1(y,n,"y",1)));
                }
            }
        } else {
            current_statement_begin__ = 322;
            std::stringstream errmsg_stream__;
            errmsg_stream__ << "Invalid link";
            throw std::domain_error(errmsg_stream__.str());
        }
        current_statement_begin__ = 322;
        current_statement_begin__ = 323;
        return stan::math::promote_scalar<fun_return_scalar_t__>(get_lp(lp__, lp_accum__));
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct ll_binom_lp_functor__ {
    template <typename T2__, typename T_lp__, typename T_lp_accum__>
        typename boost::math::tools::promote_args<T2__, T_lp__>::type
    operator()(const std::vector<int>& y,
                const std::vector<int>& trials,
                const Eigen::Matrix<T2__, Eigen::Dynamic,1>& eta,
                const int& link, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) const {
        return ll_binom_lp(y, trials, eta, link, lp__, lp_accum__, pstream__);
    }
};

template <typename T2__>
Eigen::Matrix<typename boost::math::tools::promote_args<T2__>::type, Eigen::Dynamic,1>
pw_binom(const std::vector<int>& y,
             const std::vector<int>& trials,
             const Eigen::Matrix<T2__, Eigen::Dynamic,1>& eta,
             const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T2__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            int N(0);
            (void) N;  // dummy to suppress unused var warning

            stan::math::fill(N, std::numeric_limits<int>::min());
            stan::math::assign(N,rows(eta));
            validate_non_negative_index("ll", "N", N);
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  ll(static_cast<Eigen::VectorXd::Index>(N));
            (void) ll;  // dummy to suppress unused var warning

            stan::math::initialize(ll, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(ll,DUMMY_VAR__);


            current_statement_begin__ = 336;
            if (as_bool(logical_eq(link,1))) {

                current_statement_begin__ = 337;
                for (int n = 1; n <= N; ++n) {
                    current_statement_begin__ = 338;
                    stan::math::assign(get_base1_lhs(ll,n,"ll",1), binomial_logit_log(get_base1(y,n,"y",1),get_base1(trials,n,"trials",1),get_base1(eta,n,"eta",1)));
                }
            } else if (as_bool(logical_lte(link,5))) {
                {
                    validate_non_negative_index("pi", "N", N);
                    Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  pi(static_cast<Eigen::VectorXd::Index>(N));
                    (void) pi;  // dummy to suppress unused var warning

                    stan::math::initialize(pi, std::numeric_limits<double>::quiet_NaN());
                    stan::math::fill(pi,DUMMY_VAR__);
                    stan::math::assign(pi,linkinv_binom(eta,link, pstream__));


                    current_statement_begin__ = 342;
                    for (int n = 1; n <= N; ++n) {
                        current_statement_begin__ = 342;
                        stan::math::assign(get_base1_lhs(ll,n,"ll",1), binomial_log(get_base1(y,n,"y",1),get_base1(trials,n,"trials",1),get_base1(pi,n,"pi",1)));
                    }
                }
            } else {
                current_statement_begin__ = 344;
                std::stringstream errmsg_stream__;
                errmsg_stream__ << "Invalid link";
                throw std::domain_error(errmsg_stream__.str());
            }
            current_statement_begin__ = 344;
            current_statement_begin__ = 345;
            return stan::math::promote_scalar<fun_return_scalar_t__>(ll);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct pw_binom_functor__ {
    template <typename T2__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T2__>::type, Eigen::Dynamic,1>
    operator()(const std::vector<int>& y,
             const std::vector<int>& trials,
             const Eigen::Matrix<T2__, Eigen::Dynamic,1>& eta,
             const int& link, std::ostream* pstream__) const {
        return pw_binom(y, trials, eta, link, pstream__);
    }
};

class model_binomial : public prob_grad {
private:
    int N;
    int K;
    vector_d xbar;
    int dense_X;
    vector<matrix_d> X;
    int nnz_X;
    vector_d w_X;
    vector<int> v_X;
    vector<int> u_X;
    int K_smooth;
    matrix_d S;
    vector<int> smooth_map;
    vector<int> y;
    vector<int> trials;
    int prior_PD;
    int has_intercept;
    int family;
    int link;
    int prior_dist;
    int prior_dist_for_intercept;
    int prior_dist_for_aux;
    int prior_dist_for_smooth;
    int has_weights;
    vector_d weights;
    int has_offset;
    vector_d offset;
    vector_d prior_scale;
    double prior_scale_for_intercept;
    double prior_scale_for_aux;
    vector_d prior_scale_for_smooth;
    vector_d prior_mean;
    double prior_mean_for_intercept;
    double prior_mean_for_aux;
    vector_d prior_mean_for_smooth;
    vector_d prior_df;
    double prior_df_for_intercept;
    double prior_df_for_aux;
    vector_d prior_df_for_smooth;
    double global_prior_df;
    double global_prior_scale;
    vector<int> num_normals;
    int t;
    vector<int> p;
    vector<int> l;
    int q;
    int len_theta_L;
    vector_d shape;
    vector_d scale;
    int len_concentration;
    vector<double> concentration;
    int len_regularization;
    vector<double> regularization;
    int num_non_zero;
    vector_d w;
    vector<int> v;
    vector<int> u;
    int special_case;
    double aux;
    vector<vector<int> > V;
    int len_z_T;
    int len_var_group;
    int len_rho;
    int is_continuous;
    int pos;
    vector<double> delta;
    int hs;
public:
    model_binomial(stan::io::var_context& context__,
        std::ostream* pstream__ = 0)
        : prob_grad(0) {
        ctor_body(context__, 0, pstream__);
    }

    model_binomial(stan::io::var_context& context__,
        unsigned int random_seed__,
        std::ostream* pstream__ = 0)
        : prob_grad(0) {
        ctor_body(context__, random_seed__, pstream__);
    }

    void ctor_body(stan::io::var_context& context__,
                   unsigned int random_seed__,
                   std::ostream* pstream__) {
        boost::ecuyer1988 base_rng__ =
          stan::services::util::create_rng(random_seed__, 0);
        (void) base_rng__;  // suppress unused var warning

        current_statement_begin__ = -1;

        static const char* function__ = "model_binomial_namespace::model_binomial";
        (void) function__;  // dummy to suppress unused var warning
        size_t pos__;
        (void) pos__;  // dummy to suppress unused var warning
        std::vector<int> vals_i__;
        std::vector<double> vals_r__;
        double DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

        // initialize member variables
        context__.validate_dims("data initialization", "N", "int", context__.to_vec());
        N = int(0);
        vals_i__ = context__.vals_i("N");
        pos__ = 0;
        N = vals_i__[pos__++];
        context__.validate_dims("data initialization", "K", "int", context__.to_vec());
        K = int(0);
        vals_i__ = context__.vals_i("K");
        pos__ = 0;
        K = vals_i__[pos__++];
        validate_non_negative_index("xbar", "K", K);
        context__.validate_dims("data initialization", "xbar", "vector_d", context__.to_vec(K));
        validate_non_negative_index("xbar", "K", K);
        xbar = vector_d(static_cast<Eigen::VectorXd::Index>(K));
        vals_r__ = context__.vals_r("xbar");
        pos__ = 0;
        size_t xbar_i_vec_lim__ = K;
        for (size_t i_vec__ = 0; i_vec__ < xbar_i_vec_lim__; ++i_vec__) {
            xbar[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "dense_X", "int", context__.to_vec());
        dense_X = int(0);
        vals_i__ = context__.vals_i("dense_X");
        pos__ = 0;
        dense_X = vals_i__[pos__++];
        validate_non_negative_index("X", "dense_X", dense_X);
        validate_non_negative_index("X", "N", N);
        validate_non_negative_index("X", "K", K);
        context__.validate_dims("data initialization", "X", "matrix_d", context__.to_vec(dense_X,N,K));
        validate_non_negative_index("X", "dense_X", dense_X);
        validate_non_negative_index("X", "N", N);
        validate_non_negative_index("X", "K", K);
        X = std::vector<matrix_d>(dense_X,matrix_d(static_cast<Eigen::VectorXd::Index>(N),static_cast<Eigen::VectorXd::Index>(K)));
        vals_r__ = context__.vals_r("X");
        pos__ = 0;
        size_t X_m_mat_lim__ = N;
        size_t X_n_mat_lim__ = K;
        for (size_t n_mat__ = 0; n_mat__ < X_n_mat_lim__; ++n_mat__) {
            for (size_t m_mat__ = 0; m_mat__ < X_m_mat_lim__; ++m_mat__) {
                size_t X_limit_0__ = dense_X;
                for (size_t i_0__ = 0; i_0__ < X_limit_0__; ++i_0__) {
                    X[i_0__](m_mat__,n_mat__) = vals_r__[pos__++];
            }
            }
        }
        context__.validate_dims("data initialization", "nnz_X", "int", context__.to_vec());
        nnz_X = int(0);
        vals_i__ = context__.vals_i("nnz_X");
        pos__ = 0;
        nnz_X = vals_i__[pos__++];
        validate_non_negative_index("w_X", "nnz_X", nnz_X);
        context__.validate_dims("data initialization", "w_X", "vector_d", context__.to_vec(nnz_X));
        validate_non_negative_index("w_X", "nnz_X", nnz_X);
        w_X = vector_d(static_cast<Eigen::VectorXd::Index>(nnz_X));
        vals_r__ = context__.vals_r("w_X");
        pos__ = 0;
        size_t w_X_i_vec_lim__ = nnz_X;
        for (size_t i_vec__ = 0; i_vec__ < w_X_i_vec_lim__; ++i_vec__) {
            w_X[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("v_X", "nnz_X", nnz_X);
        context__.validate_dims("data initialization", "v_X", "int", context__.to_vec(nnz_X));
        validate_non_negative_index("v_X", "nnz_X", nnz_X);
        v_X = std::vector<int>(nnz_X,int(0));
        vals_i__ = context__.vals_i("v_X");
        pos__ = 0;
        size_t v_X_limit_0__ = nnz_X;
        for (size_t i_0__ = 0; i_0__ < v_X_limit_0__; ++i_0__) {
            v_X[i_0__] = vals_i__[pos__++];
        }
        validate_non_negative_index("u_X", "(dense_X ? 0 : (N + 1) )", (dense_X ? 0 : (N + 1) ));
        context__.validate_dims("data initialization", "u_X", "int", context__.to_vec((dense_X ? 0 : (N + 1) )));
        validate_non_negative_index("u_X", "(dense_X ? 0 : (N + 1) )", (dense_X ? 0 : (N + 1) ));
        u_X = std::vector<int>((dense_X ? 0 : (N + 1) ),int(0));
        vals_i__ = context__.vals_i("u_X");
        pos__ = 0;
        size_t u_X_limit_0__ = (dense_X ? 0 : (N + 1) );
        for (size_t i_0__ = 0; i_0__ < u_X_limit_0__; ++i_0__) {
            u_X[i_0__] = vals_i__[pos__++];
        }
        context__.validate_dims("data initialization", "K_smooth", "int", context__.to_vec());
        K_smooth = int(0);
        vals_i__ = context__.vals_i("K_smooth");
        pos__ = 0;
        K_smooth = vals_i__[pos__++];
        validate_non_negative_index("S", "N", N);
        validate_non_negative_index("S", "K_smooth", K_smooth);
        context__.validate_dims("data initialization", "S", "matrix_d", context__.to_vec(N,K_smooth));
        validate_non_negative_index("S", "N", N);
        validate_non_negative_index("S", "K_smooth", K_smooth);
        S = matrix_d(static_cast<Eigen::VectorXd::Index>(N),static_cast<Eigen::VectorXd::Index>(K_smooth));
        vals_r__ = context__.vals_r("S");
        pos__ = 0;
        size_t S_m_mat_lim__ = N;
        size_t S_n_mat_lim__ = K_smooth;
        for (size_t n_mat__ = 0; n_mat__ < S_n_mat_lim__; ++n_mat__) {
            for (size_t m_mat__ = 0; m_mat__ < S_m_mat_lim__; ++m_mat__) {
                S(m_mat__,n_mat__) = vals_r__[pos__++];
            }
        }
        validate_non_negative_index("smooth_map", "K_smooth", K_smooth);
        context__.validate_dims("data initialization", "smooth_map", "int", context__.to_vec(K_smooth));
        validate_non_negative_index("smooth_map", "K_smooth", K_smooth);
        smooth_map = std::vector<int>(K_smooth,int(0));
        vals_i__ = context__.vals_i("smooth_map");
        pos__ = 0;
        size_t smooth_map_limit_0__ = K_smooth;
        for (size_t i_0__ = 0; i_0__ < smooth_map_limit_0__; ++i_0__) {
            smooth_map[i_0__] = vals_i__[pos__++];
        }
        validate_non_negative_index("y", "N", N);
        context__.validate_dims("data initialization", "y", "int", context__.to_vec(N));
        validate_non_negative_index("y", "N", N);
        y = std::vector<int>(N,int(0));
        vals_i__ = context__.vals_i("y");
        pos__ = 0;
        size_t y_limit_0__ = N;
        for (size_t i_0__ = 0; i_0__ < y_limit_0__; ++i_0__) {
            y[i_0__] = vals_i__[pos__++];
        }
        validate_non_negative_index("trials", "N", N);
        context__.validate_dims("data initialization", "trials", "int", context__.to_vec(N));
        validate_non_negative_index("trials", "N", N);
        trials = std::vector<int>(N,int(0));
        vals_i__ = context__.vals_i("trials");
        pos__ = 0;
        size_t trials_limit_0__ = N;
        for (size_t i_0__ = 0; i_0__ < trials_limit_0__; ++i_0__) {
            trials[i_0__] = vals_i__[pos__++];
        }
        context__.validate_dims("data initialization", "prior_PD", "int", context__.to_vec());
        prior_PD = int(0);
        vals_i__ = context__.vals_i("prior_PD");
        pos__ = 0;
        prior_PD = vals_i__[pos__++];
        context__.validate_dims("data initialization", "has_intercept", "int", context__.to_vec());
        has_intercept = int(0);
        vals_i__ = context__.vals_i("has_intercept");
        pos__ = 0;
        has_intercept = vals_i__[pos__++];
        context__.validate_dims("data initialization", "family", "int", context__.to_vec());
        family = int(0);
        vals_i__ = context__.vals_i("family");
        pos__ = 0;
        family = vals_i__[pos__++];
        context__.validate_dims("data initialization", "link", "int", context__.to_vec());
        link = int(0);
        vals_i__ = context__.vals_i("link");
        pos__ = 0;
        link = vals_i__[pos__++];
        context__.validate_dims("data initialization", "prior_dist", "int", context__.to_vec());
        prior_dist = int(0);
        vals_i__ = context__.vals_i("prior_dist");
        pos__ = 0;
        prior_dist = vals_i__[pos__++];
        context__.validate_dims("data initialization", "prior_dist_for_intercept", "int", context__.to_vec());
        prior_dist_for_intercept = int(0);
        vals_i__ = context__.vals_i("prior_dist_for_intercept");
        pos__ = 0;
        prior_dist_for_intercept = vals_i__[pos__++];
        context__.validate_dims("data initialization", "prior_dist_for_aux", "int", context__.to_vec());
        prior_dist_for_aux = int(0);
        vals_i__ = context__.vals_i("prior_dist_for_aux");
        pos__ = 0;
        prior_dist_for_aux = vals_i__[pos__++];
        context__.validate_dims("data initialization", "prior_dist_for_smooth", "int", context__.to_vec());
        prior_dist_for_smooth = int(0);
        vals_i__ = context__.vals_i("prior_dist_for_smooth");
        pos__ = 0;
        prior_dist_for_smooth = vals_i__[pos__++];
        context__.validate_dims("data initialization", "has_weights", "int", context__.to_vec());
        has_weights = int(0);
        vals_i__ = context__.vals_i("has_weights");
        pos__ = 0;
        has_weights = vals_i__[pos__++];
        validate_non_negative_index("weights", "(has_weights ? N : 0 )", (has_weights ? N : 0 ));
        context__.validate_dims("data initialization", "weights", "vector_d", context__.to_vec((has_weights ? N : 0 )));
        validate_non_negative_index("weights", "(has_weights ? N : 0 )", (has_weights ? N : 0 ));
        weights = vector_d(static_cast<Eigen::VectorXd::Index>((has_weights ? N : 0 )));
        vals_r__ = context__.vals_r("weights");
        pos__ = 0;
        size_t weights_i_vec_lim__ = (has_weights ? N : 0 );
        for (size_t i_vec__ = 0; i_vec__ < weights_i_vec_lim__; ++i_vec__) {
            weights[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "has_offset", "int", context__.to_vec());
        has_offset = int(0);
        vals_i__ = context__.vals_i("has_offset");
        pos__ = 0;
        has_offset = vals_i__[pos__++];
        validate_non_negative_index("offset", "(has_offset ? N : 0 )", (has_offset ? N : 0 ));
        context__.validate_dims("data initialization", "offset", "vector_d", context__.to_vec((has_offset ? N : 0 )));
        validate_non_negative_index("offset", "(has_offset ? N : 0 )", (has_offset ? N : 0 ));
        offset = vector_d(static_cast<Eigen::VectorXd::Index>((has_offset ? N : 0 )));
        vals_r__ = context__.vals_r("offset");
        pos__ = 0;
        size_t offset_i_vec_lim__ = (has_offset ? N : 0 );
        for (size_t i_vec__ = 0; i_vec__ < offset_i_vec_lim__; ++i_vec__) {
            offset[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("prior_scale", "K", K);
        context__.validate_dims("data initialization", "prior_scale", "vector_d", context__.to_vec(K));
        validate_non_negative_index("prior_scale", "K", K);
        prior_scale = vector_d(static_cast<Eigen::VectorXd::Index>(K));
        vals_r__ = context__.vals_r("prior_scale");
        pos__ = 0;
        size_t prior_scale_i_vec_lim__ = K;
        for (size_t i_vec__ = 0; i_vec__ < prior_scale_i_vec_lim__; ++i_vec__) {
            prior_scale[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "prior_scale_for_intercept", "double", context__.to_vec());
        prior_scale_for_intercept = double(0);
        vals_r__ = context__.vals_r("prior_scale_for_intercept");
        pos__ = 0;
        prior_scale_for_intercept = vals_r__[pos__++];
        context__.validate_dims("data initialization", "prior_scale_for_aux", "double", context__.to_vec());
        prior_scale_for_aux = double(0);
        vals_r__ = context__.vals_r("prior_scale_for_aux");
        pos__ = 0;
        prior_scale_for_aux = vals_r__[pos__++];
        validate_non_negative_index("prior_scale_for_smooth", "(logical_gt(K_smooth,0) ? max(smooth_map) : 0 )", (logical_gt(K_smooth,0) ? max(smooth_map) : 0 ));
        context__.validate_dims("data initialization", "prior_scale_for_smooth", "vector_d", context__.to_vec((logical_gt(K_smooth,0) ? max(smooth_map) : 0 )));
        validate_non_negative_index("prior_scale_for_smooth", "(logical_gt(K_smooth,0) ? max(smooth_map) : 0 )", (logical_gt(K_smooth,0) ? max(smooth_map) : 0 ));
        prior_scale_for_smooth = vector_d(static_cast<Eigen::VectorXd::Index>((logical_gt(K_smooth,0) ? max(smooth_map) : 0 )));
        vals_r__ = context__.vals_r("prior_scale_for_smooth");
        pos__ = 0;
        size_t prior_scale_for_smooth_i_vec_lim__ = (logical_gt(K_smooth,0) ? max(smooth_map) : 0 );
        for (size_t i_vec__ = 0; i_vec__ < prior_scale_for_smooth_i_vec_lim__; ++i_vec__) {
            prior_scale_for_smooth[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("prior_mean", "K", K);
        context__.validate_dims("data initialization", "prior_mean", "vector_d", context__.to_vec(K));
        validate_non_negative_index("prior_mean", "K", K);
        prior_mean = vector_d(static_cast<Eigen::VectorXd::Index>(K));
        vals_r__ = context__.vals_r("prior_mean");
        pos__ = 0;
        size_t prior_mean_i_vec_lim__ = K;
        for (size_t i_vec__ = 0; i_vec__ < prior_mean_i_vec_lim__; ++i_vec__) {
            prior_mean[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "prior_mean_for_intercept", "double", context__.to_vec());
        prior_mean_for_intercept = double(0);
        vals_r__ = context__.vals_r("prior_mean_for_intercept");
        pos__ = 0;
        prior_mean_for_intercept = vals_r__[pos__++];
        context__.validate_dims("data initialization", "prior_mean_for_aux", "double", context__.to_vec());
        prior_mean_for_aux = double(0);
        vals_r__ = context__.vals_r("prior_mean_for_aux");
        pos__ = 0;
        prior_mean_for_aux = vals_r__[pos__++];
        validate_non_negative_index("prior_mean_for_smooth", "(logical_gt(K_smooth,0) ? max(smooth_map) : 0 )", (logical_gt(K_smooth,0) ? max(smooth_map) : 0 ));
        context__.validate_dims("data initialization", "prior_mean_for_smooth", "vector_d", context__.to_vec((logical_gt(K_smooth,0) ? max(smooth_map) : 0 )));
        validate_non_negative_index("prior_mean_for_smooth", "(logical_gt(K_smooth,0) ? max(smooth_map) : 0 )", (logical_gt(K_smooth,0) ? max(smooth_map) : 0 ));
        prior_mean_for_smooth = vector_d(static_cast<Eigen::VectorXd::Index>((logical_gt(K_smooth,0) ? max(smooth_map) : 0 )));
        vals_r__ = context__.vals_r("prior_mean_for_smooth");
        pos__ = 0;
        size_t prior_mean_for_smooth_i_vec_lim__ = (logical_gt(K_smooth,0) ? max(smooth_map) : 0 );
        for (size_t i_vec__ = 0; i_vec__ < prior_mean_for_smooth_i_vec_lim__; ++i_vec__) {
            prior_mean_for_smooth[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("prior_df", "K", K);
        context__.validate_dims("data initialization", "prior_df", "vector_d", context__.to_vec(K));
        validate_non_negative_index("prior_df", "K", K);
        prior_df = vector_d(static_cast<Eigen::VectorXd::Index>(K));
        vals_r__ = context__.vals_r("prior_df");
        pos__ = 0;
        size_t prior_df_i_vec_lim__ = K;
        for (size_t i_vec__ = 0; i_vec__ < prior_df_i_vec_lim__; ++i_vec__) {
            prior_df[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "prior_df_for_intercept", "double", context__.to_vec());
        prior_df_for_intercept = double(0);
        vals_r__ = context__.vals_r("prior_df_for_intercept");
        pos__ = 0;
        prior_df_for_intercept = vals_r__[pos__++];
        context__.validate_dims("data initialization", "prior_df_for_aux", "double", context__.to_vec());
        prior_df_for_aux = double(0);
        vals_r__ = context__.vals_r("prior_df_for_aux");
        pos__ = 0;
        prior_df_for_aux = vals_r__[pos__++];
        validate_non_negative_index("prior_df_for_smooth", "(logical_gt(K_smooth,0) ? max(smooth_map) : 0 )", (logical_gt(K_smooth,0) ? max(smooth_map) : 0 ));
        context__.validate_dims("data initialization", "prior_df_for_smooth", "vector_d", context__.to_vec((logical_gt(K_smooth,0) ? max(smooth_map) : 0 )));
        validate_non_negative_index("prior_df_for_smooth", "(logical_gt(K_smooth,0) ? max(smooth_map) : 0 )", (logical_gt(K_smooth,0) ? max(smooth_map) : 0 ));
        prior_df_for_smooth = vector_d(static_cast<Eigen::VectorXd::Index>((logical_gt(K_smooth,0) ? max(smooth_map) : 0 )));
        vals_r__ = context__.vals_r("prior_df_for_smooth");
        pos__ = 0;
        size_t prior_df_for_smooth_i_vec_lim__ = (logical_gt(K_smooth,0) ? max(smooth_map) : 0 );
        for (size_t i_vec__ = 0; i_vec__ < prior_df_for_smooth_i_vec_lim__; ++i_vec__) {
            prior_df_for_smooth[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "global_prior_df", "double", context__.to_vec());
        global_prior_df = double(0);
        vals_r__ = context__.vals_r("global_prior_df");
        pos__ = 0;
        global_prior_df = vals_r__[pos__++];
        context__.validate_dims("data initialization", "global_prior_scale", "double", context__.to_vec());
        global_prior_scale = double(0);
        vals_r__ = context__.vals_r("global_prior_scale");
        pos__ = 0;
        global_prior_scale = vals_r__[pos__++];
        validate_non_negative_index("num_normals", "(logical_eq(prior_dist,7) ? K : 0 )", (logical_eq(prior_dist,7) ? K : 0 ));
        context__.validate_dims("data initialization", "num_normals", "int", context__.to_vec((logical_eq(prior_dist,7) ? K : 0 )));
        validate_non_negative_index("num_normals", "(logical_eq(prior_dist,7) ? K : 0 )", (logical_eq(prior_dist,7) ? K : 0 ));
        num_normals = std::vector<int>((logical_eq(prior_dist,7) ? K : 0 ),int(0));
        vals_i__ = context__.vals_i("num_normals");
        pos__ = 0;
        size_t num_normals_limit_0__ = (logical_eq(prior_dist,7) ? K : 0 );
        for (size_t i_0__ = 0; i_0__ < num_normals_limit_0__; ++i_0__) {
            num_normals[i_0__] = vals_i__[pos__++];
        }
        context__.validate_dims("data initialization", "t", "int", context__.to_vec());
        t = int(0);
        vals_i__ = context__.vals_i("t");
        pos__ = 0;
        t = vals_i__[pos__++];
        validate_non_negative_index("p", "t", t);
        context__.validate_dims("data initialization", "p", "int", context__.to_vec(t));
        validate_non_negative_index("p", "t", t);
        p = std::vector<int>(t,int(0));
        vals_i__ = context__.vals_i("p");
        pos__ = 0;
        size_t p_limit_0__ = t;
        for (size_t i_0__ = 0; i_0__ < p_limit_0__; ++i_0__) {
            p[i_0__] = vals_i__[pos__++];
        }
        validate_non_negative_index("l", "t", t);
        context__.validate_dims("data initialization", "l", "int", context__.to_vec(t));
        validate_non_negative_index("l", "t", t);
        l = std::vector<int>(t,int(0));
        vals_i__ = context__.vals_i("l");
        pos__ = 0;
        size_t l_limit_0__ = t;
        for (size_t i_0__ = 0; i_0__ < l_limit_0__; ++i_0__) {
            l[i_0__] = vals_i__[pos__++];
        }
        context__.validate_dims("data initialization", "q", "int", context__.to_vec());
        q = int(0);
        vals_i__ = context__.vals_i("q");
        pos__ = 0;
        q = vals_i__[pos__++];
        context__.validate_dims("data initialization", "len_theta_L", "int", context__.to_vec());
        len_theta_L = int(0);
        vals_i__ = context__.vals_i("len_theta_L");
        pos__ = 0;
        len_theta_L = vals_i__[pos__++];
        validate_non_negative_index("shape", "t", t);
        context__.validate_dims("data initialization", "shape", "vector_d", context__.to_vec(t));
        validate_non_negative_index("shape", "t", t);
        shape = vector_d(static_cast<Eigen::VectorXd::Index>(t));
        vals_r__ = context__.vals_r("shape");
        pos__ = 0;
        size_t shape_i_vec_lim__ = t;
        for (size_t i_vec__ = 0; i_vec__ < shape_i_vec_lim__; ++i_vec__) {
            shape[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("scale", "t", t);
        context__.validate_dims("data initialization", "scale", "vector_d", context__.to_vec(t));
        validate_non_negative_index("scale", "t", t);
        scale = vector_d(static_cast<Eigen::VectorXd::Index>(t));
        vals_r__ = context__.vals_r("scale");
        pos__ = 0;
        size_t scale_i_vec_lim__ = t;
        for (size_t i_vec__ = 0; i_vec__ < scale_i_vec_lim__; ++i_vec__) {
            scale[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "len_concentration", "int", context__.to_vec());
        len_concentration = int(0);
        vals_i__ = context__.vals_i("len_concentration");
        pos__ = 0;
        len_concentration = vals_i__[pos__++];
        validate_non_negative_index("concentration", "len_concentration", len_concentration);
        context__.validate_dims("data initialization", "concentration", "double", context__.to_vec(len_concentration));
        validate_non_negative_index("concentration", "len_concentration", len_concentration);
        concentration = std::vector<double>(len_concentration,double(0));
        vals_r__ = context__.vals_r("concentration");
        pos__ = 0;
        size_t concentration_limit_0__ = len_concentration;
        for (size_t i_0__ = 0; i_0__ < concentration_limit_0__; ++i_0__) {
            concentration[i_0__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "len_regularization", "int", context__.to_vec());
        len_regularization = int(0);
        vals_i__ = context__.vals_i("len_regularization");
        pos__ = 0;
        len_regularization = vals_i__[pos__++];
        validate_non_negative_index("regularization", "len_regularization", len_regularization);
        context__.validate_dims("data initialization", "regularization", "double", context__.to_vec(len_regularization));
        validate_non_negative_index("regularization", "len_regularization", len_regularization);
        regularization = std::vector<double>(len_regularization,double(0));
        vals_r__ = context__.vals_r("regularization");
        pos__ = 0;
        size_t regularization_limit_0__ = len_regularization;
        for (size_t i_0__ = 0; i_0__ < regularization_limit_0__; ++i_0__) {
            regularization[i_0__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "num_non_zero", "int", context__.to_vec());
        num_non_zero = int(0);
        vals_i__ = context__.vals_i("num_non_zero");
        pos__ = 0;
        num_non_zero = vals_i__[pos__++];
        validate_non_negative_index("w", "num_non_zero", num_non_zero);
        context__.validate_dims("data initialization", "w", "vector_d", context__.to_vec(num_non_zero));
        validate_non_negative_index("w", "num_non_zero", num_non_zero);
        w = vector_d(static_cast<Eigen::VectorXd::Index>(num_non_zero));
        vals_r__ = context__.vals_r("w");
        pos__ = 0;
        size_t w_i_vec_lim__ = num_non_zero;
        for (size_t i_vec__ = 0; i_vec__ < w_i_vec_lim__; ++i_vec__) {
            w[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("v", "num_non_zero", num_non_zero);
        context__.validate_dims("data initialization", "v", "int", context__.to_vec(num_non_zero));
        validate_non_negative_index("v", "num_non_zero", num_non_zero);
        v = std::vector<int>(num_non_zero,int(0));
        vals_i__ = context__.vals_i("v");
        pos__ = 0;
        size_t v_limit_0__ = num_non_zero;
        for (size_t i_0__ = 0; i_0__ < v_limit_0__; ++i_0__) {
            v[i_0__] = vals_i__[pos__++];
        }
        validate_non_negative_index("u", "(logical_gt(t,0) ? (N + 1) : 0 )", (logical_gt(t,0) ? (N + 1) : 0 ));
        context__.validate_dims("data initialization", "u", "int", context__.to_vec((logical_gt(t,0) ? (N + 1) : 0 )));
        validate_non_negative_index("u", "(logical_gt(t,0) ? (N + 1) : 0 )", (logical_gt(t,0) ? (N + 1) : 0 ));
        u = std::vector<int>((logical_gt(t,0) ? (N + 1) : 0 ),int(0));
        vals_i__ = context__.vals_i("u");
        pos__ = 0;
        size_t u_limit_0__ = (logical_gt(t,0) ? (N + 1) : 0 );
        for (size_t i_0__ = 0; i_0__ < u_limit_0__; ++i_0__) {
            u[i_0__] = vals_i__[pos__++];
        }
        context__.validate_dims("data initialization", "special_case", "int", context__.to_vec());
        special_case = int(0);
        vals_i__ = context__.vals_i("special_case");
        pos__ = 0;
        special_case = vals_i__[pos__++];

        // validate, data variables
        check_greater_or_equal(function__,"N",N,0);
        check_greater_or_equal(function__,"K",K,0);
        check_greater_or_equal(function__,"dense_X",dense_X,0);
        check_less_or_equal(function__,"dense_X",dense_X,1);
        check_greater_or_equal(function__,"nnz_X",nnz_X,0);
        for (int k0__ = 0; k0__ < nnz_X; ++k0__) {
            check_greater_or_equal(function__,"v_X[k0__]",v_X[k0__],0);
        }
        for (int k0__ = 0; k0__ < (dense_X ? 0 : (N + 1) ); ++k0__) {
            check_greater_or_equal(function__,"u_X[k0__]",u_X[k0__],0);
        }
        check_greater_or_equal(function__,"K_smooth",K_smooth,0);
        for (int k0__ = 0; k0__ < K_smooth; ++k0__) {
            check_greater_or_equal(function__,"smooth_map[k0__]",smooth_map[k0__],1);
        }
        for (int k0__ = 0; k0__ < N; ++k0__) {
            check_greater_or_equal(function__,"y[k0__]",y[k0__],0);
        }
        for (int k0__ = 0; k0__ < N; ++k0__) {
            check_greater_or_equal(function__,"trials[k0__]",trials[k0__],0);
        }
        check_greater_or_equal(function__,"prior_PD",prior_PD,0);
        check_less_or_equal(function__,"prior_PD",prior_PD,1);
        check_greater_or_equal(function__,"has_intercept",has_intercept,0);
        check_less_or_equal(function__,"has_intercept",has_intercept,1);
        check_greater_or_equal(function__,"family",family,1);
        check_greater_or_equal(function__,"link",link,1);
        check_greater_or_equal(function__,"prior_dist",prior_dist,0);
        check_less_or_equal(function__,"prior_dist",prior_dist,7);
        check_greater_or_equal(function__,"prior_dist_for_intercept",prior_dist_for_intercept,0);
        check_less_or_equal(function__,"prior_dist_for_intercept",prior_dist_for_intercept,2);
        check_greater_or_equal(function__,"prior_dist_for_aux",prior_dist_for_aux,0);
        check_less_or_equal(function__,"prior_dist_for_aux",prior_dist_for_aux,3);
        check_greater_or_equal(function__,"prior_dist_for_smooth",prior_dist_for_smooth,0);
        check_less_or_equal(function__,"prior_dist_for_smooth",prior_dist_for_smooth,3);
        check_greater_or_equal(function__,"has_weights",has_weights,0);
        check_less_or_equal(function__,"has_weights",has_weights,1);
        check_greater_or_equal(function__,"has_offset",has_offset,0);
        check_less_or_equal(function__,"has_offset",has_offset,1);
        check_greater_or_equal(function__,"prior_scale",prior_scale,0);
        check_greater_or_equal(function__,"prior_scale_for_intercept",prior_scale_for_intercept,0);
        check_greater_or_equal(function__,"prior_scale_for_aux",prior_scale_for_aux,0);
        check_greater_or_equal(function__,"prior_scale_for_smooth",prior_scale_for_smooth,0);
        check_greater_or_equal(function__,"prior_mean_for_aux",prior_mean_for_aux,0);
        check_greater_or_equal(function__,"prior_mean_for_smooth",prior_mean_for_smooth,0);
        check_greater_or_equal(function__,"prior_df",prior_df,0);
        check_greater_or_equal(function__,"prior_df_for_intercept",prior_df_for_intercept,0);
        check_greater_or_equal(function__,"prior_df_for_aux",prior_df_for_aux,0);
        check_greater_or_equal(function__,"prior_df_for_smooth",prior_df_for_smooth,0);
        check_greater_or_equal(function__,"global_prior_df",global_prior_df,0);
        check_greater_or_equal(function__,"global_prior_scale",global_prior_scale,0);
        for (int k0__ = 0; k0__ < (logical_eq(prior_dist,7) ? K : 0 ); ++k0__) {
            check_greater_or_equal(function__,"num_normals[k0__]",num_normals[k0__],2);
        }
        check_greater_or_equal(function__,"t",t,0);
        for (int k0__ = 0; k0__ < t; ++k0__) {
            check_greater_or_equal(function__,"p[k0__]",p[k0__],1);
        }
        for (int k0__ = 0; k0__ < t; ++k0__) {
            check_greater_or_equal(function__,"l[k0__]",l[k0__],1);
        }
        check_greater_or_equal(function__,"q",q,0);
        check_greater_or_equal(function__,"len_theta_L",len_theta_L,0);
        check_greater_or_equal(function__,"shape",shape,0);
        check_greater_or_equal(function__,"scale",scale,0);
        check_greater_or_equal(function__,"len_concentration",len_concentration,0);
        for (int k0__ = 0; k0__ < len_concentration; ++k0__) {
            check_greater_or_equal(function__,"concentration[k0__]",concentration[k0__],0);
        }
        check_greater_or_equal(function__,"len_regularization",len_regularization,0);
        for (int k0__ = 0; k0__ < len_regularization; ++k0__) {
            check_greater_or_equal(function__,"regularization[k0__]",regularization[k0__],0);
        }
        check_greater_or_equal(function__,"num_non_zero",num_non_zero,0);
        for (int k0__ = 0; k0__ < num_non_zero; ++k0__) {
            check_greater_or_equal(function__,"v[k0__]",v[k0__],0);
        }
        for (int k0__ = 0; k0__ < (logical_gt(t,0) ? (N + 1) : 0 ); ++k0__) {
            check_greater_or_equal(function__,"u[k0__]",u[k0__],0);
        }
        check_greater_or_equal(function__,"special_case",special_case,0);
        check_less_or_equal(function__,"special_case",special_case,1);
        // initialize data variables
        aux = double(0);
        stan::math::fill(aux,DUMMY_VAR__);
        stan::math::assign(aux,stan::math::not_a_number());
        validate_non_negative_index("V", "(special_case ? t : 0 )", (special_case ? t : 0 ));
        validate_non_negative_index("V", "N", N);
        V = std::vector<std::vector<int> >((special_case ? t : 0 ),std::vector<int>(N,int(0)));
        stan::math::fill(V, std::numeric_limits<int>::min());
        stan::math::assign(V,make_V(N,(special_case ? t : 0 ),v, pstream__));
        len_z_T = int(0);
        stan::math::fill(len_z_T, std::numeric_limits<int>::min());
        stan::math::assign(len_z_T,0);
        len_var_group = int(0);
        stan::math::fill(len_var_group, std::numeric_limits<int>::min());
        stan::math::assign(len_var_group,(sum(p) * logical_gt(t,0)));
        len_rho = int(0);
        stan::math::fill(len_rho, std::numeric_limits<int>::min());
        stan::math::assign(len_rho,(sum(p) - t));
        is_continuous = int(0);
        stan::math::fill(is_continuous, std::numeric_limits<int>::min());
        stan::math::assign(is_continuous,0);
        pos = int(0);
        stan::math::fill(pos, std::numeric_limits<int>::min());
        stan::math::assign(pos,1);
        validate_non_negative_index("delta", "len_concentration", len_concentration);
        delta = std::vector<double>(len_concentration,double(0));
        stan::math::fill(delta,DUMMY_VAR__);
        hs = int(0);
        stan::math::fill(hs, std::numeric_limits<int>::min());

        try {
            current_statement_begin__ = 455;
            if (as_bool(logical_lte(prior_dist,2))) {
                current_statement_begin__ = 455;
                stan::math::assign(hs, 0);
            } else if (as_bool(logical_eq(prior_dist,3))) {
                current_statement_begin__ = 456;
                stan::math::assign(hs, 2);
            } else if (as_bool(logical_eq(prior_dist,4))) {
                current_statement_begin__ = 457;
                stan::math::assign(hs, 4);
            } else {
                current_statement_begin__ = 458;
                stan::math::assign(hs, 0);
            }
            current_statement_begin__ = 460;
            stan::math::assign(pos, 1);
            current_statement_begin__ = 461;
            for (int i = 1; i <= t; ++i) {

                current_statement_begin__ = 462;
                if (as_bool(logical_gt(get_base1(p,i,"p",1),1))) {

                    current_statement_begin__ = 463;
                    for (int j = 1; j <= get_base1(p,i,"p",1); ++j) {

                        current_statement_begin__ = 464;
                        stan::math::assign(get_base1_lhs(delta,pos,"delta",1), get_base1(concentration,j,"concentration",1));
                        current_statement_begin__ = 465;
                        stan::math::assign(pos, (pos + 1));
                    }
                }
                current_statement_begin__ = 468;
                for (int j = 3; j <= get_base1(p,i,"p",1); ++j) {
                    current_statement_begin__ = 468;
                    stan::math::assign(len_z_T, ((len_z_T + get_base1(p,i,"p",1)) - 1));
                }
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        // validate transformed data
        for (int k0__ = 0; k0__ < (special_case ? t : 0 ); ++k0__) {
            for (int k1__ = 0; k1__ < N; ++k1__) {
                check_greater_or_equal(function__,"V[k0__][k1__]",V[k0__][k1__],1);
            }
        }
        check_greater_or_equal(function__,"len_z_T",len_z_T,0);
        check_greater_or_equal(function__,"len_var_group",len_var_group,0);
        check_greater_or_equal(function__,"len_rho",len_rho,0);
        check_greater_or_equal(function__,"is_continuous",is_continuous,0);
        check_less_or_equal(function__,"is_continuous",is_continuous,1);
        check_greater_or_equal(function__,"pos",pos,1);
        for (int k0__ = 0; k0__ < len_concentration; ++k0__) {
            check_greater_or_equal(function__,"delta[k0__]",delta[k0__],0);
        }
        check_greater_or_equal(function__,"hs",hs,0);

        // validate, set parameter ranges
        num_params_r__ = 0U;
        param_ranges_i__.clear();
        validate_non_negative_index("gamma", "has_intercept", has_intercept);
        num_params_r__ += has_intercept;
        validate_non_negative_index("z_beta", "(logical_eq(prior_dist,7) ? sum(num_normals) : K )", (logical_eq(prior_dist,7) ? sum(num_normals) : K ));
        num_params_r__ += (logical_eq(prior_dist,7) ? sum(num_normals) : K );
        validate_non_negative_index("z_beta_smooth", "K_smooth", K_smooth);
        num_params_r__ += K_smooth;
        validate_non_negative_index("smooth_sd_raw", "(logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,\"smooth_map\",1) : 0 )", (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));
        num_params_r__ += (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 );
        validate_non_negative_index("global", "hs", hs);
        num_params_r__ += hs;
        validate_non_negative_index("local", "K", K);
        validate_non_negative_index("local", "hs", hs);
        num_params_r__ += K * hs;
        validate_non_negative_index("mix", "K", K);
        validate_non_negative_index("mix", "(primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6)))", (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))));
        num_params_r__ += K * (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6)));
        validate_non_negative_index("one_over_lambda", "logical_eq(prior_dist,6)", logical_eq(prior_dist,6));
        num_params_r__ += logical_eq(prior_dist,6);
        validate_non_negative_index("z_b", "q", q);
        num_params_r__ += q;
        validate_non_negative_index("z_T", "len_z_T", len_z_T);
        num_params_r__ += len_z_T;
        validate_non_negative_index("rho", "len_rho", len_rho);
        num_params_r__ += len_rho;
        validate_non_negative_index("zeta", "len_concentration", len_concentration);
        num_params_r__ += len_concentration;
        validate_non_negative_index("tau", "t", t);
        num_params_r__ += t;
    }

    ~model_binomial() { }


    void transform_inits(const stan::io::var_context& context__,
                         std::vector<int>& params_i__,
                         std::vector<double>& params_r__,
                         std::ostream* pstream__) const {
        stan::io::writer<double> writer__(params_r__,params_i__);
        size_t pos__;
        (void) pos__; // dummy call to supress warning
        std::vector<double> vals_r__;
        std::vector<int> vals_i__;

        if (!(context__.contains_r("gamma")))
            throw std::runtime_error("variable gamma missing");
        vals_r__ = context__.vals_r("gamma");
        pos__ = 0U;
        validate_non_negative_index("gamma", "has_intercept", has_intercept);
        context__.validate_dims("initialization", "gamma", "double", context__.to_vec(has_intercept));
        // generate_declaration gamma
        std::vector<double> gamma(has_intercept,double(0));
        for (int i0__ = 0U; i0__ < has_intercept; ++i0__)
            gamma[i0__] = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < has_intercept; ++i0__)
            try {
            writer__.scalar_ub_unconstrain((logical_eq(link,4) ? 0.0 : stan::math::positive_infinity() ),gamma[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable gamma: ") + e.what());
        }

        if (!(context__.contains_r("z_beta")))
            throw std::runtime_error("variable z_beta missing");
        vals_r__ = context__.vals_r("z_beta");
        pos__ = 0U;
        validate_non_negative_index("z_beta", "(logical_eq(prior_dist,7) ? sum(num_normals) : K )", (logical_eq(prior_dist,7) ? sum(num_normals) : K ));
        context__.validate_dims("initialization", "z_beta", "vector_d", context__.to_vec((logical_eq(prior_dist,7) ? sum(num_normals) : K )));
        // generate_declaration z_beta
        vector_d z_beta(static_cast<Eigen::VectorXd::Index>((logical_eq(prior_dist,7) ? sum(num_normals) : K )));
        for (int j1__ = 0U; j1__ < (logical_eq(prior_dist,7) ? sum(num_normals) : K ); ++j1__)
            z_beta(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_unconstrain(z_beta);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable z_beta: ") + e.what());
        }

        if (!(context__.contains_r("z_beta_smooth")))
            throw std::runtime_error("variable z_beta_smooth missing");
        vals_r__ = context__.vals_r("z_beta_smooth");
        pos__ = 0U;
        validate_non_negative_index("z_beta_smooth", "K_smooth", K_smooth);
        context__.validate_dims("initialization", "z_beta_smooth", "vector_d", context__.to_vec(K_smooth));
        // generate_declaration z_beta_smooth
        vector_d z_beta_smooth(static_cast<Eigen::VectorXd::Index>(K_smooth));
        for (int j1__ = 0U; j1__ < K_smooth; ++j1__)
            z_beta_smooth(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_unconstrain(z_beta_smooth);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable z_beta_smooth: ") + e.what());
        }

        if (!(context__.contains_r("smooth_sd_raw")))
            throw std::runtime_error("variable smooth_sd_raw missing");
        vals_r__ = context__.vals_r("smooth_sd_raw");
        pos__ = 0U;
        validate_non_negative_index("smooth_sd_raw", "(logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,\"smooth_map\",1) : 0 )", (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));
        context__.validate_dims("initialization", "smooth_sd_raw", "vector_d", context__.to_vec((logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 )));
        // generate_declaration smooth_sd_raw
        vector_d smooth_sd_raw(static_cast<Eigen::VectorXd::Index>((logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 )));
        for (int j1__ = 0U; j1__ < (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++j1__)
            smooth_sd_raw(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_lb_unconstrain(0,smooth_sd_raw);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable smooth_sd_raw: ") + e.what());
        }

        if (!(context__.contains_r("global")))
            throw std::runtime_error("variable global missing");
        vals_r__ = context__.vals_r("global");
        pos__ = 0U;
        validate_non_negative_index("global", "hs", hs);
        context__.validate_dims("initialization", "global", "double", context__.to_vec(hs));
        // generate_declaration global
        std::vector<double> global(hs,double(0));
        for (int i0__ = 0U; i0__ < hs; ++i0__)
            global[i0__] = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < hs; ++i0__)
            try {
            writer__.scalar_lb_unconstrain(0,global[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable global: ") + e.what());
        }

        if (!(context__.contains_r("local")))
            throw std::runtime_error("variable local missing");
        vals_r__ = context__.vals_r("local");
        pos__ = 0U;
        validate_non_negative_index("local", "hs", hs);
        validate_non_negative_index("local", "K", K);
        context__.validate_dims("initialization", "local", "vector_d", context__.to_vec(hs,K));
        // generate_declaration local
        std::vector<vector_d> local(hs,vector_d(static_cast<Eigen::VectorXd::Index>(K)));
        for (int j1__ = 0U; j1__ < K; ++j1__)
            for (int i0__ = 0U; i0__ < hs; ++i0__)
                local[i0__](j1__) = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < hs; ++i0__)
            try {
            writer__.vector_lb_unconstrain(0,local[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable local: ") + e.what());
        }

        if (!(context__.contains_r("mix")))
            throw std::runtime_error("variable mix missing");
        vals_r__ = context__.vals_r("mix");
        pos__ = 0U;
        validate_non_negative_index("mix", "(primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6)))", (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))));
        validate_non_negative_index("mix", "K", K);
        context__.validate_dims("initialization", "mix", "vector_d", context__.to_vec((primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))),K));
        // generate_declaration mix
        std::vector<vector_d> mix((primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))),vector_d(static_cast<Eigen::VectorXd::Index>(K)));
        for (int j1__ = 0U; j1__ < K; ++j1__)
            for (int i0__ = 0U; i0__ < (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))); ++i0__)
                mix[i0__](j1__) = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))); ++i0__)
            try {
            writer__.vector_lb_unconstrain(0,mix[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable mix: ") + e.what());
        }

        if (!(context__.contains_r("one_over_lambda")))
            throw std::runtime_error("variable one_over_lambda missing");
        vals_r__ = context__.vals_r("one_over_lambda");
        pos__ = 0U;
        validate_non_negative_index("one_over_lambda", "logical_eq(prior_dist,6)", logical_eq(prior_dist,6));
        context__.validate_dims("initialization", "one_over_lambda", "double", context__.to_vec(logical_eq(prior_dist,6)));
        // generate_declaration one_over_lambda
        std::vector<double> one_over_lambda(logical_eq(prior_dist,6),double(0));
        for (int i0__ = 0U; i0__ < logical_eq(prior_dist,6); ++i0__)
            one_over_lambda[i0__] = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < logical_eq(prior_dist,6); ++i0__)
            try {
            writer__.scalar_lb_unconstrain(0,one_over_lambda[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable one_over_lambda: ") + e.what());
        }

        if (!(context__.contains_r("z_b")))
            throw std::runtime_error("variable z_b missing");
        vals_r__ = context__.vals_r("z_b");
        pos__ = 0U;
        validate_non_negative_index("z_b", "q", q);
        context__.validate_dims("initialization", "z_b", "vector_d", context__.to_vec(q));
        // generate_declaration z_b
        vector_d z_b(static_cast<Eigen::VectorXd::Index>(q));
        for (int j1__ = 0U; j1__ < q; ++j1__)
            z_b(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_unconstrain(z_b);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable z_b: ") + e.what());
        }

        if (!(context__.contains_r("z_T")))
            throw std::runtime_error("variable z_T missing");
        vals_r__ = context__.vals_r("z_T");
        pos__ = 0U;
        validate_non_negative_index("z_T", "len_z_T", len_z_T);
        context__.validate_dims("initialization", "z_T", "vector_d", context__.to_vec(len_z_T));
        // generate_declaration z_T
        vector_d z_T(static_cast<Eigen::VectorXd::Index>(len_z_T));
        for (int j1__ = 0U; j1__ < len_z_T; ++j1__)
            z_T(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_unconstrain(z_T);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable z_T: ") + e.what());
        }

        if (!(context__.contains_r("rho")))
            throw std::runtime_error("variable rho missing");
        vals_r__ = context__.vals_r("rho");
        pos__ = 0U;
        validate_non_negative_index("rho", "len_rho", len_rho);
        context__.validate_dims("initialization", "rho", "vector_d", context__.to_vec(len_rho));
        // generate_declaration rho
        vector_d rho(static_cast<Eigen::VectorXd::Index>(len_rho));
        for (int j1__ = 0U; j1__ < len_rho; ++j1__)
            rho(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_lub_unconstrain(0,1,rho);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable rho: ") + e.what());
        }

        if (!(context__.contains_r("zeta")))
            throw std::runtime_error("variable zeta missing");
        vals_r__ = context__.vals_r("zeta");
        pos__ = 0U;
        validate_non_negative_index("zeta", "len_concentration", len_concentration);
        context__.validate_dims("initialization", "zeta", "vector_d", context__.to_vec(len_concentration));
        // generate_declaration zeta
        vector_d zeta(static_cast<Eigen::VectorXd::Index>(len_concentration));
        for (int j1__ = 0U; j1__ < len_concentration; ++j1__)
            zeta(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_lb_unconstrain(0,zeta);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable zeta: ") + e.what());
        }

        if (!(context__.contains_r("tau")))
            throw std::runtime_error("variable tau missing");
        vals_r__ = context__.vals_r("tau");
        pos__ = 0U;
        validate_non_negative_index("tau", "t", t);
        context__.validate_dims("initialization", "tau", "vector_d", context__.to_vec(t));
        // generate_declaration tau
        vector_d tau(static_cast<Eigen::VectorXd::Index>(t));
        for (int j1__ = 0U; j1__ < t; ++j1__)
            tau(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_lb_unconstrain(0,tau);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable tau: ") + e.what());
        }

        params_r__ = writer__.data_r();
        params_i__ = writer__.data_i();
    }

    void transform_inits(const stan::io::var_context& context,
                         Eigen::Matrix<double,Eigen::Dynamic,1>& params_r,
                         std::ostream* pstream__) const {
      std::vector<double> params_r_vec;
      std::vector<int> params_i_vec;
      transform_inits(context, params_i_vec, params_r_vec, pstream__);
      params_r.resize(params_r_vec.size());
      for (int i = 0; i < params_r.size(); ++i)
        params_r(i) = params_r_vec[i];
    }


    template <bool propto__, bool jacobian__, typename T__>
    T__ log_prob(vector<T__>& params_r__,
                 vector<int>& params_i__,
                 std::ostream* pstream__ = 0) const {

        T__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

        T__ lp__(0.0);
        stan::math::accumulator<T__> lp_accum__;

        // model parameters
        stan::io::reader<T__> in__(params_r__,params_i__);

        vector<T__> gamma;
        size_t dim_gamma_0__ = has_intercept;
        gamma.reserve(dim_gamma_0__);
        for (size_t k_0__ = 0; k_0__ < dim_gamma_0__; ++k_0__) {
            if (jacobian__)
                gamma.push_back(in__.scalar_ub_constrain((logical_eq(link,4) ? 0.0 : stan::math::positive_infinity() ),lp__));
            else
                gamma.push_back(in__.scalar_ub_constrain((logical_eq(link,4) ? 0.0 : stan::math::positive_infinity() )));
        }

        Eigen::Matrix<T__,Eigen::Dynamic,1>  z_beta;
        (void) z_beta;  // dummy to suppress unused var warning
        if (jacobian__)
            z_beta = in__.vector_constrain((logical_eq(prior_dist,7) ? sum(num_normals) : K ),lp__);
        else
            z_beta = in__.vector_constrain((logical_eq(prior_dist,7) ? sum(num_normals) : K ));

        Eigen::Matrix<T__,Eigen::Dynamic,1>  z_beta_smooth;
        (void) z_beta_smooth;  // dummy to suppress unused var warning
        if (jacobian__)
            z_beta_smooth = in__.vector_constrain(K_smooth,lp__);
        else
            z_beta_smooth = in__.vector_constrain(K_smooth);

        Eigen::Matrix<T__,Eigen::Dynamic,1>  smooth_sd_raw;
        (void) smooth_sd_raw;  // dummy to suppress unused var warning
        if (jacobian__)
            smooth_sd_raw = in__.vector_lb_constrain(0,(logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ),lp__);
        else
            smooth_sd_raw = in__.vector_lb_constrain(0,(logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));

        vector<T__> global;
        size_t dim_global_0__ = hs;
        global.reserve(dim_global_0__);
        for (size_t k_0__ = 0; k_0__ < dim_global_0__; ++k_0__) {
            if (jacobian__)
                global.push_back(in__.scalar_lb_constrain(0,lp__));
            else
                global.push_back(in__.scalar_lb_constrain(0));
        }

        vector<Eigen::Matrix<T__,Eigen::Dynamic,1> > local;
        size_t dim_local_0__ = hs;
        local.reserve(dim_local_0__);
        for (size_t k_0__ = 0; k_0__ < dim_local_0__; ++k_0__) {
            if (jacobian__)
                local.push_back(in__.vector_lb_constrain(0,K,lp__));
            else
                local.push_back(in__.vector_lb_constrain(0,K));
        }

        vector<Eigen::Matrix<T__,Eigen::Dynamic,1> > mix;
        size_t dim_mix_0__ = (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6)));
        mix.reserve(dim_mix_0__);
        for (size_t k_0__ = 0; k_0__ < dim_mix_0__; ++k_0__) {
            if (jacobian__)
                mix.push_back(in__.vector_lb_constrain(0,K,lp__));
            else
                mix.push_back(in__.vector_lb_constrain(0,K));
        }

        vector<T__> one_over_lambda;
        size_t dim_one_over_lambda_0__ = logical_eq(prior_dist,6);
        one_over_lambda.reserve(dim_one_over_lambda_0__);
        for (size_t k_0__ = 0; k_0__ < dim_one_over_lambda_0__; ++k_0__) {
            if (jacobian__)
                one_over_lambda.push_back(in__.scalar_lb_constrain(0,lp__));
            else
                one_over_lambda.push_back(in__.scalar_lb_constrain(0));
        }

        Eigen::Matrix<T__,Eigen::Dynamic,1>  z_b;
        (void) z_b;  // dummy to suppress unused var warning
        if (jacobian__)
            z_b = in__.vector_constrain(q,lp__);
        else
            z_b = in__.vector_constrain(q);

        Eigen::Matrix<T__,Eigen::Dynamic,1>  z_T;
        (void) z_T;  // dummy to suppress unused var warning
        if (jacobian__)
            z_T = in__.vector_constrain(len_z_T,lp__);
        else
            z_T = in__.vector_constrain(len_z_T);

        Eigen::Matrix<T__,Eigen::Dynamic,1>  rho;
        (void) rho;  // dummy to suppress unused var warning
        if (jacobian__)
            rho = in__.vector_lub_constrain(0,1,len_rho,lp__);
        else
            rho = in__.vector_lub_constrain(0,1,len_rho);

        Eigen::Matrix<T__,Eigen::Dynamic,1>  zeta;
        (void) zeta;  // dummy to suppress unused var warning
        if (jacobian__)
            zeta = in__.vector_lb_constrain(0,len_concentration,lp__);
        else
            zeta = in__.vector_lb_constrain(0,len_concentration);

        Eigen::Matrix<T__,Eigen::Dynamic,1>  tau;
        (void) tau;  // dummy to suppress unused var warning
        if (jacobian__)
            tau = in__.vector_lb_constrain(0,t,lp__);
        else
            tau = in__.vector_lb_constrain(0,t);


        // transformed parameters
        validate_non_negative_index("beta", "K", K);
        Eigen::Matrix<T__,Eigen::Dynamic,1>  beta(static_cast<Eigen::VectorXd::Index>(K));
        (void) beta;  // dummy to suppress unused var warning

        stan::math::initialize(beta, DUMMY_VAR__);
        stan::math::fill(beta,DUMMY_VAR__);
        validate_non_negative_index("beta_smooth", "K_smooth", K_smooth);
        Eigen::Matrix<T__,Eigen::Dynamic,1>  beta_smooth(static_cast<Eigen::VectorXd::Index>(K_smooth));
        (void) beta_smooth;  // dummy to suppress unused var warning

        stan::math::initialize(beta_smooth, DUMMY_VAR__);
        stan::math::fill(beta_smooth,DUMMY_VAR__);
        validate_non_negative_index("smooth_sd", "(logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,\"smooth_map\",1) : 0 )", (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));
        Eigen::Matrix<T__,Eigen::Dynamic,1>  smooth_sd(static_cast<Eigen::VectorXd::Index>((logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 )));
        (void) smooth_sd;  // dummy to suppress unused var warning

        stan::math::initialize(smooth_sd, DUMMY_VAR__);
        stan::math::fill(smooth_sd,DUMMY_VAR__);
        validate_non_negative_index("b", "q", q);
        Eigen::Matrix<T__,Eigen::Dynamic,1>  b(static_cast<Eigen::VectorXd::Index>(q));
        (void) b;  // dummy to suppress unused var warning

        stan::math::initialize(b, DUMMY_VAR__);
        stan::math::fill(b,DUMMY_VAR__);
        validate_non_negative_index("theta_L", "len_theta_L", len_theta_L);
        Eigen::Matrix<T__,Eigen::Dynamic,1>  theta_L(static_cast<Eigen::VectorXd::Index>(len_theta_L));
        (void) theta_L;  // dummy to suppress unused var warning

        stan::math::initialize(theta_L, DUMMY_VAR__);
        stan::math::fill(theta_L,DUMMY_VAR__);


        try {
            current_statement_begin__ = 496;
            if (as_bool(logical_eq(prior_dist,0))) {
                current_statement_begin__ = 496;
                stan::math::assign(beta, z_beta);
            } else if (as_bool(logical_eq(prior_dist,1))) {
                current_statement_begin__ = 497;
                stan::math::assign(beta, add(elt_multiply(z_beta,prior_scale),prior_mean));
            } else if (as_bool(logical_eq(prior_dist,2))) {
                current_statement_begin__ = 498;
                for (int k = 1; k <= K; ++k) {

                    current_statement_begin__ = 499;
                    stan::math::assign(get_base1_lhs(beta,k,"beta",1), ((CFt(get_base1(z_beta,k,"z_beta",1),get_base1(prior_df,k,"prior_df",1), pstream__) * get_base1(prior_scale,k,"prior_scale",1)) + get_base1(prior_mean,k,"prior_mean",1)));
                }
            } else if (as_bool(logical_eq(prior_dist,3))) {

                current_statement_begin__ = 502;
                if (as_bool((primitive_value(logical_eq(is_continuous,1)) && primitive_value(logical_eq(family,1))))) {
                    current_statement_begin__ = 503;
                    stan::math::assign(beta, hs_prior(z_beta,global,local,global_prior_scale,aux, pstream__));
                } else {
                    current_statement_begin__ = 504;
                    stan::math::assign(beta, hs_prior(z_beta,global,local,global_prior_scale,1, pstream__));
                }
            } else if (as_bool(logical_eq(prior_dist,4))) {

                current_statement_begin__ = 507;
                if (as_bool((primitive_value(logical_eq(is_continuous,1)) && primitive_value(logical_eq(family,1))))) {
                    current_statement_begin__ = 508;
                    stan::math::assign(beta, hsplus_prior(z_beta,global,local,global_prior_scale,aux, pstream__));
                } else {
                    current_statement_begin__ = 509;
                    stan::math::assign(beta, hsplus_prior(z_beta,global,local,global_prior_scale,1, pstream__));
                }
            } else if (as_bool(logical_eq(prior_dist,5))) {
                current_statement_begin__ = 512;
                stan::math::assign(beta, add(prior_mean,elt_multiply(elt_multiply(prior_scale,sqrt(multiply(2,get_base1(mix,1,"mix",1)))),z_beta)));
            } else if (as_bool(logical_eq(prior_dist,6))) {
                current_statement_begin__ = 514;
                stan::math::assign(beta, add(prior_mean,elt_multiply(elt_multiply(multiply(get_base1(one_over_lambda,1,"one_over_lambda",1),prior_scale),sqrt(multiply(2,get_base1(mix,1,"mix",1)))),z_beta)));
            } else if (as_bool(logical_eq(prior_dist,7))) {
                {
                    int z_pos(0);
                    (void) z_pos;  // dummy to suppress unused var warning

                    stan::math::fill(z_pos, std::numeric_limits<int>::min());
                    stan::math::assign(z_pos,1);


                    current_statement_begin__ = 517;
                    for (int k = 1; k <= K; ++k) {

                        current_statement_begin__ = 518;
                        stan::math::assign(get_base1_lhs(beta,k,"beta",1), get_base1(z_beta,z_pos,"z_beta",1));
                        current_statement_begin__ = 519;
                        stan::math::assign(z_pos, (z_pos + 1));
                        current_statement_begin__ = 520;
                        for (int n = 2; n <= get_base1(num_normals,k,"num_normals",1); ++n) {

                            current_statement_begin__ = 521;
                            stan::math::assign(get_base1_lhs(beta,k,"beta",1), (get_base1(beta,k,"beta",1) * get_base1(z_beta,z_pos,"z_beta",1)));
                            current_statement_begin__ = 522;
                            stan::math::assign(z_pos, (z_pos + 1));
                        }
                        current_statement_begin__ = 524;
                        stan::math::assign(get_base1_lhs(beta,k,"beta",1), ((get_base1(beta,k,"beta",1) * pow(get_base1(prior_scale,k,"prior_scale",1),get_base1(num_normals,k,"num_normals",1))) + get_base1(prior_mean,k,"prior_mean",1)));
                    }
                }
            }
            current_statement_begin__ = 528;
            if (as_bool(K_smooth)) {

                current_statement_begin__ = 529;
                stan::math::assign(smooth_sd, add(prior_mean_for_smooth,elt_multiply(prior_scale_for_smooth,smooth_sd_raw)));
                current_statement_begin__ = 530;
                if (as_bool((primitive_value(is_continuous) && primitive_value(logical_eq(family,1))))) {
                    current_statement_begin__ = 530;
                    stan::math::assign(smooth_sd, multiply(smooth_sd,aux));
                }
                current_statement_begin__ = 531;
                stan::math::assign(beta_smooth, elt_multiply(z_beta_smooth,stan::model::rvalue(smooth_sd, stan::model::cons_list(stan::model::index_multi(smooth_map), stan::model::nil_index_list()), "smooth_sd")));
            }
            current_statement_begin__ = 533;
            if (as_bool(logical_gt(t,0))) {

                current_statement_begin__ = 534;
                if (as_bool(logical_eq(special_case,1))) {
                    {
                        int start(0);
                        (void) start;  // dummy to suppress unused var warning

                        stan::math::fill(start, std::numeric_limits<int>::min());
                        stan::math::assign(start,1);


                        current_statement_begin__ = 536;
                        stan::math::assign(theta_L, elt_multiply(scale,tau));
                        current_statement_begin__ = 537;
                        if (as_bool(logical_eq(t,1))) {
                            current_statement_begin__ = 537;
                            stan::math::assign(b, multiply(get_base1(theta_L,1,"theta_L",1),z_b));
                        } else {
                            current_statement_begin__ = 538;
                            for (int i = 1; i <= t; ++i) {
                                {
                                    int end(0);
                                    (void) end;  // dummy to suppress unused var warning

                                    stan::math::fill(end, std::numeric_limits<int>::min());
                                    stan::math::assign(end,((start + get_base1(l,i,"l",1)) - 1));


                                    current_statement_begin__ = 540;
                                    stan::model::assign(b, 
                                                stan::model::cons_list(stan::model::index_min_max(start, end), stan::model::nil_index_list()), 
                                                multiply(get_base1(theta_L,i,"theta_L",1),stan::model::rvalue(z_b, stan::model::cons_list(stan::model::index_min_max(start, end), stan::model::nil_index_list()), "z_b")), 
                                                "assigning variable b");
                                    current_statement_begin__ = 541;
                                    stan::math::assign(start, (end + 1));
                                }
                            }
                        }
                    }
                } else {

                    current_statement_begin__ = 545;
                    stan::math::assign(theta_L, make_theta_L(len_theta_L,p,1.0,tau,scale,zeta,rho,z_T, pstream__));
                    current_statement_begin__ = 547;
                    stan::math::assign(b, make_b(z_b,theta_L,p,l, pstream__));
                }
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        // validate transformed parameters
        for (int i0__ = 0; i0__ < K; ++i0__) {
            if (stan::math::is_uninitialized(beta(i0__))) {
                std::stringstream msg__;
                msg__ << "Undefined transformed parameter: beta" << '[' << i0__ << ']';
                throw std::runtime_error(msg__.str());
            }
        }
        for (int i0__ = 0; i0__ < K_smooth; ++i0__) {
            if (stan::math::is_uninitialized(beta_smooth(i0__))) {
                std::stringstream msg__;
                msg__ << "Undefined transformed parameter: beta_smooth" << '[' << i0__ << ']';
                throw std::runtime_error(msg__.str());
            }
        }
        for (int i0__ = 0; i0__ < (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++i0__) {
            if (stan::math::is_uninitialized(smooth_sd(i0__))) {
                std::stringstream msg__;
                msg__ << "Undefined transformed parameter: smooth_sd" << '[' << i0__ << ']';
                throw std::runtime_error(msg__.str());
            }
        }
        for (int i0__ = 0; i0__ < q; ++i0__) {
            if (stan::math::is_uninitialized(b(i0__))) {
                std::stringstream msg__;
                msg__ << "Undefined transformed parameter: b" << '[' << i0__ << ']';
                throw std::runtime_error(msg__.str());
            }
        }
        for (int i0__ = 0; i0__ < len_theta_L; ++i0__) {
            if (stan::math::is_uninitialized(theta_L(i0__))) {
                std::stringstream msg__;
                msg__ << "Undefined transformed parameter: theta_L" << '[' << i0__ << ']';
                throw std::runtime_error(msg__.str());
            }
        }

        const char* function__ = "validate transformed params";
        (void) function__;  // dummy to suppress unused var warning

        // model body
        try {
            {
                validate_non_negative_index("eta", "N", N);
                Eigen::Matrix<T__,Eigen::Dynamic,1>  eta(static_cast<Eigen::VectorXd::Index>(N));
                (void) eta;  // dummy to suppress unused var warning

                stan::math::initialize(eta, DUMMY_VAR__);
                stan::math::fill(eta,DUMMY_VAR__);


                current_statement_begin__ = 554;
                if (as_bool(logical_gt(K,0))) {

                    current_statement_begin__ = 555;
                    if (as_bool(dense_X)) {
                        current_statement_begin__ = 555;
                        stan::math::assign(eta, multiply(get_base1(X,1,"X",1),beta));
                    } else {
                        current_statement_begin__ = 556;
                        stan::math::assign(eta, csr_matrix_times_vector(N,K,w_X,v_X,u_X,beta));
                    }
                } else {
                    current_statement_begin__ = 558;
                    stan::math::assign(eta, rep_vector(0.0,N));
                }
                current_statement_begin__ = 559;
                if (as_bool(logical_eq(has_offset,1))) {
                    current_statement_begin__ = 559;
                    stan::math::assign(eta, add(eta,offset));
                }
                current_statement_begin__ = 560;
                if (as_bool(K_smooth)) {
                    current_statement_begin__ = 560;
                    stan::math::assign(eta, add(eta,multiply(S,beta_smooth)));
                }
                current_statement_begin__ = 561;
                if (as_bool(logical_gt(t,0))) {

                    current_statement_begin__ = 563;
                    if (as_bool(special_case)) {
                        current_statement_begin__ = 563;
                        for (int i = 1; i <= t; ++i) {
                            current_statement_begin__ = 563;
                            stan::math::assign(eta, add(eta,stan::model::rvalue(b, stan::model::cons_list(stan::model::index_multi(get_base1(V,i,"V",1)), stan::model::nil_index_list()), "b")));
                        }
                    } else {
                        current_statement_begin__ = 564;
                        stan::math::assign(eta, add(eta,csr_matrix_times_vector(N,q,w,v,u,b)));
                    }
                }
                current_statement_begin__ = 566;
                if (as_bool(logical_eq(has_intercept,1))) {

                    current_statement_begin__ = 567;
                    if (as_bool(logical_neq(link,4))) {
                        current_statement_begin__ = 567;
                        stan::math::assign(eta, add(eta,get_base1(gamma,1,"gamma",1)));
                    } else {
                        current_statement_begin__ = 568;
                        stan::math::assign(eta, subtract(add(get_base1(gamma,1,"gamma",1),eta),max(eta)));
                    }
                } else {

                    current_statement_begin__ = 573;
                    stan::math::assign(eta, add(eta,dot_product(xbar,beta)));
                }
                current_statement_begin__ = 577;
                if (as_bool((primitive_value(logical_eq(has_weights,0)) && primitive_value(logical_eq(prior_PD,0))))) {
                    {
                        T__ dummy;
                        (void) dummy;  // dummy to suppress unused var warning

                        stan::math::initialize(dummy, DUMMY_VAR__);
                        stan::math::fill(dummy,DUMMY_VAR__);


                        current_statement_begin__ = 579;
                        stan::math::assign(dummy, ll_binom_lp(y,trials,eta,link, lp__, lp_accum__, pstream__));
                    }
                } else if (as_bool(logical_eq(prior_PD,0))) {
                    current_statement_begin__ = 582;
                    lp_accum__.add(dot_product(weights,pw_binom(y,trials,eta,link, pstream__)));
                }
                current_statement_begin__ = 587;
                if (as_bool(logical_eq(prior_dist,1))) {
                    current_statement_begin__ = 587;
                    lp_accum__.add(normal_log(z_beta,0,1));
                } else if (as_bool(logical_eq(prior_dist,2))) {
                    current_statement_begin__ = 588;
                    lp_accum__.add(normal_log(z_beta,0,1));
                } else if (as_bool(logical_eq(prior_dist,3))) {
                    {
                        T__ log_half;
                        (void) log_half;  // dummy to suppress unused var warning

                        stan::math::initialize(log_half, DUMMY_VAR__);
                        stan::math::fill(log_half,DUMMY_VAR__);
                        stan::math::assign(log_half,-(0.6931471805599454));


                        current_statement_begin__ = 591;
                        lp_accum__.add(normal_log(z_beta,0,1));
                        current_statement_begin__ = 592;
                        lp_accum__.add((normal_log(get_base1(local,1,"local",1),0,1) - log_half));
                        current_statement_begin__ = 593;
                        lp_accum__.add(inv_gamma_log(get_base1(local,2,"local",1),multiply(0.5,prior_df),multiply(0.5,prior_df)));
                        current_statement_begin__ = 594;
                        lp_accum__.add((normal_log(get_base1(global,1,"global",1),0,1) - log_half));
                        current_statement_begin__ = 595;
                        lp_accum__.add(inv_gamma_log(get_base1(global,2,"global",1),(0.5 * global_prior_df),(0.5 * global_prior_df)));
                    }
                } else if (as_bool(logical_eq(prior_dist,4))) {
                    {
                        T__ log_half;
                        (void) log_half;  // dummy to suppress unused var warning

                        stan::math::initialize(log_half, DUMMY_VAR__);
                        stan::math::fill(log_half,DUMMY_VAR__);
                        stan::math::assign(log_half,-(0.6931471805599454));


                        current_statement_begin__ = 599;
                        lp_accum__.add(normal_log(z_beta,0,1));
                        current_statement_begin__ = 600;
                        lp_accum__.add((normal_log(get_base1(local,1,"local",1),0,1) - log_half));
                        current_statement_begin__ = 601;
                        lp_accum__.add(inv_gamma_log(get_base1(local,2,"local",1),multiply(0.5,prior_df),multiply(0.5,prior_df)));
                        current_statement_begin__ = 602;
                        lp_accum__.add((normal_log(get_base1(local,3,"local",1),0,1) - log_half));
                        current_statement_begin__ = 604;
                        lp_accum__.add(inv_gamma_log(get_base1(local,4,"local",1),multiply(0.5,prior_scale),multiply(0.5,prior_scale)));
                        current_statement_begin__ = 605;
                        lp_accum__.add((normal_log(get_base1(global,1,"global",1),0,1) - log_half));
                        current_statement_begin__ = 606;
                        lp_accum__.add(inv_gamma_log(get_base1(global,2,"global",1),(0.5 * global_prior_df),(0.5 * global_prior_df)));
                    }
                } else if (as_bool(logical_eq(prior_dist,5))) {

                    current_statement_begin__ = 609;
                    lp_accum__.add(normal_log(z_beta,0,1));
                    current_statement_begin__ = 610;
                    lp_accum__.add(exponential_log(get_base1(mix,1,"mix",1),1));
                } else if (as_bool(logical_eq(prior_dist,6))) {

                    current_statement_begin__ = 613;
                    lp_accum__.add(normal_log(z_beta,0,1));
                    current_statement_begin__ = 614;
                    lp_accum__.add(exponential_log(get_base1(mix,1,"mix",1),1));
                    current_statement_begin__ = 615;
                    lp_accum__.add(chi_square_log(get_base1(one_over_lambda,1,"one_over_lambda",1),get_base1(prior_df,1,"prior_df",1)));
                } else if (as_bool(logical_eq(prior_dist,7))) {

                    current_statement_begin__ = 618;
                    lp_accum__.add(normal_log(z_beta,0,1));
                }
                current_statement_begin__ = 623;
                if (as_bool(logical_eq(has_intercept,1))) {

                    current_statement_begin__ = 624;
                    if (as_bool(logical_eq(prior_dist_for_intercept,1))) {
                        current_statement_begin__ = 625;
                        lp_accum__.add(normal_log(gamma,prior_mean_for_intercept,prior_scale_for_intercept));
                    } else if (as_bool(logical_eq(prior_dist_for_intercept,2))) {
                        current_statement_begin__ = 627;
                        lp_accum__.add(student_t_log(gamma,prior_df_for_intercept,prior_mean_for_intercept,prior_scale_for_intercept));
                    }
                }
                current_statement_begin__ = 632;
                if (as_bool(K_smooth)) {

                    current_statement_begin__ = 633;
                    lp_accum__.add(normal_log(z_beta_smooth,0,1));
                    current_statement_begin__ = 634;
                    if (as_bool(logical_gt(prior_dist_for_smooth,0))) {
                        {
                            T__ log_half;
                            (void) log_half;  // dummy to suppress unused var warning

                            stan::math::initialize(log_half, DUMMY_VAR__);
                            stan::math::fill(log_half,DUMMY_VAR__);
                            stan::math::assign(log_half,-(0.6931471805599454));


                            current_statement_begin__ = 636;
                            if (as_bool(logical_eq(prior_dist_for_smooth,1))) {
                                current_statement_begin__ = 637;
                                lp_accum__.add((normal_log(smooth_sd_raw,0,1) - log_half));
                            } else if (as_bool(logical_eq(prior_dist_for_smooth,2))) {
                                current_statement_begin__ = 639;
                                lp_accum__.add((student_t_log(smooth_sd_raw,prior_df_for_smooth,0,1) - log_half));
                            } else if (as_bool(logical_eq(prior_dist_for_smooth,3))) {
                                current_statement_begin__ = 641;
                                lp_accum__.add(exponential_log(smooth_sd_raw,1));
                            }
                        }
                    }
                }
                current_statement_begin__ = 645;
                if (as_bool(logical_gt(t,0))) {
                    current_statement_begin__ = 645;
                    decov_lp(z_b,z_T,rho,zeta,tau,regularization,delta,shape,t,p, lp__, lp_accum__, pstream__);
                }
                current_statement_begin__ = 646;
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        lp_accum__.add(lp__);
        return lp_accum__.sum();

    } // log_prob()

    template <bool propto, bool jacobian, typename T_>
    T_ log_prob(Eigen::Matrix<T_,Eigen::Dynamic,1>& params_r,
               std::ostream* pstream = 0) const {
      std::vector<T_> vec_params_r;
      vec_params_r.reserve(params_r.size());
      for (int i = 0; i < params_r.size(); ++i)
        vec_params_r.push_back(params_r(i));
      std::vector<int> vec_params_i;
      return log_prob<propto,jacobian,T_>(vec_params_r, vec_params_i, pstream);
    }


    void get_param_names(std::vector<std::string>& names__) const {
        names__.resize(0);
        names__.push_back("gamma");
        names__.push_back("z_beta");
        names__.push_back("z_beta_smooth");
        names__.push_back("smooth_sd_raw");
        names__.push_back("global");
        names__.push_back("local");
        names__.push_back("mix");
        names__.push_back("one_over_lambda");
        names__.push_back("z_b");
        names__.push_back("z_T");
        names__.push_back("rho");
        names__.push_back("zeta");
        names__.push_back("tau");
        names__.push_back("beta");
        names__.push_back("beta_smooth");
        names__.push_back("smooth_sd");
        names__.push_back("b");
        names__.push_back("theta_L");
        names__.push_back("alpha");
        names__.push_back("mean_PPD");
    }


    void get_dims(std::vector<std::vector<size_t> >& dimss__) const {
        dimss__.resize(0);
        std::vector<size_t> dims__;
        dims__.resize(0);
        dims__.push_back(has_intercept);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((logical_eq(prior_dist,7) ? sum(num_normals) : K ));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(K_smooth);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(hs);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(hs);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))));
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(logical_eq(prior_dist,6));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(q);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(len_z_T);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(len_rho);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(len_concentration);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(t);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(K_smooth);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(q);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(len_theta_L);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(has_intercept);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dimss__.push_back(dims__);
    }

    template <typename RNG>
    void write_array(RNG& base_rng__,
                     std::vector<double>& params_r__,
                     std::vector<int>& params_i__,
                     std::vector<double>& vars__,
                     bool include_tparams__ = true,
                     bool include_gqs__ = true,
                     std::ostream* pstream__ = 0) const {
        vars__.resize(0);
        stan::io::reader<double> in__(params_r__,params_i__);
        static const char* function__ = "model_binomial_namespace::write_array";
        (void) function__;  // dummy to suppress unused var warning
        // read-transform, write parameters
        vector<double> gamma;
        size_t dim_gamma_0__ = has_intercept;
        for (size_t k_0__ = 0; k_0__ < dim_gamma_0__; ++k_0__) {
            gamma.push_back(in__.scalar_ub_constrain((logical_eq(link,4) ? 0.0 : stan::math::positive_infinity() )));
        }
        vector_d z_beta = in__.vector_constrain((logical_eq(prior_dist,7) ? sum(num_normals) : K ));
        vector_d z_beta_smooth = in__.vector_constrain(K_smooth);
        vector_d smooth_sd_raw = in__.vector_lb_constrain(0,(logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));
        vector<double> global;
        size_t dim_global_0__ = hs;
        for (size_t k_0__ = 0; k_0__ < dim_global_0__; ++k_0__) {
            global.push_back(in__.scalar_lb_constrain(0));
        }
        vector<vector_d> local;
        size_t dim_local_0__ = hs;
        for (size_t k_0__ = 0; k_0__ < dim_local_0__; ++k_0__) {
            local.push_back(in__.vector_lb_constrain(0,K));
        }
        vector<vector_d> mix;
        size_t dim_mix_0__ = (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6)));
        for (size_t k_0__ = 0; k_0__ < dim_mix_0__; ++k_0__) {
            mix.push_back(in__.vector_lb_constrain(0,K));
        }
        vector<double> one_over_lambda;
        size_t dim_one_over_lambda_0__ = logical_eq(prior_dist,6);
        for (size_t k_0__ = 0; k_0__ < dim_one_over_lambda_0__; ++k_0__) {
            one_over_lambda.push_back(in__.scalar_lb_constrain(0));
        }
        vector_d z_b = in__.vector_constrain(q);
        vector_d z_T = in__.vector_constrain(len_z_T);
        vector_d rho = in__.vector_lub_constrain(0,1,len_rho);
        vector_d zeta = in__.vector_lb_constrain(0,len_concentration);
        vector_d tau = in__.vector_lb_constrain(0,t);
        for (int k_0__ = 0; k_0__ < has_intercept; ++k_0__) {
            vars__.push_back(gamma[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < (logical_eq(prior_dist,7) ? sum(num_normals) : K ); ++k_0__) {
            vars__.push_back(z_beta[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < K_smooth; ++k_0__) {
            vars__.push_back(z_beta_smooth[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++k_0__) {
            vars__.push_back(smooth_sd_raw[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < hs; ++k_0__) {
            vars__.push_back(global[k_0__]);
        }
        for (int k_1__ = 0; k_1__ < K; ++k_1__) {
            for (int k_0__ = 0; k_0__ < hs; ++k_0__) {
                vars__.push_back(local[k_0__][k_1__]);
            }
        }
        for (int k_1__ = 0; k_1__ < K; ++k_1__) {
            for (int k_0__ = 0; k_0__ < (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))); ++k_0__) {
                vars__.push_back(mix[k_0__][k_1__]);
            }
        }
        for (int k_0__ = 0; k_0__ < logical_eq(prior_dist,6); ++k_0__) {
            vars__.push_back(one_over_lambda[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < q; ++k_0__) {
            vars__.push_back(z_b[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < len_z_T; ++k_0__) {
            vars__.push_back(z_T[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < len_rho; ++k_0__) {
            vars__.push_back(rho[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < len_concentration; ++k_0__) {
            vars__.push_back(zeta[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < t; ++k_0__) {
            vars__.push_back(tau[k_0__]);
        }

        if (!include_tparams__) return;
        // declare and define transformed parameters
        double lp__ = 0.0;
        (void) lp__;  // dummy to suppress unused var warning
        stan::math::accumulator<double> lp_accum__;

        double DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

        validate_non_negative_index("beta", "K", K);
        vector_d beta(static_cast<Eigen::VectorXd::Index>(K));
        (void) beta;  // dummy to suppress unused var warning

        stan::math::initialize(beta, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(beta,DUMMY_VAR__);
        validate_non_negative_index("beta_smooth", "K_smooth", K_smooth);
        vector_d beta_smooth(static_cast<Eigen::VectorXd::Index>(K_smooth));
        (void) beta_smooth;  // dummy to suppress unused var warning

        stan::math::initialize(beta_smooth, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(beta_smooth,DUMMY_VAR__);
        validate_non_negative_index("smooth_sd", "(logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,\"smooth_map\",1) : 0 )", (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));
        vector_d smooth_sd(static_cast<Eigen::VectorXd::Index>((logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 )));
        (void) smooth_sd;  // dummy to suppress unused var warning

        stan::math::initialize(smooth_sd, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(smooth_sd,DUMMY_VAR__);
        validate_non_negative_index("b", "q", q);
        vector_d b(static_cast<Eigen::VectorXd::Index>(q));
        (void) b;  // dummy to suppress unused var warning

        stan::math::initialize(b, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(b,DUMMY_VAR__);
        validate_non_negative_index("theta_L", "len_theta_L", len_theta_L);
        vector_d theta_L(static_cast<Eigen::VectorXd::Index>(len_theta_L));
        (void) theta_L;  // dummy to suppress unused var warning

        stan::math::initialize(theta_L, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(theta_L,DUMMY_VAR__);


        try {
            current_statement_begin__ = 496;
            if (as_bool(logical_eq(prior_dist,0))) {
                current_statement_begin__ = 496;
                stan::math::assign(beta, z_beta);
            } else if (as_bool(logical_eq(prior_dist,1))) {
                current_statement_begin__ = 497;
                stan::math::assign(beta, add(elt_multiply(z_beta,prior_scale),prior_mean));
            } else if (as_bool(logical_eq(prior_dist,2))) {
                current_statement_begin__ = 498;
                for (int k = 1; k <= K; ++k) {

                    current_statement_begin__ = 499;
                    stan::math::assign(get_base1_lhs(beta,k,"beta",1), ((CFt(get_base1(z_beta,k,"z_beta",1),get_base1(prior_df,k,"prior_df",1), pstream__) * get_base1(prior_scale,k,"prior_scale",1)) + get_base1(prior_mean,k,"prior_mean",1)));
                }
            } else if (as_bool(logical_eq(prior_dist,3))) {

                current_statement_begin__ = 502;
                if (as_bool((primitive_value(logical_eq(is_continuous,1)) && primitive_value(logical_eq(family,1))))) {
                    current_statement_begin__ = 503;
                    stan::math::assign(beta, hs_prior(z_beta,global,local,global_prior_scale,aux, pstream__));
                } else {
                    current_statement_begin__ = 504;
                    stan::math::assign(beta, hs_prior(z_beta,global,local,global_prior_scale,1, pstream__));
                }
            } else if (as_bool(logical_eq(prior_dist,4))) {

                current_statement_begin__ = 507;
                if (as_bool((primitive_value(logical_eq(is_continuous,1)) && primitive_value(logical_eq(family,1))))) {
                    current_statement_begin__ = 508;
                    stan::math::assign(beta, hsplus_prior(z_beta,global,local,global_prior_scale,aux, pstream__));
                } else {
                    current_statement_begin__ = 509;
                    stan::math::assign(beta, hsplus_prior(z_beta,global,local,global_prior_scale,1, pstream__));
                }
            } else if (as_bool(logical_eq(prior_dist,5))) {
                current_statement_begin__ = 512;
                stan::math::assign(beta, add(prior_mean,elt_multiply(elt_multiply(prior_scale,sqrt(multiply(2,get_base1(mix,1,"mix",1)))),z_beta)));
            } else if (as_bool(logical_eq(prior_dist,6))) {
                current_statement_begin__ = 514;
                stan::math::assign(beta, add(prior_mean,elt_multiply(elt_multiply(multiply(get_base1(one_over_lambda,1,"one_over_lambda",1),prior_scale),sqrt(multiply(2,get_base1(mix,1,"mix",1)))),z_beta)));
            } else if (as_bool(logical_eq(prior_dist,7))) {
                {
                    int z_pos(0);
                    (void) z_pos;  // dummy to suppress unused var warning

                    stan::math::fill(z_pos, std::numeric_limits<int>::min());
                    stan::math::assign(z_pos,1);


                    current_statement_begin__ = 517;
                    for (int k = 1; k <= K; ++k) {

                        current_statement_begin__ = 518;
                        stan::math::assign(get_base1_lhs(beta,k,"beta",1), get_base1(z_beta,z_pos,"z_beta",1));
                        current_statement_begin__ = 519;
                        stan::math::assign(z_pos, (z_pos + 1));
                        current_statement_begin__ = 520;
                        for (int n = 2; n <= get_base1(num_normals,k,"num_normals",1); ++n) {

                            current_statement_begin__ = 521;
                            stan::math::assign(get_base1_lhs(beta,k,"beta",1), (get_base1(beta,k,"beta",1) * get_base1(z_beta,z_pos,"z_beta",1)));
                            current_statement_begin__ = 522;
                            stan::math::assign(z_pos, (z_pos + 1));
                        }
                        current_statement_begin__ = 524;
                        stan::math::assign(get_base1_lhs(beta,k,"beta",1), ((get_base1(beta,k,"beta",1) * pow(get_base1(prior_scale,k,"prior_scale",1),get_base1(num_normals,k,"num_normals",1))) + get_base1(prior_mean,k,"prior_mean",1)));
                    }
                }
            }
            current_statement_begin__ = 528;
            if (as_bool(K_smooth)) {

                current_statement_begin__ = 529;
                stan::math::assign(smooth_sd, add(prior_mean_for_smooth,elt_multiply(prior_scale_for_smooth,smooth_sd_raw)));
                current_statement_begin__ = 530;
                if (as_bool((primitive_value(is_continuous) && primitive_value(logical_eq(family,1))))) {
                    current_statement_begin__ = 530;
                    stan::math::assign(smooth_sd, multiply(smooth_sd,aux));
                }
                current_statement_begin__ = 531;
                stan::math::assign(beta_smooth, elt_multiply(z_beta_smooth,stan::model::rvalue(smooth_sd, stan::model::cons_list(stan::model::index_multi(smooth_map), stan::model::nil_index_list()), "smooth_sd")));
            }
            current_statement_begin__ = 533;
            if (as_bool(logical_gt(t,0))) {

                current_statement_begin__ = 534;
                if (as_bool(logical_eq(special_case,1))) {
                    {
                        int start(0);
                        (void) start;  // dummy to suppress unused var warning

                        stan::math::fill(start, std::numeric_limits<int>::min());
                        stan::math::assign(start,1);


                        current_statement_begin__ = 536;
                        stan::math::assign(theta_L, elt_multiply(scale,tau));
                        current_statement_begin__ = 537;
                        if (as_bool(logical_eq(t,1))) {
                            current_statement_begin__ = 537;
                            stan::math::assign(b, multiply(get_base1(theta_L,1,"theta_L",1),z_b));
                        } else {
                            current_statement_begin__ = 538;
                            for (int i = 1; i <= t; ++i) {
                                {
                                    int end(0);
                                    (void) end;  // dummy to suppress unused var warning

                                    stan::math::fill(end, std::numeric_limits<int>::min());
                                    stan::math::assign(end,((start + get_base1(l,i,"l",1)) - 1));


                                    current_statement_begin__ = 540;
                                    stan::model::assign(b, 
                                                stan::model::cons_list(stan::model::index_min_max(start, end), stan::model::nil_index_list()), 
                                                multiply(get_base1(theta_L,i,"theta_L",1),stan::model::rvalue(z_b, stan::model::cons_list(stan::model::index_min_max(start, end), stan::model::nil_index_list()), "z_b")), 
                                                "assigning variable b");
                                    current_statement_begin__ = 541;
                                    stan::math::assign(start, (end + 1));
                                }
                            }
                        }
                    }
                } else {

                    current_statement_begin__ = 545;
                    stan::math::assign(theta_L, make_theta_L(len_theta_L,p,1.0,tau,scale,zeta,rho,z_T, pstream__));
                    current_statement_begin__ = 547;
                    stan::math::assign(b, make_b(z_b,theta_L,p,l, pstream__));
                }
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        // validate transformed parameters

        // write transformed parameters
        for (int k_0__ = 0; k_0__ < K; ++k_0__) {
            vars__.push_back(beta[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < K_smooth; ++k_0__) {
            vars__.push_back(beta_smooth[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++k_0__) {
            vars__.push_back(smooth_sd[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < q; ++k_0__) {
            vars__.push_back(b[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < len_theta_L; ++k_0__) {
            vars__.push_back(theta_L[k_0__]);
        }

        if (!include_gqs__) return;
        // declare and define generated quantities
        validate_non_negative_index("alpha", "has_intercept", has_intercept);
        vector<double> alpha(has_intercept, 0.0);
        stan::math::initialize(alpha, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(alpha,DUMMY_VAR__);
        double mean_PPD(0.0);
        (void) mean_PPD;  // dummy to suppress unused var warning

        stan::math::initialize(mean_PPD, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(mean_PPD,DUMMY_VAR__);
        stan::math::assign(mean_PPD,0);


        try {
            current_statement_begin__ = 651;
            if (as_bool(logical_eq(has_intercept,1))) {

                current_statement_begin__ = 652;
                if (as_bool(dense_X)) {
                    current_statement_begin__ = 652;
                    stan::math::assign(get_base1_lhs(alpha,1,"alpha",1), (get_base1(gamma,1,"gamma",1) - dot_product(xbar,beta)));
                } else {
                    current_statement_begin__ = 653;
                    stan::math::assign(get_base1_lhs(alpha,1,"alpha",1), get_base1(gamma,1,"gamma",1));
                }
            }
            {
                validate_non_negative_index("pi", "N", N);
                vector_d pi(static_cast<Eigen::VectorXd::Index>(N));
                (void) pi;  // dummy to suppress unused var warning

                stan::math::initialize(pi, std::numeric_limits<double>::quiet_NaN());
                stan::math::fill(pi,DUMMY_VAR__);
                validate_non_negative_index("eta", "N", N);
                vector_d eta(static_cast<Eigen::VectorXd::Index>(N));
                (void) eta;  // dummy to suppress unused var warning

                stan::math::initialize(eta, std::numeric_limits<double>::quiet_NaN());
                stan::math::fill(eta,DUMMY_VAR__);


                current_statement_begin__ = 659;
                if (as_bool(logical_gt(K,0))) {

                    current_statement_begin__ = 660;
                    if (as_bool(dense_X)) {
                        current_statement_begin__ = 660;
                        stan::math::assign(eta, multiply(get_base1(X,1,"X",1),beta));
                    } else {
                        current_statement_begin__ = 661;
                        stan::math::assign(eta, csr_matrix_times_vector(N,K,w_X,v_X,u_X,beta));
                    }
                } else {
                    current_statement_begin__ = 663;
                    stan::math::assign(eta, rep_vector(0.0,N));
                }
                current_statement_begin__ = 664;
                if (as_bool(logical_eq(has_offset,1))) {
                    current_statement_begin__ = 664;
                    stan::math::assign(eta, add(eta,offset));
                }
                current_statement_begin__ = 665;
                if (as_bool(K_smooth)) {
                    current_statement_begin__ = 665;
                    stan::math::assign(eta, add(eta,multiply(S,beta_smooth)));
                }
                current_statement_begin__ = 666;
                if (as_bool(logical_gt(t,0))) {

                    current_statement_begin__ = 668;
                    if (as_bool(special_case)) {
                        current_statement_begin__ = 668;
                        for (int i = 1; i <= t; ++i) {
                            current_statement_begin__ = 668;
                            stan::math::assign(eta, add(eta,stan::model::rvalue(b, stan::model::cons_list(stan::model::index_multi(get_base1(V,i,"V",1)), stan::model::nil_index_list()), "b")));
                        }
                    } else {
                        current_statement_begin__ = 669;
                        stan::math::assign(eta, add(eta,csr_matrix_times_vector(N,q,w,v,u,b)));
                    }
                }
                current_statement_begin__ = 671;
                if (as_bool(logical_eq(has_intercept,1))) {

                    current_statement_begin__ = 672;
                    if (as_bool(logical_neq(link,4))) {
                        current_statement_begin__ = 672;
                        stan::math::assign(eta, add(eta,get_base1(gamma,1,"gamma",1)));
                    } else {
                        {
                            double shift(0.0);
                            (void) shift;  // dummy to suppress unused var warning

                            stan::math::initialize(shift, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(shift,DUMMY_VAR__);


                            current_statement_begin__ = 675;
                            stan::math::assign(shift, max(eta));
                            current_statement_begin__ = 676;
                            stan::math::assign(eta, subtract(add(get_base1(gamma,1,"gamma",1),eta),shift));
                            current_statement_begin__ = 677;
                            stan::math::assign(get_base1_lhs(alpha,1,"alpha",1), (get_base1(alpha,1,"alpha",1) - shift));
                        }
                    }
                } else {

                    current_statement_begin__ = 683;
                    stan::math::assign(eta, add(eta,dot_product(xbar,beta)));
                }
                current_statement_begin__ = 686;
                stan::math::assign(pi, linkinv_binom(eta,link, pstream__));
                current_statement_begin__ = 687;
                for (int n = 1; n <= N; ++n) {
                    current_statement_begin__ = 687;
                    stan::math::assign(mean_PPD, (mean_PPD + binomial_rng(get_base1(trials,n,"trials",1),get_base1(pi,n,"pi",1), base_rng__)));
                }
                current_statement_begin__ = 688;
                stan::math::assign(mean_PPD, (mean_PPD / N));
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        // validate generated quantities

        // write generated quantities
        for (int k_0__ = 0; k_0__ < has_intercept; ++k_0__) {
            vars__.push_back(alpha[k_0__]);
        }
        vars__.push_back(mean_PPD);

    }

    template <typename RNG>
    void write_array(RNG& base_rng,
                     Eigen::Matrix<double,Eigen::Dynamic,1>& params_r,
                     Eigen::Matrix<double,Eigen::Dynamic,1>& vars,
                     bool include_tparams = true,
                     bool include_gqs = true,
                     std::ostream* pstream = 0) const {
      std::vector<double> params_r_vec(params_r.size());
      for (int i = 0; i < params_r.size(); ++i)
        params_r_vec[i] = params_r(i);
      std::vector<double> vars_vec;
      std::vector<int> params_i_vec;
      write_array(base_rng,params_r_vec,params_i_vec,vars_vec,include_tparams,include_gqs,pstream);
      vars.resize(vars_vec.size());
      for (int i = 0; i < vars.size(); ++i)
        vars(i) = vars_vec[i];
    }

    static std::string model_name() {
        return "model_binomial";
    }


    void constrained_param_names(std::vector<std::string>& param_names__,
                                 bool include_tparams__ = true,
                                 bool include_gqs__ = true) const {
        std::stringstream param_name_stream__;
        for (int k_0__ = 1; k_0__ <= has_intercept; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "gamma" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (logical_eq(prior_dist,7) ? sum(num_normals) : K ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_beta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= K_smooth; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_beta_smooth" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "smooth_sd_raw" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= hs; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "global" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_1__ = 1; k_1__ <= K; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= hs; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "local" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        for (int k_1__ = 1; k_1__ <= K; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))); ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "mix" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        for (int k_0__ = 1; k_0__ <= logical_eq(prior_dist,6); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "one_over_lambda" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= q; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_b" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_z_T; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_T" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_rho; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "rho" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_concentration; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "zeta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= t; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "tau" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__ && !include_tparams__) return;
        for (int k_0__ = 1; k_0__ <= K; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "beta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= K_smooth; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "beta_smooth" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "smooth_sd" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= q; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "b" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_theta_L; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "theta_L" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__) return;
        for (int k_0__ = 1; k_0__ <= has_intercept; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "alpha" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        param_name_stream__.str(std::string());
        param_name_stream__ << "mean_PPD";
        param_names__.push_back(param_name_stream__.str());
    }


    void unconstrained_param_names(std::vector<std::string>& param_names__,
                                   bool include_tparams__ = true,
                                   bool include_gqs__ = true) const {
        std::stringstream param_name_stream__;
        for (int k_0__ = 1; k_0__ <= has_intercept; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "gamma" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (logical_eq(prior_dist,7) ? sum(num_normals) : K ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_beta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= K_smooth; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_beta_smooth" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "smooth_sd_raw" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= hs; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "global" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_1__ = 1; k_1__ <= K; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= hs; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "local" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        for (int k_1__ = 1; k_1__ <= K; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))); ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "mix" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        for (int k_0__ = 1; k_0__ <= logical_eq(prior_dist,6); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "one_over_lambda" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= q; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_b" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_z_T; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_T" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_rho; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "rho" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_concentration; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "zeta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= t; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "tau" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__ && !include_tparams__) return;
        for (int k_0__ = 1; k_0__ <= K; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "beta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= K_smooth; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "beta_smooth" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "smooth_sd" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= q; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "b" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_theta_L; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "theta_L" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__) return;
        for (int k_0__ = 1; k_0__ <= has_intercept; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "alpha" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        param_name_stream__.str(std::string());
        param_name_stream__ << "mean_PPD";
        param_names__.push_back(param_name_stream__.str());
    }

}; // model

}




// Code generated by Stan version 2.16.0

#include <stan/model/model_header.hpp>

namespace model_continuous_namespace {

using std::istream;
using std::string;
using std::stringstream;
using std::vector;
using stan::io::dump;
using stan::math::lgamma;
using stan::model::prob_grad;
using namespace stan::math;

typedef Eigen::Matrix<double,Eigen::Dynamic,1> vector_d;
typedef Eigen::Matrix<double,1,Eigen::Dynamic> row_vector_d;
typedef Eigen::Matrix<double,Eigen::Dynamic,Eigen::Dynamic> matrix_d;

static int current_statement_begin__;

stan::io::program_reader prog_reader__() {
    stan::io::program_reader reader;
    reader.add_event(0, 0, "start", "model_continuous");
    reader.add_event(1369, 1369, "end", "model_continuous");
    return reader;
}

template <typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T7__>
Eigen::Matrix<typename boost::math::tools::promote_args<T2__, T3__, T4__, T5__, typename boost::math::tools::promote_args<T6__, T7__>::type>::type, Eigen::Dynamic,1>
make_theta_L(const int& len_theta_L,
                 const std::vector<int>& p,
                 const T2__& dispersion,
                 const Eigen::Matrix<T3__, Eigen::Dynamic,1>& tau,
                 const Eigen::Matrix<T4__, Eigen::Dynamic,1>& scale,
                 const Eigen::Matrix<T5__, Eigen::Dynamic,1>& zeta,
                 const Eigen::Matrix<T6__, Eigen::Dynamic,1>& rho,
                 const Eigen::Matrix<T7__, Eigen::Dynamic,1>& z_T, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T2__, T3__, T4__, T5__, typename boost::math::tools::promote_args<T6__, T7__>::type>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            validate_non_negative_index("theta_L", "len_theta_L", len_theta_L);
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  theta_L(static_cast<Eigen::VectorXd::Index>(len_theta_L));
            (void) theta_L;  // dummy to suppress unused var warning

            stan::math::initialize(theta_L, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(theta_L,DUMMY_VAR__);
            int zeta_mark(0);
            (void) zeta_mark;  // dummy to suppress unused var warning

            stan::math::fill(zeta_mark, std::numeric_limits<int>::min());
            stan::math::assign(zeta_mark,1);
            int rho_mark(0);
            (void) rho_mark;  // dummy to suppress unused var warning

            stan::math::fill(rho_mark, std::numeric_limits<int>::min());
            stan::math::assign(rho_mark,1);
            int z_T_mark(0);
            (void) z_T_mark;  // dummy to suppress unused var warning

            stan::math::fill(z_T_mark, std::numeric_limits<int>::min());
            stan::math::assign(z_T_mark,1);
            int theta_L_mark(0);
            (void) theta_L_mark;  // dummy to suppress unused var warning

            stan::math::fill(theta_L_mark, std::numeric_limits<int>::min());
            stan::math::assign(theta_L_mark,1);


            current_statement_begin__ = 52;
            for (int i = 1; i <= size(p); ++i) {
                {
                    int nc(0);
                    (void) nc;  // dummy to suppress unused var warning

                    stan::math::fill(nc, std::numeric_limits<int>::min());
                    stan::math::assign(nc,get_base1(p,i,"p",1));


                    current_statement_begin__ = 54;
                    if (as_bool(logical_eq(nc,1))) {

                        current_statement_begin__ = 55;
                        stan::math::assign(get_base1_lhs(theta_L,theta_L_mark,"theta_L",1), ((get_base1(tau,i,"tau",1) * get_base1(scale,i,"scale",1)) * dispersion));
                        current_statement_begin__ = 57;
                        stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                    } else {
                        {
                            validate_non_negative_index("T_i", "nc", nc);
                            validate_non_negative_index("T_i", "nc", nc);
                            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,Eigen::Dynamic>  T_i(static_cast<Eigen::VectorXd::Index>(nc),static_cast<Eigen::VectorXd::Index>(nc));
                            (void) T_i;  // dummy to suppress unused var warning

                            stan::math::initialize(T_i, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(T_i,DUMMY_VAR__);
                            fun_scalar_t__ std_dev;
                            (void) std_dev;  // dummy to suppress unused var warning

                            stan::math::initialize(std_dev, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(std_dev,DUMMY_VAR__);
                            fun_scalar_t__ T21;
                            (void) T21;  // dummy to suppress unused var warning

                            stan::math::initialize(T21, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(T21,DUMMY_VAR__);
                            fun_scalar_t__ trace_T_i;
                            (void) trace_T_i;  // dummy to suppress unused var warning

                            stan::math::initialize(trace_T_i, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(trace_T_i,DUMMY_VAR__);
                            stan::math::assign(trace_T_i,(square(((get_base1(tau,i,"tau",1) * get_base1(scale,i,"scale",1)) * dispersion)) * nc));
                            validate_non_negative_index("pi", "nc", nc);
                            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  pi(static_cast<Eigen::VectorXd::Index>(nc));
                            (void) pi;  // dummy to suppress unused var warning

                            stan::math::initialize(pi, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(pi,DUMMY_VAR__);
                            stan::math::assign(pi,segment(zeta,zeta_mark,nc));


                            current_statement_begin__ = 65;
                            stan::math::assign(pi, divide(pi,sum(pi)));
                            current_statement_begin__ = 68;
                            stan::math::assign(zeta_mark, (zeta_mark + nc));
                            current_statement_begin__ = 69;
                            stan::math::assign(std_dev, sqrt((get_base1(pi,1,"pi",1) * trace_T_i)));
                            current_statement_begin__ = 70;
                            stan::math::assign(get_base1_lhs(T_i,1,1,"T_i",1), std_dev);
                            current_statement_begin__ = 73;
                            stan::math::assign(std_dev, sqrt((get_base1(pi,2,"pi",1) * trace_T_i)));
                            current_statement_begin__ = 74;
                            stan::math::assign(T21, ((2.0 * get_base1(rho,rho_mark,"rho",1)) - 1.0));
                            current_statement_begin__ = 75;
                            stan::math::assign(rho_mark, (rho_mark + 1));
                            current_statement_begin__ = 76;
                            stan::math::assign(get_base1_lhs(T_i,2,2,"T_i",1), (std_dev * sqrt((1.0 - square(T21)))));
                            current_statement_begin__ = 77;
                            stan::math::assign(get_base1_lhs(T_i,2,1,"T_i",1), (std_dev * T21));
                            current_statement_begin__ = 79;
                            for (int r = 2; r <= (nc - 1); ++r) {
                                {
                                    int rp1(0);
                                    (void) rp1;  // dummy to suppress unused var warning

                                    stan::math::fill(rp1, std::numeric_limits<int>::min());
                                    stan::math::assign(rp1,(r + 1));
                                    validate_non_negative_index("T_row", "r", r);
                                    Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  T_row(static_cast<Eigen::VectorXd::Index>(r));
                                    (void) T_row;  // dummy to suppress unused var warning

                                    stan::math::initialize(T_row, std::numeric_limits<double>::quiet_NaN());
                                    stan::math::fill(T_row,DUMMY_VAR__);
                                    stan::math::assign(T_row,segment(z_T,z_T_mark,r));
                                    fun_scalar_t__ scale_factor;
                                    (void) scale_factor;  // dummy to suppress unused var warning

                                    stan::math::initialize(scale_factor, std::numeric_limits<double>::quiet_NaN());
                                    stan::math::fill(scale_factor,DUMMY_VAR__);
                                    stan::math::assign(scale_factor,(sqrt((get_base1(rho,rho_mark,"rho",1) / dot_self(T_row))) * std_dev));


                                    current_statement_begin__ = 83;
                                    stan::math::assign(z_T_mark, (z_T_mark + r));
                                    current_statement_begin__ = 84;
                                    stan::math::assign(std_dev, sqrt((get_base1(pi,rp1,"pi",1) * trace_T_i)));
                                    current_statement_begin__ = 85;
                                    for (int c = 1; c <= r; ++c) {
                                        current_statement_begin__ = 85;
                                        stan::math::assign(get_base1_lhs(T_i,rp1,c,"T_i",1), (get_base1(T_row,c,"T_row",1) * scale_factor));
                                    }
                                    current_statement_begin__ = 86;
                                    stan::math::assign(get_base1_lhs(T_i,rp1,rp1,"T_i",1), (sqrt((1.0 - get_base1(rho,rho_mark,"rho",1))) * std_dev));
                                    current_statement_begin__ = 87;
                                    stan::math::assign(rho_mark, (rho_mark + 1));
                                }
                            }
                            current_statement_begin__ = 91;
                            for (int c = 1; c <= nc; ++c) {
                                current_statement_begin__ = 91;
                                for (int r = c; r <= nc; ++r) {

                                    current_statement_begin__ = 92;
                                    stan::math::assign(get_base1_lhs(theta_L,theta_L_mark,"theta_L",1), get_base1(T_i,r,c,"T_i",1));
                                    current_statement_begin__ = 93;
                                    stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                                }
                            }
                        }
                    }
                }
            }
            current_statement_begin__ = 97;
            return stan::math::promote_scalar<fun_return_scalar_t__>(theta_L);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct make_theta_L_functor__ {
    template <typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T7__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T2__, T3__, T4__, T5__, typename boost::math::tools::promote_args<T6__, T7__>::type>::type, Eigen::Dynamic,1>
    operator()(const int& len_theta_L,
                 const std::vector<int>& p,
                 const T2__& dispersion,
                 const Eigen::Matrix<T3__, Eigen::Dynamic,1>& tau,
                 const Eigen::Matrix<T4__, Eigen::Dynamic,1>& scale,
                 const Eigen::Matrix<T5__, Eigen::Dynamic,1>& zeta,
                 const Eigen::Matrix<T6__, Eigen::Dynamic,1>& rho,
                 const Eigen::Matrix<T7__, Eigen::Dynamic,1>& z_T, std::ostream* pstream__) const {
        return make_theta_L(len_theta_L, p, dispersion, tau, scale, zeta, rho, z_T, pstream__);
    }
};

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
make_b(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_b,
           const Eigen::Matrix<T1__, Eigen::Dynamic,1>& theta_L,
           const std::vector<int>& p,
           const std::vector<int>& l, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            validate_non_negative_index("b", "rows(z_b)", rows(z_b));
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  b(static_cast<Eigen::VectorXd::Index>(rows(z_b)));
            (void) b;  // dummy to suppress unused var warning

            stan::math::initialize(b, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(b,DUMMY_VAR__);
            int b_mark(0);
            (void) b_mark;  // dummy to suppress unused var warning

            stan::math::fill(b_mark, std::numeric_limits<int>::min());
            stan::math::assign(b_mark,1);
            int theta_L_mark(0);
            (void) theta_L_mark;  // dummy to suppress unused var warning

            stan::math::fill(theta_L_mark, std::numeric_limits<int>::min());
            stan::math::assign(theta_L_mark,1);


            current_statement_begin__ = 115;
            for (int i = 1; i <= size(p); ++i) {
                {
                    int nc(0);
                    (void) nc;  // dummy to suppress unused var warning

                    stan::math::fill(nc, std::numeric_limits<int>::min());
                    stan::math::assign(nc,get_base1(p,i,"p",1));


                    current_statement_begin__ = 117;
                    if (as_bool(logical_eq(nc,1))) {
                        {
                            fun_scalar_t__ theta_L_start;
                            (void) theta_L_start;  // dummy to suppress unused var warning

                            stan::math::initialize(theta_L_start, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(theta_L_start,DUMMY_VAR__);
                            stan::math::assign(theta_L_start,get_base1(theta_L,theta_L_mark,"theta_L",1));


                            current_statement_begin__ = 119;
                            for (int s = b_mark; s <= ((b_mark + get_base1(l,i,"l",1)) - 1); ++s) {
                                current_statement_begin__ = 120;
                                stan::math::assign(get_base1_lhs(b,s,"b",1), (theta_L_start * get_base1(z_b,s,"z_b",1)));
                            }
                            current_statement_begin__ = 121;
                            stan::math::assign(b_mark, (b_mark + get_base1(l,i,"l",1)));
                            current_statement_begin__ = 122;
                            stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                        }
                    } else {
                        {
                            validate_non_negative_index("T_i", "nc", nc);
                            validate_non_negative_index("T_i", "nc", nc);
                            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,Eigen::Dynamic>  T_i(static_cast<Eigen::VectorXd::Index>(nc),static_cast<Eigen::VectorXd::Index>(nc));
                            (void) T_i;  // dummy to suppress unused var warning

                            stan::math::initialize(T_i, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(T_i,DUMMY_VAR__);
                            stan::math::assign(T_i,rep_matrix(0,nc,nc));


                            current_statement_begin__ = 126;
                            for (int c = 1; c <= nc; ++c) {

                                current_statement_begin__ = 127;
                                stan::math::assign(get_base1_lhs(T_i,c,c,"T_i",1), get_base1(theta_L,theta_L_mark,"theta_L",1));
                                current_statement_begin__ = 128;
                                stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                                current_statement_begin__ = 129;
                                for (int r = (c + 1); r <= nc; ++r) {

                                    current_statement_begin__ = 130;
                                    stan::math::assign(get_base1_lhs(T_i,r,c,"T_i",1), get_base1(theta_L,theta_L_mark,"theta_L",1));
                                    current_statement_begin__ = 131;
                                    stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                                }
                            }
                            current_statement_begin__ = 134;
                            for (int j = 1; j <= get_base1(l,i,"l",1); ++j) {
                                {
                                    validate_non_negative_index("temp", "nc", nc);
                                    Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  temp(static_cast<Eigen::VectorXd::Index>(nc));
                                    (void) temp;  // dummy to suppress unused var warning

                                    stan::math::initialize(temp, std::numeric_limits<double>::quiet_NaN());
                                    stan::math::fill(temp,DUMMY_VAR__);
                                    stan::math::assign(temp,multiply(T_i,segment(z_b,b_mark,nc)));


                                    current_statement_begin__ = 136;
                                    stan::math::assign(b_mark, (b_mark - 1));
                                    current_statement_begin__ = 137;
                                    for (int s = 1; s <= nc; ++s) {
                                        current_statement_begin__ = 137;
                                        stan::math::assign(get_base1_lhs(b,(b_mark + s),"b",1), get_base1(temp,s,"temp",1));
                                    }
                                    current_statement_begin__ = 138;
                                    stan::math::assign(b_mark, ((b_mark + nc) + 1));
                                }
                            }
                        }
                    }
                }
            }
            current_statement_begin__ = 142;
            return stan::math::promote_scalar<fun_return_scalar_t__>(b);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct make_b_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_b,
           const Eigen::Matrix<T1__, Eigen::Dynamic,1>& theta_L,
           const std::vector<int>& p,
           const std::vector<int>& l, std::ostream* pstream__) const {
        return make_b(z_b, theta_L, p, l, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T7__, typename T_lp__, typename T_lp_accum__>
void
decov_lp(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_b,
             const Eigen::Matrix<T1__, Eigen::Dynamic,1>& z_T,
             const Eigen::Matrix<T2__, Eigen::Dynamic,1>& rho,
             const Eigen::Matrix<T3__, Eigen::Dynamic,1>& zeta,
             const Eigen::Matrix<T4__, Eigen::Dynamic,1>& tau,
             const std::vector<T5__>& regularization,
             const std::vector<T6__>& delta,
             const Eigen::Matrix<T7__, Eigen::Dynamic,1>& shape,
             const int& t,
             const std::vector<int>& p, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__, T6__, T7__, T_lp__>::type>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            int pos_reg(0);
            (void) pos_reg;  // dummy to suppress unused var warning

            stan::math::fill(pos_reg, std::numeric_limits<int>::min());
            stan::math::assign(pos_reg,1);
            int pos_rho(0);
            (void) pos_rho;  // dummy to suppress unused var warning

            stan::math::fill(pos_rho, std::numeric_limits<int>::min());
            stan::math::assign(pos_rho,1);


            current_statement_begin__ = 165;
            lp_accum__.add(normal_log(z_b,0,1));
            current_statement_begin__ = 166;
            lp_accum__.add(normal_log(z_T,0,1));
            current_statement_begin__ = 167;
            for (int i = 1; i <= t; ++i) {
                current_statement_begin__ = 167;
                if (as_bool(logical_gt(get_base1(p,i,"p",1),1))) {
                    {
                        validate_non_negative_index("shape1", "(get_base1(p,i,\"p\",1) - 1)", (get_base1(p,i,"p",1) - 1));
                        Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  shape1(static_cast<Eigen::VectorXd::Index>((get_base1(p,i,"p",1) - 1)));
                        (void) shape1;  // dummy to suppress unused var warning

                        stan::math::initialize(shape1, std::numeric_limits<double>::quiet_NaN());
                        stan::math::fill(shape1,DUMMY_VAR__);
                        validate_non_negative_index("shape2", "(get_base1(p,i,\"p\",1) - 1)", (get_base1(p,i,"p",1) - 1));
                        Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  shape2(static_cast<Eigen::VectorXd::Index>((get_base1(p,i,"p",1) - 1)));
                        (void) shape2;  // dummy to suppress unused var warning

                        stan::math::initialize(shape2, std::numeric_limits<double>::quiet_NaN());
                        stan::math::fill(shape2,DUMMY_VAR__);
                        fun_scalar_t__ nu;
                        (void) nu;  // dummy to suppress unused var warning

                        stan::math::initialize(nu, std::numeric_limits<double>::quiet_NaN());
                        stan::math::fill(nu,DUMMY_VAR__);
                        stan::math::assign(nu,(get_base1(regularization,pos_reg,"regularization",1) + (0.5 * (get_base1(p,i,"p",1) - 2))));


                        current_statement_begin__ = 171;
                        stan::math::assign(pos_reg, (pos_reg + 1));
                        current_statement_begin__ = 172;
                        stan::math::assign(get_base1_lhs(shape1,1,"shape1",1), nu);
                        current_statement_begin__ = 173;
                        stan::math::assign(get_base1_lhs(shape2,1,"shape2",1), nu);
                        current_statement_begin__ = 174;
                        for (int j = 2; j <= (get_base1(p,i,"p",1) - 1); ++j) {

                            current_statement_begin__ = 175;
                            stan::math::assign(nu, (nu - 0.5));
                            current_statement_begin__ = 176;
                            stan::math::assign(get_base1_lhs(shape1,j,"shape1",1), (0.5 * j));
                            current_statement_begin__ = 177;
                            stan::math::assign(get_base1_lhs(shape2,j,"shape2",1), nu);
                        }
                        current_statement_begin__ = 179;
                        lp_accum__.add(beta_log(stan::model::rvalue(rho, stan::model::cons_list(stan::model::index_min_max(pos_rho, ((pos_rho + get_base1(p,i,"p",1)) - 2)), stan::model::nil_index_list()), "rho"),shape1,shape2));
                        current_statement_begin__ = 180;
                        stan::math::assign(pos_rho, ((pos_rho + get_base1(p,i,"p",1)) - 1));
                    }
                }
            }
            current_statement_begin__ = 182;
            lp_accum__.add(gamma_log(zeta,delta,1));
            current_statement_begin__ = 183;
            lp_accum__.add(gamma_log(tau,shape,1));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct decov_lp_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T7__, typename T_lp__, typename T_lp_accum__>
        void
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_b,
             const Eigen::Matrix<T1__, Eigen::Dynamic,1>& z_T,
             const Eigen::Matrix<T2__, Eigen::Dynamic,1>& rho,
             const Eigen::Matrix<T3__, Eigen::Dynamic,1>& zeta,
             const Eigen::Matrix<T4__, Eigen::Dynamic,1>& tau,
             const std::vector<T5__>& regularization,
             const std::vector<T6__>& delta,
             const Eigen::Matrix<T7__, Eigen::Dynamic,1>& shape,
             const int& t,
             const std::vector<int>& p, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) const {
        return decov_lp(z_b, z_T, rho, zeta, tau, regularization, delta, shape, t, p, lp__, lp_accum__, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type, Eigen::Dynamic,1>
hs_prior(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_beta,
             const std::vector<T1__>& global,
             const std::vector<Eigen::Matrix<T2__, Eigen::Dynamic,1> >& local,
             const T3__& global_prior_scale,
             const T4__& error_scale, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            validate_non_negative_index("lambda", "rows(z_beta)", rows(z_beta));
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  lambda(static_cast<Eigen::VectorXd::Index>(rows(z_beta)));
            (void) lambda;  // dummy to suppress unused var warning

            stan::math::initialize(lambda, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(lambda,DUMMY_VAR__);
            int K(0);
            (void) K;  // dummy to suppress unused var warning

            stan::math::fill(K, std::numeric_limits<int>::min());


            current_statement_begin__ = 200;
            stan::math::assign(K, rows(z_beta));
            current_statement_begin__ = 201;
            for (int k = 1; k <= K; ++k) {
                current_statement_begin__ = 201;
                stan::math::assign(get_base1_lhs(lambda,k,"lambda",1), (get_base1(get_base1(local,1,"local",1),k,"local",2) * sqrt(get_base1(get_base1(local,2,"local",1),k,"local",2))));
            }
            current_statement_begin__ = 202;
            return stan::math::promote_scalar<fun_return_scalar_t__>(multiply(multiply(multiply(multiply(elt_multiply(z_beta,lambda),get_base1(global,1,"global",1)),sqrt(get_base1(global,2,"global",1))),global_prior_scale),error_scale));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct hs_prior_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_beta,
             const std::vector<T1__>& global,
             const std::vector<Eigen::Matrix<T2__, Eigen::Dynamic,1> >& local,
             const T3__& global_prior_scale,
             const T4__& error_scale, std::ostream* pstream__) const {
        return hs_prior(z_beta, global, local, global_prior_scale, error_scale, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type, Eigen::Dynamic,1>
hsplus_prior(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_beta,
                 const std::vector<T1__>& global,
                 const std::vector<Eigen::Matrix<T2__, Eigen::Dynamic,1> >& local,
                 const T3__& global_prior_scale,
                 const T4__& error_scale, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 218;
        return stan::math::promote_scalar<fun_return_scalar_t__>(multiply(multiply(multiply(multiply(elt_multiply(elt_multiply(z_beta,elt_multiply(get_base1(local,1,"local",1),sqrt(get_base1(local,2,"local",1)))),elt_multiply(get_base1(local,3,"local",1),sqrt(get_base1(local,4,"local",1)))),get_base1(global,1,"global",1)),sqrt(get_base1(global,2,"global",1))),global_prior_scale),error_scale));
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct hsplus_prior_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_beta,
                 const std::vector<T1__>& global,
                 const std::vector<Eigen::Matrix<T2__, Eigen::Dynamic,1> >& local,
                 const T3__& global_prior_scale,
                 const T4__& error_scale, std::ostream* pstream__) const {
        return hsplus_prior(z_beta, global, local, global_prior_scale, error_scale, pstream__);
    }
};

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
divide_real_by_vector(const T0__& x,
                          const Eigen::Matrix<T1__, Eigen::Dynamic,1>& y, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            int K(0);
            (void) K;  // dummy to suppress unused var warning

            stan::math::fill(K, std::numeric_limits<int>::min());
            stan::math::assign(K,rows(y));
            validate_non_negative_index("ret", "K", K);
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  ret(static_cast<Eigen::VectorXd::Index>(K));
            (void) ret;  // dummy to suppress unused var warning

            stan::math::initialize(ret, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(ret,DUMMY_VAR__);


            current_statement_begin__ = 233;
            for (int k = 1; k <= K; ++k) {
                current_statement_begin__ = 233;
                stan::math::assign(get_base1_lhs(ret,k,"ret",1), (x / get_base1(y,k,"y",1)));
            }
            current_statement_begin__ = 234;
            return stan::math::promote_scalar<fun_return_scalar_t__>(ret);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct divide_real_by_vector_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
    operator()(const T0__& x,
                          const Eigen::Matrix<T1__, Eigen::Dynamic,1>& y, std::ostream* pstream__) const {
        return divide_real_by_vector(x, y, pstream__);
    }
};

template <typename T0__, typename T1__>
typename boost::math::tools::promote_args<T0__, T1__>::type
CFt(const T0__& z,
        const T1__& df, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            fun_scalar_t__ z2;
            (void) z2;  // dummy to suppress unused var warning

            stan::math::initialize(z2, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(z2,DUMMY_VAR__);
            stan::math::assign(z2,square(z));
            fun_scalar_t__ z3;
            (void) z3;  // dummy to suppress unused var warning

            stan::math::initialize(z3, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(z3,DUMMY_VAR__);
            stan::math::assign(z3,(z2 * z));
            fun_scalar_t__ z5;
            (void) z5;  // dummy to suppress unused var warning

            stan::math::initialize(z5, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(z5,DUMMY_VAR__);
            stan::math::assign(z5,(z2 * z3));
            fun_scalar_t__ z7;
            (void) z7;  // dummy to suppress unused var warning

            stan::math::initialize(z7, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(z7,DUMMY_VAR__);
            stan::math::assign(z7,(z2 * z5));
            fun_scalar_t__ z9;
            (void) z9;  // dummy to suppress unused var warning

            stan::math::initialize(z9, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(z9,DUMMY_VAR__);
            stan::math::assign(z9,(z2 * z7));
            fun_scalar_t__ df2;
            (void) df2;  // dummy to suppress unused var warning

            stan::math::initialize(df2, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(df2,DUMMY_VAR__);
            stan::math::assign(df2,square(df));
            fun_scalar_t__ df3;
            (void) df3;  // dummy to suppress unused var warning

            stan::math::initialize(df3, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(df3,DUMMY_VAR__);
            stan::math::assign(df3,(df2 * df));
            fun_scalar_t__ df4;
            (void) df4;  // dummy to suppress unused var warning

            stan::math::initialize(df4, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(df4,DUMMY_VAR__);
            stan::math::assign(df4,(df2 * df2));


            current_statement_begin__ = 256;
            return stan::math::promote_scalar<fun_return_scalar_t__>(((((z + ((z3 + z) / (4 * df))) + ((((5 * z5) + (16 * z3)) + (3 * z)) / (96 * df2))) + (((((3 * z7) + (19 * z5)) + (17 * z3)) - (15 * z)) / (384 * df3))) + ((((((79 * z9) + (776 * z7)) + (1482 * z5)) - (1920 * z3)) - (945 * z)) / (92160 * df4))));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct CFt_functor__ {
    template <typename T0__, typename T1__>
        typename boost::math::tools::promote_args<T0__, T1__>::type
    operator()(const T0__& z,
        const T1__& df, std::ostream* pstream__) const {
        return CFt(z, df, pstream__);
    }
};

std::vector<std::vector<int> >
make_V(const int& N,
           const int& t,
           const std::vector<int>& v, std::ostream* pstream__) {
    typedef double fun_scalar_t__;
    typedef int fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            validate_non_negative_index("V", "t", t);
            validate_non_negative_index("V", "N", N);
            vector<vector<int> > V(t, (vector<int>(N, 0)));
            stan::math::fill(V, std::numeric_limits<int>::min());
            int pos(0);
            (void) pos;  // dummy to suppress unused var warning

            stan::math::fill(pos, std::numeric_limits<int>::min());
            stan::math::assign(pos,1);


            current_statement_begin__ = 271;
            if (as_bool(logical_gt(t,0))) {
                current_statement_begin__ = 271;
                for (int j = 1; j <= N; ++j) {
                    current_statement_begin__ = 271;
                    for (int i = 1; i <= t; ++i) {

                        current_statement_begin__ = 272;
                        stan::math::assign(get_base1_lhs(get_base1_lhs(V,i,"V",1),j,"V",2), get_base1(v,pos,"v",1));
                        current_statement_begin__ = 273;
                        stan::math::assign(pos, (pos + 1));
                    }
                }
            }
            current_statement_begin__ = 275;
            return stan::math::promote_scalar<fun_return_scalar_t__>(V);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct make_V_functor__ {
            std::vector<std::vector<int> >
    operator()(const int& N,
           const int& t,
           const std::vector<int>& v, std::ostream* pstream__) const {
        return make_V(N, t, v, pstream__);
    }
};

template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
linkinv_gauss(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                  const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 287;
        if (as_bool(logical_eq(link,1))) {
            current_statement_begin__ = 287;
            return stan::math::promote_scalar<fun_return_scalar_t__>(eta);
        } else if (as_bool(logical_eq(link,2))) {
            current_statement_begin__ = 288;
            return stan::math::promote_scalar<fun_return_scalar_t__>(exp(eta));
        } else if (as_bool(logical_eq(link,3))) {
            current_statement_begin__ = 289;
            return stan::math::promote_scalar<fun_return_scalar_t__>(inv(eta));
        } else {
            current_statement_begin__ = 290;
            std::stringstream errmsg_stream__;
            errmsg_stream__ << "Invalid link";
            throw std::domain_error(errmsg_stream__.str());
        }
        current_statement_begin__ = 290;
        current_statement_begin__ = 291;
        return stan::math::promote_scalar<fun_return_scalar_t__>(eta);
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct linkinv_gauss_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                  const int& link, std::ostream* pstream__) const {
        return linkinv_gauss(eta, link, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
pw_gauss(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& y,
             const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
             const T2__& sigma,
             const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 302;
        return stan::math::promote_scalar<fun_return_scalar_t__>(subtract((-(0.5) * log((6.2831853071795862 * sigma))),multiply(0.5,square(divide(subtract(y,linkinv_gauss(eta,link, pstream__)),sigma)))));
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct pw_gauss_functor__ {
    template <typename T0__, typename T1__, typename T2__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& y,
             const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
             const T2__& sigma,
             const int& link, std::ostream* pstream__) const {
        return pw_gauss(y, eta, sigma, link, pstream__);
    }
};

template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
linkinv_gamma(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                  const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 314;
        if (as_bool(logical_eq(link,1))) {
            current_statement_begin__ = 314;
            return stan::math::promote_scalar<fun_return_scalar_t__>(eta);
        } else if (as_bool(logical_eq(link,2))) {
            current_statement_begin__ = 315;
            return stan::math::promote_scalar<fun_return_scalar_t__>(exp(eta));
        } else if (as_bool(logical_eq(link,3))) {
            current_statement_begin__ = 316;
            return stan::math::promote_scalar<fun_return_scalar_t__>(inv(eta));
        } else {
            current_statement_begin__ = 317;
            std::stringstream errmsg_stream__;
            errmsg_stream__ << "Invalid link";
            throw std::domain_error(errmsg_stream__.str());
        }
        current_statement_begin__ = 317;
        current_statement_begin__ = 318;
        return stan::math::promote_scalar<fun_return_scalar_t__>(eta);
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct linkinv_gamma_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                  const int& link, std::ostream* pstream__) const {
        return linkinv_gamma(eta, link, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__, typename T4__>
typename boost::math::tools::promote_args<T0__, T1__, T2__, T4__>::type
GammaReg(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& y,
             const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
             const T2__& shape,
             const int& link,
             const T4__& sum_log_y, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T4__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            fun_scalar_t__ ret;
            (void) ret;  // dummy to suppress unused var warning

            stan::math::initialize(ret, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(ret,DUMMY_VAR__);
            stan::math::assign(ret,((rows(y) * ((shape * log(shape)) - stan::math::lgamma(shape))) + ((shape - 1) * sum_log_y)));


            current_statement_begin__ = 335;
            if (as_bool(logical_eq(link,2))) {
                current_statement_begin__ = 336;
                stan::math::assign(ret, ((ret - (shape * sum(eta))) - (shape * sum(elt_divide(y,exp(eta))))));
            } else if (as_bool(logical_eq(link,1))) {
                current_statement_begin__ = 338;
                stan::math::assign(ret, ((ret - (shape * sum(log(eta)))) - (shape * sum(elt_divide(y,eta)))));
            } else if (as_bool(logical_eq(link,3))) {
                current_statement_begin__ = 340;
                stan::math::assign(ret, ((ret + (shape * sum(log(eta)))) - (shape * dot_product(eta,y))));
            } else {
                current_statement_begin__ = 341;
                std::stringstream errmsg_stream__;
                errmsg_stream__ << "Invalid link";
                throw std::domain_error(errmsg_stream__.str());
            }
            current_statement_begin__ = 341;
            current_statement_begin__ = 342;
            return stan::math::promote_scalar<fun_return_scalar_t__>(ret);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct GammaReg_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T4__>
        typename boost::math::tools::promote_args<T0__, T1__, T2__, T4__>::type
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& y,
             const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
             const T2__& shape,
             const int& link,
             const T4__& sum_log_y, std::ostream* pstream__) const {
        return GammaReg(y, eta, shape, link, sum_log_y, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
pw_gamma(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& y,
             const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
             const T2__& shape,
             const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            int N(0);
            (void) N;  // dummy to suppress unused var warning

            stan::math::fill(N, std::numeric_limits<int>::min());
            stan::math::assign(N,rows(eta));
            validate_non_negative_index("ll", "N", N);
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  ll(static_cast<Eigen::VectorXd::Index>(N));
            (void) ll;  // dummy to suppress unused var warning

            stan::math::initialize(ll, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(ll,DUMMY_VAR__);


            current_statement_begin__ = 356;
            if (as_bool(logical_eq(link,3))) {

                current_statement_begin__ = 357;
                for (int n = 1; n <= N; ++n) {

                    current_statement_begin__ = 358;
                    stan::math::assign(get_base1_lhs(ll,n,"ll",1), gamma_log(get_base1(y,n,"y",1),shape,(shape * get_base1(eta,n,"eta",1))));
                }
            } else if (as_bool(logical_eq(link,2))) {

                current_statement_begin__ = 362;
                for (int n = 1; n <= N; ++n) {

                    current_statement_begin__ = 363;
                    stan::math::assign(get_base1_lhs(ll,n,"ll",1), gamma_log(get_base1(y,n,"y",1),shape,(shape / exp(get_base1(eta,n,"eta",1)))));
                }
            } else if (as_bool(logical_eq(link,1))) {

                current_statement_begin__ = 367;
                for (int n = 1; n <= N; ++n) {

                    current_statement_begin__ = 368;
                    stan::math::assign(get_base1_lhs(ll,n,"ll",1), gamma_log(get_base1(y,n,"y",1),shape,(shape / get_base1(eta,n,"eta",1))));
                }
            } else {
                current_statement_begin__ = 371;
                std::stringstream errmsg_stream__;
                errmsg_stream__ << "Invalid link";
                throw std::domain_error(errmsg_stream__.str());
            }
            current_statement_begin__ = 371;
            current_statement_begin__ = 372;
            return stan::math::promote_scalar<fun_return_scalar_t__>(ll);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct pw_gamma_functor__ {
    template <typename T0__, typename T1__, typename T2__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& y,
             const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
             const T2__& shape,
             const int& link, std::ostream* pstream__) const {
        return pw_gamma(y, eta, shape, link, pstream__);
    }
};

template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
linkinv_inv_gaussian(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                         const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 383;
        if (as_bool(logical_eq(link,1))) {
            current_statement_begin__ = 383;
            return stan::math::promote_scalar<fun_return_scalar_t__>(eta);
        } else if (as_bool(logical_eq(link,2))) {
            current_statement_begin__ = 384;
            return stan::math::promote_scalar<fun_return_scalar_t__>(exp(eta));
        } else if (as_bool(logical_eq(link,3))) {
            current_statement_begin__ = 385;
            return stan::math::promote_scalar<fun_return_scalar_t__>(inv(eta));
        } else if (as_bool(logical_eq(link,4))) {
            current_statement_begin__ = 386;
            return stan::math::promote_scalar<fun_return_scalar_t__>(inv_sqrt(eta));
        } else {
            current_statement_begin__ = 387;
            std::stringstream errmsg_stream__;
            errmsg_stream__ << "Invalid link";
            throw std::domain_error(errmsg_stream__.str());
        }
        current_statement_begin__ = 387;
        current_statement_begin__ = 388;
        return stan::math::promote_scalar<fun_return_scalar_t__>(eta);
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct linkinv_inv_gaussian_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                         const int& link, std::ostream* pstream__) const {
        return linkinv_inv_gaussian(eta, link, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__>
typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type
inv_gaussian(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& y,
                 const Eigen::Matrix<T1__, Eigen::Dynamic,1>& mu,
                 const T2__& lambda,
                 const T3__& sum_log_y,
                 const Eigen::Matrix<T4__, Eigen::Dynamic,1>& sqrt_y, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 403;
        return stan::math::promote_scalar<fun_return_scalar_t__>(((((0.5 * rows(y)) * log((lambda / 6.2831853071795862))) - (1.5 * sum_log_y)) - ((0.5 * lambda) * dot_self(elt_divide(subtract(y,mu),elt_multiply(mu,sqrt_y))))));
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct inv_gaussian_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__>
        typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& y,
                 const Eigen::Matrix<T1__, Eigen::Dynamic,1>& mu,
                 const T2__& lambda,
                 const T3__& sum_log_y,
                 const Eigen::Matrix<T4__, Eigen::Dynamic,1>& sqrt_y, std::ostream* pstream__) const {
        return inv_gaussian(y, mu, lambda, sum_log_y, sqrt_y, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__, typename T4__, typename T5__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T4__, typename boost::math::tools::promote_args<T5__>::type>::type, Eigen::Dynamic,1>
pw_inv_gaussian(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& y,
                    const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
                    const T2__& lambda,
                    const int& link,
                    const Eigen::Matrix<T4__, Eigen::Dynamic,1>& log_y,
                    const Eigen::Matrix<T5__, Eigen::Dynamic,1>& sqrt_y, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T4__, typename boost::math::tools::promote_args<T5__>::type>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            validate_non_negative_index("mu", "rows(y)", rows(y));
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  mu(static_cast<Eigen::VectorXd::Index>(rows(y)));
            (void) mu;  // dummy to suppress unused var warning

            stan::math::initialize(mu, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(mu,DUMMY_VAR__);
            stan::math::assign(mu,linkinv_inv_gaussian(eta,link, pstream__));


            current_statement_begin__ = 422;
            return stan::math::promote_scalar<fun_return_scalar_t__>(subtract(add(multiply((-(0.5) * lambda),square(elt_divide(subtract(y,mu),elt_multiply(mu,sqrt_y)))),(0.5 * log((lambda / 6.2831853071795862)))),multiply(1.5,log_y)));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct pw_inv_gaussian_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T4__, typename T5__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T4__, typename boost::math::tools::promote_args<T5__>::type>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& y,
                    const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
                    const T2__& lambda,
                    const int& link,
                    const Eigen::Matrix<T4__, Eigen::Dynamic,1>& log_y,
                    const Eigen::Matrix<T5__, Eigen::Dynamic,1>& sqrt_y, std::ostream* pstream__) const {
        return pw_inv_gaussian(y, eta, lambda, link, log_y, sqrt_y, pstream__);
    }
};

template <typename T0__, typename T1__, class RNG>
typename boost::math::tools::promote_args<T0__, T1__>::type
inv_gaussian_rng(const T0__& mu,
                     const T1__& lambda, RNG& base_rng__, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            fun_scalar_t__ mu2;
            (void) mu2;  // dummy to suppress unused var warning

            stan::math::initialize(mu2, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(mu2,DUMMY_VAR__);
            stan::math::assign(mu2,square(mu));
            fun_scalar_t__ z;
            (void) z;  // dummy to suppress unused var warning

            stan::math::initialize(z, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(z,DUMMY_VAR__);
            stan::math::assign(z,uniform_rng(0,1, base_rng__));
            fun_scalar_t__ y;
            (void) y;  // dummy to suppress unused var warning

            stan::math::initialize(y, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(y,DUMMY_VAR__);
            stan::math::assign(y,square(normal_rng(0,1, base_rng__)));
            fun_scalar_t__ x;
            (void) x;  // dummy to suppress unused var warning

            stan::math::initialize(x, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(x,DUMMY_VAR__);
            stan::math::assign(x,(mu + (((mu2 * y) - (mu * sqrt(((((4 * mu) * lambda) * y) + (mu2 * square(y)))))) / (2 * lambda))));


            current_statement_begin__ = 441;
            if (as_bool(logical_lte(z,(mu / (mu + x))))) {
                current_statement_begin__ = 441;
                return stan::math::promote_scalar<fun_return_scalar_t__>(x);
            } else {
                current_statement_begin__ = 442;
                return stan::math::promote_scalar<fun_return_scalar_t__>((mu2 / x));
            }
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct inv_gaussian_rng_functor__ {
    template <typename T0__, typename T1__, class RNG>
        typename boost::math::tools::promote_args<T0__, T1__>::type
    operator()(const T0__& mu,
                     const T1__& lambda, RNG& base_rng__, std::ostream* pstream__) const {
        return inv_gaussian_rng(mu, lambda, base_rng__, pstream__);
    }
};

template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
linkinv_beta(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                 const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 453;
        if (as_bool(logical_eq(link,1))) {
            current_statement_begin__ = 453;
            return stan::math::promote_scalar<fun_return_scalar_t__>(inv_logit(eta));
        } else if (as_bool(logical_eq(link,2))) {
            current_statement_begin__ = 454;
            return stan::math::promote_scalar<fun_return_scalar_t__>(Phi(eta));
        } else if (as_bool(logical_eq(link,3))) {
            current_statement_begin__ = 455;
            return stan::math::promote_scalar<fun_return_scalar_t__>(inv_cloglog(eta));
        } else if (as_bool(logical_eq(link,4))) {
            current_statement_begin__ = 456;
            return stan::math::promote_scalar<fun_return_scalar_t__>(add(0.5,divide(atan(eta),stan::math::pi())));
        } else if (as_bool(logical_eq(link,5))) {
            current_statement_begin__ = 457;
            return stan::math::promote_scalar<fun_return_scalar_t__>(exp(eta));
        } else if (as_bool(logical_eq(link,6))) {
            current_statement_begin__ = 458;
            return stan::math::promote_scalar<fun_return_scalar_t__>(subtract(1,inv_cloglog(minus(eta))));
        } else {
            current_statement_begin__ = 459;
            std::stringstream errmsg_stream__;
            errmsg_stream__ << "invalid link";
            throw std::domain_error(errmsg_stream__.str());
        }
        current_statement_begin__ = 459;
        current_statement_begin__ = 460;
        return stan::math::promote_scalar<fun_return_scalar_t__>(eta);
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct linkinv_beta_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                 const int& link, std::ostream* pstream__) const {
        return linkinv_beta(eta, link, pstream__);
    }
};

template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
linkinv_beta_z(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                   const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 471;
        if (as_bool(logical_eq(link,1))) {
            current_statement_begin__ = 471;
            return stan::math::promote_scalar<fun_return_scalar_t__>(exp(eta));
        } else if (as_bool(logical_eq(link,2))) {
            current_statement_begin__ = 472;
            return stan::math::promote_scalar<fun_return_scalar_t__>(eta);
        } else if (as_bool(logical_eq(link,3))) {
            current_statement_begin__ = 473;
            return stan::math::promote_scalar<fun_return_scalar_t__>(square(eta));
        } else {
            current_statement_begin__ = 474;
            std::stringstream errmsg_stream__;
            errmsg_stream__ << "Invalid link";
            throw std::domain_error(errmsg_stream__.str());
        }
        current_statement_begin__ = 475;
        return stan::math::promote_scalar<fun_return_scalar_t__>(eta);
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct linkinv_beta_z_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                   const int& link, std::ostream* pstream__) const {
        return linkinv_beta_z(eta, link, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
pw_beta(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& y,
            const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
            const T2__& dispersion,
            const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            validate_non_negative_index("ll", "rows(y)", rows(y));
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  ll(static_cast<Eigen::VectorXd::Index>(rows(y)));
            (void) ll;  // dummy to suppress unused var warning

            stan::math::initialize(ll, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(ll,DUMMY_VAR__);
            validate_non_negative_index("mu", "rows(y)", rows(y));
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  mu(static_cast<Eigen::VectorXd::Index>(rows(y)));
            (void) mu;  // dummy to suppress unused var warning

            stan::math::initialize(mu, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(mu,DUMMY_VAR__);
            stan::math::assign(mu,linkinv_beta(eta,link, pstream__));


            current_statement_begin__ = 490;
            for (int n = 1; n <= rows(y); ++n) {

                current_statement_begin__ = 491;
                stan::math::assign(get_base1_lhs(ll,n,"ll",1), beta_log(get_base1(y,n,"y",1),(get_base1(mu,n,"mu",1) * dispersion),((1 - get_base1(mu,n,"mu",1)) * dispersion)));
            }
            current_statement_begin__ = 493;
            return stan::math::promote_scalar<fun_return_scalar_t__>(ll);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct pw_beta_functor__ {
    template <typename T0__, typename T1__, typename T2__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& y,
            const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
            const T2__& dispersion,
            const int& link, std::ostream* pstream__) const {
        return pw_beta(y, eta, dispersion, link, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
pw_beta_z(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& y,
              const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
              const Eigen::Matrix<T2__, Eigen::Dynamic,1>& eta_z,
              const int& link,
              const int& link_phi, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            validate_non_negative_index("ll", "rows(y)", rows(y));
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  ll(static_cast<Eigen::VectorXd::Index>(rows(y)));
            (void) ll;  // dummy to suppress unused var warning

            stan::math::initialize(ll, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(ll,DUMMY_VAR__);
            validate_non_negative_index("mu", "rows(y)", rows(y));
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  mu(static_cast<Eigen::VectorXd::Index>(rows(y)));
            (void) mu;  // dummy to suppress unused var warning

            stan::math::initialize(mu, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(mu,DUMMY_VAR__);
            stan::math::assign(mu,linkinv_beta(eta,link, pstream__));
            validate_non_negative_index("mu_z", "rows(y)", rows(y));
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  mu_z(static_cast<Eigen::VectorXd::Index>(rows(y)));
            (void) mu_z;  // dummy to suppress unused var warning

            stan::math::initialize(mu_z, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(mu_z,DUMMY_VAR__);
            stan::math::assign(mu_z,linkinv_beta_z(eta_z,link_phi, pstream__));


            current_statement_begin__ = 510;
            for (int n = 1; n <= rows(y); ++n) {

                current_statement_begin__ = 511;
                stan::math::assign(get_base1_lhs(ll,n,"ll",1), beta_log(get_base1(y,n,"y",1),(get_base1(mu,n,"mu",1) * get_base1(mu_z,n,"mu_z",1)),((1 - get_base1(mu,n,"mu",1)) * get_base1(mu_z,n,"mu_z",1))));
            }
            current_statement_begin__ = 513;
            return stan::math::promote_scalar<fun_return_scalar_t__>(ll);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct pw_beta_z_functor__ {
    template <typename T0__, typename T1__, typename T2__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& y,
              const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
              const Eigen::Matrix<T2__, Eigen::Dynamic,1>& eta_z,
              const int& link,
              const int& link_phi, std::ostream* pstream__) const {
        return pw_beta_z(y, eta, eta_z, link, link_phi, pstream__);
    }
};

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
SS_asymp(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& input,
             const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& Phi, std::ostream* pstream__);

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
SS_asympOff(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& input,
                const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& Phi, std::ostream* pstream__);

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
SS_asympOrig(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& input,
                 const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& Phi, std::ostream* pstream__);

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
SS_biexp(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& input,
             const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& Phi, std::ostream* pstream__);

template <typename T0__, typename T1__, typename T2__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
SS_fol(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& Dose,
           const Eigen::Matrix<T1__, Eigen::Dynamic,1>& input,
           const Eigen::Matrix<T2__, Eigen::Dynamic,Eigen::Dynamic>& Phi, std::ostream* pstream__);

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
SS_fpl(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& input,
           const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& Phi, std::ostream* pstream__);

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
SS_gompertz(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& x,
                const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& Phi, std::ostream* pstream__);

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
SS_logis(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& input,
             const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& Phi, std::ostream* pstream__);

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
SS_micmen(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& input,
              const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& Phi, std::ostream* pstream__);

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
SS_weibull(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& x,
               const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& Phi, std::ostream* pstream__);

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
SS_asymp(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& input,
             const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& Phi, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 535;
        if (as_bool(logical_gt(rows(Phi),1))) {
            {
                validate_non_negative_index("Asym", "rows(Phi)", rows(Phi));
                Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  Asym(static_cast<Eigen::VectorXd::Index>(rows(Phi)));
                (void) Asym;  // dummy to suppress unused var warning

                stan::math::initialize(Asym, std::numeric_limits<double>::quiet_NaN());
                stan::math::fill(Asym,DUMMY_VAR__);
                stan::math::assign(Asym,stan::model::rvalue(Phi, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list())), "Phi"));


                current_statement_begin__ = 537;
                return stan::math::promote_scalar<fun_return_scalar_t__>(add(Asym,elt_multiply(subtract(stan::model::rvalue(Phi, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(2), stan::model::nil_index_list())), "Phi"),Asym),exp(elt_multiply(minus(exp(stan::model::rvalue(Phi, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(3), stan::model::nil_index_list())), "Phi"))),input)))));
            }
        } else {
            {
                fun_scalar_t__ Asym;
                (void) Asym;  // dummy to suppress unused var warning

                stan::math::initialize(Asym, std::numeric_limits<double>::quiet_NaN());
                stan::math::fill(Asym,DUMMY_VAR__);
                stan::math::assign(Asym,get_base1(Phi,1,1,"Phi",1));


                current_statement_begin__ = 541;
                return stan::math::promote_scalar<fun_return_scalar_t__>(add(Asym,multiply((get_base1(Phi,1,2,"Phi",1) - Asym),exp(multiply(-(exp(get_base1(Phi,1,3,"Phi",1))),input)))));
            }
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct SS_asymp_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& input,
             const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& Phi, std::ostream* pstream__) const {
        return SS_asymp(input, Phi, pstream__);
    }
};

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
SS_asympOff(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& input,
                const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& Phi, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 547;
        if (as_bool(logical_gt(rows(Phi),1))) {
            current_statement_begin__ = 548;
            return stan::math::promote_scalar<fun_return_scalar_t__>(elt_multiply(stan::model::rvalue(Phi, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list())), "Phi"),subtract(1,exp(elt_multiply(minus(exp(stan::model::rvalue(Phi, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(2), stan::model::nil_index_list())), "Phi"))),subtract(input,stan::model::rvalue(Phi, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(3), stan::model::nil_index_list())), "Phi")))))));
        } else {
            current_statement_begin__ = 550;
            return stan::math::promote_scalar<fun_return_scalar_t__>(multiply(get_base1(Phi,1,1,"Phi",1),subtract(1,exp(multiply(-(exp(get_base1(Phi,1,2,"Phi",1))),subtract(input,get_base1(Phi,1,3,"Phi",1)))))));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct SS_asympOff_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& input,
                const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& Phi, std::ostream* pstream__) const {
        return SS_asympOff(input, Phi, pstream__);
    }
};

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
SS_asympOrig(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& input,
                 const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& Phi, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 555;
        if (as_bool(logical_gt(rows(Phi),1))) {
            current_statement_begin__ = 556;
            return stan::math::promote_scalar<fun_return_scalar_t__>(elt_multiply(stan::model::rvalue(Phi, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list())), "Phi"),subtract(1,exp(elt_multiply(minus(exp(stan::model::rvalue(Phi, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(2), stan::model::nil_index_list())), "Phi"))),input)))));
        } else {
            current_statement_begin__ = 558;
            return stan::math::promote_scalar<fun_return_scalar_t__>(multiply(get_base1(Phi,1,1,"Phi",1),subtract(1,exp(multiply(-(exp(get_base1(Phi,1,2,"Phi",1))),input)))));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct SS_asympOrig_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& input,
                 const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& Phi, std::ostream* pstream__) const {
        return SS_asympOrig(input, Phi, pstream__);
    }
};

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
SS_biexp(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& input,
             const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& Phi, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 563;
        if (as_bool(logical_gt(rows(Phi),1))) {
            current_statement_begin__ = 564;
            return stan::math::promote_scalar<fun_return_scalar_t__>(add(elt_multiply(stan::model::rvalue(Phi, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list())), "Phi"),exp(elt_multiply(minus(exp(stan::model::rvalue(Phi, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(2), stan::model::nil_index_list())), "Phi"))),input))),elt_multiply(stan::model::rvalue(Phi, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(3), stan::model::nil_index_list())), "Phi"),exp(elt_multiply(minus(exp(stan::model::rvalue(Phi, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(4), stan::model::nil_index_list())), "Phi"))),input)))));
        } else {
            current_statement_begin__ = 567;
            return stan::math::promote_scalar<fun_return_scalar_t__>(add(multiply(get_base1(Phi,1,1,"Phi",1),exp(multiply(-(exp(get_base1(Phi,1,2,"Phi",1))),input))),multiply(get_base1(Phi,1,3,"Phi",1),exp(multiply(-(exp(get_base1(Phi,1,4,"Phi",1))),input)))));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct SS_biexp_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& input,
             const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& Phi, std::ostream* pstream__) const {
        return SS_biexp(input, Phi, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
SS_fol(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& Dose,
           const Eigen::Matrix<T1__, Eigen::Dynamic,1>& input,
           const Eigen::Matrix<T2__, Eigen::Dynamic,Eigen::Dynamic>& Phi, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            int Phi_rows(0);
            (void) Phi_rows;  // dummy to suppress unused var warning

            stan::math::fill(Phi_rows, std::numeric_limits<int>::min());
            stan::math::assign(Phi_rows,rows(Phi));


            current_statement_begin__ = 574;
            if (as_bool(logical_gt(Phi_rows,1))) {
                {
                    validate_non_negative_index("lKe", "Phi_rows", Phi_rows);
                    Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  lKe(static_cast<Eigen::VectorXd::Index>(Phi_rows));
                    (void) lKe;  // dummy to suppress unused var warning

                    stan::math::initialize(lKe, std::numeric_limits<double>::quiet_NaN());
                    stan::math::fill(lKe,DUMMY_VAR__);
                    stan::math::assign(lKe,stan::model::rvalue(Phi, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list())), "Phi"));
                    validate_non_negative_index("lKa", "Phi_rows", Phi_rows);
                    Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  lKa(static_cast<Eigen::VectorXd::Index>(Phi_rows));
                    (void) lKa;  // dummy to suppress unused var warning

                    stan::math::initialize(lKa, std::numeric_limits<double>::quiet_NaN());
                    stan::math::fill(lKa,DUMMY_VAR__);
                    stan::math::assign(lKa,stan::model::rvalue(Phi, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(2), stan::model::nil_index_list())), "Phi"));
                    validate_non_negative_index("exp_lKe", "Phi_rows", Phi_rows);
                    Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  exp_lKe(static_cast<Eigen::VectorXd::Index>(Phi_rows));
                    (void) exp_lKe;  // dummy to suppress unused var warning

                    stan::math::initialize(exp_lKe, std::numeric_limits<double>::quiet_NaN());
                    stan::math::fill(exp_lKe,DUMMY_VAR__);
                    stan::math::assign(exp_lKe,exp(lKe));
                    validate_non_negative_index("exp_lKa", "Phi_rows", Phi_rows);
                    Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  exp_lKa(static_cast<Eigen::VectorXd::Index>(Phi_rows));
                    (void) exp_lKa;  // dummy to suppress unused var warning

                    stan::math::initialize(exp_lKa, std::numeric_limits<double>::quiet_NaN());
                    stan::math::fill(exp_lKa,DUMMY_VAR__);
                    stan::math::assign(exp_lKa,exp(lKa));


                    current_statement_begin__ = 579;
                    return stan::math::promote_scalar<fun_return_scalar_t__>(elt_divide(elt_multiply(elt_multiply(Dose,exp(subtract(add(lKe,lKa),stan::model::rvalue(Phi, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(3), stan::model::nil_index_list())), "Phi")))),subtract(exp(elt_multiply(minus(exp_lKe),input)),exp(elt_multiply(minus(exp_lKa),input)))),subtract(exp_lKa,exp_lKe)));
                }
            } else {
                {
                    fun_scalar_t__ lKe;
                    (void) lKe;  // dummy to suppress unused var warning

                    stan::math::initialize(lKe, std::numeric_limits<double>::quiet_NaN());
                    stan::math::fill(lKe,DUMMY_VAR__);
                    stan::math::assign(lKe,get_base1(Phi,1,1,"Phi",1));
                    fun_scalar_t__ lKa;
                    (void) lKa;  // dummy to suppress unused var warning

                    stan::math::initialize(lKa, std::numeric_limits<double>::quiet_NaN());
                    stan::math::fill(lKa,DUMMY_VAR__);
                    stan::math::assign(lKa,get_base1(Phi,1,2,"Phi",1));
                    fun_scalar_t__ exp_lKe;
                    (void) exp_lKe;  // dummy to suppress unused var warning

                    stan::math::initialize(exp_lKe, std::numeric_limits<double>::quiet_NaN());
                    stan::math::fill(exp_lKe,DUMMY_VAR__);
                    stan::math::assign(exp_lKe,exp(lKe));
                    fun_scalar_t__ exp_lKa;
                    (void) exp_lKa;  // dummy to suppress unused var warning

                    stan::math::initialize(exp_lKa, std::numeric_limits<double>::quiet_NaN());
                    stan::math::fill(exp_lKa,DUMMY_VAR__);
                    stan::math::assign(exp_lKa,exp(lKa));


                    current_statement_begin__ = 587;
                    return stan::math::promote_scalar<fun_return_scalar_t__>(divide(elt_multiply(multiply(Dose,exp(((lKe + lKa) - get_base1(Phi,1,3,"Phi",1)))),subtract(exp(multiply(-(exp_lKe),input)),exp(multiply(-(exp_lKa),input)))),(exp_lKa - exp_lKe)));
                }
            }
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct SS_fol_functor__ {
    template <typename T0__, typename T1__, typename T2__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& Dose,
           const Eigen::Matrix<T1__, Eigen::Dynamic,1>& input,
           const Eigen::Matrix<T2__, Eigen::Dynamic,Eigen::Dynamic>& Phi, std::ostream* pstream__) const {
        return SS_fol(Dose, input, Phi, pstream__);
    }
};

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
SS_fpl(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& input,
           const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& Phi, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 595;
        if (as_bool(logical_gt(rows(Phi),1))) {
            {
                validate_non_negative_index("A", "rows(Phi)", rows(Phi));
                Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  A(static_cast<Eigen::VectorXd::Index>(rows(Phi)));
                (void) A;  // dummy to suppress unused var warning

                stan::math::initialize(A, std::numeric_limits<double>::quiet_NaN());
                stan::math::fill(A,DUMMY_VAR__);
                stan::math::assign(A,stan::model::rvalue(Phi, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list())), "Phi"));


                current_statement_begin__ = 597;
                return stan::math::promote_scalar<fun_return_scalar_t__>(add(A,elt_divide(subtract(stan::model::rvalue(Phi, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(2), stan::model::nil_index_list())), "Phi"),A),add(1,exp(elt_divide(subtract(stan::model::rvalue(Phi, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(3), stan::model::nil_index_list())), "Phi"),input),exp(stan::model::rvalue(Phi, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(4), stan::model::nil_index_list())), "Phi"))))))));
            }
        } else {
            {
                fun_scalar_t__ A;
                (void) A;  // dummy to suppress unused var warning

                stan::math::initialize(A, std::numeric_limits<double>::quiet_NaN());
                stan::math::fill(A,DUMMY_VAR__);
                stan::math::assign(A,get_base1(Phi,1,1,"Phi",1));


                current_statement_begin__ = 601;
                return stan::math::promote_scalar<fun_return_scalar_t__>(add(A,elt_divide(rep_vector((get_base1(Phi,1,2,"Phi",1) - A),rows(input)),add(1,exp(divide(subtract(get_base1(Phi,1,3,"Phi",1),input),exp(get_base1(Phi,1,4,"Phi",1))))))));
            }
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct SS_fpl_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& input,
           const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& Phi, std::ostream* pstream__) const {
        return SS_fpl(input, Phi, pstream__);
    }
};

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
SS_gompertz(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& x,
                const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& Phi, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            validate_non_negative_index("out", "rows(x)", rows(x));
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  out(static_cast<Eigen::VectorXd::Index>(rows(x)));
            (void) out;  // dummy to suppress unused var warning

            stan::math::initialize(out, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(out,DUMMY_VAR__);


            current_statement_begin__ = 609;
            if (as_bool(logical_gt(rows(Phi),1))) {
                current_statement_begin__ = 609;
                for (int i = 1; i <= rows(x); ++i) {
                    current_statement_begin__ = 610;
                    stan::math::assign(get_base1_lhs(out,i,"out",1), (get_base1(Phi,i,1,"Phi",1) * exp((-(get_base1(Phi,i,2,"Phi",1)) * pow(get_base1(Phi,i,3,"Phi",1),get_base1(x,i,"x",1))))));
                }
            } else {
                {
                    fun_scalar_t__ Asym;
                    (void) Asym;  // dummy to suppress unused var warning

                    stan::math::initialize(Asym, std::numeric_limits<double>::quiet_NaN());
                    stan::math::fill(Asym,DUMMY_VAR__);
                    stan::math::assign(Asym,get_base1(Phi,1,1,"Phi",1));
                    fun_scalar_t__ b2;
                    (void) b2;  // dummy to suppress unused var warning

                    stan::math::initialize(b2, std::numeric_limits<double>::quiet_NaN());
                    stan::math::fill(b2,DUMMY_VAR__);
                    stan::math::assign(b2,get_base1(Phi,1,2,"Phi",1));
                    fun_scalar_t__ b3;
                    (void) b3;  // dummy to suppress unused var warning

                    stan::math::initialize(b3, std::numeric_limits<double>::quiet_NaN());
                    stan::math::fill(b3,DUMMY_VAR__);
                    stan::math::assign(b3,get_base1(Phi,1,3,"Phi",1));


                    current_statement_begin__ = 615;
                    for (int i = 1; i <= rows(x); ++i) {
                        current_statement_begin__ = 615;
                        stan::math::assign(get_base1_lhs(out,i,"out",1), (Asym * exp((-(b2) * pow(b3,get_base1(x,i,"x",1))))));
                    }
                }
            }
            current_statement_begin__ = 617;
            return stan::math::promote_scalar<fun_return_scalar_t__>(out);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct SS_gompertz_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& x,
                const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& Phi, std::ostream* pstream__) const {
        return SS_gompertz(x, Phi, pstream__);
    }
};

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
SS_logis(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& input,
             const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& Phi, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 623;
        if (as_bool(logical_gt(rows(Phi),1))) {
            current_statement_begin__ = 624;
            return stan::math::promote_scalar<fun_return_scalar_t__>(elt_divide(stan::model::rvalue(Phi, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list())), "Phi"),add(1,exp(elt_divide(subtract(stan::model::rvalue(Phi, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(2), stan::model::nil_index_list())), "Phi"),input),exp(stan::model::rvalue(Phi, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(3), stan::model::nil_index_list())), "Phi")))))));
        } else {
            current_statement_begin__ = 626;
            return stan::math::promote_scalar<fun_return_scalar_t__>(elt_divide(rep_vector(get_base1(Phi,1,1,"Phi",1),rows(input)),add(1,exp(divide(subtract(get_base1(Phi,1,2,"Phi",1),input),exp(get_base1(Phi,1,3,"Phi",1)))))));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct SS_logis_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& input,
             const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& Phi, std::ostream* pstream__) const {
        return SS_logis(input, Phi, pstream__);
    }
};

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
SS_micmen(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& input,
              const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& Phi, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 632;
        if (as_bool(logical_gt(rows(Phi),1))) {
            current_statement_begin__ = 633;
            return stan::math::promote_scalar<fun_return_scalar_t__>(elt_divide(elt_multiply(stan::model::rvalue(Phi, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list())), "Phi"),input),add(stan::model::rvalue(Phi, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(2), stan::model::nil_index_list())), "Phi"),input)));
        } else {
            current_statement_begin__ = 635;
            return stan::math::promote_scalar<fun_return_scalar_t__>(elt_divide(multiply(get_base1(Phi,1,1,"Phi",1),input),add(get_base1(Phi,1,2,"Phi",1),input)));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct SS_micmen_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& input,
              const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& Phi, std::ostream* pstream__) const {
        return SS_micmen(input, Phi, pstream__);
    }
};

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
SS_weibull(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& x,
               const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& Phi, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            validate_non_negative_index("out", "rows(x)", rows(x));
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  out(static_cast<Eigen::VectorXd::Index>(rows(x)));
            (void) out;  // dummy to suppress unused var warning

            stan::math::initialize(out, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(out,DUMMY_VAR__);


            current_statement_begin__ = 641;
            if (as_bool(logical_gt(rows(Phi),1))) {
                current_statement_begin__ = 641;
                for (int i = 1; i <= rows(x); ++i) {
                    current_statement_begin__ = 642;
                    stan::math::assign(get_base1_lhs(out,i,"out",1), (get_base1(Phi,i,1,"Phi",1) - (get_base1(Phi,i,2,"Phi",1) * exp((-(exp(get_base1(Phi,i,3,"Phi",1))) * pow(get_base1(x,i,"x",1),get_base1(Phi,i,4,"Phi",1)))))));
                }
            } else {
                {
                    fun_scalar_t__ Asym;
                    (void) Asym;  // dummy to suppress unused var warning

                    stan::math::initialize(Asym, std::numeric_limits<double>::quiet_NaN());
                    stan::math::fill(Asym,DUMMY_VAR__);
                    stan::math::assign(Asym,get_base1(Phi,1,1,"Phi",1));
                    fun_scalar_t__ Drop;
                    (void) Drop;  // dummy to suppress unused var warning

                    stan::math::initialize(Drop, std::numeric_limits<double>::quiet_NaN());
                    stan::math::fill(Drop,DUMMY_VAR__);
                    stan::math::assign(Drop,get_base1(Phi,1,2,"Phi",1));
                    fun_scalar_t__ lrc;
                    (void) lrc;  // dummy to suppress unused var warning

                    stan::math::initialize(lrc, std::numeric_limits<double>::quiet_NaN());
                    stan::math::fill(lrc,DUMMY_VAR__);
                    stan::math::assign(lrc,get_base1(Phi,1,3,"Phi",1));
                    fun_scalar_t__ pwr;
                    (void) pwr;  // dummy to suppress unused var warning

                    stan::math::initialize(pwr, std::numeric_limits<double>::quiet_NaN());
                    stan::math::fill(pwr,DUMMY_VAR__);
                    stan::math::assign(pwr,get_base1(Phi,1,4,"Phi",1));


                    current_statement_begin__ = 648;
                    for (int i = 1; i <= rows(x); ++i) {
                        current_statement_begin__ = 649;
                        stan::math::assign(get_base1_lhs(out,i,"out",1), (Asym - (Drop * exp((-(exp(lrc)) * pow(get_base1(x,i,"x",1),pwr))))));
                    }
                }
            }
            current_statement_begin__ = 651;
            return stan::math::promote_scalar<fun_return_scalar_t__>(out);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct SS_weibull_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& x,
               const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& Phi, std::ostream* pstream__) const {
        return SS_weibull(x, Phi, pstream__);
    }
};

template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,Eigen::Dynamic>
reshape_vec(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& x,
                const int& Rows,
                const int& Cols, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            validate_non_negative_index("out", "Rows", Rows);
            validate_non_negative_index("out", "Cols", Cols);
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,Eigen::Dynamic>  out(static_cast<Eigen::VectorXd::Index>(Rows),static_cast<Eigen::VectorXd::Index>(Cols));
            (void) out;  // dummy to suppress unused var warning

            stan::math::initialize(out, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(out,DUMMY_VAR__);
            int pos(0);
            (void) pos;  // dummy to suppress unused var warning

            stan::math::fill(pos, std::numeric_limits<int>::min());
            stan::math::assign(pos,1);


            current_statement_begin__ = 657;
            if (as_bool(logical_neq(rows(x),(Rows * Cols)))) {
                current_statement_begin__ = 657;
                std::stringstream errmsg_stream__;
                errmsg_stream__ << "x is the wrong length";
                throw std::domain_error(errmsg_stream__.str());
            }
            current_statement_begin__ = 657;
            current_statement_begin__ = 658;
            for (int c = 1; c <= Cols; ++c) {
                current_statement_begin__ = 658;
                for (int r = 1; r <= Rows; ++r) {

                    current_statement_begin__ = 659;
                    stan::math::assign(get_base1_lhs(out,r,c,"out",1), get_base1(x,pos,"x",1));
                    current_statement_begin__ = 660;
                    stan::math::assign(pos, (pos + 1));
                }
            }
            current_statement_begin__ = 662;
            return stan::math::promote_scalar<fun_return_scalar_t__>(out);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct reshape_vec_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,Eigen::Dynamic>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& x,
                const int& Rows,
                const int& Cols, std::ostream* pstream__) const {
        return reshape_vec(x, Rows, Cols, pstream__);
    }
};

double
make_lower(const int& family,
               const int& link, std::ostream* pstream__) {
    typedef double fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 673;
        if (as_bool(logical_eq(family,1))) {
            current_statement_begin__ = 673;
            return stan::math::promote_scalar<fun_return_scalar_t__>(stan::math::negative_infinity());
        }
        current_statement_begin__ = 674;
        if (as_bool(logical_lte(family,3))) {

            current_statement_begin__ = 675;
            if (as_bool(logical_eq(link,2))) {
                current_statement_begin__ = 675;
                return stan::math::promote_scalar<fun_return_scalar_t__>(stan::math::negative_infinity());
            }
            current_statement_begin__ = 676;
            return stan::math::promote_scalar<fun_return_scalar_t__>(0);
        }
        current_statement_begin__ = 678;
        return stan::math::promote_scalar<fun_return_scalar_t__>(stan::math::negative_infinity());
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct make_lower_functor__ {
            double
    operator()(const int& family,
               const int& link, std::ostream* pstream__) const {
        return make_lower(family, link, pstream__);
    }
};

double
make_upper(const int& family,
               const int& link, std::ostream* pstream__) {
    typedef double fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 689;
        if (as_bool((primitive_value(logical_eq(family,4)) && primitive_value(logical_eq(link,5))))) {
            current_statement_begin__ = 689;
            return stan::math::promote_scalar<fun_return_scalar_t__>(0);
        }
        current_statement_begin__ = 690;
        return stan::math::promote_scalar<fun_return_scalar_t__>(stan::math::positive_infinity());
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct make_upper_functor__ {
            double
    operator()(const int& family,
               const int& link, std::ostream* pstream__) const {
        return make_upper(family, link, pstream__);
    }
};

template <typename T2__, typename T5__>
Eigen::Matrix<typename boost::math::tools::promote_args<T2__, T5__>::type, Eigen::Dynamic,1>
test_csr_matrix_times_vector(const int& m,
                                 const int& n,
                                 const Eigen::Matrix<T2__, Eigen::Dynamic,1>& w,
                                 const std::vector<int>& v,
                                 const std::vector<int>& u,
                                 const Eigen::Matrix<T5__, Eigen::Dynamic,1>& b, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T2__, T5__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 706;
        return stan::math::promote_scalar<fun_return_scalar_t__>(csr_matrix_times_vector(m,n,w,v,u,b));
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct test_csr_matrix_times_vector_functor__ {
    template <typename T2__, typename T5__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T2__, T5__>::type, Eigen::Dynamic,1>
    operator()(const int& m,
                                 const int& n,
                                 const Eigen::Matrix<T2__, Eigen::Dynamic,1>& w,
                                 const std::vector<int>& v,
                                 const std::vector<int>& u,
                                 const Eigen::Matrix<T5__, Eigen::Dynamic,1>& b, std::ostream* pstream__) const {
        return test_csr_matrix_times_vector(m, n, w, v, u, b, pstream__);
    }
};

class model_continuous : public prob_grad {
private:
    int N;
    int K;
    vector_d xbar;
    int dense_X;
    vector<matrix_d> X;
    int nnz_X;
    vector_d w_X;
    vector<int> v_X;
    vector<int> u_X;
    int K_smooth;
    matrix_d S;
    vector<int> smooth_map;
    int len_y;
    double lb_y;
    double ub_y;
    vector_d y;
    int prior_PD;
    int has_intercept;
    int family;
    int link;
    int prior_dist;
    int prior_dist_for_intercept;
    int prior_dist_for_aux;
    int prior_dist_for_smooth;
    int has_weights;
    vector_d weights;
    int has_offset;
    vector_d offset;
    vector_d prior_scale;
    double prior_scale_for_intercept;
    double prior_scale_for_aux;
    vector_d prior_scale_for_smooth;
    vector_d prior_mean;
    double prior_mean_for_intercept;
    double prior_mean_for_aux;
    vector_d prior_mean_for_smooth;
    vector_d prior_df;
    double prior_df_for_intercept;
    double prior_df_for_aux;
    vector_d prior_df_for_smooth;
    double global_prior_df;
    double global_prior_scale;
    vector<int> num_normals;
    int t;
    vector<int> p;
    vector<int> l;
    int q;
    int len_theta_L;
    vector_d shape;
    vector_d scale;
    int len_concentration;
    vector<double> concentration;
    int len_regularization;
    vector<double> regularization;
    int num_non_zero;
    vector_d w;
    vector<int> v;
    vector<int> u;
    int special_case;
    int has_intercept_z;
    int link_phi;
    int z_dim;
    matrix_d betareg_z;
    row_vector_d zbar;
    int prior_dist_z;
    int prior_dist_for_intercept_z;
    vector_d prior_scale_z;
    double prior_scale_for_intercept_z;
    vector_d prior_mean_z;
    double prior_mean_for_intercept_z;
    vector_d prior_df_z;
    double prior_df_for_intercept_z;
    double global_prior_scale_z;
    vector<int> num_normals_z;
    int SSfun;
    vector_d input;
    vector_d Dose;
    vector_d sqrt_y;
    vector_d log_y;
    double sum_log_y;
    vector<vector<int> > V;
    int hs_z;
    int len_z_T;
    int len_var_group;
    int len_rho;
    int is_continuous;
    int pos;
    vector<double> delta;
    int hs;
public:
    model_continuous(stan::io::var_context& context__,
        std::ostream* pstream__ = 0)
        : prob_grad(0) {
        ctor_body(context__, 0, pstream__);
    }

    model_continuous(stan::io::var_context& context__,
        unsigned int random_seed__,
        std::ostream* pstream__ = 0)
        : prob_grad(0) {
        ctor_body(context__, random_seed__, pstream__);
    }

    void ctor_body(stan::io::var_context& context__,
                   unsigned int random_seed__,
                   std::ostream* pstream__) {
        boost::ecuyer1988 base_rng__ =
          stan::services::util::create_rng(random_seed__, 0);
        (void) base_rng__;  // suppress unused var warning

        current_statement_begin__ = -1;

        static const char* function__ = "model_continuous_namespace::model_continuous";
        (void) function__;  // dummy to suppress unused var warning
        size_t pos__;
        (void) pos__;  // dummy to suppress unused var warning
        std::vector<int> vals_i__;
        std::vector<double> vals_r__;
        double DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

        // initialize member variables
        context__.validate_dims("data initialization", "N", "int", context__.to_vec());
        N = int(0);
        vals_i__ = context__.vals_i("N");
        pos__ = 0;
        N = vals_i__[pos__++];
        context__.validate_dims("data initialization", "K", "int", context__.to_vec());
        K = int(0);
        vals_i__ = context__.vals_i("K");
        pos__ = 0;
        K = vals_i__[pos__++];
        validate_non_negative_index("xbar", "K", K);
        context__.validate_dims("data initialization", "xbar", "vector_d", context__.to_vec(K));
        validate_non_negative_index("xbar", "K", K);
        xbar = vector_d(static_cast<Eigen::VectorXd::Index>(K));
        vals_r__ = context__.vals_r("xbar");
        pos__ = 0;
        size_t xbar_i_vec_lim__ = K;
        for (size_t i_vec__ = 0; i_vec__ < xbar_i_vec_lim__; ++i_vec__) {
            xbar[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "dense_X", "int", context__.to_vec());
        dense_X = int(0);
        vals_i__ = context__.vals_i("dense_X");
        pos__ = 0;
        dense_X = vals_i__[pos__++];
        validate_non_negative_index("X", "dense_X", dense_X);
        validate_non_negative_index("X", "N", N);
        validate_non_negative_index("X", "K", K);
        context__.validate_dims("data initialization", "X", "matrix_d", context__.to_vec(dense_X,N,K));
        validate_non_negative_index("X", "dense_X", dense_X);
        validate_non_negative_index("X", "N", N);
        validate_non_negative_index("X", "K", K);
        X = std::vector<matrix_d>(dense_X,matrix_d(static_cast<Eigen::VectorXd::Index>(N),static_cast<Eigen::VectorXd::Index>(K)));
        vals_r__ = context__.vals_r("X");
        pos__ = 0;
        size_t X_m_mat_lim__ = N;
        size_t X_n_mat_lim__ = K;
        for (size_t n_mat__ = 0; n_mat__ < X_n_mat_lim__; ++n_mat__) {
            for (size_t m_mat__ = 0; m_mat__ < X_m_mat_lim__; ++m_mat__) {
                size_t X_limit_0__ = dense_X;
                for (size_t i_0__ = 0; i_0__ < X_limit_0__; ++i_0__) {
                    X[i_0__](m_mat__,n_mat__) = vals_r__[pos__++];
            }
            }
        }
        context__.validate_dims("data initialization", "nnz_X", "int", context__.to_vec());
        nnz_X = int(0);
        vals_i__ = context__.vals_i("nnz_X");
        pos__ = 0;
        nnz_X = vals_i__[pos__++];
        validate_non_negative_index("w_X", "nnz_X", nnz_X);
        context__.validate_dims("data initialization", "w_X", "vector_d", context__.to_vec(nnz_X));
        validate_non_negative_index("w_X", "nnz_X", nnz_X);
        w_X = vector_d(static_cast<Eigen::VectorXd::Index>(nnz_X));
        vals_r__ = context__.vals_r("w_X");
        pos__ = 0;
        size_t w_X_i_vec_lim__ = nnz_X;
        for (size_t i_vec__ = 0; i_vec__ < w_X_i_vec_lim__; ++i_vec__) {
            w_X[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("v_X", "nnz_X", nnz_X);
        context__.validate_dims("data initialization", "v_X", "int", context__.to_vec(nnz_X));
        validate_non_negative_index("v_X", "nnz_X", nnz_X);
        v_X = std::vector<int>(nnz_X,int(0));
        vals_i__ = context__.vals_i("v_X");
        pos__ = 0;
        size_t v_X_limit_0__ = nnz_X;
        for (size_t i_0__ = 0; i_0__ < v_X_limit_0__; ++i_0__) {
            v_X[i_0__] = vals_i__[pos__++];
        }
        validate_non_negative_index("u_X", "(dense_X ? 0 : (N + 1) )", (dense_X ? 0 : (N + 1) ));
        context__.validate_dims("data initialization", "u_X", "int", context__.to_vec((dense_X ? 0 : (N + 1) )));
        validate_non_negative_index("u_X", "(dense_X ? 0 : (N + 1) )", (dense_X ? 0 : (N + 1) ));
        u_X = std::vector<int>((dense_X ? 0 : (N + 1) ),int(0));
        vals_i__ = context__.vals_i("u_X");
        pos__ = 0;
        size_t u_X_limit_0__ = (dense_X ? 0 : (N + 1) );
        for (size_t i_0__ = 0; i_0__ < u_X_limit_0__; ++i_0__) {
            u_X[i_0__] = vals_i__[pos__++];
        }
        context__.validate_dims("data initialization", "K_smooth", "int", context__.to_vec());
        K_smooth = int(0);
        vals_i__ = context__.vals_i("K_smooth");
        pos__ = 0;
        K_smooth = vals_i__[pos__++];
        validate_non_negative_index("S", "N", N);
        validate_non_negative_index("S", "K_smooth", K_smooth);
        context__.validate_dims("data initialization", "S", "matrix_d", context__.to_vec(N,K_smooth));
        validate_non_negative_index("S", "N", N);
        validate_non_negative_index("S", "K_smooth", K_smooth);
        S = matrix_d(static_cast<Eigen::VectorXd::Index>(N),static_cast<Eigen::VectorXd::Index>(K_smooth));
        vals_r__ = context__.vals_r("S");
        pos__ = 0;
        size_t S_m_mat_lim__ = N;
        size_t S_n_mat_lim__ = K_smooth;
        for (size_t n_mat__ = 0; n_mat__ < S_n_mat_lim__; ++n_mat__) {
            for (size_t m_mat__ = 0; m_mat__ < S_m_mat_lim__; ++m_mat__) {
                S(m_mat__,n_mat__) = vals_r__[pos__++];
            }
        }
        validate_non_negative_index("smooth_map", "K_smooth", K_smooth);
        context__.validate_dims("data initialization", "smooth_map", "int", context__.to_vec(K_smooth));
        validate_non_negative_index("smooth_map", "K_smooth", K_smooth);
        smooth_map = std::vector<int>(K_smooth,int(0));
        vals_i__ = context__.vals_i("smooth_map");
        pos__ = 0;
        size_t smooth_map_limit_0__ = K_smooth;
        for (size_t i_0__ = 0; i_0__ < smooth_map_limit_0__; ++i_0__) {
            smooth_map[i_0__] = vals_i__[pos__++];
        }
        context__.validate_dims("data initialization", "len_y", "int", context__.to_vec());
        len_y = int(0);
        vals_i__ = context__.vals_i("len_y");
        pos__ = 0;
        len_y = vals_i__[pos__++];
        context__.validate_dims("data initialization", "lb_y", "double", context__.to_vec());
        lb_y = double(0);
        vals_r__ = context__.vals_r("lb_y");
        pos__ = 0;
        lb_y = vals_r__[pos__++];
        context__.validate_dims("data initialization", "ub_y", "double", context__.to_vec());
        ub_y = double(0);
        vals_r__ = context__.vals_r("ub_y");
        pos__ = 0;
        ub_y = vals_r__[pos__++];
        validate_non_negative_index("y", "len_y", len_y);
        context__.validate_dims("data initialization", "y", "vector_d", context__.to_vec(len_y));
        validate_non_negative_index("y", "len_y", len_y);
        y = vector_d(static_cast<Eigen::VectorXd::Index>(len_y));
        vals_r__ = context__.vals_r("y");
        pos__ = 0;
        size_t y_i_vec_lim__ = len_y;
        for (size_t i_vec__ = 0; i_vec__ < y_i_vec_lim__; ++i_vec__) {
            y[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "prior_PD", "int", context__.to_vec());
        prior_PD = int(0);
        vals_i__ = context__.vals_i("prior_PD");
        pos__ = 0;
        prior_PD = vals_i__[pos__++];
        context__.validate_dims("data initialization", "has_intercept", "int", context__.to_vec());
        has_intercept = int(0);
        vals_i__ = context__.vals_i("has_intercept");
        pos__ = 0;
        has_intercept = vals_i__[pos__++];
        context__.validate_dims("data initialization", "family", "int", context__.to_vec());
        family = int(0);
        vals_i__ = context__.vals_i("family");
        pos__ = 0;
        family = vals_i__[pos__++];
        context__.validate_dims("data initialization", "link", "int", context__.to_vec());
        link = int(0);
        vals_i__ = context__.vals_i("link");
        pos__ = 0;
        link = vals_i__[pos__++];
        context__.validate_dims("data initialization", "prior_dist", "int", context__.to_vec());
        prior_dist = int(0);
        vals_i__ = context__.vals_i("prior_dist");
        pos__ = 0;
        prior_dist = vals_i__[pos__++];
        context__.validate_dims("data initialization", "prior_dist_for_intercept", "int", context__.to_vec());
        prior_dist_for_intercept = int(0);
        vals_i__ = context__.vals_i("prior_dist_for_intercept");
        pos__ = 0;
        prior_dist_for_intercept = vals_i__[pos__++];
        context__.validate_dims("data initialization", "prior_dist_for_aux", "int", context__.to_vec());
        prior_dist_for_aux = int(0);
        vals_i__ = context__.vals_i("prior_dist_for_aux");
        pos__ = 0;
        prior_dist_for_aux = vals_i__[pos__++];
        context__.validate_dims("data initialization", "prior_dist_for_smooth", "int", context__.to_vec());
        prior_dist_for_smooth = int(0);
        vals_i__ = context__.vals_i("prior_dist_for_smooth");
        pos__ = 0;
        prior_dist_for_smooth = vals_i__[pos__++];
        context__.validate_dims("data initialization", "has_weights", "int", context__.to_vec());
        has_weights = int(0);
        vals_i__ = context__.vals_i("has_weights");
        pos__ = 0;
        has_weights = vals_i__[pos__++];
        validate_non_negative_index("weights", "(has_weights ? N : 0 )", (has_weights ? N : 0 ));
        context__.validate_dims("data initialization", "weights", "vector_d", context__.to_vec((has_weights ? N : 0 )));
        validate_non_negative_index("weights", "(has_weights ? N : 0 )", (has_weights ? N : 0 ));
        weights = vector_d(static_cast<Eigen::VectorXd::Index>((has_weights ? N : 0 )));
        vals_r__ = context__.vals_r("weights");
        pos__ = 0;
        size_t weights_i_vec_lim__ = (has_weights ? N : 0 );
        for (size_t i_vec__ = 0; i_vec__ < weights_i_vec_lim__; ++i_vec__) {
            weights[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "has_offset", "int", context__.to_vec());
        has_offset = int(0);
        vals_i__ = context__.vals_i("has_offset");
        pos__ = 0;
        has_offset = vals_i__[pos__++];
        validate_non_negative_index("offset", "(has_offset ? N : 0 )", (has_offset ? N : 0 ));
        context__.validate_dims("data initialization", "offset", "vector_d", context__.to_vec((has_offset ? N : 0 )));
        validate_non_negative_index("offset", "(has_offset ? N : 0 )", (has_offset ? N : 0 ));
        offset = vector_d(static_cast<Eigen::VectorXd::Index>((has_offset ? N : 0 )));
        vals_r__ = context__.vals_r("offset");
        pos__ = 0;
        size_t offset_i_vec_lim__ = (has_offset ? N : 0 );
        for (size_t i_vec__ = 0; i_vec__ < offset_i_vec_lim__; ++i_vec__) {
            offset[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("prior_scale", "K", K);
        context__.validate_dims("data initialization", "prior_scale", "vector_d", context__.to_vec(K));
        validate_non_negative_index("prior_scale", "K", K);
        prior_scale = vector_d(static_cast<Eigen::VectorXd::Index>(K));
        vals_r__ = context__.vals_r("prior_scale");
        pos__ = 0;
        size_t prior_scale_i_vec_lim__ = K;
        for (size_t i_vec__ = 0; i_vec__ < prior_scale_i_vec_lim__; ++i_vec__) {
            prior_scale[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "prior_scale_for_intercept", "double", context__.to_vec());
        prior_scale_for_intercept = double(0);
        vals_r__ = context__.vals_r("prior_scale_for_intercept");
        pos__ = 0;
        prior_scale_for_intercept = vals_r__[pos__++];
        context__.validate_dims("data initialization", "prior_scale_for_aux", "double", context__.to_vec());
        prior_scale_for_aux = double(0);
        vals_r__ = context__.vals_r("prior_scale_for_aux");
        pos__ = 0;
        prior_scale_for_aux = vals_r__[pos__++];
        validate_non_negative_index("prior_scale_for_smooth", "(logical_gt(K_smooth,0) ? max(smooth_map) : 0 )", (logical_gt(K_smooth,0) ? max(smooth_map) : 0 ));
        context__.validate_dims("data initialization", "prior_scale_for_smooth", "vector_d", context__.to_vec((logical_gt(K_smooth,0) ? max(smooth_map) : 0 )));
        validate_non_negative_index("prior_scale_for_smooth", "(logical_gt(K_smooth,0) ? max(smooth_map) : 0 )", (logical_gt(K_smooth,0) ? max(smooth_map) : 0 ));
        prior_scale_for_smooth = vector_d(static_cast<Eigen::VectorXd::Index>((logical_gt(K_smooth,0) ? max(smooth_map) : 0 )));
        vals_r__ = context__.vals_r("prior_scale_for_smooth");
        pos__ = 0;
        size_t prior_scale_for_smooth_i_vec_lim__ = (logical_gt(K_smooth,0) ? max(smooth_map) : 0 );
        for (size_t i_vec__ = 0; i_vec__ < prior_scale_for_smooth_i_vec_lim__; ++i_vec__) {
            prior_scale_for_smooth[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("prior_mean", "K", K);
        context__.validate_dims("data initialization", "prior_mean", "vector_d", context__.to_vec(K));
        validate_non_negative_index("prior_mean", "K", K);
        prior_mean = vector_d(static_cast<Eigen::VectorXd::Index>(K));
        vals_r__ = context__.vals_r("prior_mean");
        pos__ = 0;
        size_t prior_mean_i_vec_lim__ = K;
        for (size_t i_vec__ = 0; i_vec__ < prior_mean_i_vec_lim__; ++i_vec__) {
            prior_mean[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "prior_mean_for_intercept", "double", context__.to_vec());
        prior_mean_for_intercept = double(0);
        vals_r__ = context__.vals_r("prior_mean_for_intercept");
        pos__ = 0;
        prior_mean_for_intercept = vals_r__[pos__++];
        context__.validate_dims("data initialization", "prior_mean_for_aux", "double", context__.to_vec());
        prior_mean_for_aux = double(0);
        vals_r__ = context__.vals_r("prior_mean_for_aux");
        pos__ = 0;
        prior_mean_for_aux = vals_r__[pos__++];
        validate_non_negative_index("prior_mean_for_smooth", "(logical_gt(K_smooth,0) ? max(smooth_map) : 0 )", (logical_gt(K_smooth,0) ? max(smooth_map) : 0 ));
        context__.validate_dims("data initialization", "prior_mean_for_smooth", "vector_d", context__.to_vec((logical_gt(K_smooth,0) ? max(smooth_map) : 0 )));
        validate_non_negative_index("prior_mean_for_smooth", "(logical_gt(K_smooth,0) ? max(smooth_map) : 0 )", (logical_gt(K_smooth,0) ? max(smooth_map) : 0 ));
        prior_mean_for_smooth = vector_d(static_cast<Eigen::VectorXd::Index>((logical_gt(K_smooth,0) ? max(smooth_map) : 0 )));
        vals_r__ = context__.vals_r("prior_mean_for_smooth");
        pos__ = 0;
        size_t prior_mean_for_smooth_i_vec_lim__ = (logical_gt(K_smooth,0) ? max(smooth_map) : 0 );
        for (size_t i_vec__ = 0; i_vec__ < prior_mean_for_smooth_i_vec_lim__; ++i_vec__) {
            prior_mean_for_smooth[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("prior_df", "K", K);
        context__.validate_dims("data initialization", "prior_df", "vector_d", context__.to_vec(K));
        validate_non_negative_index("prior_df", "K", K);
        prior_df = vector_d(static_cast<Eigen::VectorXd::Index>(K));
        vals_r__ = context__.vals_r("prior_df");
        pos__ = 0;
        size_t prior_df_i_vec_lim__ = K;
        for (size_t i_vec__ = 0; i_vec__ < prior_df_i_vec_lim__; ++i_vec__) {
            prior_df[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "prior_df_for_intercept", "double", context__.to_vec());
        prior_df_for_intercept = double(0);
        vals_r__ = context__.vals_r("prior_df_for_intercept");
        pos__ = 0;
        prior_df_for_intercept = vals_r__[pos__++];
        context__.validate_dims("data initialization", "prior_df_for_aux", "double", context__.to_vec());
        prior_df_for_aux = double(0);
        vals_r__ = context__.vals_r("prior_df_for_aux");
        pos__ = 0;
        prior_df_for_aux = vals_r__[pos__++];
        validate_non_negative_index("prior_df_for_smooth", "(logical_gt(K_smooth,0) ? max(smooth_map) : 0 )", (logical_gt(K_smooth,0) ? max(smooth_map) : 0 ));
        context__.validate_dims("data initialization", "prior_df_for_smooth", "vector_d", context__.to_vec((logical_gt(K_smooth,0) ? max(smooth_map) : 0 )));
        validate_non_negative_index("prior_df_for_smooth", "(logical_gt(K_smooth,0) ? max(smooth_map) : 0 )", (logical_gt(K_smooth,0) ? max(smooth_map) : 0 ));
        prior_df_for_smooth = vector_d(static_cast<Eigen::VectorXd::Index>((logical_gt(K_smooth,0) ? max(smooth_map) : 0 )));
        vals_r__ = context__.vals_r("prior_df_for_smooth");
        pos__ = 0;
        size_t prior_df_for_smooth_i_vec_lim__ = (logical_gt(K_smooth,0) ? max(smooth_map) : 0 );
        for (size_t i_vec__ = 0; i_vec__ < prior_df_for_smooth_i_vec_lim__; ++i_vec__) {
            prior_df_for_smooth[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "global_prior_df", "double", context__.to_vec());
        global_prior_df = double(0);
        vals_r__ = context__.vals_r("global_prior_df");
        pos__ = 0;
        global_prior_df = vals_r__[pos__++];
        context__.validate_dims("data initialization", "global_prior_scale", "double", context__.to_vec());
        global_prior_scale = double(0);
        vals_r__ = context__.vals_r("global_prior_scale");
        pos__ = 0;
        global_prior_scale = vals_r__[pos__++];
        validate_non_negative_index("num_normals", "(logical_eq(prior_dist,7) ? K : 0 )", (logical_eq(prior_dist,7) ? K : 0 ));
        context__.validate_dims("data initialization", "num_normals", "int", context__.to_vec((logical_eq(prior_dist,7) ? K : 0 )));
        validate_non_negative_index("num_normals", "(logical_eq(prior_dist,7) ? K : 0 )", (logical_eq(prior_dist,7) ? K : 0 ));
        num_normals = std::vector<int>((logical_eq(prior_dist,7) ? K : 0 ),int(0));
        vals_i__ = context__.vals_i("num_normals");
        pos__ = 0;
        size_t num_normals_limit_0__ = (logical_eq(prior_dist,7) ? K : 0 );
        for (size_t i_0__ = 0; i_0__ < num_normals_limit_0__; ++i_0__) {
            num_normals[i_0__] = vals_i__[pos__++];
        }
        context__.validate_dims("data initialization", "t", "int", context__.to_vec());
        t = int(0);
        vals_i__ = context__.vals_i("t");
        pos__ = 0;
        t = vals_i__[pos__++];
        validate_non_negative_index("p", "t", t);
        context__.validate_dims("data initialization", "p", "int", context__.to_vec(t));
        validate_non_negative_index("p", "t", t);
        p = std::vector<int>(t,int(0));
        vals_i__ = context__.vals_i("p");
        pos__ = 0;
        size_t p_limit_0__ = t;
        for (size_t i_0__ = 0; i_0__ < p_limit_0__; ++i_0__) {
            p[i_0__] = vals_i__[pos__++];
        }
        validate_non_negative_index("l", "t", t);
        context__.validate_dims("data initialization", "l", "int", context__.to_vec(t));
        validate_non_negative_index("l", "t", t);
        l = std::vector<int>(t,int(0));
        vals_i__ = context__.vals_i("l");
        pos__ = 0;
        size_t l_limit_0__ = t;
        for (size_t i_0__ = 0; i_0__ < l_limit_0__; ++i_0__) {
            l[i_0__] = vals_i__[pos__++];
        }
        context__.validate_dims("data initialization", "q", "int", context__.to_vec());
        q = int(0);
        vals_i__ = context__.vals_i("q");
        pos__ = 0;
        q = vals_i__[pos__++];
        context__.validate_dims("data initialization", "len_theta_L", "int", context__.to_vec());
        len_theta_L = int(0);
        vals_i__ = context__.vals_i("len_theta_L");
        pos__ = 0;
        len_theta_L = vals_i__[pos__++];
        validate_non_negative_index("shape", "t", t);
        context__.validate_dims("data initialization", "shape", "vector_d", context__.to_vec(t));
        validate_non_negative_index("shape", "t", t);
        shape = vector_d(static_cast<Eigen::VectorXd::Index>(t));
        vals_r__ = context__.vals_r("shape");
        pos__ = 0;
        size_t shape_i_vec_lim__ = t;
        for (size_t i_vec__ = 0; i_vec__ < shape_i_vec_lim__; ++i_vec__) {
            shape[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("scale", "t", t);
        context__.validate_dims("data initialization", "scale", "vector_d", context__.to_vec(t));
        validate_non_negative_index("scale", "t", t);
        scale = vector_d(static_cast<Eigen::VectorXd::Index>(t));
        vals_r__ = context__.vals_r("scale");
        pos__ = 0;
        size_t scale_i_vec_lim__ = t;
        for (size_t i_vec__ = 0; i_vec__ < scale_i_vec_lim__; ++i_vec__) {
            scale[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "len_concentration", "int", context__.to_vec());
        len_concentration = int(0);
        vals_i__ = context__.vals_i("len_concentration");
        pos__ = 0;
        len_concentration = vals_i__[pos__++];
        validate_non_negative_index("concentration", "len_concentration", len_concentration);
        context__.validate_dims("data initialization", "concentration", "double", context__.to_vec(len_concentration));
        validate_non_negative_index("concentration", "len_concentration", len_concentration);
        concentration = std::vector<double>(len_concentration,double(0));
        vals_r__ = context__.vals_r("concentration");
        pos__ = 0;
        size_t concentration_limit_0__ = len_concentration;
        for (size_t i_0__ = 0; i_0__ < concentration_limit_0__; ++i_0__) {
            concentration[i_0__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "len_regularization", "int", context__.to_vec());
        len_regularization = int(0);
        vals_i__ = context__.vals_i("len_regularization");
        pos__ = 0;
        len_regularization = vals_i__[pos__++];
        validate_non_negative_index("regularization", "len_regularization", len_regularization);
        context__.validate_dims("data initialization", "regularization", "double", context__.to_vec(len_regularization));
        validate_non_negative_index("regularization", "len_regularization", len_regularization);
        regularization = std::vector<double>(len_regularization,double(0));
        vals_r__ = context__.vals_r("regularization");
        pos__ = 0;
        size_t regularization_limit_0__ = len_regularization;
        for (size_t i_0__ = 0; i_0__ < regularization_limit_0__; ++i_0__) {
            regularization[i_0__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "num_non_zero", "int", context__.to_vec());
        num_non_zero = int(0);
        vals_i__ = context__.vals_i("num_non_zero");
        pos__ = 0;
        num_non_zero = vals_i__[pos__++];
        validate_non_negative_index("w", "num_non_zero", num_non_zero);
        context__.validate_dims("data initialization", "w", "vector_d", context__.to_vec(num_non_zero));
        validate_non_negative_index("w", "num_non_zero", num_non_zero);
        w = vector_d(static_cast<Eigen::VectorXd::Index>(num_non_zero));
        vals_r__ = context__.vals_r("w");
        pos__ = 0;
        size_t w_i_vec_lim__ = num_non_zero;
        for (size_t i_vec__ = 0; i_vec__ < w_i_vec_lim__; ++i_vec__) {
            w[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("v", "num_non_zero", num_non_zero);
        context__.validate_dims("data initialization", "v", "int", context__.to_vec(num_non_zero));
        validate_non_negative_index("v", "num_non_zero", num_non_zero);
        v = std::vector<int>(num_non_zero,int(0));
        vals_i__ = context__.vals_i("v");
        pos__ = 0;
        size_t v_limit_0__ = num_non_zero;
        for (size_t i_0__ = 0; i_0__ < v_limit_0__; ++i_0__) {
            v[i_0__] = vals_i__[pos__++];
        }
        validate_non_negative_index("u", "(logical_gt(t,0) ? (N + 1) : 0 )", (logical_gt(t,0) ? (N + 1) : 0 ));
        context__.validate_dims("data initialization", "u", "int", context__.to_vec((logical_gt(t,0) ? (N + 1) : 0 )));
        validate_non_negative_index("u", "(logical_gt(t,0) ? (N + 1) : 0 )", (logical_gt(t,0) ? (N + 1) : 0 ));
        u = std::vector<int>((logical_gt(t,0) ? (N + 1) : 0 ),int(0));
        vals_i__ = context__.vals_i("u");
        pos__ = 0;
        size_t u_limit_0__ = (logical_gt(t,0) ? (N + 1) : 0 );
        for (size_t i_0__ = 0; i_0__ < u_limit_0__; ++i_0__) {
            u[i_0__] = vals_i__[pos__++];
        }
        context__.validate_dims("data initialization", "special_case", "int", context__.to_vec());
        special_case = int(0);
        vals_i__ = context__.vals_i("special_case");
        pos__ = 0;
        special_case = vals_i__[pos__++];
        context__.validate_dims("data initialization", "has_intercept_z", "int", context__.to_vec());
        has_intercept_z = int(0);
        vals_i__ = context__.vals_i("has_intercept_z");
        pos__ = 0;
        has_intercept_z = vals_i__[pos__++];
        context__.validate_dims("data initialization", "link_phi", "int", context__.to_vec());
        link_phi = int(0);
        vals_i__ = context__.vals_i("link_phi");
        pos__ = 0;
        link_phi = vals_i__[pos__++];
        context__.validate_dims("data initialization", "z_dim", "int", context__.to_vec());
        z_dim = int(0);
        vals_i__ = context__.vals_i("z_dim");
        pos__ = 0;
        z_dim = vals_i__[pos__++];
        validate_non_negative_index("betareg_z", "N", N);
        validate_non_negative_index("betareg_z", "z_dim", z_dim);
        context__.validate_dims("data initialization", "betareg_z", "matrix_d", context__.to_vec(N,z_dim));
        validate_non_negative_index("betareg_z", "N", N);
        validate_non_negative_index("betareg_z", "z_dim", z_dim);
        betareg_z = matrix_d(static_cast<Eigen::VectorXd::Index>(N),static_cast<Eigen::VectorXd::Index>(z_dim));
        vals_r__ = context__.vals_r("betareg_z");
        pos__ = 0;
        size_t betareg_z_m_mat_lim__ = N;
        size_t betareg_z_n_mat_lim__ = z_dim;
        for (size_t n_mat__ = 0; n_mat__ < betareg_z_n_mat_lim__; ++n_mat__) {
            for (size_t m_mat__ = 0; m_mat__ < betareg_z_m_mat_lim__; ++m_mat__) {
                betareg_z(m_mat__,n_mat__) = vals_r__[pos__++];
            }
        }
        validate_non_negative_index("zbar", "z_dim", z_dim);
        context__.validate_dims("data initialization", "zbar", "row_vector_d", context__.to_vec(z_dim));
        validate_non_negative_index("zbar", "z_dim", z_dim);
        zbar = row_vector_d(static_cast<Eigen::VectorXd::Index>(z_dim));
        vals_r__ = context__.vals_r("zbar");
        pos__ = 0;
        size_t zbar_i_vec_lim__ = z_dim;
        for (size_t i_vec__ = 0; i_vec__ < zbar_i_vec_lim__; ++i_vec__) {
            zbar[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "prior_dist_z", "int", context__.to_vec());
        prior_dist_z = int(0);
        vals_i__ = context__.vals_i("prior_dist_z");
        pos__ = 0;
        prior_dist_z = vals_i__[pos__++];
        context__.validate_dims("data initialization", "prior_dist_for_intercept_z", "int", context__.to_vec());
        prior_dist_for_intercept_z = int(0);
        vals_i__ = context__.vals_i("prior_dist_for_intercept_z");
        pos__ = 0;
        prior_dist_for_intercept_z = vals_i__[pos__++];
        validate_non_negative_index("prior_scale_z", "z_dim", z_dim);
        context__.validate_dims("data initialization", "prior_scale_z", "vector_d", context__.to_vec(z_dim));
        validate_non_negative_index("prior_scale_z", "z_dim", z_dim);
        prior_scale_z = vector_d(static_cast<Eigen::VectorXd::Index>(z_dim));
        vals_r__ = context__.vals_r("prior_scale_z");
        pos__ = 0;
        size_t prior_scale_z_i_vec_lim__ = z_dim;
        for (size_t i_vec__ = 0; i_vec__ < prior_scale_z_i_vec_lim__; ++i_vec__) {
            prior_scale_z[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "prior_scale_for_intercept_z", "double", context__.to_vec());
        prior_scale_for_intercept_z = double(0);
        vals_r__ = context__.vals_r("prior_scale_for_intercept_z");
        pos__ = 0;
        prior_scale_for_intercept_z = vals_r__[pos__++];
        validate_non_negative_index("prior_mean_z", "z_dim", z_dim);
        context__.validate_dims("data initialization", "prior_mean_z", "vector_d", context__.to_vec(z_dim));
        validate_non_negative_index("prior_mean_z", "z_dim", z_dim);
        prior_mean_z = vector_d(static_cast<Eigen::VectorXd::Index>(z_dim));
        vals_r__ = context__.vals_r("prior_mean_z");
        pos__ = 0;
        size_t prior_mean_z_i_vec_lim__ = z_dim;
        for (size_t i_vec__ = 0; i_vec__ < prior_mean_z_i_vec_lim__; ++i_vec__) {
            prior_mean_z[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "prior_mean_for_intercept_z", "double", context__.to_vec());
        prior_mean_for_intercept_z = double(0);
        vals_r__ = context__.vals_r("prior_mean_for_intercept_z");
        pos__ = 0;
        prior_mean_for_intercept_z = vals_r__[pos__++];
        validate_non_negative_index("prior_df_z", "z_dim", z_dim);
        context__.validate_dims("data initialization", "prior_df_z", "vector_d", context__.to_vec(z_dim));
        validate_non_negative_index("prior_df_z", "z_dim", z_dim);
        prior_df_z = vector_d(static_cast<Eigen::VectorXd::Index>(z_dim));
        vals_r__ = context__.vals_r("prior_df_z");
        pos__ = 0;
        size_t prior_df_z_i_vec_lim__ = z_dim;
        for (size_t i_vec__ = 0; i_vec__ < prior_df_z_i_vec_lim__; ++i_vec__) {
            prior_df_z[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "prior_df_for_intercept_z", "double", context__.to_vec());
        prior_df_for_intercept_z = double(0);
        vals_r__ = context__.vals_r("prior_df_for_intercept_z");
        pos__ = 0;
        prior_df_for_intercept_z = vals_r__[pos__++];
        context__.validate_dims("data initialization", "global_prior_scale_z", "double", context__.to_vec());
        global_prior_scale_z = double(0);
        vals_r__ = context__.vals_r("global_prior_scale_z");
        pos__ = 0;
        global_prior_scale_z = vals_r__[pos__++];
        validate_non_negative_index("num_normals_z", "(logical_eq(prior_dist_z,7) ? z_dim : 0 )", (logical_eq(prior_dist_z,7) ? z_dim : 0 ));
        context__.validate_dims("data initialization", "num_normals_z", "int", context__.to_vec((logical_eq(prior_dist_z,7) ? z_dim : 0 )));
        validate_non_negative_index("num_normals_z", "(logical_eq(prior_dist_z,7) ? z_dim : 0 )", (logical_eq(prior_dist_z,7) ? z_dim : 0 ));
        num_normals_z = std::vector<int>((logical_eq(prior_dist_z,7) ? z_dim : 0 ),int(0));
        vals_i__ = context__.vals_i("num_normals_z");
        pos__ = 0;
        size_t num_normals_z_limit_0__ = (logical_eq(prior_dist_z,7) ? z_dim : 0 );
        for (size_t i_0__ = 0; i_0__ < num_normals_z_limit_0__; ++i_0__) {
            num_normals_z[i_0__] = vals_i__[pos__++];
        }
        context__.validate_dims("data initialization", "SSfun", "int", context__.to_vec());
        SSfun = int(0);
        vals_i__ = context__.vals_i("SSfun");
        pos__ = 0;
        SSfun = vals_i__[pos__++];
        validate_non_negative_index("input", "(logical_gt(SSfun,0) ? len_y : 0 )", (logical_gt(SSfun,0) ? len_y : 0 ));
        context__.validate_dims("data initialization", "input", "vector_d", context__.to_vec((logical_gt(SSfun,0) ? len_y : 0 )));
        validate_non_negative_index("input", "(logical_gt(SSfun,0) ? len_y : 0 )", (logical_gt(SSfun,0) ? len_y : 0 ));
        input = vector_d(static_cast<Eigen::VectorXd::Index>((logical_gt(SSfun,0) ? len_y : 0 )));
        vals_r__ = context__.vals_r("input");
        pos__ = 0;
        size_t input_i_vec_lim__ = (logical_gt(SSfun,0) ? len_y : 0 );
        for (size_t i_vec__ = 0; i_vec__ < input_i_vec_lim__; ++i_vec__) {
            input[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("Dose", "(logical_eq(SSfun,5) ? len_y : 0 )", (logical_eq(SSfun,5) ? len_y : 0 ));
        context__.validate_dims("data initialization", "Dose", "vector_d", context__.to_vec((logical_eq(SSfun,5) ? len_y : 0 )));
        validate_non_negative_index("Dose", "(logical_eq(SSfun,5) ? len_y : 0 )", (logical_eq(SSfun,5) ? len_y : 0 ));
        Dose = vector_d(static_cast<Eigen::VectorXd::Index>((logical_eq(SSfun,5) ? len_y : 0 )));
        vals_r__ = context__.vals_r("Dose");
        pos__ = 0;
        size_t Dose_i_vec_lim__ = (logical_eq(SSfun,5) ? len_y : 0 );
        for (size_t i_vec__ = 0; i_vec__ < Dose_i_vec_lim__; ++i_vec__) {
            Dose[i_vec__] = vals_r__[pos__++];
        }

        // validate, data variables
        check_greater_or_equal(function__,"N",N,0);
        check_greater_or_equal(function__,"K",K,0);
        check_greater_or_equal(function__,"dense_X",dense_X,0);
        check_less_or_equal(function__,"dense_X",dense_X,1);
        check_greater_or_equal(function__,"nnz_X",nnz_X,0);
        for (int k0__ = 0; k0__ < nnz_X; ++k0__) {
            check_greater_or_equal(function__,"v_X[k0__]",v_X[k0__],0);
        }
        for (int k0__ = 0; k0__ < (dense_X ? 0 : (N + 1) ); ++k0__) {
            check_greater_or_equal(function__,"u_X[k0__]",u_X[k0__],0);
        }
        check_greater_or_equal(function__,"K_smooth",K_smooth,0);
        for (int k0__ = 0; k0__ < K_smooth; ++k0__) {
            check_greater_or_equal(function__,"smooth_map[k0__]",smooth_map[k0__],1);
        }
        check_greater_or_equal(function__,"len_y",len_y,0);
        check_greater_or_equal(function__,"ub_y",ub_y,lb_y);
        check_greater_or_equal(function__,"y",y,lb_y);
        check_less_or_equal(function__,"y",y,ub_y);
        check_greater_or_equal(function__,"prior_PD",prior_PD,0);
        check_less_or_equal(function__,"prior_PD",prior_PD,1);
        check_greater_or_equal(function__,"has_intercept",has_intercept,0);
        check_less_or_equal(function__,"has_intercept",has_intercept,1);
        check_greater_or_equal(function__,"family",family,1);
        check_greater_or_equal(function__,"link",link,1);
        check_greater_or_equal(function__,"prior_dist",prior_dist,0);
        check_less_or_equal(function__,"prior_dist",prior_dist,7);
        check_greater_or_equal(function__,"prior_dist_for_intercept",prior_dist_for_intercept,0);
        check_less_or_equal(function__,"prior_dist_for_intercept",prior_dist_for_intercept,2);
        check_greater_or_equal(function__,"prior_dist_for_aux",prior_dist_for_aux,0);
        check_less_or_equal(function__,"prior_dist_for_aux",prior_dist_for_aux,3);
        check_greater_or_equal(function__,"prior_dist_for_smooth",prior_dist_for_smooth,0);
        check_less_or_equal(function__,"prior_dist_for_smooth",prior_dist_for_smooth,3);
        check_greater_or_equal(function__,"has_weights",has_weights,0);
        check_less_or_equal(function__,"has_weights",has_weights,1);
        check_greater_or_equal(function__,"has_offset",has_offset,0);
        check_less_or_equal(function__,"has_offset",has_offset,1);
        check_greater_or_equal(function__,"prior_scale",prior_scale,0);
        check_greater_or_equal(function__,"prior_scale_for_intercept",prior_scale_for_intercept,0);
        check_greater_or_equal(function__,"prior_scale_for_aux",prior_scale_for_aux,0);
        check_greater_or_equal(function__,"prior_scale_for_smooth",prior_scale_for_smooth,0);
        check_greater_or_equal(function__,"prior_mean_for_aux",prior_mean_for_aux,0);
        check_greater_or_equal(function__,"prior_mean_for_smooth",prior_mean_for_smooth,0);
        check_greater_or_equal(function__,"prior_df",prior_df,0);
        check_greater_or_equal(function__,"prior_df_for_intercept",prior_df_for_intercept,0);
        check_greater_or_equal(function__,"prior_df_for_aux",prior_df_for_aux,0);
        check_greater_or_equal(function__,"prior_df_for_smooth",prior_df_for_smooth,0);
        check_greater_or_equal(function__,"global_prior_df",global_prior_df,0);
        check_greater_or_equal(function__,"global_prior_scale",global_prior_scale,0);
        for (int k0__ = 0; k0__ < (logical_eq(prior_dist,7) ? K : 0 ); ++k0__) {
            check_greater_or_equal(function__,"num_normals[k0__]",num_normals[k0__],2);
        }
        check_greater_or_equal(function__,"t",t,0);
        for (int k0__ = 0; k0__ < t; ++k0__) {
            check_greater_or_equal(function__,"p[k0__]",p[k0__],1);
        }
        for (int k0__ = 0; k0__ < t; ++k0__) {
            check_greater_or_equal(function__,"l[k0__]",l[k0__],1);
        }
        check_greater_or_equal(function__,"q",q,0);
        check_greater_or_equal(function__,"len_theta_L",len_theta_L,0);
        check_greater_or_equal(function__,"shape",shape,0);
        check_greater_or_equal(function__,"scale",scale,0);
        check_greater_or_equal(function__,"len_concentration",len_concentration,0);
        for (int k0__ = 0; k0__ < len_concentration; ++k0__) {
            check_greater_or_equal(function__,"concentration[k0__]",concentration[k0__],0);
        }
        check_greater_or_equal(function__,"len_regularization",len_regularization,0);
        for (int k0__ = 0; k0__ < len_regularization; ++k0__) {
            check_greater_or_equal(function__,"regularization[k0__]",regularization[k0__],0);
        }
        check_greater_or_equal(function__,"num_non_zero",num_non_zero,0);
        for (int k0__ = 0; k0__ < num_non_zero; ++k0__) {
            check_greater_or_equal(function__,"v[k0__]",v[k0__],0);
        }
        for (int k0__ = 0; k0__ < (logical_gt(t,0) ? (N + 1) : 0 ); ++k0__) {
            check_greater_or_equal(function__,"u[k0__]",u[k0__],0);
        }
        check_greater_or_equal(function__,"special_case",special_case,0);
        check_less_or_equal(function__,"special_case",special_case,1);
        check_greater_or_equal(function__,"has_intercept_z",has_intercept_z,0);
        check_less_or_equal(function__,"has_intercept_z",has_intercept_z,1);
        check_greater_or_equal(function__,"link_phi",link_phi,0);
        check_greater_or_equal(function__,"z_dim",z_dim,0);
        check_greater_or_equal(function__,"prior_dist_z",prior_dist_z,0);
        check_less_or_equal(function__,"prior_dist_z",prior_dist_z,7);
        check_greater_or_equal(function__,"prior_dist_for_intercept_z",prior_dist_for_intercept_z,0);
        check_less_or_equal(function__,"prior_dist_for_intercept_z",prior_dist_for_intercept_z,2);
        check_greater_or_equal(function__,"prior_scale_z",prior_scale_z,0);
        check_greater_or_equal(function__,"prior_scale_for_intercept_z",prior_scale_for_intercept_z,0);
        check_greater_or_equal(function__,"prior_df_z",prior_df_z,0);
        check_greater_or_equal(function__,"prior_df_for_intercept_z",prior_df_for_intercept_z,0);
        check_greater_or_equal(function__,"global_prior_scale_z",global_prior_scale_z,0);
        for (int k0__ = 0; k0__ < (logical_eq(prior_dist_z,7) ? z_dim : 0 ); ++k0__) {
            check_greater_or_equal(function__,"num_normals_z[k0__]",num_normals_z[k0__],2);
        }
        check_greater_or_equal(function__,"SSfun",SSfun,0);
        check_less_or_equal(function__,"SSfun",SSfun,10);
        // initialize data variables
        validate_non_negative_index("sqrt_y", "(logical_eq(family,3) ? len_y : 0 )", (logical_eq(family,3) ? len_y : 0 ));
        sqrt_y = vector_d(static_cast<Eigen::VectorXd::Index>((logical_eq(family,3) ? len_y : 0 )));
        stan::math::fill(sqrt_y,DUMMY_VAR__);
        validate_non_negative_index("log_y", "(logical_eq(family,3) ? len_y : 0 )", (logical_eq(family,3) ? len_y : 0 ));
        log_y = vector_d(static_cast<Eigen::VectorXd::Index>((logical_eq(family,3) ? len_y : 0 )));
        stan::math::fill(log_y,DUMMY_VAR__);
        sum_log_y = double(0);
        stan::math::fill(sum_log_y,DUMMY_VAR__);
        stan::math::assign(sum_log_y,(logical_eq(family,1) ? stan::math::not_a_number() : sum(log(y)) ));
        validate_non_negative_index("V", "(special_case ? t : 0 )", (special_case ? t : 0 ));
        validate_non_negative_index("V", "len_y", len_y);
        V = std::vector<std::vector<int> >((special_case ? t : 0 ),std::vector<int>(len_y,int(0)));
        stan::math::fill(V, std::numeric_limits<int>::min());
        stan::math::assign(V,make_V(len_y,(special_case ? t : 0 ),v, pstream__));
        hs_z = int(0);
        stan::math::fill(hs_z, std::numeric_limits<int>::min());
        len_z_T = int(0);
        stan::math::fill(len_z_T, std::numeric_limits<int>::min());
        stan::math::assign(len_z_T,0);
        len_var_group = int(0);
        stan::math::fill(len_var_group, std::numeric_limits<int>::min());
        stan::math::assign(len_var_group,(sum(p) * logical_gt(t,0)));
        len_rho = int(0);
        stan::math::fill(len_rho, std::numeric_limits<int>::min());
        stan::math::assign(len_rho,(sum(p) - t));
        is_continuous = int(0);
        stan::math::fill(is_continuous, std::numeric_limits<int>::min());
        stan::math::assign(is_continuous,0);
        pos = int(0);
        stan::math::fill(pos, std::numeric_limits<int>::min());
        stan::math::assign(pos,1);
        validate_non_negative_index("delta", "len_concentration", len_concentration);
        delta = std::vector<double>(len_concentration,double(0));
        stan::math::fill(delta,DUMMY_VAR__);
        hs = int(0);
        stan::math::fill(hs, std::numeric_limits<int>::min());

        try {
            current_statement_begin__ = 843;
            if (as_bool(logical_lte(prior_dist,2))) {
                current_statement_begin__ = 843;
                stan::math::assign(hs, 0);
            } else if (as_bool(logical_eq(prior_dist,3))) {
                current_statement_begin__ = 844;
                stan::math::assign(hs, 2);
            } else if (as_bool(logical_eq(prior_dist,4))) {
                current_statement_begin__ = 845;
                stan::math::assign(hs, 4);
            } else {
                current_statement_begin__ = 846;
                stan::math::assign(hs, 0);
            }
            current_statement_begin__ = 848;
            stan::math::assign(pos, 1);
            current_statement_begin__ = 849;
            for (int i = 1; i <= t; ++i) {

                current_statement_begin__ = 850;
                if (as_bool(logical_gt(get_base1(p,i,"p",1),1))) {

                    current_statement_begin__ = 851;
                    for (int j = 1; j <= get_base1(p,i,"p",1); ++j) {

                        current_statement_begin__ = 852;
                        stan::math::assign(get_base1_lhs(delta,pos,"delta",1), get_base1(concentration,j,"concentration",1));
                        current_statement_begin__ = 853;
                        stan::math::assign(pos, (pos + 1));
                    }
                }
                current_statement_begin__ = 856;
                for (int j = 3; j <= get_base1(p,i,"p",1); ++j) {
                    current_statement_begin__ = 856;
                    stan::math::assign(len_z_T, ((len_z_T + get_base1(p,i,"p",1)) - 1));
                }
            }
            current_statement_begin__ = 859;
            if (as_bool(logical_lte(prior_dist_z,2))) {
                current_statement_begin__ = 859;
                stan::math::assign(hs_z, 0);
            } else if (as_bool(logical_eq(prior_dist_z,3))) {
                current_statement_begin__ = 860;
                stan::math::assign(hs_z, 2);
            } else if (as_bool(logical_eq(prior_dist_z,4))) {
                current_statement_begin__ = 861;
                stan::math::assign(hs_z, 4);
            } else {
                current_statement_begin__ = 862;
                stan::math::assign(hs_z, 0);
            }
            current_statement_begin__ = 863;
            stan::math::assign(is_continuous, 1);
            current_statement_begin__ = 865;
            if (as_bool(logical_eq(family,3))) {

                current_statement_begin__ = 866;
                stan::math::assign(sqrt_y, sqrt(y));
                current_statement_begin__ = 867;
                stan::math::assign(log_y, log(y));
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        // validate transformed data
        for (int k0__ = 0; k0__ < (special_case ? t : 0 ); ++k0__) {
            for (int k1__ = 0; k1__ < len_y; ++k1__) {
                check_greater_or_equal(function__,"V[k0__][k1__]",V[k0__][k1__],1);
            }
        }
        check_greater_or_equal(function__,"hs_z",hs_z,0);
        check_greater_or_equal(function__,"len_z_T",len_z_T,0);
        check_greater_or_equal(function__,"len_var_group",len_var_group,0);
        check_greater_or_equal(function__,"len_rho",len_rho,0);
        check_greater_or_equal(function__,"is_continuous",is_continuous,0);
        check_less_or_equal(function__,"is_continuous",is_continuous,1);
        check_greater_or_equal(function__,"pos",pos,1);
        for (int k0__ = 0; k0__ < len_concentration; ++k0__) {
            check_greater_or_equal(function__,"delta[k0__]",delta[k0__],0);
        }
        check_greater_or_equal(function__,"hs",hs,0);

        // validate, set parameter ranges
        num_params_r__ = 0U;
        param_ranges_i__.clear();
        validate_non_negative_index("gamma", "has_intercept", has_intercept);
        num_params_r__ += has_intercept;
        validate_non_negative_index("z_beta", "(logical_eq(prior_dist,7) ? sum(num_normals) : K )", (logical_eq(prior_dist,7) ? sum(num_normals) : K ));
        num_params_r__ += (logical_eq(prior_dist,7) ? sum(num_normals) : K );
        validate_non_negative_index("z_beta_smooth", "K_smooth", K_smooth);
        num_params_r__ += K_smooth;
        validate_non_negative_index("smooth_sd_raw", "(logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,\"smooth_map\",1) : 0 )", (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));
        num_params_r__ += (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 );
        validate_non_negative_index("global", "hs", hs);
        num_params_r__ += hs;
        validate_non_negative_index("local", "K", K);
        validate_non_negative_index("local", "hs", hs);
        num_params_r__ += K * hs;
        validate_non_negative_index("mix", "K", K);
        validate_non_negative_index("mix", "(primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6)))", (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))));
        num_params_r__ += K * (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6)));
        validate_non_negative_index("one_over_lambda", "logical_eq(prior_dist,6)", logical_eq(prior_dist,6));
        num_params_r__ += logical_eq(prior_dist,6);
        validate_non_negative_index("z_b", "q", q);
        num_params_r__ += q;
        validate_non_negative_index("z_T", "len_z_T", len_z_T);
        num_params_r__ += len_z_T;
        validate_non_negative_index("rho", "len_rho", len_rho);
        num_params_r__ += len_rho;
        validate_non_negative_index("zeta", "len_concentration", len_concentration);
        num_params_r__ += len_concentration;
        validate_non_negative_index("tau", "t", t);
        num_params_r__ += t;
        ++num_params_r__;
        validate_non_negative_index("z_omega", "(logical_eq(prior_dist_z,7) ? sum(num_normals_z) : z_dim )", (logical_eq(prior_dist_z,7) ? sum(num_normals_z) : z_dim ));
        num_params_r__ += (logical_eq(prior_dist_z,7) ? sum(num_normals_z) : z_dim );
        validate_non_negative_index("gamma_z", "has_intercept_z", has_intercept_z);
        num_params_r__ += has_intercept_z;
        validate_non_negative_index("global_z", "hs_z", hs_z);
        num_params_r__ += hs_z;
        validate_non_negative_index("local_z", "z_dim", z_dim);
        validate_non_negative_index("local_z", "hs_z", hs_z);
        num_params_r__ += z_dim * hs_z;
        validate_non_negative_index("S_z", "z_dim", z_dim);
        validate_non_negative_index("S_z", "(primitive_value(logical_eq(prior_dist_z,5)) || primitive_value(logical_eq(prior_dist_z,6)))", (primitive_value(logical_eq(prior_dist_z,5)) || primitive_value(logical_eq(prior_dist_z,6))));
        num_params_r__ += z_dim * (primitive_value(logical_eq(prior_dist_z,5)) || primitive_value(logical_eq(prior_dist_z,6)));
        validate_non_negative_index("one_over_lambda_z", "logical_eq(prior_dist_z,6)", logical_eq(prior_dist_z,6));
        num_params_r__ += logical_eq(prior_dist_z,6);
    }

    ~model_continuous() { }


    void transform_inits(const stan::io::var_context& context__,
                         std::vector<int>& params_i__,
                         std::vector<double>& params_r__,
                         std::ostream* pstream__) const {
        stan::io::writer<double> writer__(params_r__,params_i__);
        size_t pos__;
        (void) pos__; // dummy call to supress warning
        std::vector<double> vals_r__;
        std::vector<int> vals_i__;

        if (!(context__.contains_r("gamma")))
            throw std::runtime_error("variable gamma missing");
        vals_r__ = context__.vals_r("gamma");
        pos__ = 0U;
        validate_non_negative_index("gamma", "has_intercept", has_intercept);
        context__.validate_dims("initialization", "gamma", "double", context__.to_vec(has_intercept));
        // generate_declaration gamma
        std::vector<double> gamma(has_intercept,double(0));
        for (int i0__ = 0U; i0__ < has_intercept; ++i0__)
            gamma[i0__] = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < has_intercept; ++i0__)
            try {
            writer__.scalar_lub_unconstrain(make_lower(family,link, pstream__),make_upper(family,link, pstream__),gamma[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable gamma: ") + e.what());
        }

        if (!(context__.contains_r("z_beta")))
            throw std::runtime_error("variable z_beta missing");
        vals_r__ = context__.vals_r("z_beta");
        pos__ = 0U;
        validate_non_negative_index("z_beta", "(logical_eq(prior_dist,7) ? sum(num_normals) : K )", (logical_eq(prior_dist,7) ? sum(num_normals) : K ));
        context__.validate_dims("initialization", "z_beta", "vector_d", context__.to_vec((logical_eq(prior_dist,7) ? sum(num_normals) : K )));
        // generate_declaration z_beta
        vector_d z_beta(static_cast<Eigen::VectorXd::Index>((logical_eq(prior_dist,7) ? sum(num_normals) : K )));
        for (int j1__ = 0U; j1__ < (logical_eq(prior_dist,7) ? sum(num_normals) : K ); ++j1__)
            z_beta(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_unconstrain(z_beta);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable z_beta: ") + e.what());
        }

        if (!(context__.contains_r("z_beta_smooth")))
            throw std::runtime_error("variable z_beta_smooth missing");
        vals_r__ = context__.vals_r("z_beta_smooth");
        pos__ = 0U;
        validate_non_negative_index("z_beta_smooth", "K_smooth", K_smooth);
        context__.validate_dims("initialization", "z_beta_smooth", "vector_d", context__.to_vec(K_smooth));
        // generate_declaration z_beta_smooth
        vector_d z_beta_smooth(static_cast<Eigen::VectorXd::Index>(K_smooth));
        for (int j1__ = 0U; j1__ < K_smooth; ++j1__)
            z_beta_smooth(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_unconstrain(z_beta_smooth);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable z_beta_smooth: ") + e.what());
        }

        if (!(context__.contains_r("smooth_sd_raw")))
            throw std::runtime_error("variable smooth_sd_raw missing");
        vals_r__ = context__.vals_r("smooth_sd_raw");
        pos__ = 0U;
        validate_non_negative_index("smooth_sd_raw", "(logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,\"smooth_map\",1) : 0 )", (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));
        context__.validate_dims("initialization", "smooth_sd_raw", "vector_d", context__.to_vec((logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 )));
        // generate_declaration smooth_sd_raw
        vector_d smooth_sd_raw(static_cast<Eigen::VectorXd::Index>((logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 )));
        for (int j1__ = 0U; j1__ < (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++j1__)
            smooth_sd_raw(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_lb_unconstrain(0,smooth_sd_raw);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable smooth_sd_raw: ") + e.what());
        }

        if (!(context__.contains_r("global")))
            throw std::runtime_error("variable global missing");
        vals_r__ = context__.vals_r("global");
        pos__ = 0U;
        validate_non_negative_index("global", "hs", hs);
        context__.validate_dims("initialization", "global", "double", context__.to_vec(hs));
        // generate_declaration global
        std::vector<double> global(hs,double(0));
        for (int i0__ = 0U; i0__ < hs; ++i0__)
            global[i0__] = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < hs; ++i0__)
            try {
            writer__.scalar_lb_unconstrain(0,global[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable global: ") + e.what());
        }

        if (!(context__.contains_r("local")))
            throw std::runtime_error("variable local missing");
        vals_r__ = context__.vals_r("local");
        pos__ = 0U;
        validate_non_negative_index("local", "hs", hs);
        validate_non_negative_index("local", "K", K);
        context__.validate_dims("initialization", "local", "vector_d", context__.to_vec(hs,K));
        // generate_declaration local
        std::vector<vector_d> local(hs,vector_d(static_cast<Eigen::VectorXd::Index>(K)));
        for (int j1__ = 0U; j1__ < K; ++j1__)
            for (int i0__ = 0U; i0__ < hs; ++i0__)
                local[i0__](j1__) = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < hs; ++i0__)
            try {
            writer__.vector_lb_unconstrain(0,local[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable local: ") + e.what());
        }

        if (!(context__.contains_r("mix")))
            throw std::runtime_error("variable mix missing");
        vals_r__ = context__.vals_r("mix");
        pos__ = 0U;
        validate_non_negative_index("mix", "(primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6)))", (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))));
        validate_non_negative_index("mix", "K", K);
        context__.validate_dims("initialization", "mix", "vector_d", context__.to_vec((primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))),K));
        // generate_declaration mix
        std::vector<vector_d> mix((primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))),vector_d(static_cast<Eigen::VectorXd::Index>(K)));
        for (int j1__ = 0U; j1__ < K; ++j1__)
            for (int i0__ = 0U; i0__ < (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))); ++i0__)
                mix[i0__](j1__) = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))); ++i0__)
            try {
            writer__.vector_lb_unconstrain(0,mix[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable mix: ") + e.what());
        }

        if (!(context__.contains_r("one_over_lambda")))
            throw std::runtime_error("variable one_over_lambda missing");
        vals_r__ = context__.vals_r("one_over_lambda");
        pos__ = 0U;
        validate_non_negative_index("one_over_lambda", "logical_eq(prior_dist,6)", logical_eq(prior_dist,6));
        context__.validate_dims("initialization", "one_over_lambda", "double", context__.to_vec(logical_eq(prior_dist,6)));
        // generate_declaration one_over_lambda
        std::vector<double> one_over_lambda(logical_eq(prior_dist,6),double(0));
        for (int i0__ = 0U; i0__ < logical_eq(prior_dist,6); ++i0__)
            one_over_lambda[i0__] = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < logical_eq(prior_dist,6); ++i0__)
            try {
            writer__.scalar_lb_unconstrain(0,one_over_lambda[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable one_over_lambda: ") + e.what());
        }

        if (!(context__.contains_r("z_b")))
            throw std::runtime_error("variable z_b missing");
        vals_r__ = context__.vals_r("z_b");
        pos__ = 0U;
        validate_non_negative_index("z_b", "q", q);
        context__.validate_dims("initialization", "z_b", "vector_d", context__.to_vec(q));
        // generate_declaration z_b
        vector_d z_b(static_cast<Eigen::VectorXd::Index>(q));
        for (int j1__ = 0U; j1__ < q; ++j1__)
            z_b(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_unconstrain(z_b);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable z_b: ") + e.what());
        }

        if (!(context__.contains_r("z_T")))
            throw std::runtime_error("variable z_T missing");
        vals_r__ = context__.vals_r("z_T");
        pos__ = 0U;
        validate_non_negative_index("z_T", "len_z_T", len_z_T);
        context__.validate_dims("initialization", "z_T", "vector_d", context__.to_vec(len_z_T));
        // generate_declaration z_T
        vector_d z_T(static_cast<Eigen::VectorXd::Index>(len_z_T));
        for (int j1__ = 0U; j1__ < len_z_T; ++j1__)
            z_T(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_unconstrain(z_T);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable z_T: ") + e.what());
        }

        if (!(context__.contains_r("rho")))
            throw std::runtime_error("variable rho missing");
        vals_r__ = context__.vals_r("rho");
        pos__ = 0U;
        validate_non_negative_index("rho", "len_rho", len_rho);
        context__.validate_dims("initialization", "rho", "vector_d", context__.to_vec(len_rho));
        // generate_declaration rho
        vector_d rho(static_cast<Eigen::VectorXd::Index>(len_rho));
        for (int j1__ = 0U; j1__ < len_rho; ++j1__)
            rho(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_lub_unconstrain(0,1,rho);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable rho: ") + e.what());
        }

        if (!(context__.contains_r("zeta")))
            throw std::runtime_error("variable zeta missing");
        vals_r__ = context__.vals_r("zeta");
        pos__ = 0U;
        validate_non_negative_index("zeta", "len_concentration", len_concentration);
        context__.validate_dims("initialization", "zeta", "vector_d", context__.to_vec(len_concentration));
        // generate_declaration zeta
        vector_d zeta(static_cast<Eigen::VectorXd::Index>(len_concentration));
        for (int j1__ = 0U; j1__ < len_concentration; ++j1__)
            zeta(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_lb_unconstrain(0,zeta);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable zeta: ") + e.what());
        }

        if (!(context__.contains_r("tau")))
            throw std::runtime_error("variable tau missing");
        vals_r__ = context__.vals_r("tau");
        pos__ = 0U;
        validate_non_negative_index("tau", "t", t);
        context__.validate_dims("initialization", "tau", "vector_d", context__.to_vec(t));
        // generate_declaration tau
        vector_d tau(static_cast<Eigen::VectorXd::Index>(t));
        for (int j1__ = 0U; j1__ < t; ++j1__)
            tau(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_lb_unconstrain(0,tau);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable tau: ") + e.what());
        }

        if (!(context__.contains_r("aux_unscaled")))
            throw std::runtime_error("variable aux_unscaled missing");
        vals_r__ = context__.vals_r("aux_unscaled");
        pos__ = 0U;
        context__.validate_dims("initialization", "aux_unscaled", "double", context__.to_vec());
        // generate_declaration aux_unscaled
        double aux_unscaled(0);
        aux_unscaled = vals_r__[pos__++];
        try {
            writer__.scalar_lb_unconstrain(0,aux_unscaled);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable aux_unscaled: ") + e.what());
        }

        if (!(context__.contains_r("z_omega")))
            throw std::runtime_error("variable z_omega missing");
        vals_r__ = context__.vals_r("z_omega");
        pos__ = 0U;
        validate_non_negative_index("z_omega", "(logical_eq(prior_dist_z,7) ? sum(num_normals_z) : z_dim )", (logical_eq(prior_dist_z,7) ? sum(num_normals_z) : z_dim ));
        context__.validate_dims("initialization", "z_omega", "vector_d", context__.to_vec((logical_eq(prior_dist_z,7) ? sum(num_normals_z) : z_dim )));
        // generate_declaration z_omega
        vector_d z_omega(static_cast<Eigen::VectorXd::Index>((logical_eq(prior_dist_z,7) ? sum(num_normals_z) : z_dim )));
        for (int j1__ = 0U; j1__ < (logical_eq(prior_dist_z,7) ? sum(num_normals_z) : z_dim ); ++j1__)
            z_omega(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_unconstrain(z_omega);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable z_omega: ") + e.what());
        }

        if (!(context__.contains_r("gamma_z")))
            throw std::runtime_error("variable gamma_z missing");
        vals_r__ = context__.vals_r("gamma_z");
        pos__ = 0U;
        validate_non_negative_index("gamma_z", "has_intercept_z", has_intercept_z);
        context__.validate_dims("initialization", "gamma_z", "double", context__.to_vec(has_intercept_z));
        // generate_declaration gamma_z
        std::vector<double> gamma_z(has_intercept_z,double(0));
        for (int i0__ = 0U; i0__ < has_intercept_z; ++i0__)
            gamma_z[i0__] = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < has_intercept_z; ++i0__)
            try {
            writer__.scalar_lb_unconstrain((logical_lte(link_phi,1) ? stan::math::promote_scalar<double>(stan::math::negative_infinity()) : stan::math::promote_scalar<double>(0) ),gamma_z[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable gamma_z: ") + e.what());
        }

        if (!(context__.contains_r("global_z")))
            throw std::runtime_error("variable global_z missing");
        vals_r__ = context__.vals_r("global_z");
        pos__ = 0U;
        validate_non_negative_index("global_z", "hs_z", hs_z);
        context__.validate_dims("initialization", "global_z", "double", context__.to_vec(hs_z));
        // generate_declaration global_z
        std::vector<double> global_z(hs_z,double(0));
        for (int i0__ = 0U; i0__ < hs_z; ++i0__)
            global_z[i0__] = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < hs_z; ++i0__)
            try {
            writer__.scalar_lb_unconstrain(0,global_z[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable global_z: ") + e.what());
        }

        if (!(context__.contains_r("local_z")))
            throw std::runtime_error("variable local_z missing");
        vals_r__ = context__.vals_r("local_z");
        pos__ = 0U;
        validate_non_negative_index("local_z", "hs_z", hs_z);
        validate_non_negative_index("local_z", "z_dim", z_dim);
        context__.validate_dims("initialization", "local_z", "vector_d", context__.to_vec(hs_z,z_dim));
        // generate_declaration local_z
        std::vector<vector_d> local_z(hs_z,vector_d(static_cast<Eigen::VectorXd::Index>(z_dim)));
        for (int j1__ = 0U; j1__ < z_dim; ++j1__)
            for (int i0__ = 0U; i0__ < hs_z; ++i0__)
                local_z[i0__](j1__) = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < hs_z; ++i0__)
            try {
            writer__.vector_lb_unconstrain(0,local_z[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable local_z: ") + e.what());
        }

        if (!(context__.contains_r("S_z")))
            throw std::runtime_error("variable S_z missing");
        vals_r__ = context__.vals_r("S_z");
        pos__ = 0U;
        validate_non_negative_index("S_z", "(primitive_value(logical_eq(prior_dist_z,5)) || primitive_value(logical_eq(prior_dist_z,6)))", (primitive_value(logical_eq(prior_dist_z,5)) || primitive_value(logical_eq(prior_dist_z,6))));
        validate_non_negative_index("S_z", "z_dim", z_dim);
        context__.validate_dims("initialization", "S_z", "vector_d", context__.to_vec((primitive_value(logical_eq(prior_dist_z,5)) || primitive_value(logical_eq(prior_dist_z,6))),z_dim));
        // generate_declaration S_z
        std::vector<vector_d> S_z((primitive_value(logical_eq(prior_dist_z,5)) || primitive_value(logical_eq(prior_dist_z,6))),vector_d(static_cast<Eigen::VectorXd::Index>(z_dim)));
        for (int j1__ = 0U; j1__ < z_dim; ++j1__)
            for (int i0__ = 0U; i0__ < (primitive_value(logical_eq(prior_dist_z,5)) || primitive_value(logical_eq(prior_dist_z,6))); ++i0__)
                S_z[i0__](j1__) = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < (primitive_value(logical_eq(prior_dist_z,5)) || primitive_value(logical_eq(prior_dist_z,6))); ++i0__)
            try {
            writer__.vector_lb_unconstrain(0,S_z[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable S_z: ") + e.what());
        }

        if (!(context__.contains_r("one_over_lambda_z")))
            throw std::runtime_error("variable one_over_lambda_z missing");
        vals_r__ = context__.vals_r("one_over_lambda_z");
        pos__ = 0U;
        validate_non_negative_index("one_over_lambda_z", "logical_eq(prior_dist_z,6)", logical_eq(prior_dist_z,6));
        context__.validate_dims("initialization", "one_over_lambda_z", "double", context__.to_vec(logical_eq(prior_dist_z,6)));
        // generate_declaration one_over_lambda_z
        std::vector<double> one_over_lambda_z(logical_eq(prior_dist_z,6),double(0));
        for (int i0__ = 0U; i0__ < logical_eq(prior_dist_z,6); ++i0__)
            one_over_lambda_z[i0__] = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < logical_eq(prior_dist_z,6); ++i0__)
            try {
            writer__.scalar_lb_unconstrain(0,one_over_lambda_z[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable one_over_lambda_z: ") + e.what());
        }

        params_r__ = writer__.data_r();
        params_i__ = writer__.data_i();
    }

    void transform_inits(const stan::io::var_context& context,
                         Eigen::Matrix<double,Eigen::Dynamic,1>& params_r,
                         std::ostream* pstream__) const {
      std::vector<double> params_r_vec;
      std::vector<int> params_i_vec;
      transform_inits(context, params_i_vec, params_r_vec, pstream__);
      params_r.resize(params_r_vec.size());
      for (int i = 0; i < params_r.size(); ++i)
        params_r(i) = params_r_vec[i];
    }


    template <bool propto__, bool jacobian__, typename T__>
    T__ log_prob(vector<T__>& params_r__,
                 vector<int>& params_i__,
                 std::ostream* pstream__ = 0) const {

        T__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

        T__ lp__(0.0);
        stan::math::accumulator<T__> lp_accum__;

        // model parameters
        stan::io::reader<T__> in__(params_r__,params_i__);

        vector<T__> gamma;
        size_t dim_gamma_0__ = has_intercept;
        gamma.reserve(dim_gamma_0__);
        for (size_t k_0__ = 0; k_0__ < dim_gamma_0__; ++k_0__) {
            if (jacobian__)
                gamma.push_back(in__.scalar_lub_constrain(make_lower(family,link, pstream__),make_upper(family,link, pstream__),lp__));
            else
                gamma.push_back(in__.scalar_lub_constrain(make_lower(family,link, pstream__),make_upper(family,link, pstream__)));
        }

        Eigen::Matrix<T__,Eigen::Dynamic,1>  z_beta;
        (void) z_beta;  // dummy to suppress unused var warning
        if (jacobian__)
            z_beta = in__.vector_constrain((logical_eq(prior_dist,7) ? sum(num_normals) : K ),lp__);
        else
            z_beta = in__.vector_constrain((logical_eq(prior_dist,7) ? sum(num_normals) : K ));

        Eigen::Matrix<T__,Eigen::Dynamic,1>  z_beta_smooth;
        (void) z_beta_smooth;  // dummy to suppress unused var warning
        if (jacobian__)
            z_beta_smooth = in__.vector_constrain(K_smooth,lp__);
        else
            z_beta_smooth = in__.vector_constrain(K_smooth);

        Eigen::Matrix<T__,Eigen::Dynamic,1>  smooth_sd_raw;
        (void) smooth_sd_raw;  // dummy to suppress unused var warning
        if (jacobian__)
            smooth_sd_raw = in__.vector_lb_constrain(0,(logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ),lp__);
        else
            smooth_sd_raw = in__.vector_lb_constrain(0,(logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));

        vector<T__> global;
        size_t dim_global_0__ = hs;
        global.reserve(dim_global_0__);
        for (size_t k_0__ = 0; k_0__ < dim_global_0__; ++k_0__) {
            if (jacobian__)
                global.push_back(in__.scalar_lb_constrain(0,lp__));
            else
                global.push_back(in__.scalar_lb_constrain(0));
        }

        vector<Eigen::Matrix<T__,Eigen::Dynamic,1> > local;
        size_t dim_local_0__ = hs;
        local.reserve(dim_local_0__);
        for (size_t k_0__ = 0; k_0__ < dim_local_0__; ++k_0__) {
            if (jacobian__)
                local.push_back(in__.vector_lb_constrain(0,K,lp__));
            else
                local.push_back(in__.vector_lb_constrain(0,K));
        }

        vector<Eigen::Matrix<T__,Eigen::Dynamic,1> > mix;
        size_t dim_mix_0__ = (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6)));
        mix.reserve(dim_mix_0__);
        for (size_t k_0__ = 0; k_0__ < dim_mix_0__; ++k_0__) {
            if (jacobian__)
                mix.push_back(in__.vector_lb_constrain(0,K,lp__));
            else
                mix.push_back(in__.vector_lb_constrain(0,K));
        }

        vector<T__> one_over_lambda;
        size_t dim_one_over_lambda_0__ = logical_eq(prior_dist,6);
        one_over_lambda.reserve(dim_one_over_lambda_0__);
        for (size_t k_0__ = 0; k_0__ < dim_one_over_lambda_0__; ++k_0__) {
            if (jacobian__)
                one_over_lambda.push_back(in__.scalar_lb_constrain(0,lp__));
            else
                one_over_lambda.push_back(in__.scalar_lb_constrain(0));
        }

        Eigen::Matrix<T__,Eigen::Dynamic,1>  z_b;
        (void) z_b;  // dummy to suppress unused var warning
        if (jacobian__)
            z_b = in__.vector_constrain(q,lp__);
        else
            z_b = in__.vector_constrain(q);

        Eigen::Matrix<T__,Eigen::Dynamic,1>  z_T;
        (void) z_T;  // dummy to suppress unused var warning
        if (jacobian__)
            z_T = in__.vector_constrain(len_z_T,lp__);
        else
            z_T = in__.vector_constrain(len_z_T);

        Eigen::Matrix<T__,Eigen::Dynamic,1>  rho;
        (void) rho;  // dummy to suppress unused var warning
        if (jacobian__)
            rho = in__.vector_lub_constrain(0,1,len_rho,lp__);
        else
            rho = in__.vector_lub_constrain(0,1,len_rho);

        Eigen::Matrix<T__,Eigen::Dynamic,1>  zeta;
        (void) zeta;  // dummy to suppress unused var warning
        if (jacobian__)
            zeta = in__.vector_lb_constrain(0,len_concentration,lp__);
        else
            zeta = in__.vector_lb_constrain(0,len_concentration);

        Eigen::Matrix<T__,Eigen::Dynamic,1>  tau;
        (void) tau;  // dummy to suppress unused var warning
        if (jacobian__)
            tau = in__.vector_lb_constrain(0,t,lp__);
        else
            tau = in__.vector_lb_constrain(0,t);

        T__ aux_unscaled;
        (void) aux_unscaled;  // dummy to suppress unused var warning
        if (jacobian__)
            aux_unscaled = in__.scalar_lb_constrain(0,lp__);
        else
            aux_unscaled = in__.scalar_lb_constrain(0);

        Eigen::Matrix<T__,Eigen::Dynamic,1>  z_omega;
        (void) z_omega;  // dummy to suppress unused var warning
        if (jacobian__)
            z_omega = in__.vector_constrain((logical_eq(prior_dist_z,7) ? sum(num_normals_z) : z_dim ),lp__);
        else
            z_omega = in__.vector_constrain((logical_eq(prior_dist_z,7) ? sum(num_normals_z) : z_dim ));

        vector<T__> gamma_z;
        size_t dim_gamma_z_0__ = has_intercept_z;
        gamma_z.reserve(dim_gamma_z_0__);
        for (size_t k_0__ = 0; k_0__ < dim_gamma_z_0__; ++k_0__) {
            if (jacobian__)
                gamma_z.push_back(in__.scalar_lb_constrain((logical_lte(link_phi,1) ? stan::math::promote_scalar<double>(stan::math::negative_infinity()) : stan::math::promote_scalar<double>(0) ),lp__));
            else
                gamma_z.push_back(in__.scalar_lb_constrain((logical_lte(link_phi,1) ? stan::math::promote_scalar<double>(stan::math::negative_infinity()) : stan::math::promote_scalar<double>(0) )));
        }

        vector<T__> global_z;
        size_t dim_global_z_0__ = hs_z;
        global_z.reserve(dim_global_z_0__);
        for (size_t k_0__ = 0; k_0__ < dim_global_z_0__; ++k_0__) {
            if (jacobian__)
                global_z.push_back(in__.scalar_lb_constrain(0,lp__));
            else
                global_z.push_back(in__.scalar_lb_constrain(0));
        }

        vector<Eigen::Matrix<T__,Eigen::Dynamic,1> > local_z;
        size_t dim_local_z_0__ = hs_z;
        local_z.reserve(dim_local_z_0__);
        for (size_t k_0__ = 0; k_0__ < dim_local_z_0__; ++k_0__) {
            if (jacobian__)
                local_z.push_back(in__.vector_lb_constrain(0,z_dim,lp__));
            else
                local_z.push_back(in__.vector_lb_constrain(0,z_dim));
        }

        vector<Eigen::Matrix<T__,Eigen::Dynamic,1> > S_z;
        size_t dim_S_z_0__ = (primitive_value(logical_eq(prior_dist_z,5)) || primitive_value(logical_eq(prior_dist_z,6)));
        S_z.reserve(dim_S_z_0__);
        for (size_t k_0__ = 0; k_0__ < dim_S_z_0__; ++k_0__) {
            if (jacobian__)
                S_z.push_back(in__.vector_lb_constrain(0,z_dim,lp__));
            else
                S_z.push_back(in__.vector_lb_constrain(0,z_dim));
        }

        vector<T__> one_over_lambda_z;
        size_t dim_one_over_lambda_z_0__ = logical_eq(prior_dist_z,6);
        one_over_lambda_z.reserve(dim_one_over_lambda_z_0__);
        for (size_t k_0__ = 0; k_0__ < dim_one_over_lambda_z_0__; ++k_0__) {
            if (jacobian__)
                one_over_lambda_z.push_back(in__.scalar_lb_constrain(0,lp__));
            else
                one_over_lambda_z.push_back(in__.scalar_lb_constrain(0));
        }


        // transformed parameters
        T__ aux;
        (void) aux;  // dummy to suppress unused var warning

        stan::math::initialize(aux, DUMMY_VAR__);
        stan::math::fill(aux,DUMMY_VAR__);
        stan::math::assign(aux,(logical_eq(prior_dist_for_aux,0) ? stan::math::promote_scalar<T__>(aux_unscaled) : stan::math::promote_scalar<T__>((logical_lte(prior_dist_for_aux,2) ? stan::math::promote_scalar<T__>(((prior_scale_for_aux * aux_unscaled) + prior_mean_for_aux)) : stan::math::promote_scalar<T__>((prior_scale_for_aux * aux_unscaled)) )) ));
        validate_non_negative_index("omega", "z_dim", z_dim);
        Eigen::Matrix<T__,Eigen::Dynamic,1>  omega(static_cast<Eigen::VectorXd::Index>(z_dim));
        (void) omega;  // dummy to suppress unused var warning

        stan::math::initialize(omega, DUMMY_VAR__);
        stan::math::fill(omega,DUMMY_VAR__);
        validate_non_negative_index("beta", "K", K);
        Eigen::Matrix<T__,Eigen::Dynamic,1>  beta(static_cast<Eigen::VectorXd::Index>(K));
        (void) beta;  // dummy to suppress unused var warning

        stan::math::initialize(beta, DUMMY_VAR__);
        stan::math::fill(beta,DUMMY_VAR__);
        validate_non_negative_index("beta_smooth", "K_smooth", K_smooth);
        Eigen::Matrix<T__,Eigen::Dynamic,1>  beta_smooth(static_cast<Eigen::VectorXd::Index>(K_smooth));
        (void) beta_smooth;  // dummy to suppress unused var warning

        stan::math::initialize(beta_smooth, DUMMY_VAR__);
        stan::math::fill(beta_smooth,DUMMY_VAR__);
        validate_non_negative_index("smooth_sd", "(logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,\"smooth_map\",1) : 0 )", (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));
        Eigen::Matrix<T__,Eigen::Dynamic,1>  smooth_sd(static_cast<Eigen::VectorXd::Index>((logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 )));
        (void) smooth_sd;  // dummy to suppress unused var warning

        stan::math::initialize(smooth_sd, DUMMY_VAR__);
        stan::math::fill(smooth_sd,DUMMY_VAR__);
        validate_non_negative_index("b", "q", q);
        Eigen::Matrix<T__,Eigen::Dynamic,1>  b(static_cast<Eigen::VectorXd::Index>(q));
        (void) b;  // dummy to suppress unused var warning

        stan::math::initialize(b, DUMMY_VAR__);
        stan::math::fill(b,DUMMY_VAR__);
        validate_non_negative_index("theta_L", "len_theta_L", len_theta_L);
        Eigen::Matrix<T__,Eigen::Dynamic,1>  theta_L(static_cast<Eigen::VectorXd::Index>(len_theta_L));
        (void) theta_L;  // dummy to suppress unused var warning

        stan::math::initialize(theta_L, DUMMY_VAR__);
        stan::math::fill(theta_L,DUMMY_VAR__);


        try {
            current_statement_begin__ = 908;
            if (as_bool(logical_eq(prior_dist,0))) {
                current_statement_begin__ = 908;
                stan::math::assign(beta, z_beta);
            } else if (as_bool(logical_eq(prior_dist,1))) {
                current_statement_begin__ = 909;
                stan::math::assign(beta, add(elt_multiply(z_beta,prior_scale),prior_mean));
            } else if (as_bool(logical_eq(prior_dist,2))) {
                current_statement_begin__ = 910;
                for (int k = 1; k <= K; ++k) {

                    current_statement_begin__ = 911;
                    stan::math::assign(get_base1_lhs(beta,k,"beta",1), ((CFt(get_base1(z_beta,k,"z_beta",1),get_base1(prior_df,k,"prior_df",1), pstream__) * get_base1(prior_scale,k,"prior_scale",1)) + get_base1(prior_mean,k,"prior_mean",1)));
                }
            } else if (as_bool(logical_eq(prior_dist,3))) {

                current_statement_begin__ = 914;
                if (as_bool((primitive_value(logical_eq(is_continuous,1)) && primitive_value(logical_eq(family,1))))) {
                    current_statement_begin__ = 915;
                    stan::math::assign(beta, hs_prior(z_beta,global,local,global_prior_scale,aux, pstream__));
                } else {
                    current_statement_begin__ = 916;
                    stan::math::assign(beta, hs_prior(z_beta,global,local,global_prior_scale,1, pstream__));
                }
            } else if (as_bool(logical_eq(prior_dist,4))) {

                current_statement_begin__ = 919;
                if (as_bool((primitive_value(logical_eq(is_continuous,1)) && primitive_value(logical_eq(family,1))))) {
                    current_statement_begin__ = 920;
                    stan::math::assign(beta, hsplus_prior(z_beta,global,local,global_prior_scale,aux, pstream__));
                } else {
                    current_statement_begin__ = 921;
                    stan::math::assign(beta, hsplus_prior(z_beta,global,local,global_prior_scale,1, pstream__));
                }
            } else if (as_bool(logical_eq(prior_dist,5))) {
                current_statement_begin__ = 924;
                stan::math::assign(beta, add(prior_mean,elt_multiply(elt_multiply(prior_scale,sqrt(multiply(2,get_base1(mix,1,"mix",1)))),z_beta)));
            } else if (as_bool(logical_eq(prior_dist,6))) {
                current_statement_begin__ = 926;
                stan::math::assign(beta, add(prior_mean,elt_multiply(elt_multiply(multiply(get_base1(one_over_lambda,1,"one_over_lambda",1),prior_scale),sqrt(multiply(2,get_base1(mix,1,"mix",1)))),z_beta)));
            } else if (as_bool(logical_eq(prior_dist,7))) {
                {
                    int z_pos(0);
                    (void) z_pos;  // dummy to suppress unused var warning

                    stan::math::fill(z_pos, std::numeric_limits<int>::min());
                    stan::math::assign(z_pos,1);


                    current_statement_begin__ = 929;
                    for (int k = 1; k <= K; ++k) {

                        current_statement_begin__ = 930;
                        stan::math::assign(get_base1_lhs(beta,k,"beta",1), get_base1(z_beta,z_pos,"z_beta",1));
                        current_statement_begin__ = 931;
                        stan::math::assign(z_pos, (z_pos + 1));
                        current_statement_begin__ = 932;
                        for (int n = 2; n <= get_base1(num_normals,k,"num_normals",1); ++n) {

                            current_statement_begin__ = 933;
                            stan::math::assign(get_base1_lhs(beta,k,"beta",1), (get_base1(beta,k,"beta",1) * get_base1(z_beta,z_pos,"z_beta",1)));
                            current_statement_begin__ = 934;
                            stan::math::assign(z_pos, (z_pos + 1));
                        }
                        current_statement_begin__ = 936;
                        stan::math::assign(get_base1_lhs(beta,k,"beta",1), ((get_base1(beta,k,"beta",1) * pow(get_base1(prior_scale,k,"prior_scale",1),get_base1(num_normals,k,"num_normals",1))) + get_base1(prior_mean,k,"prior_mean",1)));
                    }
                }
            }
            current_statement_begin__ = 940;
            if (as_bool(K_smooth)) {

                current_statement_begin__ = 941;
                stan::math::assign(smooth_sd, add(prior_mean_for_smooth,elt_multiply(prior_scale_for_smooth,smooth_sd_raw)));
                current_statement_begin__ = 942;
                if (as_bool((primitive_value(is_continuous) && primitive_value(logical_eq(family,1))))) {
                    current_statement_begin__ = 942;
                    stan::math::assign(smooth_sd, multiply(smooth_sd,aux));
                }
                current_statement_begin__ = 943;
                stan::math::assign(beta_smooth, elt_multiply(z_beta_smooth,stan::model::rvalue(smooth_sd, stan::model::cons_list(stan::model::index_multi(smooth_map), stan::model::nil_index_list()), "smooth_sd")));
            }
            current_statement_begin__ = 946;
            if (as_bool(logical_eq(prior_dist_z,0))) {
                current_statement_begin__ = 946;
                stan::math::assign(omega, z_omega);
            } else if (as_bool(logical_eq(prior_dist_z,1))) {
                current_statement_begin__ = 947;
                stan::math::assign(omega, add(elt_multiply(z_omega,prior_scale_z),prior_mean_z));
            } else if (as_bool(logical_eq(prior_dist_z,2))) {
                current_statement_begin__ = 948;
                for (int k = 1; k <= z_dim; ++k) {

                    current_statement_begin__ = 949;
                    stan::math::assign(get_base1_lhs(omega,k,"omega",1), ((CFt(get_base1(omega,k,"omega",1),get_base1(prior_df_z,k,"prior_df_z",1), pstream__) * get_base1(prior_scale_z,k,"prior_scale_z",1)) + get_base1(prior_mean_z,k,"prior_mean_z",1)));
                }
            } else if (as_bool(logical_eq(prior_dist_z,3))) {
                current_statement_begin__ = 952;
                stan::math::assign(omega, hs_prior(z_omega,global_z,local_z,global_prior_scale,1, pstream__));
            } else if (as_bool(logical_eq(prior_dist_z,4))) {
                current_statement_begin__ = 954;
                stan::math::assign(omega, hsplus_prior(z_omega,global_z,local_z,global_prior_scale,1, pstream__));
            } else if (as_bool(logical_eq(prior_dist_z,5))) {
                current_statement_begin__ = 956;
                stan::math::assign(omega, add(prior_mean_z,elt_multiply(elt_multiply(prior_scale_z,sqrt(multiply(2,get_base1(S_z,1,"S_z",1)))),z_omega)));
            } else if (as_bool(logical_eq(prior_dist_z,6))) {
                current_statement_begin__ = 958;
                stan::math::assign(omega, add(prior_mean_z,elt_multiply(elt_multiply(multiply(get_base1(one_over_lambda_z,1,"one_over_lambda_z",1),prior_scale_z),sqrt(multiply(2,get_base1(S_z,1,"S_z",1)))),z_omega)));
            } else if (as_bool(logical_eq(prior_dist_z,7))) {
                {
                    int z_pos(0);
                    (void) z_pos;  // dummy to suppress unused var warning

                    stan::math::fill(z_pos, std::numeric_limits<int>::min());
                    stan::math::assign(z_pos,1);


                    current_statement_begin__ = 961;
                    for (int k = 1; k <= z_dim; ++k) {

                        current_statement_begin__ = 962;
                        stan::math::assign(get_base1_lhs(omega,k,"omega",1), get_base1(z_omega,z_pos,"z_omega",1));
                        current_statement_begin__ = 963;
                        stan::math::assign(z_pos, (z_pos + 1));
                        current_statement_begin__ = 964;
                        for (int n = 2; n <= get_base1(num_normals_z,k,"num_normals_z",1); ++n) {

                            current_statement_begin__ = 965;
                            stan::math::assign(get_base1_lhs(omega,k,"omega",1), (get_base1(omega,k,"omega",1) * get_base1(z_omega,z_pos,"z_omega",1)));
                            current_statement_begin__ = 966;
                            stan::math::assign(z_pos, (z_pos + 1));
                        }
                        current_statement_begin__ = 968;
                        stan::math::assign(get_base1_lhs(omega,k,"omega",1), ((get_base1(omega,k,"omega",1) * pow(get_base1(prior_scale_z,k,"prior_scale_z",1),get_base1(num_normals_z,k,"num_normals_z",1))) + get_base1(prior_mean_z,k,"prior_mean_z",1)));
                    }
                }
            }
            current_statement_begin__ = 973;
            if (as_bool(logical_gt(t,0))) {

                current_statement_begin__ = 974;
                if (as_bool(logical_eq(special_case,1))) {
                    {
                        int start(0);
                        (void) start;  // dummy to suppress unused var warning

                        stan::math::fill(start, std::numeric_limits<int>::min());
                        stan::math::assign(start,1);


                        current_statement_begin__ = 976;
                        stan::math::assign(theta_L, multiply(elt_multiply(scale,tau),aux));
                        current_statement_begin__ = 977;
                        if (as_bool(logical_eq(t,1))) {
                            current_statement_begin__ = 977;
                            stan::math::assign(b, multiply(get_base1(theta_L,1,"theta_L",1),z_b));
                        } else {
                            current_statement_begin__ = 978;
                            for (int i = 1; i <= t; ++i) {
                                {
                                    int end(0);
                                    (void) end;  // dummy to suppress unused var warning

                                    stan::math::fill(end, std::numeric_limits<int>::min());
                                    stan::math::assign(end,((start + get_base1(l,i,"l",1)) - 1));


                                    current_statement_begin__ = 980;
                                    stan::model::assign(b, 
                                                stan::model::cons_list(stan::model::index_min_max(start, end), stan::model::nil_index_list()), 
                                                multiply(get_base1(theta_L,i,"theta_L",1),stan::model::rvalue(z_b, stan::model::cons_list(stan::model::index_min_max(start, end), stan::model::nil_index_list()), "z_b")), 
                                                "assigning variable b");
                                    current_statement_begin__ = 981;
                                    stan::math::assign(start, (end + 1));
                                }
                            }
                        }
                    }
                } else {

                    current_statement_begin__ = 985;
                    stan::math::assign(theta_L, make_theta_L(len_theta_L,p,aux,tau,scale,zeta,rho,z_T, pstream__));
                    current_statement_begin__ = 987;
                    stan::math::assign(b, make_b(z_b,theta_L,p,l, pstream__));
                }
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        // validate transformed parameters
        if (stan::math::is_uninitialized(aux)) {
            std::stringstream msg__;
            msg__ << "Undefined transformed parameter: aux";
            throw std::runtime_error(msg__.str());
        }
        for (int i0__ = 0; i0__ < z_dim; ++i0__) {
            if (stan::math::is_uninitialized(omega(i0__))) {
                std::stringstream msg__;
                msg__ << "Undefined transformed parameter: omega" << '[' << i0__ << ']';
                throw std::runtime_error(msg__.str());
            }
        }
        for (int i0__ = 0; i0__ < K; ++i0__) {
            if (stan::math::is_uninitialized(beta(i0__))) {
                std::stringstream msg__;
                msg__ << "Undefined transformed parameter: beta" << '[' << i0__ << ']';
                throw std::runtime_error(msg__.str());
            }
        }
        for (int i0__ = 0; i0__ < K_smooth; ++i0__) {
            if (stan::math::is_uninitialized(beta_smooth(i0__))) {
                std::stringstream msg__;
                msg__ << "Undefined transformed parameter: beta_smooth" << '[' << i0__ << ']';
                throw std::runtime_error(msg__.str());
            }
        }
        for (int i0__ = 0; i0__ < (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++i0__) {
            if (stan::math::is_uninitialized(smooth_sd(i0__))) {
                std::stringstream msg__;
                msg__ << "Undefined transformed parameter: smooth_sd" << '[' << i0__ << ']';
                throw std::runtime_error(msg__.str());
            }
        }
        for (int i0__ = 0; i0__ < q; ++i0__) {
            if (stan::math::is_uninitialized(b(i0__))) {
                std::stringstream msg__;
                msg__ << "Undefined transformed parameter: b" << '[' << i0__ << ']';
                throw std::runtime_error(msg__.str());
            }
        }
        for (int i0__ = 0; i0__ < len_theta_L; ++i0__) {
            if (stan::math::is_uninitialized(theta_L(i0__))) {
                std::stringstream msg__;
                msg__ << "Undefined transformed parameter: theta_L" << '[' << i0__ << ']';
                throw std::runtime_error(msg__.str());
            }
        }

        const char* function__ = "validate transformed params";
        (void) function__;  // dummy to suppress unused var warning

        // model body
        try {
            {
                validate_non_negative_index("eta_z", "N", N);
                Eigen::Matrix<T__,Eigen::Dynamic,1>  eta_z(static_cast<Eigen::VectorXd::Index>(N));
                (void) eta_z;  // dummy to suppress unused var warning

                stan::math::initialize(eta_z, DUMMY_VAR__);
                stan::math::fill(eta_z,DUMMY_VAR__);
                validate_non_negative_index("eta", "N", N);
                Eigen::Matrix<T__,Eigen::Dynamic,1>  eta(static_cast<Eigen::VectorXd::Index>(N));
                (void) eta;  // dummy to suppress unused var warning

                stan::math::initialize(eta, DUMMY_VAR__);
                stan::math::fill(eta,DUMMY_VAR__);


                current_statement_begin__ = 995;
                if (as_bool(logical_gt(K,0))) {

                    current_statement_begin__ = 996;
                    if (as_bool(dense_X)) {
                        current_statement_begin__ = 996;
                        stan::math::assign(eta, multiply(get_base1(X,1,"X",1),beta));
                    } else {
                        current_statement_begin__ = 997;
                        stan::math::assign(eta, csr_matrix_times_vector(N,K,w_X,v_X,u_X,beta));
                    }
                } else {
                    current_statement_begin__ = 999;
                    stan::math::assign(eta, rep_vector(0.0,N));
                }
                current_statement_begin__ = 1000;
                if (as_bool(logical_eq(has_offset,1))) {
                    current_statement_begin__ = 1000;
                    stan::math::assign(eta, add(eta,offset));
                }
                current_statement_begin__ = 1001;
                if (as_bool(K_smooth)) {
                    current_statement_begin__ = 1001;
                    stan::math::assign(eta, add(eta,multiply(S,beta_smooth)));
                }
                current_statement_begin__ = 1002;
                if (as_bool(logical_gt(t,0))) {

                    current_statement_begin__ = 1004;
                    if (as_bool(special_case)) {
                        current_statement_begin__ = 1004;
                        for (int i = 1; i <= t; ++i) {
                            current_statement_begin__ = 1004;
                            stan::math::assign(eta, add(eta,stan::model::rvalue(b, stan::model::cons_list(stan::model::index_multi(get_base1(V,i,"V",1)), stan::model::nil_index_list()), "b")));
                        }
                    } else {
                        current_statement_begin__ = 1005;
                        stan::math::assign(eta, add(eta,csr_matrix_times_vector(N,q,w,v,u,b)));
                    }
                }
                current_statement_begin__ = 1007;
                if (as_bool(logical_eq(has_intercept,1))) {

                    current_statement_begin__ = 1008;
                    if (as_bool((primitive_value((primitive_value(logical_eq(family,1)) || primitive_value(logical_eq(link,2)))) || primitive_value((primitive_value(logical_eq(family,4)) && primitive_value(logical_neq(link,5))))))) {
                        current_statement_begin__ = 1008;
                        stan::math::assign(eta, add(eta,get_base1(gamma,1,"gamma",1)));
                    } else if (as_bool((primitive_value(logical_eq(family,4)) && primitive_value(logical_eq(link,5))))) {
                        current_statement_begin__ = 1009;
                        stan::math::assign(eta, add(subtract(eta,max(eta)),get_base1(gamma,1,"gamma",1)));
                    } else {
                        current_statement_begin__ = 1010;
                        stan::math::assign(eta, add(subtract(eta,min(eta)),get_base1(gamma,1,"gamma",1)));
                    }
                } else {

                    current_statement_begin__ = 1015;
                    stan::math::assign(eta, add(eta,dot_product(xbar,beta)));
                }
                current_statement_begin__ = 1018;
                if (as_bool(logical_gt(SSfun,0))) {
                    {
                        validate_non_negative_index("P", "len_y", len_y);
                        validate_non_negative_index("P", "K", K);
                        Eigen::Matrix<T__,Eigen::Dynamic,Eigen::Dynamic>  P(static_cast<Eigen::VectorXd::Index>(len_y),static_cast<Eigen::VectorXd::Index>(K));
                        (void) P;  // dummy to suppress unused var warning

                        stan::math::initialize(P, DUMMY_VAR__);
                        stan::math::fill(P,DUMMY_VAR__);


                        current_statement_begin__ = 1020;
                        stan::math::assign(P, reshape_vec(eta,len_y,K, pstream__));
                        current_statement_begin__ = 1021;
                        if (as_bool(logical_lt(SSfun,5))) {

                            current_statement_begin__ = 1022;
                            if (as_bool(logical_lte(SSfun,2))) {

                                current_statement_begin__ = 1023;
                                if (as_bool(logical_eq(SSfun,1))) {
                                    current_statement_begin__ = 1023;
                                    lp_accum__.add(normal_log(y,SS_asymp(input,P, pstream__),aux));
                                } else {
                                    current_statement_begin__ = 1024;
                                    lp_accum__.add(normal_log(y,SS_asympOff(input,P, pstream__),aux));
                                }
                            } else if (as_bool(logical_eq(SSfun,3))) {
                                current_statement_begin__ = 1026;
                                lp_accum__.add(normal_log(y,SS_asympOrig(input,P, pstream__),aux));
                            } else {

                                current_statement_begin__ = 1028;
                                for (int i = 1; i <= len_y; ++i) {
                                    current_statement_begin__ = 1028;
                                    stan::math::assign(get_base1_lhs(P,i,1,"P",1), (get_base1(P,i,1,"P",1) + exp(get_base1(P,i,3,"P",1))));
                                }
                                current_statement_begin__ = 1029;
                                lp_accum__.add(normal_log(y,SS_biexp(input,P, pstream__),aux));
                            }
                        } else {

                            current_statement_begin__ = 1033;
                            if (as_bool(logical_lte(SSfun,7))) {

                                current_statement_begin__ = 1034;
                                if (as_bool(logical_eq(SSfun,5))) {
                                    current_statement_begin__ = 1034;
                                    lp_accum__.add(normal_log(y,SS_fol(Dose,input,P, pstream__),aux));
                                } else if (as_bool(logical_eq(SSfun,6))) {
                                    current_statement_begin__ = 1035;
                                    lp_accum__.add(normal_log(y,SS_fpl(input,P, pstream__),aux));
                                } else {
                                    current_statement_begin__ = 1036;
                                    lp_accum__.add(normal_log(y,SS_gompertz(input,P, pstream__),aux));
                                }
                            } else {

                                current_statement_begin__ = 1039;
                                if (as_bool(logical_eq(SSfun,8))) {
                                    current_statement_begin__ = 1039;
                                    lp_accum__.add(normal_log(y,SS_logis(input,P, pstream__),aux));
                                } else if (as_bool(logical_eq(SSfun,9))) {
                                    current_statement_begin__ = 1040;
                                    lp_accum__.add(normal_log(y,SS_micmen(input,P, pstream__),aux));
                                } else {
                                    current_statement_begin__ = 1041;
                                    lp_accum__.add(normal_log(y,SS_weibull(input,P, pstream__),aux));
                                }
                            }
                        }
                    }
                } else if (as_bool((primitive_value(logical_eq(has_weights,0)) && primitive_value(logical_eq(prior_PD,0))))) {

                    current_statement_begin__ = 1047;
                    if (as_bool((primitive_value((primitive_value(logical_eq(family,4)) && primitive_value(logical_gt(z_dim,0)))) && primitive_value(logical_gt(link_phi,0))))) {

                        current_statement_begin__ = 1048;
                        stan::math::assign(eta_z, multiply(betareg_z,omega));
                    } else if (as_bool((primitive_value((primitive_value(logical_eq(family,4)) && primitive_value(logical_eq(z_dim,0)))) && primitive_value(logical_eq(has_intercept_z,1))))) {

                        current_statement_begin__ = 1051;
                        stan::math::assign(eta_z, rep_vector(0.0,N));
                    }
                    current_statement_begin__ = 1054;
                    if (as_bool(logical_eq(has_intercept_z,1))) {

                        current_statement_begin__ = 1055;
                        if (as_bool(logical_gt(link_phi,1))) {

                            current_statement_begin__ = 1056;
                            stan::math::assign(eta_z, add(subtract(eta_z,min(eta_z)),get_base1(gamma_z,1,"gamma_z",1)));
                        } else {

                            current_statement_begin__ = 1059;
                            stan::math::assign(eta_z, add(eta_z,get_base1(gamma_z,1,"gamma_z",1)));
                        }
                    } else {

                        current_statement_begin__ = 1064;
                        if (as_bool(logical_gt(link_phi,1))) {

                            current_statement_begin__ = 1065;
                            stan::math::assign(eta_z, add(subtract(eta_z,min(eta_z)),dot_product(zbar,omega)));
                        } else {

                            current_statement_begin__ = 1068;
                            stan::math::assign(eta_z, add(eta_z,dot_product(zbar,omega)));
                        }
                    }
                    current_statement_begin__ = 1071;
                    if (as_bool(logical_eq(family,1))) {

                        current_statement_begin__ = 1072;
                        if (as_bool(logical_eq(link,1))) {
                            current_statement_begin__ = 1073;
                            lp_accum__.add(normal_log(y,eta,aux));
                        } else if (as_bool(logical_eq(link,2))) {
                            current_statement_begin__ = 1075;
                            lp_accum__.add(normal_log(y,exp(eta),aux));
                        } else {
                            current_statement_begin__ = 1077;
                            lp_accum__.add(normal_log(y,divide_real_by_vector(1,eta, pstream__),aux));
                        }
                    } else if (as_bool(logical_eq(family,2))) {

                        current_statement_begin__ = 1081;
                        lp_accum__.add(GammaReg(y,eta,aux,link,sum_log_y, pstream__));
                    } else if (as_bool(logical_eq(family,3))) {

                        current_statement_begin__ = 1084;
                        lp_accum__.add(inv_gaussian(y,linkinv_inv_gaussian(eta,link, pstream__),aux,sum_log_y,sqrt_y, pstream__));
                    } else if (as_bool((primitive_value(logical_eq(family,4)) && primitive_value(logical_eq(link_phi,0))))) {
                        {
                            validate_non_negative_index("mu", "N", N);
                            Eigen::Matrix<T__,Eigen::Dynamic,1>  mu(static_cast<Eigen::VectorXd::Index>(N));
                            (void) mu;  // dummy to suppress unused var warning

                            stan::math::initialize(mu, DUMMY_VAR__);
                            stan::math::fill(mu,DUMMY_VAR__);


                            current_statement_begin__ = 1089;
                            stan::math::assign(mu, linkinv_beta(eta,link, pstream__));
                            current_statement_begin__ = 1090;
                            lp_accum__.add(beta_log(y,multiply(mu,aux),multiply(subtract(1,mu),aux)));
                        }
                    } else if (as_bool((primitive_value(logical_eq(family,4)) && primitive_value(logical_gt(link_phi,0))))) {
                        {
                            validate_non_negative_index("mu", "N", N);
                            Eigen::Matrix<T__,Eigen::Dynamic,1>  mu(static_cast<Eigen::VectorXd::Index>(N));
                            (void) mu;  // dummy to suppress unused var warning

                            stan::math::initialize(mu, DUMMY_VAR__);
                            stan::math::fill(mu,DUMMY_VAR__);
                            validate_non_negative_index("mu_z", "N", N);
                            Eigen::Matrix<T__,Eigen::Dynamic,1>  mu_z(static_cast<Eigen::VectorXd::Index>(N));
                            (void) mu_z;  // dummy to suppress unused var warning

                            stan::math::initialize(mu_z, DUMMY_VAR__);
                            stan::math::fill(mu_z,DUMMY_VAR__);


                            current_statement_begin__ = 1095;
                            stan::math::assign(mu, linkinv_beta(eta,link, pstream__));
                            current_statement_begin__ = 1096;
                            stan::math::assign(mu_z, linkinv_beta_z(eta_z,link_phi, pstream__));
                            current_statement_begin__ = 1097;
                            lp_accum__.add(beta_log(y,rows_dot_product(mu,mu_z),rows_dot_product(subtract(1,mu),mu_z)));
                        }
                    }
                } else if (as_bool(logical_eq(prior_PD,0))) {
                    {
                        validate_non_negative_index("summands", "N", N);
                        Eigen::Matrix<T__,Eigen::Dynamic,1>  summands(static_cast<Eigen::VectorXd::Index>(N));
                        (void) summands;  // dummy to suppress unused var warning

                        stan::math::initialize(summands, DUMMY_VAR__);
                        stan::math::fill(summands,DUMMY_VAR__);


                        current_statement_begin__ = 1103;
                        if (as_bool(logical_eq(family,1))) {
                            current_statement_begin__ = 1103;
                            stan::math::assign(summands, pw_gauss(y,eta,aux,link, pstream__));
                        } else if (as_bool(logical_eq(family,2))) {
                            current_statement_begin__ = 1104;
                            stan::math::assign(summands, pw_gamma(y,eta,aux,link, pstream__));
                        } else if (as_bool(logical_eq(family,3))) {
                            current_statement_begin__ = 1105;
                            stan::math::assign(summands, pw_inv_gaussian(y,eta,aux,link,log_y,sqrt_y, pstream__));
                        } else if (as_bool((primitive_value(logical_eq(family,4)) && primitive_value(logical_eq(link_phi,0))))) {
                            current_statement_begin__ = 1106;
                            stan::math::assign(summands, pw_beta(y,eta,aux,link, pstream__));
                        } else if (as_bool((primitive_value(logical_eq(family,4)) && primitive_value(logical_gt(link_phi,0))))) {
                            current_statement_begin__ = 1107;
                            stan::math::assign(summands, pw_beta_z(y,eta,eta_z,link,link_phi, pstream__));
                        }
                        current_statement_begin__ = 1108;
                        lp_accum__.add(dot_product(weights,summands));
                    }
                }
                current_statement_begin__ = 1113;
                if (as_bool((primitive_value(logical_gt(prior_dist_for_aux,0)) && primitive_value(logical_gt(prior_scale_for_aux,0))))) {
                    {
                        T__ log_half;
                        (void) log_half;  // dummy to suppress unused var warning

                        stan::math::initialize(log_half, DUMMY_VAR__);
                        stan::math::fill(log_half,DUMMY_VAR__);
                        stan::math::assign(log_half,-(0.6931471805599454));


                        current_statement_begin__ = 1115;
                        if (as_bool(logical_eq(prior_dist_for_aux,1))) {
                            current_statement_begin__ = 1116;
                            lp_accum__.add((normal_log(aux_unscaled,0,1) - log_half));
                        } else if (as_bool(logical_eq(prior_dist_for_aux,2))) {
                            current_statement_begin__ = 1118;
                            lp_accum__.add((student_t_log(aux_unscaled,prior_df_for_aux,0,1) - log_half));
                        } else {
                            current_statement_begin__ = 1120;
                            lp_accum__.add(exponential_log(aux_unscaled,1));
                        }
                    }
                }
                current_statement_begin__ = 1126;
                if (as_bool(logical_eq(prior_dist,1))) {
                    current_statement_begin__ = 1126;
                    lp_accum__.add(normal_log(z_beta,0,1));
                } else if (as_bool(logical_eq(prior_dist,2))) {
                    current_statement_begin__ = 1127;
                    lp_accum__.add(normal_log(z_beta,0,1));
                } else if (as_bool(logical_eq(prior_dist,3))) {
                    {
                        T__ log_half;
                        (void) log_half;  // dummy to suppress unused var warning

                        stan::math::initialize(log_half, DUMMY_VAR__);
                        stan::math::fill(log_half,DUMMY_VAR__);
                        stan::math::assign(log_half,-(0.6931471805599454));


                        current_statement_begin__ = 1130;
                        lp_accum__.add(normal_log(z_beta,0,1));
                        current_statement_begin__ = 1131;
                        lp_accum__.add((normal_log(get_base1(local,1,"local",1),0,1) - log_half));
                        current_statement_begin__ = 1132;
                        lp_accum__.add(inv_gamma_log(get_base1(local,2,"local",1),multiply(0.5,prior_df),multiply(0.5,prior_df)));
                        current_statement_begin__ = 1133;
                        lp_accum__.add((normal_log(get_base1(global,1,"global",1),0,1) - log_half));
                        current_statement_begin__ = 1134;
                        lp_accum__.add(inv_gamma_log(get_base1(global,2,"global",1),(0.5 * global_prior_df),(0.5 * global_prior_df)));
                    }
                } else if (as_bool(logical_eq(prior_dist,4))) {
                    {
                        T__ log_half;
                        (void) log_half;  // dummy to suppress unused var warning

                        stan::math::initialize(log_half, DUMMY_VAR__);
                        stan::math::fill(log_half,DUMMY_VAR__);
                        stan::math::assign(log_half,-(0.6931471805599454));


                        current_statement_begin__ = 1138;
                        lp_accum__.add(normal_log(z_beta,0,1));
                        current_statement_begin__ = 1139;
                        lp_accum__.add((normal_log(get_base1(local,1,"local",1),0,1) - log_half));
                        current_statement_begin__ = 1140;
                        lp_accum__.add(inv_gamma_log(get_base1(local,2,"local",1),multiply(0.5,prior_df),multiply(0.5,prior_df)));
                        current_statement_begin__ = 1141;
                        lp_accum__.add((normal_log(get_base1(local,3,"local",1),0,1) - log_half));
                        current_statement_begin__ = 1143;
                        lp_accum__.add(inv_gamma_log(get_base1(local,4,"local",1),multiply(0.5,prior_scale),multiply(0.5,prior_scale)));
                        current_statement_begin__ = 1144;
                        lp_accum__.add((normal_log(get_base1(global,1,"global",1),0,1) - log_half));
                        current_statement_begin__ = 1145;
                        lp_accum__.add(inv_gamma_log(get_base1(global,2,"global",1),(0.5 * global_prior_df),(0.5 * global_prior_df)));
                    }
                } else if (as_bool(logical_eq(prior_dist,5))) {

                    current_statement_begin__ = 1148;
                    lp_accum__.add(normal_log(z_beta,0,1));
                    current_statement_begin__ = 1149;
                    lp_accum__.add(exponential_log(get_base1(mix,1,"mix",1),1));
                } else if (as_bool(logical_eq(prior_dist,6))) {

                    current_statement_begin__ = 1152;
                    lp_accum__.add(normal_log(z_beta,0,1));
                    current_statement_begin__ = 1153;
                    lp_accum__.add(exponential_log(get_base1(mix,1,"mix",1),1));
                    current_statement_begin__ = 1154;
                    lp_accum__.add(chi_square_log(get_base1(one_over_lambda,1,"one_over_lambda",1),get_base1(prior_df,1,"prior_df",1)));
                } else if (as_bool(logical_eq(prior_dist,7))) {

                    current_statement_begin__ = 1157;
                    lp_accum__.add(normal_log(z_beta,0,1));
                }
                current_statement_begin__ = 1162;
                if (as_bool(logical_eq(has_intercept,1))) {

                    current_statement_begin__ = 1163;
                    if (as_bool(logical_eq(prior_dist_for_intercept,1))) {
                        current_statement_begin__ = 1164;
                        lp_accum__.add(normal_log(gamma,prior_mean_for_intercept,prior_scale_for_intercept));
                    } else if (as_bool(logical_eq(prior_dist_for_intercept,2))) {
                        current_statement_begin__ = 1166;
                        lp_accum__.add(student_t_log(gamma,prior_df_for_intercept,prior_mean_for_intercept,prior_scale_for_intercept));
                    }
                }
                current_statement_begin__ = 1171;
                if (as_bool(K_smooth)) {

                    current_statement_begin__ = 1172;
                    lp_accum__.add(normal_log(z_beta_smooth,0,1));
                    current_statement_begin__ = 1173;
                    if (as_bool(logical_gt(prior_dist_for_smooth,0))) {
                        {
                            T__ log_half;
                            (void) log_half;  // dummy to suppress unused var warning

                            stan::math::initialize(log_half, DUMMY_VAR__);
                            stan::math::fill(log_half,DUMMY_VAR__);
                            stan::math::assign(log_half,-(0.6931471805599454));


                            current_statement_begin__ = 1175;
                            if (as_bool(logical_eq(prior_dist_for_smooth,1))) {
                                current_statement_begin__ = 1176;
                                lp_accum__.add((normal_log(smooth_sd_raw,0,1) - log_half));
                            } else if (as_bool(logical_eq(prior_dist_for_smooth,2))) {
                                current_statement_begin__ = 1178;
                                lp_accum__.add((student_t_log(smooth_sd_raw,prior_df_for_smooth,0,1) - log_half));
                            } else if (as_bool(logical_eq(prior_dist_for_smooth,3))) {
                                current_statement_begin__ = 1180;
                                lp_accum__.add(exponential_log(smooth_sd_raw,1));
                            }
                        }
                    }
                }
                current_statement_begin__ = 1185;
                if (as_bool(logical_eq(prior_dist_z,1))) {
                    current_statement_begin__ = 1185;
                    lp_accum__.add(normal_log(z_omega,0,1));
                } else if (as_bool(logical_eq(prior_dist_z,2))) {
                    current_statement_begin__ = 1186;
                    lp_accum__.add(normal_log(z_omega,0,1));
                } else if (as_bool(logical_eq(prior_dist_z,3))) {
                    {
                        T__ log_half;
                        (void) log_half;  // dummy to suppress unused var warning

                        stan::math::initialize(log_half, DUMMY_VAR__);
                        stan::math::fill(log_half,DUMMY_VAR__);
                        stan::math::assign(log_half,-(0.6931471805599454));


                        current_statement_begin__ = 1189;
                        lp_accum__.add(normal_log(z_omega,0,1));
                        current_statement_begin__ = 1190;
                        lp_accum__.add((normal_log(get_base1(local_z,1,"local_z",1),0,1) - log_half));
                        current_statement_begin__ = 1191;
                        lp_accum__.add(inv_gamma_log(get_base1(local_z,2,"local_z",1),multiply(0.5,prior_df_z),multiply(0.5,prior_df_z)));
                        current_statement_begin__ = 1192;
                        lp_accum__.add((normal_log(get_base1(global_z,1,"global_z",1),0,1) - log_half));
                        current_statement_begin__ = 1193;
                        lp_accum__.add(inv_gamma_log(get_base1(global_z,2,"global_z",1),0.5,0.5));
                    }
                } else if (as_bool(logical_eq(prior_dist_z,4))) {
                    {
                        T__ log_half;
                        (void) log_half;  // dummy to suppress unused var warning

                        stan::math::initialize(log_half, DUMMY_VAR__);
                        stan::math::fill(log_half,DUMMY_VAR__);
                        stan::math::assign(log_half,-(0.6931471805599454));


                        current_statement_begin__ = 1197;
                        lp_accum__.add(normal_log(z_omega,0,1));
                        current_statement_begin__ = 1198;
                        lp_accum__.add((normal_log(get_base1(local_z,1,"local_z",1),0,1) - log_half));
                        current_statement_begin__ = 1199;
                        lp_accum__.add(inv_gamma_log(get_base1(local_z,2,"local_z",1),multiply(0.5,prior_df_z),multiply(0.5,prior_df_z)));
                        current_statement_begin__ = 1200;
                        lp_accum__.add((normal_log(get_base1(local_z,3,"local_z",1),0,1) - log_half));
                        current_statement_begin__ = 1202;
                        lp_accum__.add(inv_gamma_log(get_base1(local_z,4,"local_z",1),multiply(0.5,prior_scale_z),multiply(0.5,prior_scale_z)));
                        current_statement_begin__ = 1203;
                        lp_accum__.add((normal_log(get_base1(global_z,1,"global_z",1),0,1) - log_half));
                        current_statement_begin__ = 1204;
                        lp_accum__.add(inv_gamma_log(get_base1(global_z,2,"global_z",1),0.5,0.5));
                    }
                } else if (as_bool(logical_eq(prior_dist_z,5))) {

                    current_statement_begin__ = 1207;
                    lp_accum__.add(normal_log(z_omega,0,1));
                    current_statement_begin__ = 1208;
                    lp_accum__.add(exponential_log(get_base1(S_z,1,"S_z",1),1));
                } else if (as_bool(logical_eq(prior_dist_z,6))) {

                    current_statement_begin__ = 1211;
                    lp_accum__.add(normal_log(z_omega,0,1));
                    current_statement_begin__ = 1212;
                    lp_accum__.add(exponential_log(get_base1(S_z,1,"S_z",1),1));
                    current_statement_begin__ = 1213;
                    lp_accum__.add(chi_square_log(get_base1(one_over_lambda_z,1,"one_over_lambda_z",1),get_base1(prior_df_z,1,"prior_df_z",1)));
                } else if (as_bool(logical_eq(prior_dist_z,7))) {

                    current_statement_begin__ = 1216;
                    lp_accum__.add(normal_log(z_omega,0,1));
                }
                current_statement_begin__ = 1221;
                if (as_bool(logical_eq(has_intercept_z,1))) {

                    current_statement_begin__ = 1222;
                    if (as_bool(logical_eq(prior_dist_for_intercept_z,1))) {
                        current_statement_begin__ = 1223;
                        lp_accum__.add(normal_log(gamma_z,prior_mean_for_intercept_z,prior_scale_for_intercept_z));
                    } else if (as_bool(logical_eq(prior_dist_for_intercept_z,2))) {
                        current_statement_begin__ = 1225;
                        lp_accum__.add(student_t_log(gamma_z,prior_df_for_intercept_z,prior_mean_for_intercept_z,prior_scale_for_intercept_z));
                    }
                }
                current_statement_begin__ = 1229;
                if (as_bool(logical_gt(t,0))) {
                    current_statement_begin__ = 1229;
                    decov_lp(z_b,z_T,rho,zeta,tau,regularization,delta,shape,t,p, lp__, lp_accum__, pstream__);
                }
                current_statement_begin__ = 1230;
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        lp_accum__.add(lp__);
        return lp_accum__.sum();

    } // log_prob()

    template <bool propto, bool jacobian, typename T_>
    T_ log_prob(Eigen::Matrix<T_,Eigen::Dynamic,1>& params_r,
               std::ostream* pstream = 0) const {
      std::vector<T_> vec_params_r;
      vec_params_r.reserve(params_r.size());
      for (int i = 0; i < params_r.size(); ++i)
        vec_params_r.push_back(params_r(i));
      std::vector<int> vec_params_i;
      return log_prob<propto,jacobian,T_>(vec_params_r, vec_params_i, pstream);
    }


    void get_param_names(std::vector<std::string>& names__) const {
        names__.resize(0);
        names__.push_back("gamma");
        names__.push_back("z_beta");
        names__.push_back("z_beta_smooth");
        names__.push_back("smooth_sd_raw");
        names__.push_back("global");
        names__.push_back("local");
        names__.push_back("mix");
        names__.push_back("one_over_lambda");
        names__.push_back("z_b");
        names__.push_back("z_T");
        names__.push_back("rho");
        names__.push_back("zeta");
        names__.push_back("tau");
        names__.push_back("aux_unscaled");
        names__.push_back("z_omega");
        names__.push_back("gamma_z");
        names__.push_back("global_z");
        names__.push_back("local_z");
        names__.push_back("S_z");
        names__.push_back("one_over_lambda_z");
        names__.push_back("aux");
        names__.push_back("omega");
        names__.push_back("beta");
        names__.push_back("beta_smooth");
        names__.push_back("smooth_sd");
        names__.push_back("b");
        names__.push_back("theta_L");
        names__.push_back("alpha");
        names__.push_back("omega_int");
        names__.push_back("mean_PPD");
    }


    void get_dims(std::vector<std::vector<size_t> >& dimss__) const {
        dimss__.resize(0);
        std::vector<size_t> dims__;
        dims__.resize(0);
        dims__.push_back(has_intercept);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((logical_eq(prior_dist,7) ? sum(num_normals) : K ));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(K_smooth);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(hs);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(hs);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))));
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(logical_eq(prior_dist,6));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(q);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(len_z_T);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(len_rho);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(len_concentration);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(t);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((logical_eq(prior_dist_z,7) ? sum(num_normals_z) : z_dim ));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(has_intercept_z);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(hs_z);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(hs_z);
        dims__.push_back(z_dim);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((primitive_value(logical_eq(prior_dist_z,5)) || primitive_value(logical_eq(prior_dist_z,6))));
        dims__.push_back(z_dim);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(logical_eq(prior_dist_z,6));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(z_dim);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(K_smooth);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(q);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(len_theta_L);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(has_intercept);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(has_intercept_z);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dimss__.push_back(dims__);
    }

    template <typename RNG>
    void write_array(RNG& base_rng__,
                     std::vector<double>& params_r__,
                     std::vector<int>& params_i__,
                     std::vector<double>& vars__,
                     bool include_tparams__ = true,
                     bool include_gqs__ = true,
                     std::ostream* pstream__ = 0) const {
        vars__.resize(0);
        stan::io::reader<double> in__(params_r__,params_i__);
        static const char* function__ = "model_continuous_namespace::write_array";
        (void) function__;  // dummy to suppress unused var warning
        // read-transform, write parameters
        vector<double> gamma;
        size_t dim_gamma_0__ = has_intercept;
        for (size_t k_0__ = 0; k_0__ < dim_gamma_0__; ++k_0__) {
            gamma.push_back(in__.scalar_lub_constrain(make_lower(family,link, pstream__),make_upper(family,link, pstream__)));
        }
        vector_d z_beta = in__.vector_constrain((logical_eq(prior_dist,7) ? sum(num_normals) : K ));
        vector_d z_beta_smooth = in__.vector_constrain(K_smooth);
        vector_d smooth_sd_raw = in__.vector_lb_constrain(0,(logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));
        vector<double> global;
        size_t dim_global_0__ = hs;
        for (size_t k_0__ = 0; k_0__ < dim_global_0__; ++k_0__) {
            global.push_back(in__.scalar_lb_constrain(0));
        }
        vector<vector_d> local;
        size_t dim_local_0__ = hs;
        for (size_t k_0__ = 0; k_0__ < dim_local_0__; ++k_0__) {
            local.push_back(in__.vector_lb_constrain(0,K));
        }
        vector<vector_d> mix;
        size_t dim_mix_0__ = (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6)));
        for (size_t k_0__ = 0; k_0__ < dim_mix_0__; ++k_0__) {
            mix.push_back(in__.vector_lb_constrain(0,K));
        }
        vector<double> one_over_lambda;
        size_t dim_one_over_lambda_0__ = logical_eq(prior_dist,6);
        for (size_t k_0__ = 0; k_0__ < dim_one_over_lambda_0__; ++k_0__) {
            one_over_lambda.push_back(in__.scalar_lb_constrain(0));
        }
        vector_d z_b = in__.vector_constrain(q);
        vector_d z_T = in__.vector_constrain(len_z_T);
        vector_d rho = in__.vector_lub_constrain(0,1,len_rho);
        vector_d zeta = in__.vector_lb_constrain(0,len_concentration);
        vector_d tau = in__.vector_lb_constrain(0,t);
        double aux_unscaled = in__.scalar_lb_constrain(0);
        vector_d z_omega = in__.vector_constrain((logical_eq(prior_dist_z,7) ? sum(num_normals_z) : z_dim ));
        vector<double> gamma_z;
        size_t dim_gamma_z_0__ = has_intercept_z;
        for (size_t k_0__ = 0; k_0__ < dim_gamma_z_0__; ++k_0__) {
            gamma_z.push_back(in__.scalar_lb_constrain((logical_lte(link_phi,1) ? stan::math::promote_scalar<double>(stan::math::negative_infinity()) : stan::math::promote_scalar<double>(0) )));
        }
        vector<double> global_z;
        size_t dim_global_z_0__ = hs_z;
        for (size_t k_0__ = 0; k_0__ < dim_global_z_0__; ++k_0__) {
            global_z.push_back(in__.scalar_lb_constrain(0));
        }
        vector<vector_d> local_z;
        size_t dim_local_z_0__ = hs_z;
        for (size_t k_0__ = 0; k_0__ < dim_local_z_0__; ++k_0__) {
            local_z.push_back(in__.vector_lb_constrain(0,z_dim));
        }
        vector<vector_d> S_z;
        size_t dim_S_z_0__ = (primitive_value(logical_eq(prior_dist_z,5)) || primitive_value(logical_eq(prior_dist_z,6)));
        for (size_t k_0__ = 0; k_0__ < dim_S_z_0__; ++k_0__) {
            S_z.push_back(in__.vector_lb_constrain(0,z_dim));
        }
        vector<double> one_over_lambda_z;
        size_t dim_one_over_lambda_z_0__ = logical_eq(prior_dist_z,6);
        for (size_t k_0__ = 0; k_0__ < dim_one_over_lambda_z_0__; ++k_0__) {
            one_over_lambda_z.push_back(in__.scalar_lb_constrain(0));
        }
        for (int k_0__ = 0; k_0__ < has_intercept; ++k_0__) {
            vars__.push_back(gamma[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < (logical_eq(prior_dist,7) ? sum(num_normals) : K ); ++k_0__) {
            vars__.push_back(z_beta[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < K_smooth; ++k_0__) {
            vars__.push_back(z_beta_smooth[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++k_0__) {
            vars__.push_back(smooth_sd_raw[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < hs; ++k_0__) {
            vars__.push_back(global[k_0__]);
        }
        for (int k_1__ = 0; k_1__ < K; ++k_1__) {
            for (int k_0__ = 0; k_0__ < hs; ++k_0__) {
                vars__.push_back(local[k_0__][k_1__]);
            }
        }
        for (int k_1__ = 0; k_1__ < K; ++k_1__) {
            for (int k_0__ = 0; k_0__ < (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))); ++k_0__) {
                vars__.push_back(mix[k_0__][k_1__]);
            }
        }
        for (int k_0__ = 0; k_0__ < logical_eq(prior_dist,6); ++k_0__) {
            vars__.push_back(one_over_lambda[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < q; ++k_0__) {
            vars__.push_back(z_b[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < len_z_T; ++k_0__) {
            vars__.push_back(z_T[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < len_rho; ++k_0__) {
            vars__.push_back(rho[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < len_concentration; ++k_0__) {
            vars__.push_back(zeta[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < t; ++k_0__) {
            vars__.push_back(tau[k_0__]);
        }
        vars__.push_back(aux_unscaled);
        for (int k_0__ = 0; k_0__ < (logical_eq(prior_dist_z,7) ? sum(num_normals_z) : z_dim ); ++k_0__) {
            vars__.push_back(z_omega[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < has_intercept_z; ++k_0__) {
            vars__.push_back(gamma_z[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < hs_z; ++k_0__) {
            vars__.push_back(global_z[k_0__]);
        }
        for (int k_1__ = 0; k_1__ < z_dim; ++k_1__) {
            for (int k_0__ = 0; k_0__ < hs_z; ++k_0__) {
                vars__.push_back(local_z[k_0__][k_1__]);
            }
        }
        for (int k_1__ = 0; k_1__ < z_dim; ++k_1__) {
            for (int k_0__ = 0; k_0__ < (primitive_value(logical_eq(prior_dist_z,5)) || primitive_value(logical_eq(prior_dist_z,6))); ++k_0__) {
                vars__.push_back(S_z[k_0__][k_1__]);
            }
        }
        for (int k_0__ = 0; k_0__ < logical_eq(prior_dist_z,6); ++k_0__) {
            vars__.push_back(one_over_lambda_z[k_0__]);
        }

        if (!include_tparams__) return;
        // declare and define transformed parameters
        double lp__ = 0.0;
        (void) lp__;  // dummy to suppress unused var warning
        stan::math::accumulator<double> lp_accum__;

        double DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

        double aux(0.0);
        (void) aux;  // dummy to suppress unused var warning

        stan::math::initialize(aux, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(aux,DUMMY_VAR__);
        stan::math::assign(aux,(logical_eq(prior_dist_for_aux,0) ? stan::math::promote_scalar<double>(aux_unscaled) : stan::math::promote_scalar<double>((logical_lte(prior_dist_for_aux,2) ? stan::math::promote_scalar<double>(((prior_scale_for_aux * aux_unscaled) + prior_mean_for_aux)) : stan::math::promote_scalar<double>((prior_scale_for_aux * aux_unscaled)) )) ));
        validate_non_negative_index("omega", "z_dim", z_dim);
        vector_d omega(static_cast<Eigen::VectorXd::Index>(z_dim));
        (void) omega;  // dummy to suppress unused var warning

        stan::math::initialize(omega, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(omega,DUMMY_VAR__);
        validate_non_negative_index("beta", "K", K);
        vector_d beta(static_cast<Eigen::VectorXd::Index>(K));
        (void) beta;  // dummy to suppress unused var warning

        stan::math::initialize(beta, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(beta,DUMMY_VAR__);
        validate_non_negative_index("beta_smooth", "K_smooth", K_smooth);
        vector_d beta_smooth(static_cast<Eigen::VectorXd::Index>(K_smooth));
        (void) beta_smooth;  // dummy to suppress unused var warning

        stan::math::initialize(beta_smooth, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(beta_smooth,DUMMY_VAR__);
        validate_non_negative_index("smooth_sd", "(logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,\"smooth_map\",1) : 0 )", (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));
        vector_d smooth_sd(static_cast<Eigen::VectorXd::Index>((logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 )));
        (void) smooth_sd;  // dummy to suppress unused var warning

        stan::math::initialize(smooth_sd, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(smooth_sd,DUMMY_VAR__);
        validate_non_negative_index("b", "q", q);
        vector_d b(static_cast<Eigen::VectorXd::Index>(q));
        (void) b;  // dummy to suppress unused var warning

        stan::math::initialize(b, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(b,DUMMY_VAR__);
        validate_non_negative_index("theta_L", "len_theta_L", len_theta_L);
        vector_d theta_L(static_cast<Eigen::VectorXd::Index>(len_theta_L));
        (void) theta_L;  // dummy to suppress unused var warning

        stan::math::initialize(theta_L, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(theta_L,DUMMY_VAR__);


        try {
            current_statement_begin__ = 908;
            if (as_bool(logical_eq(prior_dist,0))) {
                current_statement_begin__ = 908;
                stan::math::assign(beta, z_beta);
            } else if (as_bool(logical_eq(prior_dist,1))) {
                current_statement_begin__ = 909;
                stan::math::assign(beta, add(elt_multiply(z_beta,prior_scale),prior_mean));
            } else if (as_bool(logical_eq(prior_dist,2))) {
                current_statement_begin__ = 910;
                for (int k = 1; k <= K; ++k) {

                    current_statement_begin__ = 911;
                    stan::math::assign(get_base1_lhs(beta,k,"beta",1), ((CFt(get_base1(z_beta,k,"z_beta",1),get_base1(prior_df,k,"prior_df",1), pstream__) * get_base1(prior_scale,k,"prior_scale",1)) + get_base1(prior_mean,k,"prior_mean",1)));
                }
            } else if (as_bool(logical_eq(prior_dist,3))) {

                current_statement_begin__ = 914;
                if (as_bool((primitive_value(logical_eq(is_continuous,1)) && primitive_value(logical_eq(family,1))))) {
                    current_statement_begin__ = 915;
                    stan::math::assign(beta, hs_prior(z_beta,global,local,global_prior_scale,aux, pstream__));
                } else {
                    current_statement_begin__ = 916;
                    stan::math::assign(beta, hs_prior(z_beta,global,local,global_prior_scale,1, pstream__));
                }
            } else if (as_bool(logical_eq(prior_dist,4))) {

                current_statement_begin__ = 919;
                if (as_bool((primitive_value(logical_eq(is_continuous,1)) && primitive_value(logical_eq(family,1))))) {
                    current_statement_begin__ = 920;
                    stan::math::assign(beta, hsplus_prior(z_beta,global,local,global_prior_scale,aux, pstream__));
                } else {
                    current_statement_begin__ = 921;
                    stan::math::assign(beta, hsplus_prior(z_beta,global,local,global_prior_scale,1, pstream__));
                }
            } else if (as_bool(logical_eq(prior_dist,5))) {
                current_statement_begin__ = 924;
                stan::math::assign(beta, add(prior_mean,elt_multiply(elt_multiply(prior_scale,sqrt(multiply(2,get_base1(mix,1,"mix",1)))),z_beta)));
            } else if (as_bool(logical_eq(prior_dist,6))) {
                current_statement_begin__ = 926;
                stan::math::assign(beta, add(prior_mean,elt_multiply(elt_multiply(multiply(get_base1(one_over_lambda,1,"one_over_lambda",1),prior_scale),sqrt(multiply(2,get_base1(mix,1,"mix",1)))),z_beta)));
            } else if (as_bool(logical_eq(prior_dist,7))) {
                {
                    int z_pos(0);
                    (void) z_pos;  // dummy to suppress unused var warning

                    stan::math::fill(z_pos, std::numeric_limits<int>::min());
                    stan::math::assign(z_pos,1);


                    current_statement_begin__ = 929;
                    for (int k = 1; k <= K; ++k) {

                        current_statement_begin__ = 930;
                        stan::math::assign(get_base1_lhs(beta,k,"beta",1), get_base1(z_beta,z_pos,"z_beta",1));
                        current_statement_begin__ = 931;
                        stan::math::assign(z_pos, (z_pos + 1));
                        current_statement_begin__ = 932;
                        for (int n = 2; n <= get_base1(num_normals,k,"num_normals",1); ++n) {

                            current_statement_begin__ = 933;
                            stan::math::assign(get_base1_lhs(beta,k,"beta",1), (get_base1(beta,k,"beta",1) * get_base1(z_beta,z_pos,"z_beta",1)));
                            current_statement_begin__ = 934;
                            stan::math::assign(z_pos, (z_pos + 1));
                        }
                        current_statement_begin__ = 936;
                        stan::math::assign(get_base1_lhs(beta,k,"beta",1), ((get_base1(beta,k,"beta",1) * pow(get_base1(prior_scale,k,"prior_scale",1),get_base1(num_normals,k,"num_normals",1))) + get_base1(prior_mean,k,"prior_mean",1)));
                    }
                }
            }
            current_statement_begin__ = 940;
            if (as_bool(K_smooth)) {

                current_statement_begin__ = 941;
                stan::math::assign(smooth_sd, add(prior_mean_for_smooth,elt_multiply(prior_scale_for_smooth,smooth_sd_raw)));
                current_statement_begin__ = 942;
                if (as_bool((primitive_value(is_continuous) && primitive_value(logical_eq(family,1))))) {
                    current_statement_begin__ = 942;
                    stan::math::assign(smooth_sd, multiply(smooth_sd,aux));
                }
                current_statement_begin__ = 943;
                stan::math::assign(beta_smooth, elt_multiply(z_beta_smooth,stan::model::rvalue(smooth_sd, stan::model::cons_list(stan::model::index_multi(smooth_map), stan::model::nil_index_list()), "smooth_sd")));
            }
            current_statement_begin__ = 946;
            if (as_bool(logical_eq(prior_dist_z,0))) {
                current_statement_begin__ = 946;
                stan::math::assign(omega, z_omega);
            } else if (as_bool(logical_eq(prior_dist_z,1))) {
                current_statement_begin__ = 947;
                stan::math::assign(omega, add(elt_multiply(z_omega,prior_scale_z),prior_mean_z));
            } else if (as_bool(logical_eq(prior_dist_z,2))) {
                current_statement_begin__ = 948;
                for (int k = 1; k <= z_dim; ++k) {

                    current_statement_begin__ = 949;
                    stan::math::assign(get_base1_lhs(omega,k,"omega",1), ((CFt(get_base1(omega,k,"omega",1),get_base1(prior_df_z,k,"prior_df_z",1), pstream__) * get_base1(prior_scale_z,k,"prior_scale_z",1)) + get_base1(prior_mean_z,k,"prior_mean_z",1)));
                }
            } else if (as_bool(logical_eq(prior_dist_z,3))) {
                current_statement_begin__ = 952;
                stan::math::assign(omega, hs_prior(z_omega,global_z,local_z,global_prior_scale,1, pstream__));
            } else if (as_bool(logical_eq(prior_dist_z,4))) {
                current_statement_begin__ = 954;
                stan::math::assign(omega, hsplus_prior(z_omega,global_z,local_z,global_prior_scale,1, pstream__));
            } else if (as_bool(logical_eq(prior_dist_z,5))) {
                current_statement_begin__ = 956;
                stan::math::assign(omega, add(prior_mean_z,elt_multiply(elt_multiply(prior_scale_z,sqrt(multiply(2,get_base1(S_z,1,"S_z",1)))),z_omega)));
            } else if (as_bool(logical_eq(prior_dist_z,6))) {
                current_statement_begin__ = 958;
                stan::math::assign(omega, add(prior_mean_z,elt_multiply(elt_multiply(multiply(get_base1(one_over_lambda_z,1,"one_over_lambda_z",1),prior_scale_z),sqrt(multiply(2,get_base1(S_z,1,"S_z",1)))),z_omega)));
            } else if (as_bool(logical_eq(prior_dist_z,7))) {
                {
                    int z_pos(0);
                    (void) z_pos;  // dummy to suppress unused var warning

                    stan::math::fill(z_pos, std::numeric_limits<int>::min());
                    stan::math::assign(z_pos,1);


                    current_statement_begin__ = 961;
                    for (int k = 1; k <= z_dim; ++k) {

                        current_statement_begin__ = 962;
                        stan::math::assign(get_base1_lhs(omega,k,"omega",1), get_base1(z_omega,z_pos,"z_omega",1));
                        current_statement_begin__ = 963;
                        stan::math::assign(z_pos, (z_pos + 1));
                        current_statement_begin__ = 964;
                        for (int n = 2; n <= get_base1(num_normals_z,k,"num_normals_z",1); ++n) {

                            current_statement_begin__ = 965;
                            stan::math::assign(get_base1_lhs(omega,k,"omega",1), (get_base1(omega,k,"omega",1) * get_base1(z_omega,z_pos,"z_omega",1)));
                            current_statement_begin__ = 966;
                            stan::math::assign(z_pos, (z_pos + 1));
                        }
                        current_statement_begin__ = 968;
                        stan::math::assign(get_base1_lhs(omega,k,"omega",1), ((get_base1(omega,k,"omega",1) * pow(get_base1(prior_scale_z,k,"prior_scale_z",1),get_base1(num_normals_z,k,"num_normals_z",1))) + get_base1(prior_mean_z,k,"prior_mean_z",1)));
                    }
                }
            }
            current_statement_begin__ = 973;
            if (as_bool(logical_gt(t,0))) {

                current_statement_begin__ = 974;
                if (as_bool(logical_eq(special_case,1))) {
                    {
                        int start(0);
                        (void) start;  // dummy to suppress unused var warning

                        stan::math::fill(start, std::numeric_limits<int>::min());
                        stan::math::assign(start,1);


                        current_statement_begin__ = 976;
                        stan::math::assign(theta_L, multiply(elt_multiply(scale,tau),aux));
                        current_statement_begin__ = 977;
                        if (as_bool(logical_eq(t,1))) {
                            current_statement_begin__ = 977;
                            stan::math::assign(b, multiply(get_base1(theta_L,1,"theta_L",1),z_b));
                        } else {
                            current_statement_begin__ = 978;
                            for (int i = 1; i <= t; ++i) {
                                {
                                    int end(0);
                                    (void) end;  // dummy to suppress unused var warning

                                    stan::math::fill(end, std::numeric_limits<int>::min());
                                    stan::math::assign(end,((start + get_base1(l,i,"l",1)) - 1));


                                    current_statement_begin__ = 980;
                                    stan::model::assign(b, 
                                                stan::model::cons_list(stan::model::index_min_max(start, end), stan::model::nil_index_list()), 
                                                multiply(get_base1(theta_L,i,"theta_L",1),stan::model::rvalue(z_b, stan::model::cons_list(stan::model::index_min_max(start, end), stan::model::nil_index_list()), "z_b")), 
                                                "assigning variable b");
                                    current_statement_begin__ = 981;
                                    stan::math::assign(start, (end + 1));
                                }
                            }
                        }
                    }
                } else {

                    current_statement_begin__ = 985;
                    stan::math::assign(theta_L, make_theta_L(len_theta_L,p,aux,tau,scale,zeta,rho,z_T, pstream__));
                    current_statement_begin__ = 987;
                    stan::math::assign(b, make_b(z_b,theta_L,p,l, pstream__));
                }
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        // validate transformed parameters

        // write transformed parameters
        vars__.push_back(aux);
        for (int k_0__ = 0; k_0__ < z_dim; ++k_0__) {
            vars__.push_back(omega[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < K; ++k_0__) {
            vars__.push_back(beta[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < K_smooth; ++k_0__) {
            vars__.push_back(beta_smooth[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++k_0__) {
            vars__.push_back(smooth_sd[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < q; ++k_0__) {
            vars__.push_back(b[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < len_theta_L; ++k_0__) {
            vars__.push_back(theta_L[k_0__]);
        }

        if (!include_gqs__) return;
        // declare and define generated quantities
        validate_non_negative_index("alpha", "has_intercept", has_intercept);
        vector<double> alpha(has_intercept, 0.0);
        stan::math::initialize(alpha, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(alpha,DUMMY_VAR__);
        validate_non_negative_index("omega_int", "has_intercept_z", has_intercept_z);
        vector<double> omega_int(has_intercept_z, 0.0);
        stan::math::initialize(omega_int, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(omega_int,DUMMY_VAR__);
        double mean_PPD(0.0);
        (void) mean_PPD;  // dummy to suppress unused var warning

        stan::math::initialize(mean_PPD, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(mean_PPD,DUMMY_VAR__);
        stan::math::assign(mean_PPD,0);


        try {
            current_statement_begin__ = 1236;
            if (as_bool(logical_eq(has_intercept,1))) {

                current_statement_begin__ = 1237;
                if (as_bool(dense_X)) {
                    current_statement_begin__ = 1237;
                    stan::math::assign(get_base1_lhs(alpha,1,"alpha",1), (get_base1(gamma,1,"gamma",1) - dot_product(xbar,beta)));
                } else {
                    current_statement_begin__ = 1238;
                    stan::math::assign(get_base1_lhs(alpha,1,"alpha",1), get_base1(gamma,1,"gamma",1));
                }
            }
            current_statement_begin__ = 1240;
            if (as_bool(logical_eq(has_intercept_z,1))) {

                current_statement_begin__ = 1241;
                stan::math::assign(get_base1_lhs(omega_int,1,"omega_int",1), (get_base1(gamma_z,1,"gamma_z",1) - dot_product(zbar,omega)));
            }
            {
                validate_non_negative_index("eta_z", "N", N);
                vector_d eta_z(static_cast<Eigen::VectorXd::Index>(N));
                (void) eta_z;  // dummy to suppress unused var warning

                stan::math::initialize(eta_z, std::numeric_limits<double>::quiet_NaN());
                stan::math::fill(eta_z,DUMMY_VAR__);
                validate_non_negative_index("eta", "N", N);
                vector_d eta(static_cast<Eigen::VectorXd::Index>(N));
                (void) eta;  // dummy to suppress unused var warning

                stan::math::initialize(eta, std::numeric_limits<double>::quiet_NaN());
                stan::math::fill(eta,DUMMY_VAR__);


                current_statement_begin__ = 1247;
                if (as_bool(logical_gt(K,0))) {

                    current_statement_begin__ = 1248;
                    if (as_bool(dense_X)) {
                        current_statement_begin__ = 1248;
                        stan::math::assign(eta, multiply(get_base1(X,1,"X",1),beta));
                    } else {
                        current_statement_begin__ = 1249;
                        stan::math::assign(eta, csr_matrix_times_vector(N,K,w_X,v_X,u_X,beta));
                    }
                } else {
                    current_statement_begin__ = 1251;
                    stan::math::assign(eta, rep_vector(0.0,N));
                }
                current_statement_begin__ = 1252;
                if (as_bool(logical_eq(has_offset,1))) {
                    current_statement_begin__ = 1252;
                    stan::math::assign(eta, add(eta,offset));
                }
                current_statement_begin__ = 1253;
                if (as_bool(K_smooth)) {
                    current_statement_begin__ = 1253;
                    stan::math::assign(eta, add(eta,multiply(S,beta_smooth)));
                }
                current_statement_begin__ = 1254;
                if (as_bool(logical_gt(t,0))) {

                    current_statement_begin__ = 1256;
                    if (as_bool(special_case)) {
                        current_statement_begin__ = 1256;
                        for (int i = 1; i <= t; ++i) {
                            current_statement_begin__ = 1256;
                            stan::math::assign(eta, add(eta,stan::model::rvalue(b, stan::model::cons_list(stan::model::index_multi(get_base1(V,i,"V",1)), stan::model::nil_index_list()), "b")));
                        }
                    } else {
                        current_statement_begin__ = 1257;
                        stan::math::assign(eta, add(eta,csr_matrix_times_vector(N,q,w,v,u,b)));
                    }
                }
                current_statement_begin__ = 1259;
                if (as_bool(logical_eq(has_intercept,1))) {

                    current_statement_begin__ = 1260;
                    if (as_bool((primitive_value(logical_eq(make_lower(family,link, pstream__),stan::math::negative_infinity())) && primitive_value(logical_eq(make_upper(family,link, pstream__),stan::math::positive_infinity()))))) {
                        current_statement_begin__ = 1261;
                        stan::math::assign(eta, add(eta,get_base1(gamma,1,"gamma",1)));
                    } else if (as_bool((primitive_value(logical_eq(family,4)) && primitive_value(logical_eq(link,5))))) {
                        {
                            double max_eta(0.0);
                            (void) max_eta;  // dummy to suppress unused var warning

                            stan::math::initialize(max_eta, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(max_eta,DUMMY_VAR__);


                            current_statement_begin__ = 1264;
                            stan::math::assign(max_eta, max(eta));
                            current_statement_begin__ = 1265;
                            stan::math::assign(get_base1_lhs(alpha,1,"alpha",1), (get_base1(alpha,1,"alpha",1) - max_eta));
                            current_statement_begin__ = 1266;
                            stan::math::assign(eta, add(subtract(eta,max_eta),get_base1(gamma,1,"gamma",1)));
                        }
                    } else {
                        {
                            double min_eta(0.0);
                            (void) min_eta;  // dummy to suppress unused var warning

                            stan::math::initialize(min_eta, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(min_eta,DUMMY_VAR__);
                            stan::math::assign(min_eta,min(eta));


                            current_statement_begin__ = 1270;
                            stan::math::assign(get_base1_lhs(alpha,1,"alpha",1), (get_base1(alpha,1,"alpha",1) - min_eta));
                            current_statement_begin__ = 1271;
                            stan::math::assign(eta, add(subtract(eta,min_eta),get_base1(gamma,1,"gamma",1)));
                        }
                    }
                } else {

                    current_statement_begin__ = 1277;
                    stan::math::assign(eta, add(eta,dot_product(xbar,beta)));
                }
                current_statement_begin__ = 1281;
                if (as_bool((primitive_value((primitive_value(logical_eq(family,4)) && primitive_value(logical_gt(z_dim,0)))) && primitive_value(logical_gt(link_phi,0))))) {

                    current_statement_begin__ = 1282;
                    stan::math::assign(eta_z, multiply(betareg_z,omega));
                } else if (as_bool((primitive_value((primitive_value(logical_eq(family,4)) && primitive_value(logical_eq(z_dim,0)))) && primitive_value(logical_eq(has_intercept_z,1))))) {

                    current_statement_begin__ = 1285;
                    stan::math::assign(eta_z, rep_vector(0.0,N));
                }
                current_statement_begin__ = 1288;
                if (as_bool(logical_eq(has_intercept_z,1))) {

                    current_statement_begin__ = 1289;
                    if (as_bool(logical_gt(link_phi,1))) {

                        current_statement_begin__ = 1290;
                        stan::math::assign(get_base1_lhs(omega_int,1,"omega_int",1), (get_base1(omega_int,1,"omega_int",1) - min(eta_z)));
                        current_statement_begin__ = 1291;
                        stan::math::assign(eta_z, add(subtract(eta_z,min(eta_z)),get_base1(gamma_z,1,"gamma_z",1)));
                    } else {

                        current_statement_begin__ = 1294;
                        stan::math::assign(eta_z, add(eta_z,get_base1(gamma_z,1,"gamma_z",1)));
                    }
                } else {

                    current_statement_begin__ = 1299;
                    if (as_bool(logical_gt(link_phi,1))) {

                        current_statement_begin__ = 1300;
                        stan::math::assign(eta_z, add(subtract(eta_z,min(eta_z)),dot_product(zbar,omega)));
                    } else {

                        current_statement_begin__ = 1303;
                        stan::math::assign(eta_z, add(eta_z,dot_product(zbar,omega)));
                    }
                }
                current_statement_begin__ = 1307;
                if (as_bool(logical_gt(SSfun,0))) {
                    {
                        validate_non_negative_index("eta_nlmer", "len_y", len_y);
                        vector_d eta_nlmer(static_cast<Eigen::VectorXd::Index>(len_y));
                        (void) eta_nlmer;  // dummy to suppress unused var warning

                        stan::math::initialize(eta_nlmer, std::numeric_limits<double>::quiet_NaN());
                        stan::math::fill(eta_nlmer,DUMMY_VAR__);
                        validate_non_negative_index("P", "len_y", len_y);
                        validate_non_negative_index("P", "K", K);
                        matrix_d P(static_cast<Eigen::VectorXd::Index>(len_y),static_cast<Eigen::VectorXd::Index>(K));
                        (void) P;  // dummy to suppress unused var warning

                        stan::math::initialize(P, std::numeric_limits<double>::quiet_NaN());
                        stan::math::fill(P,DUMMY_VAR__);


                        current_statement_begin__ = 1310;
                        stan::math::assign(P, reshape_vec(eta,len_y,K, pstream__));
                        current_statement_begin__ = 1311;
                        if (as_bool(logical_lt(SSfun,5))) {

                            current_statement_begin__ = 1312;
                            if (as_bool(logical_lte(SSfun,2))) {

                                current_statement_begin__ = 1313;
                                if (as_bool(logical_eq(SSfun,1))) {
                                    current_statement_begin__ = 1313;
                                    stan::math::assign(eta_nlmer, SS_asymp(input,P, pstream__));
                                } else {
                                    current_statement_begin__ = 1314;
                                    stan::math::assign(eta_nlmer, SS_asympOff(input,P, pstream__));
                                }
                            } else if (as_bool(logical_eq(SSfun,3))) {
                                current_statement_begin__ = 1316;
                                stan::math::assign(eta_nlmer, SS_asympOrig(input,P, pstream__));
                            } else {
                                current_statement_begin__ = 1317;
                                stan::math::assign(eta_nlmer, SS_biexp(input,P, pstream__));
                            }
                        } else {

                            current_statement_begin__ = 1320;
                            if (as_bool(logical_lte(SSfun,7))) {

                                current_statement_begin__ = 1321;
                                if (as_bool(logical_eq(SSfun,5))) {
                                    current_statement_begin__ = 1321;
                                    stan::math::assign(eta_nlmer, SS_fol(Dose,input,P, pstream__));
                                } else if (as_bool(logical_eq(SSfun,6))) {
                                    current_statement_begin__ = 1322;
                                    stan::math::assign(eta_nlmer, SS_fpl(input,P, pstream__));
                                } else {
                                    current_statement_begin__ = 1323;
                                    stan::math::assign(eta_nlmer, SS_gompertz(input,P, pstream__));
                                }
                            } else {

                                current_statement_begin__ = 1326;
                                if (as_bool(logical_eq(SSfun,8))) {
                                    current_statement_begin__ = 1326;
                                    stan::math::assign(eta_nlmer, SS_logis(input,P, pstream__));
                                } else if (as_bool(logical_eq(SSfun,9))) {
                                    current_statement_begin__ = 1327;
                                    stan::math::assign(eta_nlmer, SS_micmen(input,P, pstream__));
                                } else {
                                    current_statement_begin__ = 1328;
                                    stan::math::assign(eta_nlmer, SS_weibull(input,P, pstream__));
                                }
                            }
                        }
                        current_statement_begin__ = 1331;
                        for (int n = 1; n <= len_y; ++n) {
                            current_statement_begin__ = 1331;
                            stan::math::assign(mean_PPD, (mean_PPD + normal_rng(get_base1(eta_nlmer,n,"eta_nlmer",1),aux, base_rng__)));
                        }
                    }
                } else if (as_bool(logical_eq(family,1))) {

                    current_statement_begin__ = 1334;
                    if (as_bool(logical_gt(link,1))) {
                        current_statement_begin__ = 1334;
                        stan::math::assign(eta, linkinv_gauss(eta,link, pstream__));
                    }
                    current_statement_begin__ = 1335;
                    for (int n = 1; n <= len_y; ++n) {
                        current_statement_begin__ = 1335;
                        stan::math::assign(mean_PPD, (mean_PPD + normal_rng(get_base1(eta,n,"eta",1),aux, base_rng__)));
                    }
                } else if (as_bool(logical_eq(family,2))) {

                    current_statement_begin__ = 1338;
                    if (as_bool(logical_gt(link,1))) {
                        current_statement_begin__ = 1338;
                        stan::math::assign(eta, linkinv_gamma(eta,link, pstream__));
                    }
                    current_statement_begin__ = 1339;
                    for (int n = 1; n <= len_y; ++n) {
                        current_statement_begin__ = 1339;
                        stan::math::assign(mean_PPD, (mean_PPD + gamma_rng(aux,(aux / get_base1(eta,n,"eta",1)), base_rng__)));
                    }
                } else if (as_bool(logical_eq(family,3))) {

                    current_statement_begin__ = 1342;
                    if (as_bool(logical_gt(link,1))) {
                        current_statement_begin__ = 1342;
                        stan::math::assign(eta, linkinv_inv_gaussian(eta,link, pstream__));
                    }
                    current_statement_begin__ = 1343;
                    for (int n = 1; n <= len_y; ++n) {
                        current_statement_begin__ = 1343;
                        stan::math::assign(mean_PPD, (mean_PPD + inv_gaussian_rng(get_base1(eta,n,"eta",1),aux, base_rng__, pstream__)));
                    }
                } else if (as_bool((primitive_value(logical_eq(family,4)) && primitive_value(logical_eq(link_phi,0))))) {

                    current_statement_begin__ = 1346;
                    stan::math::assign(eta, linkinv_beta(eta,link, pstream__));
                    current_statement_begin__ = 1347;
                    for (int n = 1; n <= N; ++n) {
                        {
                            double eta_n(0.0);
                            (void) eta_n;  // dummy to suppress unused var warning

                            stan::math::initialize(eta_n, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(eta_n,DUMMY_VAR__);
                            stan::math::assign(eta_n,get_base1(eta,n,"eta",1));


                            current_statement_begin__ = 1349;
                            if (as_bool(logical_lte(aux,0))) {
                                current_statement_begin__ = 1349;
                                stan::math::assign(mean_PPD, (mean_PPD + bernoulli_rng(0.5, base_rng__)));
                            } else if (as_bool(logical_gte(eta_n,1))) {
                                current_statement_begin__ = 1350;
                                stan::math::assign(mean_PPD, (mean_PPD + 1));
                            } else if (as_bool(logical_gt(eta_n,0))) {
                                current_statement_begin__ = 1352;
                                stan::math::assign(mean_PPD, (mean_PPD + beta_rng((get_base1(eta,n,"eta",1) * aux),((1 - get_base1(eta,n,"eta",1)) * aux), base_rng__)));
                            }
                        }
                    }
                } else if (as_bool((primitive_value(logical_eq(family,4)) && primitive_value(logical_gt(link_phi,0))))) {

                    current_statement_begin__ = 1356;
                    stan::math::assign(eta, linkinv_beta(eta,link, pstream__));
                    current_statement_begin__ = 1357;
                    stan::math::assign(eta_z, linkinv_beta_z(eta_z,link_phi, pstream__));
                    current_statement_begin__ = 1358;
                    for (int n = 1; n <= N; ++n) {
                        {
                            double eta_n(0.0);
                            (void) eta_n;  // dummy to suppress unused var warning

                            stan::math::initialize(eta_n, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(eta_n,DUMMY_VAR__);
                            stan::math::assign(eta_n,get_base1(eta,n,"eta",1));
                            double aux_n(0.0);
                            (void) aux_n;  // dummy to suppress unused var warning

                            stan::math::initialize(aux_n, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(aux_n,DUMMY_VAR__);
                            stan::math::assign(aux_n,get_base1(eta_z,n,"eta_z",1));


                            current_statement_begin__ = 1361;
                            if (as_bool(logical_lte(aux_n,0))) {
                                current_statement_begin__ = 1361;
                                stan::math::assign(mean_PPD, (mean_PPD + bernoulli_rng(0.5, base_rng__)));
                            } else if (as_bool(logical_gte(eta_n,1))) {
                                current_statement_begin__ = 1362;
                                stan::math::assign(mean_PPD, (mean_PPD + 1));
                            } else if (as_bool(logical_gt(eta_n,0))) {
                                current_statement_begin__ = 1364;
                                stan::math::assign(mean_PPD, (mean_PPD + beta_rng((eta_n * aux_n),((1 - eta_n) * aux_n), base_rng__)));
                            }
                        }
                    }
                }
                current_statement_begin__ = 1367;
                stan::math::assign(mean_PPD, (mean_PPD / len_y));
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        // validate generated quantities

        // write generated quantities
        for (int k_0__ = 0; k_0__ < has_intercept; ++k_0__) {
            vars__.push_back(alpha[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < has_intercept_z; ++k_0__) {
            vars__.push_back(omega_int[k_0__]);
        }
        vars__.push_back(mean_PPD);

    }

    template <typename RNG>
    void write_array(RNG& base_rng,
                     Eigen::Matrix<double,Eigen::Dynamic,1>& params_r,
                     Eigen::Matrix<double,Eigen::Dynamic,1>& vars,
                     bool include_tparams = true,
                     bool include_gqs = true,
                     std::ostream* pstream = 0) const {
      std::vector<double> params_r_vec(params_r.size());
      for (int i = 0; i < params_r.size(); ++i)
        params_r_vec[i] = params_r(i);
      std::vector<double> vars_vec;
      std::vector<int> params_i_vec;
      write_array(base_rng,params_r_vec,params_i_vec,vars_vec,include_tparams,include_gqs,pstream);
      vars.resize(vars_vec.size());
      for (int i = 0; i < vars.size(); ++i)
        vars(i) = vars_vec[i];
    }

    static std::string model_name() {
        return "model_continuous";
    }


    void constrained_param_names(std::vector<std::string>& param_names__,
                                 bool include_tparams__ = true,
                                 bool include_gqs__ = true) const {
        std::stringstream param_name_stream__;
        for (int k_0__ = 1; k_0__ <= has_intercept; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "gamma" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (logical_eq(prior_dist,7) ? sum(num_normals) : K ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_beta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= K_smooth; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_beta_smooth" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "smooth_sd_raw" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= hs; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "global" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_1__ = 1; k_1__ <= K; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= hs; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "local" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        for (int k_1__ = 1; k_1__ <= K; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))); ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "mix" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        for (int k_0__ = 1; k_0__ <= logical_eq(prior_dist,6); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "one_over_lambda" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= q; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_b" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_z_T; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_T" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_rho; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "rho" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_concentration; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "zeta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= t; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "tau" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        param_name_stream__.str(std::string());
        param_name_stream__ << "aux_unscaled";
        param_names__.push_back(param_name_stream__.str());
        for (int k_0__ = 1; k_0__ <= (logical_eq(prior_dist_z,7) ? sum(num_normals_z) : z_dim ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_omega" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= has_intercept_z; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "gamma_z" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= hs_z; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "global_z" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_1__ = 1; k_1__ <= z_dim; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= hs_z; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "local_z" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        for (int k_1__ = 1; k_1__ <= z_dim; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= (primitive_value(logical_eq(prior_dist_z,5)) || primitive_value(logical_eq(prior_dist_z,6))); ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "S_z" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        for (int k_0__ = 1; k_0__ <= logical_eq(prior_dist_z,6); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "one_over_lambda_z" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__ && !include_tparams__) return;
        param_name_stream__.str(std::string());
        param_name_stream__ << "aux";
        param_names__.push_back(param_name_stream__.str());
        for (int k_0__ = 1; k_0__ <= z_dim; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "omega" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= K; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "beta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= K_smooth; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "beta_smooth" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "smooth_sd" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= q; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "b" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_theta_L; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "theta_L" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__) return;
        for (int k_0__ = 1; k_0__ <= has_intercept; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "alpha" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= has_intercept_z; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "omega_int" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        param_name_stream__.str(std::string());
        param_name_stream__ << "mean_PPD";
        param_names__.push_back(param_name_stream__.str());
    }


    void unconstrained_param_names(std::vector<std::string>& param_names__,
                                   bool include_tparams__ = true,
                                   bool include_gqs__ = true) const {
        std::stringstream param_name_stream__;
        for (int k_0__ = 1; k_0__ <= has_intercept; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "gamma" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (logical_eq(prior_dist,7) ? sum(num_normals) : K ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_beta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= K_smooth; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_beta_smooth" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "smooth_sd_raw" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= hs; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "global" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_1__ = 1; k_1__ <= K; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= hs; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "local" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        for (int k_1__ = 1; k_1__ <= K; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))); ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "mix" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        for (int k_0__ = 1; k_0__ <= logical_eq(prior_dist,6); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "one_over_lambda" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= q; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_b" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_z_T; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_T" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_rho; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "rho" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_concentration; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "zeta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= t; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "tau" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        param_name_stream__.str(std::string());
        param_name_stream__ << "aux_unscaled";
        param_names__.push_back(param_name_stream__.str());
        for (int k_0__ = 1; k_0__ <= (logical_eq(prior_dist_z,7) ? sum(num_normals_z) : z_dim ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_omega" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= has_intercept_z; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "gamma_z" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= hs_z; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "global_z" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_1__ = 1; k_1__ <= z_dim; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= hs_z; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "local_z" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        for (int k_1__ = 1; k_1__ <= z_dim; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= (primitive_value(logical_eq(prior_dist_z,5)) || primitive_value(logical_eq(prior_dist_z,6))); ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "S_z" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        for (int k_0__ = 1; k_0__ <= logical_eq(prior_dist_z,6); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "one_over_lambda_z" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__ && !include_tparams__) return;
        param_name_stream__.str(std::string());
        param_name_stream__ << "aux";
        param_names__.push_back(param_name_stream__.str());
        for (int k_0__ = 1; k_0__ <= z_dim; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "omega" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= K; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "beta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= K_smooth; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "beta_smooth" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "smooth_sd" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= q; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "b" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_theta_L; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "theta_L" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__) return;
        for (int k_0__ = 1; k_0__ <= has_intercept; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "alpha" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= has_intercept_z; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "omega_int" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        param_name_stream__.str(std::string());
        param_name_stream__ << "mean_PPD";
        param_names__.push_back(param_name_stream__.str());
    }

}; // model

}




// Code generated by Stan version 2.16.0

#include <stan/model/model_header.hpp>

namespace model_count_namespace {

using std::istream;
using std::string;
using std::stringstream;
using std::vector;
using stan::io::dump;
using stan::math::lgamma;
using stan::model::prob_grad;
using namespace stan::math;

typedef Eigen::Matrix<double,Eigen::Dynamic,1> vector_d;
typedef Eigen::Matrix<double,1,Eigen::Dynamic> row_vector_d;
typedef Eigen::Matrix<double,Eigen::Dynamic,Eigen::Dynamic> matrix_d;

static int current_statement_begin__;

stan::io::program_reader prog_reader__() {
    stan::io::program_reader reader;
    reader.add_event(0, 0, "start", "model_count");
    reader.add_event(735, 735, "end", "model_count");
    return reader;
}

template <typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T7__>
Eigen::Matrix<typename boost::math::tools::promote_args<T2__, T3__, T4__, T5__, typename boost::math::tools::promote_args<T6__, T7__>::type>::type, Eigen::Dynamic,1>
make_theta_L(const int& len_theta_L,
                 const std::vector<int>& p,
                 const T2__& dispersion,
                 const Eigen::Matrix<T3__, Eigen::Dynamic,1>& tau,
                 const Eigen::Matrix<T4__, Eigen::Dynamic,1>& scale,
                 const Eigen::Matrix<T5__, Eigen::Dynamic,1>& zeta,
                 const Eigen::Matrix<T6__, Eigen::Dynamic,1>& rho,
                 const Eigen::Matrix<T7__, Eigen::Dynamic,1>& z_T, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T2__, T3__, T4__, T5__, typename boost::math::tools::promote_args<T6__, T7__>::type>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            validate_non_negative_index("theta_L", "len_theta_L", len_theta_L);
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  theta_L(static_cast<Eigen::VectorXd::Index>(len_theta_L));
            (void) theta_L;  // dummy to suppress unused var warning

            stan::math::initialize(theta_L, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(theta_L,DUMMY_VAR__);
            int zeta_mark(0);
            (void) zeta_mark;  // dummy to suppress unused var warning

            stan::math::fill(zeta_mark, std::numeric_limits<int>::min());
            stan::math::assign(zeta_mark,1);
            int rho_mark(0);
            (void) rho_mark;  // dummy to suppress unused var warning

            stan::math::fill(rho_mark, std::numeric_limits<int>::min());
            stan::math::assign(rho_mark,1);
            int z_T_mark(0);
            (void) z_T_mark;  // dummy to suppress unused var warning

            stan::math::fill(z_T_mark, std::numeric_limits<int>::min());
            stan::math::assign(z_T_mark,1);
            int theta_L_mark(0);
            (void) theta_L_mark;  // dummy to suppress unused var warning

            stan::math::fill(theta_L_mark, std::numeric_limits<int>::min());
            stan::math::assign(theta_L_mark,1);


            current_statement_begin__ = 52;
            for (int i = 1; i <= size(p); ++i) {
                {
                    int nc(0);
                    (void) nc;  // dummy to suppress unused var warning

                    stan::math::fill(nc, std::numeric_limits<int>::min());
                    stan::math::assign(nc,get_base1(p,i,"p",1));


                    current_statement_begin__ = 54;
                    if (as_bool(logical_eq(nc,1))) {

                        current_statement_begin__ = 55;
                        stan::math::assign(get_base1_lhs(theta_L,theta_L_mark,"theta_L",1), ((get_base1(tau,i,"tau",1) * get_base1(scale,i,"scale",1)) * dispersion));
                        current_statement_begin__ = 57;
                        stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                    } else {
                        {
                            validate_non_negative_index("T_i", "nc", nc);
                            validate_non_negative_index("T_i", "nc", nc);
                            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,Eigen::Dynamic>  T_i(static_cast<Eigen::VectorXd::Index>(nc),static_cast<Eigen::VectorXd::Index>(nc));
                            (void) T_i;  // dummy to suppress unused var warning

                            stan::math::initialize(T_i, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(T_i,DUMMY_VAR__);
                            fun_scalar_t__ std_dev;
                            (void) std_dev;  // dummy to suppress unused var warning

                            stan::math::initialize(std_dev, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(std_dev,DUMMY_VAR__);
                            fun_scalar_t__ T21;
                            (void) T21;  // dummy to suppress unused var warning

                            stan::math::initialize(T21, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(T21,DUMMY_VAR__);
                            fun_scalar_t__ trace_T_i;
                            (void) trace_T_i;  // dummy to suppress unused var warning

                            stan::math::initialize(trace_T_i, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(trace_T_i,DUMMY_VAR__);
                            stan::math::assign(trace_T_i,(square(((get_base1(tau,i,"tau",1) * get_base1(scale,i,"scale",1)) * dispersion)) * nc));
                            validate_non_negative_index("pi", "nc", nc);
                            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  pi(static_cast<Eigen::VectorXd::Index>(nc));
                            (void) pi;  // dummy to suppress unused var warning

                            stan::math::initialize(pi, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(pi,DUMMY_VAR__);
                            stan::math::assign(pi,segment(zeta,zeta_mark,nc));


                            current_statement_begin__ = 65;
                            stan::math::assign(pi, divide(pi,sum(pi)));
                            current_statement_begin__ = 68;
                            stan::math::assign(zeta_mark, (zeta_mark + nc));
                            current_statement_begin__ = 69;
                            stan::math::assign(std_dev, sqrt((get_base1(pi,1,"pi",1) * trace_T_i)));
                            current_statement_begin__ = 70;
                            stan::math::assign(get_base1_lhs(T_i,1,1,"T_i",1), std_dev);
                            current_statement_begin__ = 73;
                            stan::math::assign(std_dev, sqrt((get_base1(pi,2,"pi",1) * trace_T_i)));
                            current_statement_begin__ = 74;
                            stan::math::assign(T21, ((2.0 * get_base1(rho,rho_mark,"rho",1)) - 1.0));
                            current_statement_begin__ = 75;
                            stan::math::assign(rho_mark, (rho_mark + 1));
                            current_statement_begin__ = 76;
                            stan::math::assign(get_base1_lhs(T_i,2,2,"T_i",1), (std_dev * sqrt((1.0 - square(T21)))));
                            current_statement_begin__ = 77;
                            stan::math::assign(get_base1_lhs(T_i,2,1,"T_i",1), (std_dev * T21));
                            current_statement_begin__ = 79;
                            for (int r = 2; r <= (nc - 1); ++r) {
                                {
                                    int rp1(0);
                                    (void) rp1;  // dummy to suppress unused var warning

                                    stan::math::fill(rp1, std::numeric_limits<int>::min());
                                    stan::math::assign(rp1,(r + 1));
                                    validate_non_negative_index("T_row", "r", r);
                                    Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  T_row(static_cast<Eigen::VectorXd::Index>(r));
                                    (void) T_row;  // dummy to suppress unused var warning

                                    stan::math::initialize(T_row, std::numeric_limits<double>::quiet_NaN());
                                    stan::math::fill(T_row,DUMMY_VAR__);
                                    stan::math::assign(T_row,segment(z_T,z_T_mark,r));
                                    fun_scalar_t__ scale_factor;
                                    (void) scale_factor;  // dummy to suppress unused var warning

                                    stan::math::initialize(scale_factor, std::numeric_limits<double>::quiet_NaN());
                                    stan::math::fill(scale_factor,DUMMY_VAR__);
                                    stan::math::assign(scale_factor,(sqrt((get_base1(rho,rho_mark,"rho",1) / dot_self(T_row))) * std_dev));


                                    current_statement_begin__ = 83;
                                    stan::math::assign(z_T_mark, (z_T_mark + r));
                                    current_statement_begin__ = 84;
                                    stan::math::assign(std_dev, sqrt((get_base1(pi,rp1,"pi",1) * trace_T_i)));
                                    current_statement_begin__ = 85;
                                    for (int c = 1; c <= r; ++c) {
                                        current_statement_begin__ = 85;
                                        stan::math::assign(get_base1_lhs(T_i,rp1,c,"T_i",1), (get_base1(T_row,c,"T_row",1) * scale_factor));
                                    }
                                    current_statement_begin__ = 86;
                                    stan::math::assign(get_base1_lhs(T_i,rp1,rp1,"T_i",1), (sqrt((1.0 - get_base1(rho,rho_mark,"rho",1))) * std_dev));
                                    current_statement_begin__ = 87;
                                    stan::math::assign(rho_mark, (rho_mark + 1));
                                }
                            }
                            current_statement_begin__ = 91;
                            for (int c = 1; c <= nc; ++c) {
                                current_statement_begin__ = 91;
                                for (int r = c; r <= nc; ++r) {

                                    current_statement_begin__ = 92;
                                    stan::math::assign(get_base1_lhs(theta_L,theta_L_mark,"theta_L",1), get_base1(T_i,r,c,"T_i",1));
                                    current_statement_begin__ = 93;
                                    stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                                }
                            }
                        }
                    }
                }
            }
            current_statement_begin__ = 97;
            return stan::math::promote_scalar<fun_return_scalar_t__>(theta_L);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct make_theta_L_functor__ {
    template <typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T7__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T2__, T3__, T4__, T5__, typename boost::math::tools::promote_args<T6__, T7__>::type>::type, Eigen::Dynamic,1>
    operator()(const int& len_theta_L,
                 const std::vector<int>& p,
                 const T2__& dispersion,
                 const Eigen::Matrix<T3__, Eigen::Dynamic,1>& tau,
                 const Eigen::Matrix<T4__, Eigen::Dynamic,1>& scale,
                 const Eigen::Matrix<T5__, Eigen::Dynamic,1>& zeta,
                 const Eigen::Matrix<T6__, Eigen::Dynamic,1>& rho,
                 const Eigen::Matrix<T7__, Eigen::Dynamic,1>& z_T, std::ostream* pstream__) const {
        return make_theta_L(len_theta_L, p, dispersion, tau, scale, zeta, rho, z_T, pstream__);
    }
};

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
make_b(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_b,
           const Eigen::Matrix<T1__, Eigen::Dynamic,1>& theta_L,
           const std::vector<int>& p,
           const std::vector<int>& l, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            validate_non_negative_index("b", "rows(z_b)", rows(z_b));
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  b(static_cast<Eigen::VectorXd::Index>(rows(z_b)));
            (void) b;  // dummy to suppress unused var warning

            stan::math::initialize(b, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(b,DUMMY_VAR__);
            int b_mark(0);
            (void) b_mark;  // dummy to suppress unused var warning

            stan::math::fill(b_mark, std::numeric_limits<int>::min());
            stan::math::assign(b_mark,1);
            int theta_L_mark(0);
            (void) theta_L_mark;  // dummy to suppress unused var warning

            stan::math::fill(theta_L_mark, std::numeric_limits<int>::min());
            stan::math::assign(theta_L_mark,1);


            current_statement_begin__ = 115;
            for (int i = 1; i <= size(p); ++i) {
                {
                    int nc(0);
                    (void) nc;  // dummy to suppress unused var warning

                    stan::math::fill(nc, std::numeric_limits<int>::min());
                    stan::math::assign(nc,get_base1(p,i,"p",1));


                    current_statement_begin__ = 117;
                    if (as_bool(logical_eq(nc,1))) {
                        {
                            fun_scalar_t__ theta_L_start;
                            (void) theta_L_start;  // dummy to suppress unused var warning

                            stan::math::initialize(theta_L_start, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(theta_L_start,DUMMY_VAR__);
                            stan::math::assign(theta_L_start,get_base1(theta_L,theta_L_mark,"theta_L",1));


                            current_statement_begin__ = 119;
                            for (int s = b_mark; s <= ((b_mark + get_base1(l,i,"l",1)) - 1); ++s) {
                                current_statement_begin__ = 120;
                                stan::math::assign(get_base1_lhs(b,s,"b",1), (theta_L_start * get_base1(z_b,s,"z_b",1)));
                            }
                            current_statement_begin__ = 121;
                            stan::math::assign(b_mark, (b_mark + get_base1(l,i,"l",1)));
                            current_statement_begin__ = 122;
                            stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                        }
                    } else {
                        {
                            validate_non_negative_index("T_i", "nc", nc);
                            validate_non_negative_index("T_i", "nc", nc);
                            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,Eigen::Dynamic>  T_i(static_cast<Eigen::VectorXd::Index>(nc),static_cast<Eigen::VectorXd::Index>(nc));
                            (void) T_i;  // dummy to suppress unused var warning

                            stan::math::initialize(T_i, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(T_i,DUMMY_VAR__);
                            stan::math::assign(T_i,rep_matrix(0,nc,nc));


                            current_statement_begin__ = 126;
                            for (int c = 1; c <= nc; ++c) {

                                current_statement_begin__ = 127;
                                stan::math::assign(get_base1_lhs(T_i,c,c,"T_i",1), get_base1(theta_L,theta_L_mark,"theta_L",1));
                                current_statement_begin__ = 128;
                                stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                                current_statement_begin__ = 129;
                                for (int r = (c + 1); r <= nc; ++r) {

                                    current_statement_begin__ = 130;
                                    stan::math::assign(get_base1_lhs(T_i,r,c,"T_i",1), get_base1(theta_L,theta_L_mark,"theta_L",1));
                                    current_statement_begin__ = 131;
                                    stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                                }
                            }
                            current_statement_begin__ = 134;
                            for (int j = 1; j <= get_base1(l,i,"l",1); ++j) {
                                {
                                    validate_non_negative_index("temp", "nc", nc);
                                    Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  temp(static_cast<Eigen::VectorXd::Index>(nc));
                                    (void) temp;  // dummy to suppress unused var warning

                                    stan::math::initialize(temp, std::numeric_limits<double>::quiet_NaN());
                                    stan::math::fill(temp,DUMMY_VAR__);
                                    stan::math::assign(temp,multiply(T_i,segment(z_b,b_mark,nc)));


                                    current_statement_begin__ = 136;
                                    stan::math::assign(b_mark, (b_mark - 1));
                                    current_statement_begin__ = 137;
                                    for (int s = 1; s <= nc; ++s) {
                                        current_statement_begin__ = 137;
                                        stan::math::assign(get_base1_lhs(b,(b_mark + s),"b",1), get_base1(temp,s,"temp",1));
                                    }
                                    current_statement_begin__ = 138;
                                    stan::math::assign(b_mark, ((b_mark + nc) + 1));
                                }
                            }
                        }
                    }
                }
            }
            current_statement_begin__ = 142;
            return stan::math::promote_scalar<fun_return_scalar_t__>(b);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct make_b_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_b,
           const Eigen::Matrix<T1__, Eigen::Dynamic,1>& theta_L,
           const std::vector<int>& p,
           const std::vector<int>& l, std::ostream* pstream__) const {
        return make_b(z_b, theta_L, p, l, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T7__, typename T_lp__, typename T_lp_accum__>
void
decov_lp(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_b,
             const Eigen::Matrix<T1__, Eigen::Dynamic,1>& z_T,
             const Eigen::Matrix<T2__, Eigen::Dynamic,1>& rho,
             const Eigen::Matrix<T3__, Eigen::Dynamic,1>& zeta,
             const Eigen::Matrix<T4__, Eigen::Dynamic,1>& tau,
             const std::vector<T5__>& regularization,
             const std::vector<T6__>& delta,
             const Eigen::Matrix<T7__, Eigen::Dynamic,1>& shape,
             const int& t,
             const std::vector<int>& p, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__, T6__, T7__, T_lp__>::type>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            int pos_reg(0);
            (void) pos_reg;  // dummy to suppress unused var warning

            stan::math::fill(pos_reg, std::numeric_limits<int>::min());
            stan::math::assign(pos_reg,1);
            int pos_rho(0);
            (void) pos_rho;  // dummy to suppress unused var warning

            stan::math::fill(pos_rho, std::numeric_limits<int>::min());
            stan::math::assign(pos_rho,1);


            current_statement_begin__ = 165;
            lp_accum__.add(normal_log(z_b,0,1));
            current_statement_begin__ = 166;
            lp_accum__.add(normal_log(z_T,0,1));
            current_statement_begin__ = 167;
            for (int i = 1; i <= t; ++i) {
                current_statement_begin__ = 167;
                if (as_bool(logical_gt(get_base1(p,i,"p",1),1))) {
                    {
                        validate_non_negative_index("shape1", "(get_base1(p,i,\"p\",1) - 1)", (get_base1(p,i,"p",1) - 1));
                        Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  shape1(static_cast<Eigen::VectorXd::Index>((get_base1(p,i,"p",1) - 1)));
                        (void) shape1;  // dummy to suppress unused var warning

                        stan::math::initialize(shape1, std::numeric_limits<double>::quiet_NaN());
                        stan::math::fill(shape1,DUMMY_VAR__);
                        validate_non_negative_index("shape2", "(get_base1(p,i,\"p\",1) - 1)", (get_base1(p,i,"p",1) - 1));
                        Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  shape2(static_cast<Eigen::VectorXd::Index>((get_base1(p,i,"p",1) - 1)));
                        (void) shape2;  // dummy to suppress unused var warning

                        stan::math::initialize(shape2, std::numeric_limits<double>::quiet_NaN());
                        stan::math::fill(shape2,DUMMY_VAR__);
                        fun_scalar_t__ nu;
                        (void) nu;  // dummy to suppress unused var warning

                        stan::math::initialize(nu, std::numeric_limits<double>::quiet_NaN());
                        stan::math::fill(nu,DUMMY_VAR__);
                        stan::math::assign(nu,(get_base1(regularization,pos_reg,"regularization",1) + (0.5 * (get_base1(p,i,"p",1) - 2))));


                        current_statement_begin__ = 171;
                        stan::math::assign(pos_reg, (pos_reg + 1));
                        current_statement_begin__ = 172;
                        stan::math::assign(get_base1_lhs(shape1,1,"shape1",1), nu);
                        current_statement_begin__ = 173;
                        stan::math::assign(get_base1_lhs(shape2,1,"shape2",1), nu);
                        current_statement_begin__ = 174;
                        for (int j = 2; j <= (get_base1(p,i,"p",1) - 1); ++j) {

                            current_statement_begin__ = 175;
                            stan::math::assign(nu, (nu - 0.5));
                            current_statement_begin__ = 176;
                            stan::math::assign(get_base1_lhs(shape1,j,"shape1",1), (0.5 * j));
                            current_statement_begin__ = 177;
                            stan::math::assign(get_base1_lhs(shape2,j,"shape2",1), nu);
                        }
                        current_statement_begin__ = 179;
                        lp_accum__.add(beta_log(stan::model::rvalue(rho, stan::model::cons_list(stan::model::index_min_max(pos_rho, ((pos_rho + get_base1(p,i,"p",1)) - 2)), stan::model::nil_index_list()), "rho"),shape1,shape2));
                        current_statement_begin__ = 180;
                        stan::math::assign(pos_rho, ((pos_rho + get_base1(p,i,"p",1)) - 1));
                    }
                }
            }
            current_statement_begin__ = 182;
            lp_accum__.add(gamma_log(zeta,delta,1));
            current_statement_begin__ = 183;
            lp_accum__.add(gamma_log(tau,shape,1));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct decov_lp_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T7__, typename T_lp__, typename T_lp_accum__>
        void
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_b,
             const Eigen::Matrix<T1__, Eigen::Dynamic,1>& z_T,
             const Eigen::Matrix<T2__, Eigen::Dynamic,1>& rho,
             const Eigen::Matrix<T3__, Eigen::Dynamic,1>& zeta,
             const Eigen::Matrix<T4__, Eigen::Dynamic,1>& tau,
             const std::vector<T5__>& regularization,
             const std::vector<T6__>& delta,
             const Eigen::Matrix<T7__, Eigen::Dynamic,1>& shape,
             const int& t,
             const std::vector<int>& p, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) const {
        return decov_lp(z_b, z_T, rho, zeta, tau, regularization, delta, shape, t, p, lp__, lp_accum__, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type, Eigen::Dynamic,1>
hs_prior(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_beta,
             const std::vector<T1__>& global,
             const std::vector<Eigen::Matrix<T2__, Eigen::Dynamic,1> >& local,
             const T3__& global_prior_scale,
             const T4__& error_scale, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            validate_non_negative_index("lambda", "rows(z_beta)", rows(z_beta));
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  lambda(static_cast<Eigen::VectorXd::Index>(rows(z_beta)));
            (void) lambda;  // dummy to suppress unused var warning

            stan::math::initialize(lambda, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(lambda,DUMMY_VAR__);
            int K(0);
            (void) K;  // dummy to suppress unused var warning

            stan::math::fill(K, std::numeric_limits<int>::min());


            current_statement_begin__ = 200;
            stan::math::assign(K, rows(z_beta));
            current_statement_begin__ = 201;
            for (int k = 1; k <= K; ++k) {
                current_statement_begin__ = 201;
                stan::math::assign(get_base1_lhs(lambda,k,"lambda",1), (get_base1(get_base1(local,1,"local",1),k,"local",2) * sqrt(get_base1(get_base1(local,2,"local",1),k,"local",2))));
            }
            current_statement_begin__ = 202;
            return stan::math::promote_scalar<fun_return_scalar_t__>(multiply(multiply(multiply(multiply(elt_multiply(z_beta,lambda),get_base1(global,1,"global",1)),sqrt(get_base1(global,2,"global",1))),global_prior_scale),error_scale));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct hs_prior_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_beta,
             const std::vector<T1__>& global,
             const std::vector<Eigen::Matrix<T2__, Eigen::Dynamic,1> >& local,
             const T3__& global_prior_scale,
             const T4__& error_scale, std::ostream* pstream__) const {
        return hs_prior(z_beta, global, local, global_prior_scale, error_scale, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type, Eigen::Dynamic,1>
hsplus_prior(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_beta,
                 const std::vector<T1__>& global,
                 const std::vector<Eigen::Matrix<T2__, Eigen::Dynamic,1> >& local,
                 const T3__& global_prior_scale,
                 const T4__& error_scale, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 218;
        return stan::math::promote_scalar<fun_return_scalar_t__>(multiply(multiply(multiply(multiply(elt_multiply(elt_multiply(z_beta,elt_multiply(get_base1(local,1,"local",1),sqrt(get_base1(local,2,"local",1)))),elt_multiply(get_base1(local,3,"local",1),sqrt(get_base1(local,4,"local",1)))),get_base1(global,1,"global",1)),sqrt(get_base1(global,2,"global",1))),global_prior_scale),error_scale));
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct hsplus_prior_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_beta,
                 const std::vector<T1__>& global,
                 const std::vector<Eigen::Matrix<T2__, Eigen::Dynamic,1> >& local,
                 const T3__& global_prior_scale,
                 const T4__& error_scale, std::ostream* pstream__) const {
        return hsplus_prior(z_beta, global, local, global_prior_scale, error_scale, pstream__);
    }
};

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
divide_real_by_vector(const T0__& x,
                          const Eigen::Matrix<T1__, Eigen::Dynamic,1>& y, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            int K(0);
            (void) K;  // dummy to suppress unused var warning

            stan::math::fill(K, std::numeric_limits<int>::min());
            stan::math::assign(K,rows(y));
            validate_non_negative_index("ret", "K", K);
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  ret(static_cast<Eigen::VectorXd::Index>(K));
            (void) ret;  // dummy to suppress unused var warning

            stan::math::initialize(ret, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(ret,DUMMY_VAR__);


            current_statement_begin__ = 233;
            for (int k = 1; k <= K; ++k) {
                current_statement_begin__ = 233;
                stan::math::assign(get_base1_lhs(ret,k,"ret",1), (x / get_base1(y,k,"y",1)));
            }
            current_statement_begin__ = 234;
            return stan::math::promote_scalar<fun_return_scalar_t__>(ret);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct divide_real_by_vector_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
    operator()(const T0__& x,
                          const Eigen::Matrix<T1__, Eigen::Dynamic,1>& y, std::ostream* pstream__) const {
        return divide_real_by_vector(x, y, pstream__);
    }
};

template <typename T0__, typename T1__>
typename boost::math::tools::promote_args<T0__, T1__>::type
CFt(const T0__& z,
        const T1__& df, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            fun_scalar_t__ z2;
            (void) z2;  // dummy to suppress unused var warning

            stan::math::initialize(z2, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(z2,DUMMY_VAR__);
            stan::math::assign(z2,square(z));
            fun_scalar_t__ z3;
            (void) z3;  // dummy to suppress unused var warning

            stan::math::initialize(z3, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(z3,DUMMY_VAR__);
            stan::math::assign(z3,(z2 * z));
            fun_scalar_t__ z5;
            (void) z5;  // dummy to suppress unused var warning

            stan::math::initialize(z5, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(z5,DUMMY_VAR__);
            stan::math::assign(z5,(z2 * z3));
            fun_scalar_t__ z7;
            (void) z7;  // dummy to suppress unused var warning

            stan::math::initialize(z7, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(z7,DUMMY_VAR__);
            stan::math::assign(z7,(z2 * z5));
            fun_scalar_t__ z9;
            (void) z9;  // dummy to suppress unused var warning

            stan::math::initialize(z9, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(z9,DUMMY_VAR__);
            stan::math::assign(z9,(z2 * z7));
            fun_scalar_t__ df2;
            (void) df2;  // dummy to suppress unused var warning

            stan::math::initialize(df2, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(df2,DUMMY_VAR__);
            stan::math::assign(df2,square(df));
            fun_scalar_t__ df3;
            (void) df3;  // dummy to suppress unused var warning

            stan::math::initialize(df3, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(df3,DUMMY_VAR__);
            stan::math::assign(df3,(df2 * df));
            fun_scalar_t__ df4;
            (void) df4;  // dummy to suppress unused var warning

            stan::math::initialize(df4, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(df4,DUMMY_VAR__);
            stan::math::assign(df4,(df2 * df2));


            current_statement_begin__ = 256;
            return stan::math::promote_scalar<fun_return_scalar_t__>(((((z + ((z3 + z) / (4 * df))) + ((((5 * z5) + (16 * z3)) + (3 * z)) / (96 * df2))) + (((((3 * z7) + (19 * z5)) + (17 * z3)) - (15 * z)) / (384 * df3))) + ((((((79 * z9) + (776 * z7)) + (1482 * z5)) - (1920 * z3)) - (945 * z)) / (92160 * df4))));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct CFt_functor__ {
    template <typename T0__, typename T1__>
        typename boost::math::tools::promote_args<T0__, T1__>::type
    operator()(const T0__& z,
        const T1__& df, std::ostream* pstream__) const {
        return CFt(z, df, pstream__);
    }
};

std::vector<std::vector<int> >
make_V(const int& N,
           const int& t,
           const std::vector<int>& v, std::ostream* pstream__) {
    typedef double fun_scalar_t__;
    typedef int fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            validate_non_negative_index("V", "t", t);
            validate_non_negative_index("V", "N", N);
            vector<vector<int> > V(t, (vector<int>(N, 0)));
            stan::math::fill(V, std::numeric_limits<int>::min());
            int pos(0);
            (void) pos;  // dummy to suppress unused var warning

            stan::math::fill(pos, std::numeric_limits<int>::min());
            stan::math::assign(pos,1);


            current_statement_begin__ = 271;
            if (as_bool(logical_gt(t,0))) {
                current_statement_begin__ = 271;
                for (int j = 1; j <= N; ++j) {
                    current_statement_begin__ = 271;
                    for (int i = 1; i <= t; ++i) {

                        current_statement_begin__ = 272;
                        stan::math::assign(get_base1_lhs(get_base1_lhs(V,i,"V",1),j,"V",2), get_base1(v,pos,"v",1));
                        current_statement_begin__ = 273;
                        stan::math::assign(pos, (pos + 1));
                    }
                }
            }
            current_statement_begin__ = 275;
            return stan::math::promote_scalar<fun_return_scalar_t__>(V);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct make_V_functor__ {
            std::vector<std::vector<int> >
    operator()(const int& N,
           const int& t,
           const std::vector<int>& v, std::ostream* pstream__) const {
        return make_V(N, t, v, pstream__);
    }
};

template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
linkinv_count(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                  const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 288;
        if (as_bool(logical_eq(link,1))) {
            current_statement_begin__ = 288;
            return stan::math::promote_scalar<fun_return_scalar_t__>(exp(eta));
        } else if (as_bool(logical_eq(link,2))) {
            current_statement_begin__ = 289;
            return stan::math::promote_scalar<fun_return_scalar_t__>(eta);
        } else if (as_bool(logical_eq(link,3))) {
            current_statement_begin__ = 290;
            return stan::math::promote_scalar<fun_return_scalar_t__>(square(eta));
        } else {
            current_statement_begin__ = 291;
            std::stringstream errmsg_stream__;
            errmsg_stream__ << "Invalid link";
            throw std::domain_error(errmsg_stream__.str());
        }
        current_statement_begin__ = 291;
        current_statement_begin__ = 292;
        return stan::math::promote_scalar<fun_return_scalar_t__>(eta);
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct linkinv_count_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                  const int& link, std::ostream* pstream__) const {
        return linkinv_count(eta, link, pstream__);
    }
};

template <typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T1__>::type, Eigen::Dynamic,1>
pw_pois(const std::vector<int>& y,
            const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
            const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T1__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            int N(0);
            (void) N;  // dummy to suppress unused var warning

            stan::math::fill(N, std::numeric_limits<int>::min());
            stan::math::assign(N,rows(eta));
            validate_non_negative_index("ll", "N", N);
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  ll(static_cast<Eigen::VectorXd::Index>(N));
            (void) ll;  // dummy to suppress unused var warning

            stan::math::initialize(ll, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(ll,DUMMY_VAR__);


            current_statement_begin__ = 306;
            if (as_bool(logical_eq(link,1))) {
                current_statement_begin__ = 307;
                for (int n = 1; n <= N; ++n) {
                    current_statement_begin__ = 307;
                    stan::math::assign(get_base1_lhs(ll,n,"ll",1), poisson_log_log(get_base1(y,n,"y",1),get_base1(eta,n,"eta",1)));
                }
            } else if (as_bool(logical_lte(link,3))) {
                {
                    validate_non_negative_index("phi", "N", N);
                    Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  phi(static_cast<Eigen::VectorXd::Index>(N));
                    (void) phi;  // dummy to suppress unused var warning

                    stan::math::initialize(phi, std::numeric_limits<double>::quiet_NaN());
                    stan::math::fill(phi,DUMMY_VAR__);
                    stan::math::assign(phi,linkinv_count(eta,link, pstream__));


                    current_statement_begin__ = 310;
                    for (int n = 1; n <= N; ++n) {
                        current_statement_begin__ = 310;
                        stan::math::assign(get_base1_lhs(ll,n,"ll",1), poisson_log(get_base1(y,n,"y",1),get_base1(phi,n,"phi",1)));
                    }
                }
            } else {
                current_statement_begin__ = 312;
                std::stringstream errmsg_stream__;
                errmsg_stream__ << "Invalid link";
                throw std::domain_error(errmsg_stream__.str());
            }
            current_statement_begin__ = 312;
            current_statement_begin__ = 313;
            return stan::math::promote_scalar<fun_return_scalar_t__>(ll);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct pw_pois_functor__ {
    template <typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T1__>::type, Eigen::Dynamic,1>
    operator()(const std::vector<int>& y,
            const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
            const int& link, std::ostream* pstream__) const {
        return pw_pois(y, eta, link, pstream__);
    }
};

template <typename T1__, typename T2__>
Eigen::Matrix<typename boost::math::tools::promote_args<T1__, T2__>::type, Eigen::Dynamic,1>
pw_nb(const std::vector<int>& y,
          const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
          const T2__& theta,
          const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T1__, T2__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            int N(0);
            (void) N;  // dummy to suppress unused var warning

            stan::math::fill(N, std::numeric_limits<int>::min());
            stan::math::assign(N,rows(eta));
            validate_non_negative_index("rho", "N", N);
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  rho(static_cast<Eigen::VectorXd::Index>(N));
            (void) rho;  // dummy to suppress unused var warning

            stan::math::initialize(rho, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(rho,DUMMY_VAR__);
            stan::math::assign(rho,linkinv_count(eta,link, pstream__));
            validate_non_negative_index("ll", "N", N);
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  ll(static_cast<Eigen::VectorXd::Index>(N));
            (void) ll;  // dummy to suppress unused var warning

            stan::math::initialize(ll, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(ll,DUMMY_VAR__);


            current_statement_begin__ = 329;
            for (int n = 1; n <= N; ++n) {
                current_statement_begin__ = 329;
                stan::math::assign(get_base1_lhs(ll,n,"ll",1), neg_binomial_2_log(get_base1(y,n,"y",1),get_base1(rho,n,"rho",1),theta));
            }
            current_statement_begin__ = 330;
            return stan::math::promote_scalar<fun_return_scalar_t__>(ll);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct pw_nb_functor__ {
    template <typename T1__, typename T2__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T1__, T2__>::type, Eigen::Dynamic,1>
    operator()(const std::vector<int>& y,
          const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
          const T2__& theta,
          const int& link, std::ostream* pstream__) const {
        return pw_nb(y, eta, theta, link, pstream__);
    }
};

class model_count : public prob_grad {
private:
    int N;
    int K;
    vector_d xbar;
    int dense_X;
    vector<matrix_d> X;
    int nnz_X;
    vector_d w_X;
    vector<int> v_X;
    vector<int> u_X;
    int K_smooth;
    matrix_d S;
    vector<int> smooth_map;
    vector<int> y;
    int prior_PD;
    int has_intercept;
    int family;
    int link;
    int prior_dist;
    int prior_dist_for_intercept;
    int prior_dist_for_aux;
    int prior_dist_for_smooth;
    int has_weights;
    vector_d weights;
    int has_offset;
    vector_d offset;
    vector_d prior_scale;
    double prior_scale_for_intercept;
    double prior_scale_for_aux;
    vector_d prior_scale_for_smooth;
    vector_d prior_mean;
    double prior_mean_for_intercept;
    double prior_mean_for_aux;
    vector_d prior_mean_for_smooth;
    vector_d prior_df;
    double prior_df_for_intercept;
    double prior_df_for_aux;
    vector_d prior_df_for_smooth;
    double global_prior_df;
    double global_prior_scale;
    vector<int> num_normals;
    int t;
    vector<int> p;
    vector<int> l;
    int q;
    int len_theta_L;
    vector_d shape;
    vector_d scale;
    int len_concentration;
    vector<double> concentration;
    int len_regularization;
    vector<double> regularization;
    int num_non_zero;
    vector_d w;
    vector<int> v;
    vector<int> u;
    int special_case;
    double poisson_max;
    vector<vector<int> > V;
    int len_z_T;
    int len_var_group;
    int len_rho;
    int is_continuous;
    int pos;
    vector<double> delta;
    int hs;
public:
    model_count(stan::io::var_context& context__,
        std::ostream* pstream__ = 0)
        : prob_grad(0) {
        ctor_body(context__, 0, pstream__);
    }

    model_count(stan::io::var_context& context__,
        unsigned int random_seed__,
        std::ostream* pstream__ = 0)
        : prob_grad(0) {
        ctor_body(context__, random_seed__, pstream__);
    }

    void ctor_body(stan::io::var_context& context__,
                   unsigned int random_seed__,
                   std::ostream* pstream__) {
        boost::ecuyer1988 base_rng__ =
          stan::services::util::create_rng(random_seed__, 0);
        (void) base_rng__;  // suppress unused var warning

        current_statement_begin__ = -1;

        static const char* function__ = "model_count_namespace::model_count";
        (void) function__;  // dummy to suppress unused var warning
        size_t pos__;
        (void) pos__;  // dummy to suppress unused var warning
        std::vector<int> vals_i__;
        std::vector<double> vals_r__;
        double DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

        // initialize member variables
        context__.validate_dims("data initialization", "N", "int", context__.to_vec());
        N = int(0);
        vals_i__ = context__.vals_i("N");
        pos__ = 0;
        N = vals_i__[pos__++];
        context__.validate_dims("data initialization", "K", "int", context__.to_vec());
        K = int(0);
        vals_i__ = context__.vals_i("K");
        pos__ = 0;
        K = vals_i__[pos__++];
        validate_non_negative_index("xbar", "K", K);
        context__.validate_dims("data initialization", "xbar", "vector_d", context__.to_vec(K));
        validate_non_negative_index("xbar", "K", K);
        xbar = vector_d(static_cast<Eigen::VectorXd::Index>(K));
        vals_r__ = context__.vals_r("xbar");
        pos__ = 0;
        size_t xbar_i_vec_lim__ = K;
        for (size_t i_vec__ = 0; i_vec__ < xbar_i_vec_lim__; ++i_vec__) {
            xbar[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "dense_X", "int", context__.to_vec());
        dense_X = int(0);
        vals_i__ = context__.vals_i("dense_X");
        pos__ = 0;
        dense_X = vals_i__[pos__++];
        validate_non_negative_index("X", "dense_X", dense_X);
        validate_non_negative_index("X", "N", N);
        validate_non_negative_index("X", "K", K);
        context__.validate_dims("data initialization", "X", "matrix_d", context__.to_vec(dense_X,N,K));
        validate_non_negative_index("X", "dense_X", dense_X);
        validate_non_negative_index("X", "N", N);
        validate_non_negative_index("X", "K", K);
        X = std::vector<matrix_d>(dense_X,matrix_d(static_cast<Eigen::VectorXd::Index>(N),static_cast<Eigen::VectorXd::Index>(K)));
        vals_r__ = context__.vals_r("X");
        pos__ = 0;
        size_t X_m_mat_lim__ = N;
        size_t X_n_mat_lim__ = K;
        for (size_t n_mat__ = 0; n_mat__ < X_n_mat_lim__; ++n_mat__) {
            for (size_t m_mat__ = 0; m_mat__ < X_m_mat_lim__; ++m_mat__) {
                size_t X_limit_0__ = dense_X;
                for (size_t i_0__ = 0; i_0__ < X_limit_0__; ++i_0__) {
                    X[i_0__](m_mat__,n_mat__) = vals_r__[pos__++];
            }
            }
        }
        context__.validate_dims("data initialization", "nnz_X", "int", context__.to_vec());
        nnz_X = int(0);
        vals_i__ = context__.vals_i("nnz_X");
        pos__ = 0;
        nnz_X = vals_i__[pos__++];
        validate_non_negative_index("w_X", "nnz_X", nnz_X);
        context__.validate_dims("data initialization", "w_X", "vector_d", context__.to_vec(nnz_X));
        validate_non_negative_index("w_X", "nnz_X", nnz_X);
        w_X = vector_d(static_cast<Eigen::VectorXd::Index>(nnz_X));
        vals_r__ = context__.vals_r("w_X");
        pos__ = 0;
        size_t w_X_i_vec_lim__ = nnz_X;
        for (size_t i_vec__ = 0; i_vec__ < w_X_i_vec_lim__; ++i_vec__) {
            w_X[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("v_X", "nnz_X", nnz_X);
        context__.validate_dims("data initialization", "v_X", "int", context__.to_vec(nnz_X));
        validate_non_negative_index("v_X", "nnz_X", nnz_X);
        v_X = std::vector<int>(nnz_X,int(0));
        vals_i__ = context__.vals_i("v_X");
        pos__ = 0;
        size_t v_X_limit_0__ = nnz_X;
        for (size_t i_0__ = 0; i_0__ < v_X_limit_0__; ++i_0__) {
            v_X[i_0__] = vals_i__[pos__++];
        }
        validate_non_negative_index("u_X", "(dense_X ? 0 : (N + 1) )", (dense_X ? 0 : (N + 1) ));
        context__.validate_dims("data initialization", "u_X", "int", context__.to_vec((dense_X ? 0 : (N + 1) )));
        validate_non_negative_index("u_X", "(dense_X ? 0 : (N + 1) )", (dense_X ? 0 : (N + 1) ));
        u_X = std::vector<int>((dense_X ? 0 : (N + 1) ),int(0));
        vals_i__ = context__.vals_i("u_X");
        pos__ = 0;
        size_t u_X_limit_0__ = (dense_X ? 0 : (N + 1) );
        for (size_t i_0__ = 0; i_0__ < u_X_limit_0__; ++i_0__) {
            u_X[i_0__] = vals_i__[pos__++];
        }
        context__.validate_dims("data initialization", "K_smooth", "int", context__.to_vec());
        K_smooth = int(0);
        vals_i__ = context__.vals_i("K_smooth");
        pos__ = 0;
        K_smooth = vals_i__[pos__++];
        validate_non_negative_index("S", "N", N);
        validate_non_negative_index("S", "K_smooth", K_smooth);
        context__.validate_dims("data initialization", "S", "matrix_d", context__.to_vec(N,K_smooth));
        validate_non_negative_index("S", "N", N);
        validate_non_negative_index("S", "K_smooth", K_smooth);
        S = matrix_d(static_cast<Eigen::VectorXd::Index>(N),static_cast<Eigen::VectorXd::Index>(K_smooth));
        vals_r__ = context__.vals_r("S");
        pos__ = 0;
        size_t S_m_mat_lim__ = N;
        size_t S_n_mat_lim__ = K_smooth;
        for (size_t n_mat__ = 0; n_mat__ < S_n_mat_lim__; ++n_mat__) {
            for (size_t m_mat__ = 0; m_mat__ < S_m_mat_lim__; ++m_mat__) {
                S(m_mat__,n_mat__) = vals_r__[pos__++];
            }
        }
        validate_non_negative_index("smooth_map", "K_smooth", K_smooth);
        context__.validate_dims("data initialization", "smooth_map", "int", context__.to_vec(K_smooth));
        validate_non_negative_index("smooth_map", "K_smooth", K_smooth);
        smooth_map = std::vector<int>(K_smooth,int(0));
        vals_i__ = context__.vals_i("smooth_map");
        pos__ = 0;
        size_t smooth_map_limit_0__ = K_smooth;
        for (size_t i_0__ = 0; i_0__ < smooth_map_limit_0__; ++i_0__) {
            smooth_map[i_0__] = vals_i__[pos__++];
        }
        validate_non_negative_index("y", "N", N);
        context__.validate_dims("data initialization", "y", "int", context__.to_vec(N));
        validate_non_negative_index("y", "N", N);
        y = std::vector<int>(N,int(0));
        vals_i__ = context__.vals_i("y");
        pos__ = 0;
        size_t y_limit_0__ = N;
        for (size_t i_0__ = 0; i_0__ < y_limit_0__; ++i_0__) {
            y[i_0__] = vals_i__[pos__++];
        }
        context__.validate_dims("data initialization", "prior_PD", "int", context__.to_vec());
        prior_PD = int(0);
        vals_i__ = context__.vals_i("prior_PD");
        pos__ = 0;
        prior_PD = vals_i__[pos__++];
        context__.validate_dims("data initialization", "has_intercept", "int", context__.to_vec());
        has_intercept = int(0);
        vals_i__ = context__.vals_i("has_intercept");
        pos__ = 0;
        has_intercept = vals_i__[pos__++];
        context__.validate_dims("data initialization", "family", "int", context__.to_vec());
        family = int(0);
        vals_i__ = context__.vals_i("family");
        pos__ = 0;
        family = vals_i__[pos__++];
        context__.validate_dims("data initialization", "link", "int", context__.to_vec());
        link = int(0);
        vals_i__ = context__.vals_i("link");
        pos__ = 0;
        link = vals_i__[pos__++];
        context__.validate_dims("data initialization", "prior_dist", "int", context__.to_vec());
        prior_dist = int(0);
        vals_i__ = context__.vals_i("prior_dist");
        pos__ = 0;
        prior_dist = vals_i__[pos__++];
        context__.validate_dims("data initialization", "prior_dist_for_intercept", "int", context__.to_vec());
        prior_dist_for_intercept = int(0);
        vals_i__ = context__.vals_i("prior_dist_for_intercept");
        pos__ = 0;
        prior_dist_for_intercept = vals_i__[pos__++];
        context__.validate_dims("data initialization", "prior_dist_for_aux", "int", context__.to_vec());
        prior_dist_for_aux = int(0);
        vals_i__ = context__.vals_i("prior_dist_for_aux");
        pos__ = 0;
        prior_dist_for_aux = vals_i__[pos__++];
        context__.validate_dims("data initialization", "prior_dist_for_smooth", "int", context__.to_vec());
        prior_dist_for_smooth = int(0);
        vals_i__ = context__.vals_i("prior_dist_for_smooth");
        pos__ = 0;
        prior_dist_for_smooth = vals_i__[pos__++];
        context__.validate_dims("data initialization", "has_weights", "int", context__.to_vec());
        has_weights = int(0);
        vals_i__ = context__.vals_i("has_weights");
        pos__ = 0;
        has_weights = vals_i__[pos__++];
        validate_non_negative_index("weights", "(has_weights ? N : 0 )", (has_weights ? N : 0 ));
        context__.validate_dims("data initialization", "weights", "vector_d", context__.to_vec((has_weights ? N : 0 )));
        validate_non_negative_index("weights", "(has_weights ? N : 0 )", (has_weights ? N : 0 ));
        weights = vector_d(static_cast<Eigen::VectorXd::Index>((has_weights ? N : 0 )));
        vals_r__ = context__.vals_r("weights");
        pos__ = 0;
        size_t weights_i_vec_lim__ = (has_weights ? N : 0 );
        for (size_t i_vec__ = 0; i_vec__ < weights_i_vec_lim__; ++i_vec__) {
            weights[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "has_offset", "int", context__.to_vec());
        has_offset = int(0);
        vals_i__ = context__.vals_i("has_offset");
        pos__ = 0;
        has_offset = vals_i__[pos__++];
        validate_non_negative_index("offset", "(has_offset ? N : 0 )", (has_offset ? N : 0 ));
        context__.validate_dims("data initialization", "offset", "vector_d", context__.to_vec((has_offset ? N : 0 )));
        validate_non_negative_index("offset", "(has_offset ? N : 0 )", (has_offset ? N : 0 ));
        offset = vector_d(static_cast<Eigen::VectorXd::Index>((has_offset ? N : 0 )));
        vals_r__ = context__.vals_r("offset");
        pos__ = 0;
        size_t offset_i_vec_lim__ = (has_offset ? N : 0 );
        for (size_t i_vec__ = 0; i_vec__ < offset_i_vec_lim__; ++i_vec__) {
            offset[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("prior_scale", "K", K);
        context__.validate_dims("data initialization", "prior_scale", "vector_d", context__.to_vec(K));
        validate_non_negative_index("prior_scale", "K", K);
        prior_scale = vector_d(static_cast<Eigen::VectorXd::Index>(K));
        vals_r__ = context__.vals_r("prior_scale");
        pos__ = 0;
        size_t prior_scale_i_vec_lim__ = K;
        for (size_t i_vec__ = 0; i_vec__ < prior_scale_i_vec_lim__; ++i_vec__) {
            prior_scale[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "prior_scale_for_intercept", "double", context__.to_vec());
        prior_scale_for_intercept = double(0);
        vals_r__ = context__.vals_r("prior_scale_for_intercept");
        pos__ = 0;
        prior_scale_for_intercept = vals_r__[pos__++];
        context__.validate_dims("data initialization", "prior_scale_for_aux", "double", context__.to_vec());
        prior_scale_for_aux = double(0);
        vals_r__ = context__.vals_r("prior_scale_for_aux");
        pos__ = 0;
        prior_scale_for_aux = vals_r__[pos__++];
        validate_non_negative_index("prior_scale_for_smooth", "(logical_gt(K_smooth,0) ? max(smooth_map) : 0 )", (logical_gt(K_smooth,0) ? max(smooth_map) : 0 ));
        context__.validate_dims("data initialization", "prior_scale_for_smooth", "vector_d", context__.to_vec((logical_gt(K_smooth,0) ? max(smooth_map) : 0 )));
        validate_non_negative_index("prior_scale_for_smooth", "(logical_gt(K_smooth,0) ? max(smooth_map) : 0 )", (logical_gt(K_smooth,0) ? max(smooth_map) : 0 ));
        prior_scale_for_smooth = vector_d(static_cast<Eigen::VectorXd::Index>((logical_gt(K_smooth,0) ? max(smooth_map) : 0 )));
        vals_r__ = context__.vals_r("prior_scale_for_smooth");
        pos__ = 0;
        size_t prior_scale_for_smooth_i_vec_lim__ = (logical_gt(K_smooth,0) ? max(smooth_map) : 0 );
        for (size_t i_vec__ = 0; i_vec__ < prior_scale_for_smooth_i_vec_lim__; ++i_vec__) {
            prior_scale_for_smooth[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("prior_mean", "K", K);
        context__.validate_dims("data initialization", "prior_mean", "vector_d", context__.to_vec(K));
        validate_non_negative_index("prior_mean", "K", K);
        prior_mean = vector_d(static_cast<Eigen::VectorXd::Index>(K));
        vals_r__ = context__.vals_r("prior_mean");
        pos__ = 0;
        size_t prior_mean_i_vec_lim__ = K;
        for (size_t i_vec__ = 0; i_vec__ < prior_mean_i_vec_lim__; ++i_vec__) {
            prior_mean[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "prior_mean_for_intercept", "double", context__.to_vec());
        prior_mean_for_intercept = double(0);
        vals_r__ = context__.vals_r("prior_mean_for_intercept");
        pos__ = 0;
        prior_mean_for_intercept = vals_r__[pos__++];
        context__.validate_dims("data initialization", "prior_mean_for_aux", "double", context__.to_vec());
        prior_mean_for_aux = double(0);
        vals_r__ = context__.vals_r("prior_mean_for_aux");
        pos__ = 0;
        prior_mean_for_aux = vals_r__[pos__++];
        validate_non_negative_index("prior_mean_for_smooth", "(logical_gt(K_smooth,0) ? max(smooth_map) : 0 )", (logical_gt(K_smooth,0) ? max(smooth_map) : 0 ));
        context__.validate_dims("data initialization", "prior_mean_for_smooth", "vector_d", context__.to_vec((logical_gt(K_smooth,0) ? max(smooth_map) : 0 )));
        validate_non_negative_index("prior_mean_for_smooth", "(logical_gt(K_smooth,0) ? max(smooth_map) : 0 )", (logical_gt(K_smooth,0) ? max(smooth_map) : 0 ));
        prior_mean_for_smooth = vector_d(static_cast<Eigen::VectorXd::Index>((logical_gt(K_smooth,0) ? max(smooth_map) : 0 )));
        vals_r__ = context__.vals_r("prior_mean_for_smooth");
        pos__ = 0;
        size_t prior_mean_for_smooth_i_vec_lim__ = (logical_gt(K_smooth,0) ? max(smooth_map) : 0 );
        for (size_t i_vec__ = 0; i_vec__ < prior_mean_for_smooth_i_vec_lim__; ++i_vec__) {
            prior_mean_for_smooth[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("prior_df", "K", K);
        context__.validate_dims("data initialization", "prior_df", "vector_d", context__.to_vec(K));
        validate_non_negative_index("prior_df", "K", K);
        prior_df = vector_d(static_cast<Eigen::VectorXd::Index>(K));
        vals_r__ = context__.vals_r("prior_df");
        pos__ = 0;
        size_t prior_df_i_vec_lim__ = K;
        for (size_t i_vec__ = 0; i_vec__ < prior_df_i_vec_lim__; ++i_vec__) {
            prior_df[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "prior_df_for_intercept", "double", context__.to_vec());
        prior_df_for_intercept = double(0);
        vals_r__ = context__.vals_r("prior_df_for_intercept");
        pos__ = 0;
        prior_df_for_intercept = vals_r__[pos__++];
        context__.validate_dims("data initialization", "prior_df_for_aux", "double", context__.to_vec());
        prior_df_for_aux = double(0);
        vals_r__ = context__.vals_r("prior_df_for_aux");
        pos__ = 0;
        prior_df_for_aux = vals_r__[pos__++];
        validate_non_negative_index("prior_df_for_smooth", "(logical_gt(K_smooth,0) ? max(smooth_map) : 0 )", (logical_gt(K_smooth,0) ? max(smooth_map) : 0 ));
        context__.validate_dims("data initialization", "prior_df_for_smooth", "vector_d", context__.to_vec((logical_gt(K_smooth,0) ? max(smooth_map) : 0 )));
        validate_non_negative_index("prior_df_for_smooth", "(logical_gt(K_smooth,0) ? max(smooth_map) : 0 )", (logical_gt(K_smooth,0) ? max(smooth_map) : 0 ));
        prior_df_for_smooth = vector_d(static_cast<Eigen::VectorXd::Index>((logical_gt(K_smooth,0) ? max(smooth_map) : 0 )));
        vals_r__ = context__.vals_r("prior_df_for_smooth");
        pos__ = 0;
        size_t prior_df_for_smooth_i_vec_lim__ = (logical_gt(K_smooth,0) ? max(smooth_map) : 0 );
        for (size_t i_vec__ = 0; i_vec__ < prior_df_for_smooth_i_vec_lim__; ++i_vec__) {
            prior_df_for_smooth[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "global_prior_df", "double", context__.to_vec());
        global_prior_df = double(0);
        vals_r__ = context__.vals_r("global_prior_df");
        pos__ = 0;
        global_prior_df = vals_r__[pos__++];
        context__.validate_dims("data initialization", "global_prior_scale", "double", context__.to_vec());
        global_prior_scale = double(0);
        vals_r__ = context__.vals_r("global_prior_scale");
        pos__ = 0;
        global_prior_scale = vals_r__[pos__++];
        validate_non_negative_index("num_normals", "(logical_eq(prior_dist,7) ? K : 0 )", (logical_eq(prior_dist,7) ? K : 0 ));
        context__.validate_dims("data initialization", "num_normals", "int", context__.to_vec((logical_eq(prior_dist,7) ? K : 0 )));
        validate_non_negative_index("num_normals", "(logical_eq(prior_dist,7) ? K : 0 )", (logical_eq(prior_dist,7) ? K : 0 ));
        num_normals = std::vector<int>((logical_eq(prior_dist,7) ? K : 0 ),int(0));
        vals_i__ = context__.vals_i("num_normals");
        pos__ = 0;
        size_t num_normals_limit_0__ = (logical_eq(prior_dist,7) ? K : 0 );
        for (size_t i_0__ = 0; i_0__ < num_normals_limit_0__; ++i_0__) {
            num_normals[i_0__] = vals_i__[pos__++];
        }
        context__.validate_dims("data initialization", "t", "int", context__.to_vec());
        t = int(0);
        vals_i__ = context__.vals_i("t");
        pos__ = 0;
        t = vals_i__[pos__++];
        validate_non_negative_index("p", "t", t);
        context__.validate_dims("data initialization", "p", "int", context__.to_vec(t));
        validate_non_negative_index("p", "t", t);
        p = std::vector<int>(t,int(0));
        vals_i__ = context__.vals_i("p");
        pos__ = 0;
        size_t p_limit_0__ = t;
        for (size_t i_0__ = 0; i_0__ < p_limit_0__; ++i_0__) {
            p[i_0__] = vals_i__[pos__++];
        }
        validate_non_negative_index("l", "t", t);
        context__.validate_dims("data initialization", "l", "int", context__.to_vec(t));
        validate_non_negative_index("l", "t", t);
        l = std::vector<int>(t,int(0));
        vals_i__ = context__.vals_i("l");
        pos__ = 0;
        size_t l_limit_0__ = t;
        for (size_t i_0__ = 0; i_0__ < l_limit_0__; ++i_0__) {
            l[i_0__] = vals_i__[pos__++];
        }
        context__.validate_dims("data initialization", "q", "int", context__.to_vec());
        q = int(0);
        vals_i__ = context__.vals_i("q");
        pos__ = 0;
        q = vals_i__[pos__++];
        context__.validate_dims("data initialization", "len_theta_L", "int", context__.to_vec());
        len_theta_L = int(0);
        vals_i__ = context__.vals_i("len_theta_L");
        pos__ = 0;
        len_theta_L = vals_i__[pos__++];
        validate_non_negative_index("shape", "t", t);
        context__.validate_dims("data initialization", "shape", "vector_d", context__.to_vec(t));
        validate_non_negative_index("shape", "t", t);
        shape = vector_d(static_cast<Eigen::VectorXd::Index>(t));
        vals_r__ = context__.vals_r("shape");
        pos__ = 0;
        size_t shape_i_vec_lim__ = t;
        for (size_t i_vec__ = 0; i_vec__ < shape_i_vec_lim__; ++i_vec__) {
            shape[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("scale", "t", t);
        context__.validate_dims("data initialization", "scale", "vector_d", context__.to_vec(t));
        validate_non_negative_index("scale", "t", t);
        scale = vector_d(static_cast<Eigen::VectorXd::Index>(t));
        vals_r__ = context__.vals_r("scale");
        pos__ = 0;
        size_t scale_i_vec_lim__ = t;
        for (size_t i_vec__ = 0; i_vec__ < scale_i_vec_lim__; ++i_vec__) {
            scale[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "len_concentration", "int", context__.to_vec());
        len_concentration = int(0);
        vals_i__ = context__.vals_i("len_concentration");
        pos__ = 0;
        len_concentration = vals_i__[pos__++];
        validate_non_negative_index("concentration", "len_concentration", len_concentration);
        context__.validate_dims("data initialization", "concentration", "double", context__.to_vec(len_concentration));
        validate_non_negative_index("concentration", "len_concentration", len_concentration);
        concentration = std::vector<double>(len_concentration,double(0));
        vals_r__ = context__.vals_r("concentration");
        pos__ = 0;
        size_t concentration_limit_0__ = len_concentration;
        for (size_t i_0__ = 0; i_0__ < concentration_limit_0__; ++i_0__) {
            concentration[i_0__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "len_regularization", "int", context__.to_vec());
        len_regularization = int(0);
        vals_i__ = context__.vals_i("len_regularization");
        pos__ = 0;
        len_regularization = vals_i__[pos__++];
        validate_non_negative_index("regularization", "len_regularization", len_regularization);
        context__.validate_dims("data initialization", "regularization", "double", context__.to_vec(len_regularization));
        validate_non_negative_index("regularization", "len_regularization", len_regularization);
        regularization = std::vector<double>(len_regularization,double(0));
        vals_r__ = context__.vals_r("regularization");
        pos__ = 0;
        size_t regularization_limit_0__ = len_regularization;
        for (size_t i_0__ = 0; i_0__ < regularization_limit_0__; ++i_0__) {
            regularization[i_0__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "num_non_zero", "int", context__.to_vec());
        num_non_zero = int(0);
        vals_i__ = context__.vals_i("num_non_zero");
        pos__ = 0;
        num_non_zero = vals_i__[pos__++];
        validate_non_negative_index("w", "num_non_zero", num_non_zero);
        context__.validate_dims("data initialization", "w", "vector_d", context__.to_vec(num_non_zero));
        validate_non_negative_index("w", "num_non_zero", num_non_zero);
        w = vector_d(static_cast<Eigen::VectorXd::Index>(num_non_zero));
        vals_r__ = context__.vals_r("w");
        pos__ = 0;
        size_t w_i_vec_lim__ = num_non_zero;
        for (size_t i_vec__ = 0; i_vec__ < w_i_vec_lim__; ++i_vec__) {
            w[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("v", "num_non_zero", num_non_zero);
        context__.validate_dims("data initialization", "v", "int", context__.to_vec(num_non_zero));
        validate_non_negative_index("v", "num_non_zero", num_non_zero);
        v = std::vector<int>(num_non_zero,int(0));
        vals_i__ = context__.vals_i("v");
        pos__ = 0;
        size_t v_limit_0__ = num_non_zero;
        for (size_t i_0__ = 0; i_0__ < v_limit_0__; ++i_0__) {
            v[i_0__] = vals_i__[pos__++];
        }
        validate_non_negative_index("u", "(logical_gt(t,0) ? (N + 1) : 0 )", (logical_gt(t,0) ? (N + 1) : 0 ));
        context__.validate_dims("data initialization", "u", "int", context__.to_vec((logical_gt(t,0) ? (N + 1) : 0 )));
        validate_non_negative_index("u", "(logical_gt(t,0) ? (N + 1) : 0 )", (logical_gt(t,0) ? (N + 1) : 0 ));
        u = std::vector<int>((logical_gt(t,0) ? (N + 1) : 0 ),int(0));
        vals_i__ = context__.vals_i("u");
        pos__ = 0;
        size_t u_limit_0__ = (logical_gt(t,0) ? (N + 1) : 0 );
        for (size_t i_0__ = 0; i_0__ < u_limit_0__; ++i_0__) {
            u[i_0__] = vals_i__[pos__++];
        }
        context__.validate_dims("data initialization", "special_case", "int", context__.to_vec());
        special_case = int(0);
        vals_i__ = context__.vals_i("special_case");
        pos__ = 0;
        special_case = vals_i__[pos__++];

        // validate, data variables
        check_greater_or_equal(function__,"N",N,0);
        check_greater_or_equal(function__,"K",K,0);
        check_greater_or_equal(function__,"dense_X",dense_X,0);
        check_less_or_equal(function__,"dense_X",dense_X,1);
        check_greater_or_equal(function__,"nnz_X",nnz_X,0);
        for (int k0__ = 0; k0__ < nnz_X; ++k0__) {
            check_greater_or_equal(function__,"v_X[k0__]",v_X[k0__],0);
        }
        for (int k0__ = 0; k0__ < (dense_X ? 0 : (N + 1) ); ++k0__) {
            check_greater_or_equal(function__,"u_X[k0__]",u_X[k0__],0);
        }
        check_greater_or_equal(function__,"K_smooth",K_smooth,0);
        for (int k0__ = 0; k0__ < K_smooth; ++k0__) {
            check_greater_or_equal(function__,"smooth_map[k0__]",smooth_map[k0__],1);
        }
        for (int k0__ = 0; k0__ < N; ++k0__) {
            check_greater_or_equal(function__,"y[k0__]",y[k0__],0);
        }
        check_greater_or_equal(function__,"prior_PD",prior_PD,0);
        check_less_or_equal(function__,"prior_PD",prior_PD,1);
        check_greater_or_equal(function__,"has_intercept",has_intercept,0);
        check_less_or_equal(function__,"has_intercept",has_intercept,1);
        check_greater_or_equal(function__,"family",family,1);
        check_greater_or_equal(function__,"link",link,1);
        check_greater_or_equal(function__,"prior_dist",prior_dist,0);
        check_less_or_equal(function__,"prior_dist",prior_dist,7);
        check_greater_or_equal(function__,"prior_dist_for_intercept",prior_dist_for_intercept,0);
        check_less_or_equal(function__,"prior_dist_for_intercept",prior_dist_for_intercept,2);
        check_greater_or_equal(function__,"prior_dist_for_aux",prior_dist_for_aux,0);
        check_less_or_equal(function__,"prior_dist_for_aux",prior_dist_for_aux,3);
        check_greater_or_equal(function__,"prior_dist_for_smooth",prior_dist_for_smooth,0);
        check_less_or_equal(function__,"prior_dist_for_smooth",prior_dist_for_smooth,3);
        check_greater_or_equal(function__,"has_weights",has_weights,0);
        check_less_or_equal(function__,"has_weights",has_weights,1);
        check_greater_or_equal(function__,"has_offset",has_offset,0);
        check_less_or_equal(function__,"has_offset",has_offset,1);
        check_greater_or_equal(function__,"prior_scale",prior_scale,0);
        check_greater_or_equal(function__,"prior_scale_for_intercept",prior_scale_for_intercept,0);
        check_greater_or_equal(function__,"prior_scale_for_aux",prior_scale_for_aux,0);
        check_greater_or_equal(function__,"prior_scale_for_smooth",prior_scale_for_smooth,0);
        check_greater_or_equal(function__,"prior_mean_for_aux",prior_mean_for_aux,0);
        check_greater_or_equal(function__,"prior_mean_for_smooth",prior_mean_for_smooth,0);
        check_greater_or_equal(function__,"prior_df",prior_df,0);
        check_greater_or_equal(function__,"prior_df_for_intercept",prior_df_for_intercept,0);
        check_greater_or_equal(function__,"prior_df_for_aux",prior_df_for_aux,0);
        check_greater_or_equal(function__,"prior_df_for_smooth",prior_df_for_smooth,0);
        check_greater_or_equal(function__,"global_prior_df",global_prior_df,0);
        check_greater_or_equal(function__,"global_prior_scale",global_prior_scale,0);
        for (int k0__ = 0; k0__ < (logical_eq(prior_dist,7) ? K : 0 ); ++k0__) {
            check_greater_or_equal(function__,"num_normals[k0__]",num_normals[k0__],2);
        }
        check_greater_or_equal(function__,"t",t,0);
        for (int k0__ = 0; k0__ < t; ++k0__) {
            check_greater_or_equal(function__,"p[k0__]",p[k0__],1);
        }
        for (int k0__ = 0; k0__ < t; ++k0__) {
            check_greater_or_equal(function__,"l[k0__]",l[k0__],1);
        }
        check_greater_or_equal(function__,"q",q,0);
        check_greater_or_equal(function__,"len_theta_L",len_theta_L,0);
        check_greater_or_equal(function__,"shape",shape,0);
        check_greater_or_equal(function__,"scale",scale,0);
        check_greater_or_equal(function__,"len_concentration",len_concentration,0);
        for (int k0__ = 0; k0__ < len_concentration; ++k0__) {
            check_greater_or_equal(function__,"concentration[k0__]",concentration[k0__],0);
        }
        check_greater_or_equal(function__,"len_regularization",len_regularization,0);
        for (int k0__ = 0; k0__ < len_regularization; ++k0__) {
            check_greater_or_equal(function__,"regularization[k0__]",regularization[k0__],0);
        }
        check_greater_or_equal(function__,"num_non_zero",num_non_zero,0);
        for (int k0__ = 0; k0__ < num_non_zero; ++k0__) {
            check_greater_or_equal(function__,"v[k0__]",v[k0__],0);
        }
        for (int k0__ = 0; k0__ < (logical_gt(t,0) ? (N + 1) : 0 ); ++k0__) {
            check_greater_or_equal(function__,"u[k0__]",u[k0__],0);
        }
        check_greater_or_equal(function__,"special_case",special_case,0);
        check_less_or_equal(function__,"special_case",special_case,1);
        // initialize data variables
        poisson_max = double(0);
        stan::math::fill(poisson_max,DUMMY_VAR__);
        stan::math::assign(poisson_max,pow(2.0,30.0));
        validate_non_negative_index("V", "(special_case ? t : 0 )", (special_case ? t : 0 ));
        validate_non_negative_index("V", "N", N);
        V = std::vector<std::vector<int> >((special_case ? t : 0 ),std::vector<int>(N,int(0)));
        stan::math::fill(V, std::numeric_limits<int>::min());
        stan::math::assign(V,make_V(N,(special_case ? t : 0 ),v, pstream__));
        len_z_T = int(0);
        stan::math::fill(len_z_T, std::numeric_limits<int>::min());
        stan::math::assign(len_z_T,0);
        len_var_group = int(0);
        stan::math::fill(len_var_group, std::numeric_limits<int>::min());
        stan::math::assign(len_var_group,(sum(p) * logical_gt(t,0)));
        len_rho = int(0);
        stan::math::fill(len_rho, std::numeric_limits<int>::min());
        stan::math::assign(len_rho,(sum(p) - t));
        is_continuous = int(0);
        stan::math::fill(is_continuous, std::numeric_limits<int>::min());
        stan::math::assign(is_continuous,0);
        pos = int(0);
        stan::math::fill(pos, std::numeric_limits<int>::min());
        stan::math::assign(pos,1);
        validate_non_negative_index("delta", "len_concentration", len_concentration);
        delta = std::vector<double>(len_concentration,double(0));
        stan::math::fill(delta,DUMMY_VAR__);
        hs = int(0);
        stan::math::fill(hs, std::numeric_limits<int>::min());

        try {
            current_statement_begin__ = 439;
            if (as_bool(logical_lte(prior_dist,2))) {
                current_statement_begin__ = 439;
                stan::math::assign(hs, 0);
            } else if (as_bool(logical_eq(prior_dist,3))) {
                current_statement_begin__ = 440;
                stan::math::assign(hs, 2);
            } else if (as_bool(logical_eq(prior_dist,4))) {
                current_statement_begin__ = 441;
                stan::math::assign(hs, 4);
            } else {
                current_statement_begin__ = 442;
                stan::math::assign(hs, 0);
            }
            current_statement_begin__ = 444;
            stan::math::assign(pos, 1);
            current_statement_begin__ = 445;
            for (int i = 1; i <= t; ++i) {

                current_statement_begin__ = 446;
                if (as_bool(logical_gt(get_base1(p,i,"p",1),1))) {

                    current_statement_begin__ = 447;
                    for (int j = 1; j <= get_base1(p,i,"p",1); ++j) {

                        current_statement_begin__ = 448;
                        stan::math::assign(get_base1_lhs(delta,pos,"delta",1), get_base1(concentration,j,"concentration",1));
                        current_statement_begin__ = 449;
                        stan::math::assign(pos, (pos + 1));
                    }
                }
                current_statement_begin__ = 452;
                for (int j = 3; j <= get_base1(p,i,"p",1); ++j) {
                    current_statement_begin__ = 452;
                    stan::math::assign(len_z_T, ((len_z_T + get_base1(p,i,"p",1)) - 1));
                }
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        // validate transformed data
        for (int k0__ = 0; k0__ < (special_case ? t : 0 ); ++k0__) {
            for (int k1__ = 0; k1__ < N; ++k1__) {
                check_greater_or_equal(function__,"V[k0__][k1__]",V[k0__][k1__],1);
            }
        }
        check_greater_or_equal(function__,"len_z_T",len_z_T,0);
        check_greater_or_equal(function__,"len_var_group",len_var_group,0);
        check_greater_or_equal(function__,"len_rho",len_rho,0);
        check_greater_or_equal(function__,"is_continuous",is_continuous,0);
        check_less_or_equal(function__,"is_continuous",is_continuous,1);
        check_greater_or_equal(function__,"pos",pos,1);
        for (int k0__ = 0; k0__ < len_concentration; ++k0__) {
            check_greater_or_equal(function__,"delta[k0__]",delta[k0__],0);
        }
        check_greater_or_equal(function__,"hs",hs,0);

        // validate, set parameter ranges
        num_params_r__ = 0U;
        param_ranges_i__.clear();
        validate_non_negative_index("gamma", "has_intercept", has_intercept);
        num_params_r__ += has_intercept;
        validate_non_negative_index("z_beta", "(logical_eq(prior_dist,7) ? sum(num_normals) : K )", (logical_eq(prior_dist,7) ? sum(num_normals) : K ));
        num_params_r__ += (logical_eq(prior_dist,7) ? sum(num_normals) : K );
        validate_non_negative_index("z_beta_smooth", "K_smooth", K_smooth);
        num_params_r__ += K_smooth;
        validate_non_negative_index("smooth_sd_raw", "(logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,\"smooth_map\",1) : 0 )", (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));
        num_params_r__ += (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 );
        validate_non_negative_index("global", "hs", hs);
        num_params_r__ += hs;
        validate_non_negative_index("local", "K", K);
        validate_non_negative_index("local", "hs", hs);
        num_params_r__ += K * hs;
        validate_non_negative_index("mix", "K", K);
        validate_non_negative_index("mix", "(primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6)))", (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))));
        num_params_r__ += K * (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6)));
        validate_non_negative_index("one_over_lambda", "logical_eq(prior_dist,6)", logical_eq(prior_dist,6));
        num_params_r__ += logical_eq(prior_dist,6);
        validate_non_negative_index("z_b", "q", q);
        num_params_r__ += q;
        validate_non_negative_index("z_T", "len_z_T", len_z_T);
        num_params_r__ += len_z_T;
        validate_non_negative_index("rho", "len_rho", len_rho);
        num_params_r__ += len_rho;
        validate_non_negative_index("zeta", "len_concentration", len_concentration);
        num_params_r__ += len_concentration;
        validate_non_negative_index("tau", "t", t);
        num_params_r__ += t;
        validate_non_negative_index("aux_unscaled", "logical_gt(family,1)", logical_gt(family,1));
        num_params_r__ += logical_gt(family,1);
        validate_non_negative_index("noise", "N", N);
        validate_non_negative_index("noise", "logical_eq(family,3)", logical_eq(family,3));
        num_params_r__ += N * logical_eq(family,3);
    }

    ~model_count() { }


    void transform_inits(const stan::io::var_context& context__,
                         std::vector<int>& params_i__,
                         std::vector<double>& params_r__,
                         std::ostream* pstream__) const {
        stan::io::writer<double> writer__(params_r__,params_i__);
        size_t pos__;
        (void) pos__; // dummy call to supress warning
        std::vector<double> vals_r__;
        std::vector<int> vals_i__;

        if (!(context__.contains_r("gamma")))
            throw std::runtime_error("variable gamma missing");
        vals_r__ = context__.vals_r("gamma");
        pos__ = 0U;
        validate_non_negative_index("gamma", "has_intercept", has_intercept);
        context__.validate_dims("initialization", "gamma", "double", context__.to_vec(has_intercept));
        // generate_declaration gamma
        std::vector<double> gamma(has_intercept,double(0));
        for (int i0__ = 0U; i0__ < has_intercept; ++i0__)
            gamma[i0__] = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < has_intercept; ++i0__)
            try {
            writer__.scalar_lb_unconstrain((logical_eq(link,1) ? stan::math::negative_infinity() : 0.0 ),gamma[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable gamma: ") + e.what());
        }

        if (!(context__.contains_r("z_beta")))
            throw std::runtime_error("variable z_beta missing");
        vals_r__ = context__.vals_r("z_beta");
        pos__ = 0U;
        validate_non_negative_index("z_beta", "(logical_eq(prior_dist,7) ? sum(num_normals) : K )", (logical_eq(prior_dist,7) ? sum(num_normals) : K ));
        context__.validate_dims("initialization", "z_beta", "vector_d", context__.to_vec((logical_eq(prior_dist,7) ? sum(num_normals) : K )));
        // generate_declaration z_beta
        vector_d z_beta(static_cast<Eigen::VectorXd::Index>((logical_eq(prior_dist,7) ? sum(num_normals) : K )));
        for (int j1__ = 0U; j1__ < (logical_eq(prior_dist,7) ? sum(num_normals) : K ); ++j1__)
            z_beta(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_unconstrain(z_beta);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable z_beta: ") + e.what());
        }

        if (!(context__.contains_r("z_beta_smooth")))
            throw std::runtime_error("variable z_beta_smooth missing");
        vals_r__ = context__.vals_r("z_beta_smooth");
        pos__ = 0U;
        validate_non_negative_index("z_beta_smooth", "K_smooth", K_smooth);
        context__.validate_dims("initialization", "z_beta_smooth", "vector_d", context__.to_vec(K_smooth));
        // generate_declaration z_beta_smooth
        vector_d z_beta_smooth(static_cast<Eigen::VectorXd::Index>(K_smooth));
        for (int j1__ = 0U; j1__ < K_smooth; ++j1__)
            z_beta_smooth(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_unconstrain(z_beta_smooth);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable z_beta_smooth: ") + e.what());
        }

        if (!(context__.contains_r("smooth_sd_raw")))
            throw std::runtime_error("variable smooth_sd_raw missing");
        vals_r__ = context__.vals_r("smooth_sd_raw");
        pos__ = 0U;
        validate_non_negative_index("smooth_sd_raw", "(logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,\"smooth_map\",1) : 0 )", (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));
        context__.validate_dims("initialization", "smooth_sd_raw", "vector_d", context__.to_vec((logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 )));
        // generate_declaration smooth_sd_raw
        vector_d smooth_sd_raw(static_cast<Eigen::VectorXd::Index>((logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 )));
        for (int j1__ = 0U; j1__ < (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++j1__)
            smooth_sd_raw(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_lb_unconstrain(0,smooth_sd_raw);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable smooth_sd_raw: ") + e.what());
        }

        if (!(context__.contains_r("global")))
            throw std::runtime_error("variable global missing");
        vals_r__ = context__.vals_r("global");
        pos__ = 0U;
        validate_non_negative_index("global", "hs", hs);
        context__.validate_dims("initialization", "global", "double", context__.to_vec(hs));
        // generate_declaration global
        std::vector<double> global(hs,double(0));
        for (int i0__ = 0U; i0__ < hs; ++i0__)
            global[i0__] = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < hs; ++i0__)
            try {
            writer__.scalar_lb_unconstrain(0,global[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable global: ") + e.what());
        }

        if (!(context__.contains_r("local")))
            throw std::runtime_error("variable local missing");
        vals_r__ = context__.vals_r("local");
        pos__ = 0U;
        validate_non_negative_index("local", "hs", hs);
        validate_non_negative_index("local", "K", K);
        context__.validate_dims("initialization", "local", "vector_d", context__.to_vec(hs,K));
        // generate_declaration local
        std::vector<vector_d> local(hs,vector_d(static_cast<Eigen::VectorXd::Index>(K)));
        for (int j1__ = 0U; j1__ < K; ++j1__)
            for (int i0__ = 0U; i0__ < hs; ++i0__)
                local[i0__](j1__) = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < hs; ++i0__)
            try {
            writer__.vector_lb_unconstrain(0,local[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable local: ") + e.what());
        }

        if (!(context__.contains_r("mix")))
            throw std::runtime_error("variable mix missing");
        vals_r__ = context__.vals_r("mix");
        pos__ = 0U;
        validate_non_negative_index("mix", "(primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6)))", (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))));
        validate_non_negative_index("mix", "K", K);
        context__.validate_dims("initialization", "mix", "vector_d", context__.to_vec((primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))),K));
        // generate_declaration mix
        std::vector<vector_d> mix((primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))),vector_d(static_cast<Eigen::VectorXd::Index>(K)));
        for (int j1__ = 0U; j1__ < K; ++j1__)
            for (int i0__ = 0U; i0__ < (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))); ++i0__)
                mix[i0__](j1__) = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))); ++i0__)
            try {
            writer__.vector_lb_unconstrain(0,mix[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable mix: ") + e.what());
        }

        if (!(context__.contains_r("one_over_lambda")))
            throw std::runtime_error("variable one_over_lambda missing");
        vals_r__ = context__.vals_r("one_over_lambda");
        pos__ = 0U;
        validate_non_negative_index("one_over_lambda", "logical_eq(prior_dist,6)", logical_eq(prior_dist,6));
        context__.validate_dims("initialization", "one_over_lambda", "double", context__.to_vec(logical_eq(prior_dist,6)));
        // generate_declaration one_over_lambda
        std::vector<double> one_over_lambda(logical_eq(prior_dist,6),double(0));
        for (int i0__ = 0U; i0__ < logical_eq(prior_dist,6); ++i0__)
            one_over_lambda[i0__] = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < logical_eq(prior_dist,6); ++i0__)
            try {
            writer__.scalar_lb_unconstrain(0,one_over_lambda[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable one_over_lambda: ") + e.what());
        }

        if (!(context__.contains_r("z_b")))
            throw std::runtime_error("variable z_b missing");
        vals_r__ = context__.vals_r("z_b");
        pos__ = 0U;
        validate_non_negative_index("z_b", "q", q);
        context__.validate_dims("initialization", "z_b", "vector_d", context__.to_vec(q));
        // generate_declaration z_b
        vector_d z_b(static_cast<Eigen::VectorXd::Index>(q));
        for (int j1__ = 0U; j1__ < q; ++j1__)
            z_b(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_unconstrain(z_b);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable z_b: ") + e.what());
        }

        if (!(context__.contains_r("z_T")))
            throw std::runtime_error("variable z_T missing");
        vals_r__ = context__.vals_r("z_T");
        pos__ = 0U;
        validate_non_negative_index("z_T", "len_z_T", len_z_T);
        context__.validate_dims("initialization", "z_T", "vector_d", context__.to_vec(len_z_T));
        // generate_declaration z_T
        vector_d z_T(static_cast<Eigen::VectorXd::Index>(len_z_T));
        for (int j1__ = 0U; j1__ < len_z_T; ++j1__)
            z_T(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_unconstrain(z_T);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable z_T: ") + e.what());
        }

        if (!(context__.contains_r("rho")))
            throw std::runtime_error("variable rho missing");
        vals_r__ = context__.vals_r("rho");
        pos__ = 0U;
        validate_non_negative_index("rho", "len_rho", len_rho);
        context__.validate_dims("initialization", "rho", "vector_d", context__.to_vec(len_rho));
        // generate_declaration rho
        vector_d rho(static_cast<Eigen::VectorXd::Index>(len_rho));
        for (int j1__ = 0U; j1__ < len_rho; ++j1__)
            rho(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_lub_unconstrain(0,1,rho);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable rho: ") + e.what());
        }

        if (!(context__.contains_r("zeta")))
            throw std::runtime_error("variable zeta missing");
        vals_r__ = context__.vals_r("zeta");
        pos__ = 0U;
        validate_non_negative_index("zeta", "len_concentration", len_concentration);
        context__.validate_dims("initialization", "zeta", "vector_d", context__.to_vec(len_concentration));
        // generate_declaration zeta
        vector_d zeta(static_cast<Eigen::VectorXd::Index>(len_concentration));
        for (int j1__ = 0U; j1__ < len_concentration; ++j1__)
            zeta(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_lb_unconstrain(0,zeta);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable zeta: ") + e.what());
        }

        if (!(context__.contains_r("tau")))
            throw std::runtime_error("variable tau missing");
        vals_r__ = context__.vals_r("tau");
        pos__ = 0U;
        validate_non_negative_index("tau", "t", t);
        context__.validate_dims("initialization", "tau", "vector_d", context__.to_vec(t));
        // generate_declaration tau
        vector_d tau(static_cast<Eigen::VectorXd::Index>(t));
        for (int j1__ = 0U; j1__ < t; ++j1__)
            tau(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_lb_unconstrain(0,tau);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable tau: ") + e.what());
        }

        if (!(context__.contains_r("aux_unscaled")))
            throw std::runtime_error("variable aux_unscaled missing");
        vals_r__ = context__.vals_r("aux_unscaled");
        pos__ = 0U;
        validate_non_negative_index("aux_unscaled", "logical_gt(family,1)", logical_gt(family,1));
        context__.validate_dims("initialization", "aux_unscaled", "double", context__.to_vec(logical_gt(family,1)));
        // generate_declaration aux_unscaled
        std::vector<double> aux_unscaled(logical_gt(family,1),double(0));
        for (int i0__ = 0U; i0__ < logical_gt(family,1); ++i0__)
            aux_unscaled[i0__] = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < logical_gt(family,1); ++i0__)
            try {
            writer__.scalar_lb_unconstrain(0,aux_unscaled[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable aux_unscaled: ") + e.what());
        }

        if (!(context__.contains_r("noise")))
            throw std::runtime_error("variable noise missing");
        vals_r__ = context__.vals_r("noise");
        pos__ = 0U;
        validate_non_negative_index("noise", "logical_eq(family,3)", logical_eq(family,3));
        validate_non_negative_index("noise", "N", N);
        context__.validate_dims("initialization", "noise", "vector_d", context__.to_vec(logical_eq(family,3),N));
        // generate_declaration noise
        std::vector<vector_d> noise(logical_eq(family,3),vector_d(static_cast<Eigen::VectorXd::Index>(N)));
        for (int j1__ = 0U; j1__ < N; ++j1__)
            for (int i0__ = 0U; i0__ < logical_eq(family,3); ++i0__)
                noise[i0__](j1__) = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < logical_eq(family,3); ++i0__)
            try {
            writer__.vector_lb_unconstrain(0,noise[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable noise: ") + e.what());
        }

        params_r__ = writer__.data_r();
        params_i__ = writer__.data_i();
    }

    void transform_inits(const stan::io::var_context& context,
                         Eigen::Matrix<double,Eigen::Dynamic,1>& params_r,
                         std::ostream* pstream__) const {
      std::vector<double> params_r_vec;
      std::vector<int> params_i_vec;
      transform_inits(context, params_i_vec, params_r_vec, pstream__);
      params_r.resize(params_r_vec.size());
      for (int i = 0; i < params_r.size(); ++i)
        params_r(i) = params_r_vec[i];
    }


    template <bool propto__, bool jacobian__, typename T__>
    T__ log_prob(vector<T__>& params_r__,
                 vector<int>& params_i__,
                 std::ostream* pstream__ = 0) const {

        T__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

        T__ lp__(0.0);
        stan::math::accumulator<T__> lp_accum__;

        // model parameters
        stan::io::reader<T__> in__(params_r__,params_i__);

        vector<T__> gamma;
        size_t dim_gamma_0__ = has_intercept;
        gamma.reserve(dim_gamma_0__);
        for (size_t k_0__ = 0; k_0__ < dim_gamma_0__; ++k_0__) {
            if (jacobian__)
                gamma.push_back(in__.scalar_lb_constrain((logical_eq(link,1) ? stan::math::negative_infinity() : 0.0 ),lp__));
            else
                gamma.push_back(in__.scalar_lb_constrain((logical_eq(link,1) ? stan::math::negative_infinity() : 0.0 )));
        }

        Eigen::Matrix<T__,Eigen::Dynamic,1>  z_beta;
        (void) z_beta;  // dummy to suppress unused var warning
        if (jacobian__)
            z_beta = in__.vector_constrain((logical_eq(prior_dist,7) ? sum(num_normals) : K ),lp__);
        else
            z_beta = in__.vector_constrain((logical_eq(prior_dist,7) ? sum(num_normals) : K ));

        Eigen::Matrix<T__,Eigen::Dynamic,1>  z_beta_smooth;
        (void) z_beta_smooth;  // dummy to suppress unused var warning
        if (jacobian__)
            z_beta_smooth = in__.vector_constrain(K_smooth,lp__);
        else
            z_beta_smooth = in__.vector_constrain(K_smooth);

        Eigen::Matrix<T__,Eigen::Dynamic,1>  smooth_sd_raw;
        (void) smooth_sd_raw;  // dummy to suppress unused var warning
        if (jacobian__)
            smooth_sd_raw = in__.vector_lb_constrain(0,(logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ),lp__);
        else
            smooth_sd_raw = in__.vector_lb_constrain(0,(logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));

        vector<T__> global;
        size_t dim_global_0__ = hs;
        global.reserve(dim_global_0__);
        for (size_t k_0__ = 0; k_0__ < dim_global_0__; ++k_0__) {
            if (jacobian__)
                global.push_back(in__.scalar_lb_constrain(0,lp__));
            else
                global.push_back(in__.scalar_lb_constrain(0));
        }

        vector<Eigen::Matrix<T__,Eigen::Dynamic,1> > local;
        size_t dim_local_0__ = hs;
        local.reserve(dim_local_0__);
        for (size_t k_0__ = 0; k_0__ < dim_local_0__; ++k_0__) {
            if (jacobian__)
                local.push_back(in__.vector_lb_constrain(0,K,lp__));
            else
                local.push_back(in__.vector_lb_constrain(0,K));
        }

        vector<Eigen::Matrix<T__,Eigen::Dynamic,1> > mix;
        size_t dim_mix_0__ = (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6)));
        mix.reserve(dim_mix_0__);
        for (size_t k_0__ = 0; k_0__ < dim_mix_0__; ++k_0__) {
            if (jacobian__)
                mix.push_back(in__.vector_lb_constrain(0,K,lp__));
            else
                mix.push_back(in__.vector_lb_constrain(0,K));
        }

        vector<T__> one_over_lambda;
        size_t dim_one_over_lambda_0__ = logical_eq(prior_dist,6);
        one_over_lambda.reserve(dim_one_over_lambda_0__);
        for (size_t k_0__ = 0; k_0__ < dim_one_over_lambda_0__; ++k_0__) {
            if (jacobian__)
                one_over_lambda.push_back(in__.scalar_lb_constrain(0,lp__));
            else
                one_over_lambda.push_back(in__.scalar_lb_constrain(0));
        }

        Eigen::Matrix<T__,Eigen::Dynamic,1>  z_b;
        (void) z_b;  // dummy to suppress unused var warning
        if (jacobian__)
            z_b = in__.vector_constrain(q,lp__);
        else
            z_b = in__.vector_constrain(q);

        Eigen::Matrix<T__,Eigen::Dynamic,1>  z_T;
        (void) z_T;  // dummy to suppress unused var warning
        if (jacobian__)
            z_T = in__.vector_constrain(len_z_T,lp__);
        else
            z_T = in__.vector_constrain(len_z_T);

        Eigen::Matrix<T__,Eigen::Dynamic,1>  rho;
        (void) rho;  // dummy to suppress unused var warning
        if (jacobian__)
            rho = in__.vector_lub_constrain(0,1,len_rho,lp__);
        else
            rho = in__.vector_lub_constrain(0,1,len_rho);

        Eigen::Matrix<T__,Eigen::Dynamic,1>  zeta;
        (void) zeta;  // dummy to suppress unused var warning
        if (jacobian__)
            zeta = in__.vector_lb_constrain(0,len_concentration,lp__);
        else
            zeta = in__.vector_lb_constrain(0,len_concentration);

        Eigen::Matrix<T__,Eigen::Dynamic,1>  tau;
        (void) tau;  // dummy to suppress unused var warning
        if (jacobian__)
            tau = in__.vector_lb_constrain(0,t,lp__);
        else
            tau = in__.vector_lb_constrain(0,t);

        vector<T__> aux_unscaled;
        size_t dim_aux_unscaled_0__ = logical_gt(family,1);
        aux_unscaled.reserve(dim_aux_unscaled_0__);
        for (size_t k_0__ = 0; k_0__ < dim_aux_unscaled_0__; ++k_0__) {
            if (jacobian__)
                aux_unscaled.push_back(in__.scalar_lb_constrain(0,lp__));
            else
                aux_unscaled.push_back(in__.scalar_lb_constrain(0));
        }

        vector<Eigen::Matrix<T__,Eigen::Dynamic,1> > noise;
        size_t dim_noise_0__ = logical_eq(family,3);
        noise.reserve(dim_noise_0__);
        for (size_t k_0__ = 0; k_0__ < dim_noise_0__; ++k_0__) {
            if (jacobian__)
                noise.push_back(in__.vector_lb_constrain(0,N,lp__));
            else
                noise.push_back(in__.vector_lb_constrain(0,N));
        }


        // transformed parameters
        T__ aux;
        (void) aux;  // dummy to suppress unused var warning

        stan::math::initialize(aux, DUMMY_VAR__);
        stan::math::fill(aux,DUMMY_VAR__);
        stan::math::assign(aux,stan::math::negative_infinity());
        validate_non_negative_index("beta", "K", K);
        Eigen::Matrix<T__,Eigen::Dynamic,1>  beta(static_cast<Eigen::VectorXd::Index>(K));
        (void) beta;  // dummy to suppress unused var warning

        stan::math::initialize(beta, DUMMY_VAR__);
        stan::math::fill(beta,DUMMY_VAR__);
        validate_non_negative_index("beta_smooth", "K_smooth", K_smooth);
        Eigen::Matrix<T__,Eigen::Dynamic,1>  beta_smooth(static_cast<Eigen::VectorXd::Index>(K_smooth));
        (void) beta_smooth;  // dummy to suppress unused var warning

        stan::math::initialize(beta_smooth, DUMMY_VAR__);
        stan::math::fill(beta_smooth,DUMMY_VAR__);
        validate_non_negative_index("smooth_sd", "(logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,\"smooth_map\",1) : 0 )", (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));
        Eigen::Matrix<T__,Eigen::Dynamic,1>  smooth_sd(static_cast<Eigen::VectorXd::Index>((logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 )));
        (void) smooth_sd;  // dummy to suppress unused var warning

        stan::math::initialize(smooth_sd, DUMMY_VAR__);
        stan::math::fill(smooth_sd,DUMMY_VAR__);
        validate_non_negative_index("b", "q", q);
        Eigen::Matrix<T__,Eigen::Dynamic,1>  b(static_cast<Eigen::VectorXd::Index>(q));
        (void) b;  // dummy to suppress unused var warning

        stan::math::initialize(b, DUMMY_VAR__);
        stan::math::fill(b,DUMMY_VAR__);
        validate_non_negative_index("theta_L", "len_theta_L", len_theta_L);
        Eigen::Matrix<T__,Eigen::Dynamic,1>  theta_L(static_cast<Eigen::VectorXd::Index>(len_theta_L));
        (void) theta_L;  // dummy to suppress unused var warning

        stan::math::initialize(theta_L, DUMMY_VAR__);
        stan::math::fill(theta_L,DUMMY_VAR__);


        try {
            current_statement_begin__ = 483;
            if (as_bool(logical_eq(prior_dist,0))) {
                current_statement_begin__ = 483;
                stan::math::assign(beta, z_beta);
            } else if (as_bool(logical_eq(prior_dist,1))) {
                current_statement_begin__ = 484;
                stan::math::assign(beta, add(elt_multiply(z_beta,prior_scale),prior_mean));
            } else if (as_bool(logical_eq(prior_dist,2))) {
                current_statement_begin__ = 485;
                for (int k = 1; k <= K; ++k) {

                    current_statement_begin__ = 486;
                    stan::math::assign(get_base1_lhs(beta,k,"beta",1), ((CFt(get_base1(z_beta,k,"z_beta",1),get_base1(prior_df,k,"prior_df",1), pstream__) * get_base1(prior_scale,k,"prior_scale",1)) + get_base1(prior_mean,k,"prior_mean",1)));
                }
            } else if (as_bool(logical_eq(prior_dist,3))) {

                current_statement_begin__ = 489;
                if (as_bool((primitive_value(logical_eq(is_continuous,1)) && primitive_value(logical_eq(family,1))))) {
                    current_statement_begin__ = 490;
                    stan::math::assign(beta, hs_prior(z_beta,global,local,global_prior_scale,aux, pstream__));
                } else {
                    current_statement_begin__ = 491;
                    stan::math::assign(beta, hs_prior(z_beta,global,local,global_prior_scale,1, pstream__));
                }
            } else if (as_bool(logical_eq(prior_dist,4))) {

                current_statement_begin__ = 494;
                if (as_bool((primitive_value(logical_eq(is_continuous,1)) && primitive_value(logical_eq(family,1))))) {
                    current_statement_begin__ = 495;
                    stan::math::assign(beta, hsplus_prior(z_beta,global,local,global_prior_scale,aux, pstream__));
                } else {
                    current_statement_begin__ = 496;
                    stan::math::assign(beta, hsplus_prior(z_beta,global,local,global_prior_scale,1, pstream__));
                }
            } else if (as_bool(logical_eq(prior_dist,5))) {
                current_statement_begin__ = 499;
                stan::math::assign(beta, add(prior_mean,elt_multiply(elt_multiply(prior_scale,sqrt(multiply(2,get_base1(mix,1,"mix",1)))),z_beta)));
            } else if (as_bool(logical_eq(prior_dist,6))) {
                current_statement_begin__ = 501;
                stan::math::assign(beta, add(prior_mean,elt_multiply(elt_multiply(multiply(get_base1(one_over_lambda,1,"one_over_lambda",1),prior_scale),sqrt(multiply(2,get_base1(mix,1,"mix",1)))),z_beta)));
            } else if (as_bool(logical_eq(prior_dist,7))) {
                {
                    int z_pos(0);
                    (void) z_pos;  // dummy to suppress unused var warning

                    stan::math::fill(z_pos, std::numeric_limits<int>::min());
                    stan::math::assign(z_pos,1);


                    current_statement_begin__ = 504;
                    for (int k = 1; k <= K; ++k) {

                        current_statement_begin__ = 505;
                        stan::math::assign(get_base1_lhs(beta,k,"beta",1), get_base1(z_beta,z_pos,"z_beta",1));
                        current_statement_begin__ = 506;
                        stan::math::assign(z_pos, (z_pos + 1));
                        current_statement_begin__ = 507;
                        for (int n = 2; n <= get_base1(num_normals,k,"num_normals",1); ++n) {

                            current_statement_begin__ = 508;
                            stan::math::assign(get_base1_lhs(beta,k,"beta",1), (get_base1(beta,k,"beta",1) * get_base1(z_beta,z_pos,"z_beta",1)));
                            current_statement_begin__ = 509;
                            stan::math::assign(z_pos, (z_pos + 1));
                        }
                        current_statement_begin__ = 511;
                        stan::math::assign(get_base1_lhs(beta,k,"beta",1), ((get_base1(beta,k,"beta",1) * pow(get_base1(prior_scale,k,"prior_scale",1),get_base1(num_normals,k,"num_normals",1))) + get_base1(prior_mean,k,"prior_mean",1)));
                    }
                }
            }
            current_statement_begin__ = 515;
            if (as_bool(K_smooth)) {

                current_statement_begin__ = 516;
                stan::math::assign(smooth_sd, add(prior_mean_for_smooth,elt_multiply(prior_scale_for_smooth,smooth_sd_raw)));
                current_statement_begin__ = 517;
                if (as_bool((primitive_value(is_continuous) && primitive_value(logical_eq(family,1))))) {
                    current_statement_begin__ = 517;
                    stan::math::assign(smooth_sd, multiply(smooth_sd,aux));
                }
                current_statement_begin__ = 518;
                stan::math::assign(beta_smooth, elt_multiply(z_beta_smooth,stan::model::rvalue(smooth_sd, stan::model::cons_list(stan::model::index_multi(smooth_map), stan::model::nil_index_list()), "smooth_sd")));
            }
            current_statement_begin__ = 521;
            if (as_bool((primitive_value(logical_gt(family,1)) && primitive_value((primitive_value(logical_eq(prior_dist_for_aux,0)) || primitive_value(logical_lte(prior_scale_for_aux,0))))))) {
                current_statement_begin__ = 522;
                stan::math::assign(aux, get_base1(aux_unscaled,1,"aux_unscaled",1));
            } else if (as_bool(logical_gt(family,1))) {

                current_statement_begin__ = 524;
                stan::math::assign(aux, (prior_scale_for_aux * get_base1(aux_unscaled,1,"aux_unscaled",1)));
                current_statement_begin__ = 525;
                if (as_bool(logical_lte(prior_dist_for_aux,2))) {
                    current_statement_begin__ = 526;
                    stan::math::assign(aux, (aux + prior_mean_for_aux));
                }
            }
            current_statement_begin__ = 529;
            if (as_bool(logical_gt(t,0))) {

                current_statement_begin__ = 530;
                if (as_bool(logical_eq(special_case,1))) {
                    {
                        int start(0);
                        (void) start;  // dummy to suppress unused var warning

                        stan::math::fill(start, std::numeric_limits<int>::min());
                        stan::math::assign(start,1);


                        current_statement_begin__ = 532;
                        stan::math::assign(theta_L, elt_multiply(scale,(logical_eq(family,1) ? stan::math::promote_scalar<T__>(tau) : stan::math::promote_scalar<T__>(multiply(tau,aux)) )));
                        current_statement_begin__ = 533;
                        if (as_bool(logical_eq(t,1))) {
                            current_statement_begin__ = 533;
                            stan::math::assign(b, multiply(get_base1(theta_L,1,"theta_L",1),z_b));
                        } else {
                            current_statement_begin__ = 534;
                            for (int i = 1; i <= t; ++i) {
                                {
                                    int end(0);
                                    (void) end;  // dummy to suppress unused var warning

                                    stan::math::fill(end, std::numeric_limits<int>::min());
                                    stan::math::assign(end,((start + get_base1(l,i,"l",1)) - 1));


                                    current_statement_begin__ = 536;
                                    stan::model::assign(b, 
                                                stan::model::cons_list(stan::model::index_min_max(start, end), stan::model::nil_index_list()), 
                                                multiply(get_base1(theta_L,i,"theta_L",1),stan::model::rvalue(z_b, stan::model::cons_list(stan::model::index_min_max(start, end), stan::model::nil_index_list()), "z_b")), 
                                                "assigning variable b");
                                    current_statement_begin__ = 537;
                                    stan::math::assign(start, (end + 1));
                                }
                            }
                        }
                    }
                } else {

                    current_statement_begin__ = 541;
                    if (as_bool(logical_eq(family,1))) {
                        current_statement_begin__ = 542;
                        stan::math::assign(theta_L, make_theta_L(len_theta_L,p,1.0,tau,scale,zeta,rho,z_T, pstream__));
                    } else {
                        current_statement_begin__ = 545;
                        stan::math::assign(theta_L, make_theta_L(len_theta_L,p,aux,tau,scale,zeta,rho,z_T, pstream__));
                    }
                    current_statement_begin__ = 547;
                    stan::math::assign(b, make_b(z_b,theta_L,p,l, pstream__));
                }
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        // validate transformed parameters
        if (stan::math::is_uninitialized(aux)) {
            std::stringstream msg__;
            msg__ << "Undefined transformed parameter: aux";
            throw std::runtime_error(msg__.str());
        }
        for (int i0__ = 0; i0__ < K; ++i0__) {
            if (stan::math::is_uninitialized(beta(i0__))) {
                std::stringstream msg__;
                msg__ << "Undefined transformed parameter: beta" << '[' << i0__ << ']';
                throw std::runtime_error(msg__.str());
            }
        }
        for (int i0__ = 0; i0__ < K_smooth; ++i0__) {
            if (stan::math::is_uninitialized(beta_smooth(i0__))) {
                std::stringstream msg__;
                msg__ << "Undefined transformed parameter: beta_smooth" << '[' << i0__ << ']';
                throw std::runtime_error(msg__.str());
            }
        }
        for (int i0__ = 0; i0__ < (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++i0__) {
            if (stan::math::is_uninitialized(smooth_sd(i0__))) {
                std::stringstream msg__;
                msg__ << "Undefined transformed parameter: smooth_sd" << '[' << i0__ << ']';
                throw std::runtime_error(msg__.str());
            }
        }
        for (int i0__ = 0; i0__ < q; ++i0__) {
            if (stan::math::is_uninitialized(b(i0__))) {
                std::stringstream msg__;
                msg__ << "Undefined transformed parameter: b" << '[' << i0__ << ']';
                throw std::runtime_error(msg__.str());
            }
        }
        for (int i0__ = 0; i0__ < len_theta_L; ++i0__) {
            if (stan::math::is_uninitialized(theta_L(i0__))) {
                std::stringstream msg__;
                msg__ << "Undefined transformed parameter: theta_L" << '[' << i0__ << ']';
                throw std::runtime_error(msg__.str());
            }
        }

        const char* function__ = "validate transformed params";
        (void) function__;  // dummy to suppress unused var warning

        // model body
        try {
            {
                validate_non_negative_index("eta", "N", N);
                Eigen::Matrix<T__,Eigen::Dynamic,1>  eta(static_cast<Eigen::VectorXd::Index>(N));
                (void) eta;  // dummy to suppress unused var warning

                stan::math::initialize(eta, DUMMY_VAR__);
                stan::math::fill(eta,DUMMY_VAR__);


                current_statement_begin__ = 554;
                if (as_bool(logical_gt(K,0))) {

                    current_statement_begin__ = 555;
                    if (as_bool(dense_X)) {
                        current_statement_begin__ = 555;
                        stan::math::assign(eta, multiply(get_base1(X,1,"X",1),beta));
                    } else {
                        current_statement_begin__ = 556;
                        stan::math::assign(eta, csr_matrix_times_vector(N,K,w_X,v_X,u_X,beta));
                    }
                } else {
                    current_statement_begin__ = 558;
                    stan::math::assign(eta, rep_vector(0.0,N));
                }
                current_statement_begin__ = 559;
                if (as_bool(logical_eq(has_offset,1))) {
                    current_statement_begin__ = 559;
                    stan::math::assign(eta, add(eta,offset));
                }
                current_statement_begin__ = 560;
                if (as_bool(K_smooth)) {
                    current_statement_begin__ = 560;
                    stan::math::assign(eta, add(eta,multiply(S,beta_smooth)));
                }
                current_statement_begin__ = 561;
                if (as_bool(logical_gt(t,0))) {

                    current_statement_begin__ = 563;
                    if (as_bool(special_case)) {
                        current_statement_begin__ = 563;
                        for (int i = 1; i <= t; ++i) {
                            current_statement_begin__ = 563;
                            stan::math::assign(eta, add(eta,stan::model::rvalue(b, stan::model::cons_list(stan::model::index_multi(get_base1(V,i,"V",1)), stan::model::nil_index_list()), "b")));
                        }
                    } else {
                        current_statement_begin__ = 564;
                        stan::math::assign(eta, add(eta,csr_matrix_times_vector(N,q,w,v,u,b)));
                    }
                }
                current_statement_begin__ = 566;
                if (as_bool(logical_eq(has_intercept,1))) {

                    current_statement_begin__ = 567;
                    if (as_bool(logical_eq(link,1))) {
                        current_statement_begin__ = 567;
                        stan::math::assign(eta, add(eta,get_base1(gamma,1,"gamma",1)));
                    } else {
                        current_statement_begin__ = 568;
                        stan::math::assign(eta, add(subtract(eta,min(eta)),get_base1(gamma,1,"gamma",1)));
                    }
                } else {

                    current_statement_begin__ = 573;
                    stan::math::assign(eta, add(eta,dot_product(xbar,beta)));
                }
                current_statement_begin__ = 576;
                if (as_bool(logical_eq(family,3))) {

                    current_statement_begin__ = 577;
                    if (as_bool(logical_eq(link,1))) {
                        current_statement_begin__ = 577;
                        stan::math::assign(eta, add(add(eta,log(aux)),log(get_base1(noise,1,"noise",1))));
                    } else if (as_bool(logical_eq(link,2))) {
                        current_statement_begin__ = 578;
                        stan::math::assign(eta, elt_multiply(multiply(eta,aux),get_base1(noise,1,"noise",1)));
                    } else {
                        current_statement_begin__ = 579;
                        stan::math::assign(eta, add(add(eta,sqrt(aux)),sqrt(get_base1(noise,1,"noise",1))));
                    }
                }
                current_statement_begin__ = 583;
                if (as_bool((primitive_value(logical_eq(has_weights,0)) && primitive_value(logical_eq(prior_PD,0))))) {

                    current_statement_begin__ = 584;
                    if (as_bool(logical_neq(family,2))) {

                        current_statement_begin__ = 585;
                        if (as_bool(logical_eq(link,1))) {
                            current_statement_begin__ = 585;
                            lp_accum__.add(poisson_log_log(y,eta));
                        } else {
                            current_statement_begin__ = 586;
                            lp_accum__.add(poisson_log(y,linkinv_count(eta,link, pstream__)));
                        }
                    } else {

                        current_statement_begin__ = 589;
                        if (as_bool(logical_eq(link,1))) {
                            current_statement_begin__ = 589;
                            lp_accum__.add(neg_binomial_2_log_log(y,eta,aux));
                        } else {
                            current_statement_begin__ = 590;
                            lp_accum__.add(neg_binomial_2_log(y,linkinv_count(eta,link, pstream__),aux));
                        }
                    }
                } else if (as_bool((primitive_value(logical_neq(family,2)) && primitive_value(logical_eq(prior_PD,0))))) {
                    current_statement_begin__ = 594;
                    lp_accum__.add(dot_product(weights,pw_pois(y,eta,link, pstream__)));
                } else if (as_bool(logical_eq(prior_PD,0))) {
                    current_statement_begin__ = 596;
                    lp_accum__.add(dot_product(weights,pw_nb(y,eta,aux,link, pstream__)));
                }
                current_statement_begin__ = 599;
                if (as_bool((primitive_value((primitive_value(logical_gt(family,1)) && primitive_value(logical_gt(prior_dist_for_aux,0)))) && primitive_value(logical_gt(prior_scale_for_aux,0))))) {
                    {
                        T__ log_half;
                        (void) log_half;  // dummy to suppress unused var warning

                        stan::math::initialize(log_half, DUMMY_VAR__);
                        stan::math::fill(log_half,DUMMY_VAR__);
                        stan::math::assign(log_half,-(0.6931471805599454));


                        current_statement_begin__ = 602;
                        if (as_bool(logical_eq(prior_dist_for_aux,1))) {
                            current_statement_begin__ = 603;
                            lp_accum__.add((normal_log(aux_unscaled,0,1) - log_half));
                        } else if (as_bool(logical_eq(prior_dist_for_aux,2))) {
                            current_statement_begin__ = 605;
                            lp_accum__.add((student_t_log(aux_unscaled,prior_df_for_aux,0,1) - log_half));
                        } else {
                            current_statement_begin__ = 607;
                            lp_accum__.add(exponential_log(aux_unscaled,1));
                        }
                    }
                }
                current_statement_begin__ = 613;
                if (as_bool(logical_eq(prior_dist,1))) {
                    current_statement_begin__ = 613;
                    lp_accum__.add(normal_log(z_beta,0,1));
                } else if (as_bool(logical_eq(prior_dist,2))) {
                    current_statement_begin__ = 614;
                    lp_accum__.add(normal_log(z_beta,0,1));
                } else if (as_bool(logical_eq(prior_dist,3))) {
                    {
                        T__ log_half;
                        (void) log_half;  // dummy to suppress unused var warning

                        stan::math::initialize(log_half, DUMMY_VAR__);
                        stan::math::fill(log_half,DUMMY_VAR__);
                        stan::math::assign(log_half,-(0.6931471805599454));


                        current_statement_begin__ = 617;
                        lp_accum__.add(normal_log(z_beta,0,1));
                        current_statement_begin__ = 618;
                        lp_accum__.add((normal_log(get_base1(local,1,"local",1),0,1) - log_half));
                        current_statement_begin__ = 619;
                        lp_accum__.add(inv_gamma_log(get_base1(local,2,"local",1),multiply(0.5,prior_df),multiply(0.5,prior_df)));
                        current_statement_begin__ = 620;
                        lp_accum__.add((normal_log(get_base1(global,1,"global",1),0,1) - log_half));
                        current_statement_begin__ = 621;
                        lp_accum__.add(inv_gamma_log(get_base1(global,2,"global",1),(0.5 * global_prior_df),(0.5 * global_prior_df)));
                    }
                } else if (as_bool(logical_eq(prior_dist,4))) {
                    {
                        T__ log_half;
                        (void) log_half;  // dummy to suppress unused var warning

                        stan::math::initialize(log_half, DUMMY_VAR__);
                        stan::math::fill(log_half,DUMMY_VAR__);
                        stan::math::assign(log_half,-(0.6931471805599454));


                        current_statement_begin__ = 625;
                        lp_accum__.add(normal_log(z_beta,0,1));
                        current_statement_begin__ = 626;
                        lp_accum__.add((normal_log(get_base1(local,1,"local",1),0,1) - log_half));
                        current_statement_begin__ = 627;
                        lp_accum__.add(inv_gamma_log(get_base1(local,2,"local",1),multiply(0.5,prior_df),multiply(0.5,prior_df)));
                        current_statement_begin__ = 628;
                        lp_accum__.add((normal_log(get_base1(local,3,"local",1),0,1) - log_half));
                        current_statement_begin__ = 630;
                        lp_accum__.add(inv_gamma_log(get_base1(local,4,"local",1),multiply(0.5,prior_scale),multiply(0.5,prior_scale)));
                        current_statement_begin__ = 631;
                        lp_accum__.add((normal_log(get_base1(global,1,"global",1),0,1) - log_half));
                        current_statement_begin__ = 632;
                        lp_accum__.add(inv_gamma_log(get_base1(global,2,"global",1),(0.5 * global_prior_df),(0.5 * global_prior_df)));
                    }
                } else if (as_bool(logical_eq(prior_dist,5))) {

                    current_statement_begin__ = 635;
                    lp_accum__.add(normal_log(z_beta,0,1));
                    current_statement_begin__ = 636;
                    lp_accum__.add(exponential_log(get_base1(mix,1,"mix",1),1));
                } else if (as_bool(logical_eq(prior_dist,6))) {

                    current_statement_begin__ = 639;
                    lp_accum__.add(normal_log(z_beta,0,1));
                    current_statement_begin__ = 640;
                    lp_accum__.add(exponential_log(get_base1(mix,1,"mix",1),1));
                    current_statement_begin__ = 641;
                    lp_accum__.add(chi_square_log(get_base1(one_over_lambda,1,"one_over_lambda",1),get_base1(prior_df,1,"prior_df",1)));
                } else if (as_bool(logical_eq(prior_dist,7))) {

                    current_statement_begin__ = 644;
                    lp_accum__.add(normal_log(z_beta,0,1));
                }
                current_statement_begin__ = 649;
                if (as_bool(logical_eq(has_intercept,1))) {

                    current_statement_begin__ = 650;
                    if (as_bool(logical_eq(prior_dist_for_intercept,1))) {
                        current_statement_begin__ = 651;
                        lp_accum__.add(normal_log(gamma,prior_mean_for_intercept,prior_scale_for_intercept));
                    } else if (as_bool(logical_eq(prior_dist_for_intercept,2))) {
                        current_statement_begin__ = 653;
                        lp_accum__.add(student_t_log(gamma,prior_df_for_intercept,prior_mean_for_intercept,prior_scale_for_intercept));
                    }
                }
                current_statement_begin__ = 658;
                if (as_bool(K_smooth)) {

                    current_statement_begin__ = 659;
                    lp_accum__.add(normal_log(z_beta_smooth,0,1));
                    current_statement_begin__ = 660;
                    if (as_bool(logical_gt(prior_dist_for_smooth,0))) {
                        {
                            T__ log_half;
                            (void) log_half;  // dummy to suppress unused var warning

                            stan::math::initialize(log_half, DUMMY_VAR__);
                            stan::math::fill(log_half,DUMMY_VAR__);
                            stan::math::assign(log_half,-(0.6931471805599454));


                            current_statement_begin__ = 662;
                            if (as_bool(logical_eq(prior_dist_for_smooth,1))) {
                                current_statement_begin__ = 663;
                                lp_accum__.add((normal_log(smooth_sd_raw,0,1) - log_half));
                            } else if (as_bool(logical_eq(prior_dist_for_smooth,2))) {
                                current_statement_begin__ = 665;
                                lp_accum__.add((student_t_log(smooth_sd_raw,prior_df_for_smooth,0,1) - log_half));
                            } else if (as_bool(logical_eq(prior_dist_for_smooth,3))) {
                                current_statement_begin__ = 667;
                                lp_accum__.add(exponential_log(smooth_sd_raw,1));
                            }
                        }
                    }
                }
                current_statement_begin__ = 672;
                if (as_bool(logical_eq(family,3))) {
                    current_statement_begin__ = 672;
                    lp_accum__.add(gamma_log(get_base1(noise,1,"noise",1),aux,1));
                }
                current_statement_begin__ = 674;
                if (as_bool(logical_gt(t,0))) {
                    current_statement_begin__ = 674;
                    decov_lp(z_b,z_T,rho,zeta,tau,regularization,delta,shape,t,p, lp__, lp_accum__, pstream__);
                }
                current_statement_begin__ = 675;
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        lp_accum__.add(lp__);
        return lp_accum__.sum();

    } // log_prob()

    template <bool propto, bool jacobian, typename T_>
    T_ log_prob(Eigen::Matrix<T_,Eigen::Dynamic,1>& params_r,
               std::ostream* pstream = 0) const {
      std::vector<T_> vec_params_r;
      vec_params_r.reserve(params_r.size());
      for (int i = 0; i < params_r.size(); ++i)
        vec_params_r.push_back(params_r(i));
      std::vector<int> vec_params_i;
      return log_prob<propto,jacobian,T_>(vec_params_r, vec_params_i, pstream);
    }


    void get_param_names(std::vector<std::string>& names__) const {
        names__.resize(0);
        names__.push_back("gamma");
        names__.push_back("z_beta");
        names__.push_back("z_beta_smooth");
        names__.push_back("smooth_sd_raw");
        names__.push_back("global");
        names__.push_back("local");
        names__.push_back("mix");
        names__.push_back("one_over_lambda");
        names__.push_back("z_b");
        names__.push_back("z_T");
        names__.push_back("rho");
        names__.push_back("zeta");
        names__.push_back("tau");
        names__.push_back("aux_unscaled");
        names__.push_back("noise");
        names__.push_back("aux");
        names__.push_back("beta");
        names__.push_back("beta_smooth");
        names__.push_back("smooth_sd");
        names__.push_back("b");
        names__.push_back("theta_L");
        names__.push_back("alpha");
        names__.push_back("mean_PPD");
    }


    void get_dims(std::vector<std::vector<size_t> >& dimss__) const {
        dimss__.resize(0);
        std::vector<size_t> dims__;
        dims__.resize(0);
        dims__.push_back(has_intercept);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((logical_eq(prior_dist,7) ? sum(num_normals) : K ));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(K_smooth);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(hs);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(hs);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))));
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(logical_eq(prior_dist,6));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(q);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(len_z_T);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(len_rho);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(len_concentration);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(t);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(logical_gt(family,1));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(logical_eq(family,3));
        dims__.push_back(N);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(K_smooth);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(q);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(len_theta_L);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(has_intercept);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dimss__.push_back(dims__);
    }

    template <typename RNG>
    void write_array(RNG& base_rng__,
                     std::vector<double>& params_r__,
                     std::vector<int>& params_i__,
                     std::vector<double>& vars__,
                     bool include_tparams__ = true,
                     bool include_gqs__ = true,
                     std::ostream* pstream__ = 0) const {
        vars__.resize(0);
        stan::io::reader<double> in__(params_r__,params_i__);
        static const char* function__ = "model_count_namespace::write_array";
        (void) function__;  // dummy to suppress unused var warning
        // read-transform, write parameters
        vector<double> gamma;
        size_t dim_gamma_0__ = has_intercept;
        for (size_t k_0__ = 0; k_0__ < dim_gamma_0__; ++k_0__) {
            gamma.push_back(in__.scalar_lb_constrain((logical_eq(link,1) ? stan::math::negative_infinity() : 0.0 )));
        }
        vector_d z_beta = in__.vector_constrain((logical_eq(prior_dist,7) ? sum(num_normals) : K ));
        vector_d z_beta_smooth = in__.vector_constrain(K_smooth);
        vector_d smooth_sd_raw = in__.vector_lb_constrain(0,(logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));
        vector<double> global;
        size_t dim_global_0__ = hs;
        for (size_t k_0__ = 0; k_0__ < dim_global_0__; ++k_0__) {
            global.push_back(in__.scalar_lb_constrain(0));
        }
        vector<vector_d> local;
        size_t dim_local_0__ = hs;
        for (size_t k_0__ = 0; k_0__ < dim_local_0__; ++k_0__) {
            local.push_back(in__.vector_lb_constrain(0,K));
        }
        vector<vector_d> mix;
        size_t dim_mix_0__ = (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6)));
        for (size_t k_0__ = 0; k_0__ < dim_mix_0__; ++k_0__) {
            mix.push_back(in__.vector_lb_constrain(0,K));
        }
        vector<double> one_over_lambda;
        size_t dim_one_over_lambda_0__ = logical_eq(prior_dist,6);
        for (size_t k_0__ = 0; k_0__ < dim_one_over_lambda_0__; ++k_0__) {
            one_over_lambda.push_back(in__.scalar_lb_constrain(0));
        }
        vector_d z_b = in__.vector_constrain(q);
        vector_d z_T = in__.vector_constrain(len_z_T);
        vector_d rho = in__.vector_lub_constrain(0,1,len_rho);
        vector_d zeta = in__.vector_lb_constrain(0,len_concentration);
        vector_d tau = in__.vector_lb_constrain(0,t);
        vector<double> aux_unscaled;
        size_t dim_aux_unscaled_0__ = logical_gt(family,1);
        for (size_t k_0__ = 0; k_0__ < dim_aux_unscaled_0__; ++k_0__) {
            aux_unscaled.push_back(in__.scalar_lb_constrain(0));
        }
        vector<vector_d> noise;
        size_t dim_noise_0__ = logical_eq(family,3);
        for (size_t k_0__ = 0; k_0__ < dim_noise_0__; ++k_0__) {
            noise.push_back(in__.vector_lb_constrain(0,N));
        }
        for (int k_0__ = 0; k_0__ < has_intercept; ++k_0__) {
            vars__.push_back(gamma[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < (logical_eq(prior_dist,7) ? sum(num_normals) : K ); ++k_0__) {
            vars__.push_back(z_beta[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < K_smooth; ++k_0__) {
            vars__.push_back(z_beta_smooth[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++k_0__) {
            vars__.push_back(smooth_sd_raw[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < hs; ++k_0__) {
            vars__.push_back(global[k_0__]);
        }
        for (int k_1__ = 0; k_1__ < K; ++k_1__) {
            for (int k_0__ = 0; k_0__ < hs; ++k_0__) {
                vars__.push_back(local[k_0__][k_1__]);
            }
        }
        for (int k_1__ = 0; k_1__ < K; ++k_1__) {
            for (int k_0__ = 0; k_0__ < (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))); ++k_0__) {
                vars__.push_back(mix[k_0__][k_1__]);
            }
        }
        for (int k_0__ = 0; k_0__ < logical_eq(prior_dist,6); ++k_0__) {
            vars__.push_back(one_over_lambda[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < q; ++k_0__) {
            vars__.push_back(z_b[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < len_z_T; ++k_0__) {
            vars__.push_back(z_T[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < len_rho; ++k_0__) {
            vars__.push_back(rho[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < len_concentration; ++k_0__) {
            vars__.push_back(zeta[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < t; ++k_0__) {
            vars__.push_back(tau[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < logical_gt(family,1); ++k_0__) {
            vars__.push_back(aux_unscaled[k_0__]);
        }
        for (int k_1__ = 0; k_1__ < N; ++k_1__) {
            for (int k_0__ = 0; k_0__ < logical_eq(family,3); ++k_0__) {
                vars__.push_back(noise[k_0__][k_1__]);
            }
        }

        if (!include_tparams__) return;
        // declare and define transformed parameters
        double lp__ = 0.0;
        (void) lp__;  // dummy to suppress unused var warning
        stan::math::accumulator<double> lp_accum__;

        double DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

        double aux(0.0);
        (void) aux;  // dummy to suppress unused var warning

        stan::math::initialize(aux, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(aux,DUMMY_VAR__);
        stan::math::assign(aux,stan::math::negative_infinity());
        validate_non_negative_index("beta", "K", K);
        vector_d beta(static_cast<Eigen::VectorXd::Index>(K));
        (void) beta;  // dummy to suppress unused var warning

        stan::math::initialize(beta, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(beta,DUMMY_VAR__);
        validate_non_negative_index("beta_smooth", "K_smooth", K_smooth);
        vector_d beta_smooth(static_cast<Eigen::VectorXd::Index>(K_smooth));
        (void) beta_smooth;  // dummy to suppress unused var warning

        stan::math::initialize(beta_smooth, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(beta_smooth,DUMMY_VAR__);
        validate_non_negative_index("smooth_sd", "(logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,\"smooth_map\",1) : 0 )", (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ));
        vector_d smooth_sd(static_cast<Eigen::VectorXd::Index>((logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 )));
        (void) smooth_sd;  // dummy to suppress unused var warning

        stan::math::initialize(smooth_sd, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(smooth_sd,DUMMY_VAR__);
        validate_non_negative_index("b", "q", q);
        vector_d b(static_cast<Eigen::VectorXd::Index>(q));
        (void) b;  // dummy to suppress unused var warning

        stan::math::initialize(b, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(b,DUMMY_VAR__);
        validate_non_negative_index("theta_L", "len_theta_L", len_theta_L);
        vector_d theta_L(static_cast<Eigen::VectorXd::Index>(len_theta_L));
        (void) theta_L;  // dummy to suppress unused var warning

        stan::math::initialize(theta_L, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(theta_L,DUMMY_VAR__);


        try {
            current_statement_begin__ = 483;
            if (as_bool(logical_eq(prior_dist,0))) {
                current_statement_begin__ = 483;
                stan::math::assign(beta, z_beta);
            } else if (as_bool(logical_eq(prior_dist,1))) {
                current_statement_begin__ = 484;
                stan::math::assign(beta, add(elt_multiply(z_beta,prior_scale),prior_mean));
            } else if (as_bool(logical_eq(prior_dist,2))) {
                current_statement_begin__ = 485;
                for (int k = 1; k <= K; ++k) {

                    current_statement_begin__ = 486;
                    stan::math::assign(get_base1_lhs(beta,k,"beta",1), ((CFt(get_base1(z_beta,k,"z_beta",1),get_base1(prior_df,k,"prior_df",1), pstream__) * get_base1(prior_scale,k,"prior_scale",1)) + get_base1(prior_mean,k,"prior_mean",1)));
                }
            } else if (as_bool(logical_eq(prior_dist,3))) {

                current_statement_begin__ = 489;
                if (as_bool((primitive_value(logical_eq(is_continuous,1)) && primitive_value(logical_eq(family,1))))) {
                    current_statement_begin__ = 490;
                    stan::math::assign(beta, hs_prior(z_beta,global,local,global_prior_scale,aux, pstream__));
                } else {
                    current_statement_begin__ = 491;
                    stan::math::assign(beta, hs_prior(z_beta,global,local,global_prior_scale,1, pstream__));
                }
            } else if (as_bool(logical_eq(prior_dist,4))) {

                current_statement_begin__ = 494;
                if (as_bool((primitive_value(logical_eq(is_continuous,1)) && primitive_value(logical_eq(family,1))))) {
                    current_statement_begin__ = 495;
                    stan::math::assign(beta, hsplus_prior(z_beta,global,local,global_prior_scale,aux, pstream__));
                } else {
                    current_statement_begin__ = 496;
                    stan::math::assign(beta, hsplus_prior(z_beta,global,local,global_prior_scale,1, pstream__));
                }
            } else if (as_bool(logical_eq(prior_dist,5))) {
                current_statement_begin__ = 499;
                stan::math::assign(beta, add(prior_mean,elt_multiply(elt_multiply(prior_scale,sqrt(multiply(2,get_base1(mix,1,"mix",1)))),z_beta)));
            } else if (as_bool(logical_eq(prior_dist,6))) {
                current_statement_begin__ = 501;
                stan::math::assign(beta, add(prior_mean,elt_multiply(elt_multiply(multiply(get_base1(one_over_lambda,1,"one_over_lambda",1),prior_scale),sqrt(multiply(2,get_base1(mix,1,"mix",1)))),z_beta)));
            } else if (as_bool(logical_eq(prior_dist,7))) {
                {
                    int z_pos(0);
                    (void) z_pos;  // dummy to suppress unused var warning

                    stan::math::fill(z_pos, std::numeric_limits<int>::min());
                    stan::math::assign(z_pos,1);


                    current_statement_begin__ = 504;
                    for (int k = 1; k <= K; ++k) {

                        current_statement_begin__ = 505;
                        stan::math::assign(get_base1_lhs(beta,k,"beta",1), get_base1(z_beta,z_pos,"z_beta",1));
                        current_statement_begin__ = 506;
                        stan::math::assign(z_pos, (z_pos + 1));
                        current_statement_begin__ = 507;
                        for (int n = 2; n <= get_base1(num_normals,k,"num_normals",1); ++n) {

                            current_statement_begin__ = 508;
                            stan::math::assign(get_base1_lhs(beta,k,"beta",1), (get_base1(beta,k,"beta",1) * get_base1(z_beta,z_pos,"z_beta",1)));
                            current_statement_begin__ = 509;
                            stan::math::assign(z_pos, (z_pos + 1));
                        }
                        current_statement_begin__ = 511;
                        stan::math::assign(get_base1_lhs(beta,k,"beta",1), ((get_base1(beta,k,"beta",1) * pow(get_base1(prior_scale,k,"prior_scale",1),get_base1(num_normals,k,"num_normals",1))) + get_base1(prior_mean,k,"prior_mean",1)));
                    }
                }
            }
            current_statement_begin__ = 515;
            if (as_bool(K_smooth)) {

                current_statement_begin__ = 516;
                stan::math::assign(smooth_sd, add(prior_mean_for_smooth,elt_multiply(prior_scale_for_smooth,smooth_sd_raw)));
                current_statement_begin__ = 517;
                if (as_bool((primitive_value(is_continuous) && primitive_value(logical_eq(family,1))))) {
                    current_statement_begin__ = 517;
                    stan::math::assign(smooth_sd, multiply(smooth_sd,aux));
                }
                current_statement_begin__ = 518;
                stan::math::assign(beta_smooth, elt_multiply(z_beta_smooth,stan::model::rvalue(smooth_sd, stan::model::cons_list(stan::model::index_multi(smooth_map), stan::model::nil_index_list()), "smooth_sd")));
            }
            current_statement_begin__ = 521;
            if (as_bool((primitive_value(logical_gt(family,1)) && primitive_value((primitive_value(logical_eq(prior_dist_for_aux,0)) || primitive_value(logical_lte(prior_scale_for_aux,0))))))) {
                current_statement_begin__ = 522;
                stan::math::assign(aux, get_base1(aux_unscaled,1,"aux_unscaled",1));
            } else if (as_bool(logical_gt(family,1))) {

                current_statement_begin__ = 524;
                stan::math::assign(aux, (prior_scale_for_aux * get_base1(aux_unscaled,1,"aux_unscaled",1)));
                current_statement_begin__ = 525;
                if (as_bool(logical_lte(prior_dist_for_aux,2))) {
                    current_statement_begin__ = 526;
                    stan::math::assign(aux, (aux + prior_mean_for_aux));
                }
            }
            current_statement_begin__ = 529;
            if (as_bool(logical_gt(t,0))) {

                current_statement_begin__ = 530;
                if (as_bool(logical_eq(special_case,1))) {
                    {
                        int start(0);
                        (void) start;  // dummy to suppress unused var warning

                        stan::math::fill(start, std::numeric_limits<int>::min());
                        stan::math::assign(start,1);


                        current_statement_begin__ = 532;
                        stan::math::assign(theta_L, elt_multiply(scale,(logical_eq(family,1) ? stan::math::promote_scalar<double>(tau) : stan::math::promote_scalar<double>(multiply(tau,aux)) )));
                        current_statement_begin__ = 533;
                        if (as_bool(logical_eq(t,1))) {
                            current_statement_begin__ = 533;
                            stan::math::assign(b, multiply(get_base1(theta_L,1,"theta_L",1),z_b));
                        } else {
                            current_statement_begin__ = 534;
                            for (int i = 1; i <= t; ++i) {
                                {
                                    int end(0);
                                    (void) end;  // dummy to suppress unused var warning

                                    stan::math::fill(end, std::numeric_limits<int>::min());
                                    stan::math::assign(end,((start + get_base1(l,i,"l",1)) - 1));


                                    current_statement_begin__ = 536;
                                    stan::model::assign(b, 
                                                stan::model::cons_list(stan::model::index_min_max(start, end), stan::model::nil_index_list()), 
                                                multiply(get_base1(theta_L,i,"theta_L",1),stan::model::rvalue(z_b, stan::model::cons_list(stan::model::index_min_max(start, end), stan::model::nil_index_list()), "z_b")), 
                                                "assigning variable b");
                                    current_statement_begin__ = 537;
                                    stan::math::assign(start, (end + 1));
                                }
                            }
                        }
                    }
                } else {

                    current_statement_begin__ = 541;
                    if (as_bool(logical_eq(family,1))) {
                        current_statement_begin__ = 542;
                        stan::math::assign(theta_L, make_theta_L(len_theta_L,p,1.0,tau,scale,zeta,rho,z_T, pstream__));
                    } else {
                        current_statement_begin__ = 545;
                        stan::math::assign(theta_L, make_theta_L(len_theta_L,p,aux,tau,scale,zeta,rho,z_T, pstream__));
                    }
                    current_statement_begin__ = 547;
                    stan::math::assign(b, make_b(z_b,theta_L,p,l, pstream__));
                }
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        // validate transformed parameters

        // write transformed parameters
        vars__.push_back(aux);
        for (int k_0__ = 0; k_0__ < K; ++k_0__) {
            vars__.push_back(beta[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < K_smooth; ++k_0__) {
            vars__.push_back(beta_smooth[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++k_0__) {
            vars__.push_back(smooth_sd[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < q; ++k_0__) {
            vars__.push_back(b[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < len_theta_L; ++k_0__) {
            vars__.push_back(theta_L[k_0__]);
        }

        if (!include_gqs__) return;
        // declare and define generated quantities
        validate_non_negative_index("alpha", "has_intercept", has_intercept);
        vector<double> alpha(has_intercept, 0.0);
        stan::math::initialize(alpha, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(alpha,DUMMY_VAR__);
        double mean_PPD(0.0);
        (void) mean_PPD;  // dummy to suppress unused var warning

        stan::math::initialize(mean_PPD, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(mean_PPD,DUMMY_VAR__);
        stan::math::assign(mean_PPD,0);


        try {
            current_statement_begin__ = 680;
            if (as_bool(logical_eq(has_intercept,1))) {

                current_statement_begin__ = 681;
                if (as_bool(dense_X)) {
                    current_statement_begin__ = 681;
                    stan::math::assign(get_base1_lhs(alpha,1,"alpha",1), (get_base1(gamma,1,"gamma",1) - dot_product(xbar,beta)));
                } else {
                    current_statement_begin__ = 682;
                    stan::math::assign(get_base1_lhs(alpha,1,"alpha",1), get_base1(gamma,1,"gamma",1));
                }
            }
            {
                validate_non_negative_index("nu", "N", N);
                vector_d nu(static_cast<Eigen::VectorXd::Index>(N));
                (void) nu;  // dummy to suppress unused var warning

                stan::math::initialize(nu, std::numeric_limits<double>::quiet_NaN());
                stan::math::fill(nu,DUMMY_VAR__);
                validate_non_negative_index("eta", "N", N);
                vector_d eta(static_cast<Eigen::VectorXd::Index>(N));
                (void) eta;  // dummy to suppress unused var warning

                stan::math::initialize(eta, std::numeric_limits<double>::quiet_NaN());
                stan::math::fill(eta,DUMMY_VAR__);


                current_statement_begin__ = 688;
                if (as_bool(logical_gt(K,0))) {

                    current_statement_begin__ = 689;
                    if (as_bool(dense_X)) {
                        current_statement_begin__ = 689;
                        stan::math::assign(eta, multiply(get_base1(X,1,"X",1),beta));
                    } else {
                        current_statement_begin__ = 690;
                        stan::math::assign(eta, csr_matrix_times_vector(N,K,w_X,v_X,u_X,beta));
                    }
                } else {
                    current_statement_begin__ = 692;
                    stan::math::assign(eta, rep_vector(0.0,N));
                }
                current_statement_begin__ = 693;
                if (as_bool(logical_eq(has_offset,1))) {
                    current_statement_begin__ = 693;
                    stan::math::assign(eta, add(eta,offset));
                }
                current_statement_begin__ = 694;
                if (as_bool(K_smooth)) {
                    current_statement_begin__ = 694;
                    stan::math::assign(eta, add(eta,multiply(S,beta_smooth)));
                }
                current_statement_begin__ = 695;
                if (as_bool(logical_gt(t,0))) {

                    current_statement_begin__ = 697;
                    if (as_bool(special_case)) {
                        current_statement_begin__ = 697;
                        for (int i = 1; i <= t; ++i) {
                            current_statement_begin__ = 697;
                            stan::math::assign(eta, add(eta,stan::model::rvalue(b, stan::model::cons_list(stan::model::index_multi(get_base1(V,i,"V",1)), stan::model::nil_index_list()), "b")));
                        }
                    } else {
                        current_statement_begin__ = 698;
                        stan::math::assign(eta, add(eta,csr_matrix_times_vector(N,q,w,v,u,b)));
                    }
                }
                current_statement_begin__ = 700;
                if (as_bool(logical_eq(has_intercept,1))) {

                    current_statement_begin__ = 701;
                    if (as_bool(logical_eq(link,1))) {
                        current_statement_begin__ = 701;
                        stan::math::assign(eta, add(eta,get_base1(gamma,1,"gamma",1)));
                    } else {
                        {
                            double shift(0.0);
                            (void) shift;  // dummy to suppress unused var warning

                            stan::math::initialize(shift, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(shift,DUMMY_VAR__);


                            current_statement_begin__ = 704;
                            stan::math::assign(shift, min(eta));
                            current_statement_begin__ = 705;
                            stan::math::assign(eta, add(subtract(eta,shift),get_base1(gamma,1,"gamma",1)));
                            current_statement_begin__ = 706;
                            stan::math::assign(get_base1_lhs(alpha,1,"alpha",1), (get_base1(alpha,1,"alpha",1) - shift));
                        }
                    }
                } else {

                    current_statement_begin__ = 712;
                    stan::math::assign(eta, add(eta,dot_product(xbar,beta)));
                }
                current_statement_begin__ = 715;
                if (as_bool(logical_eq(family,3))) {

                    current_statement_begin__ = 716;
                    if (as_bool(logical_eq(link,1))) {
                        current_statement_begin__ = 716;
                        stan::math::assign(eta, add(add(eta,log(aux)),log(get_base1(noise,1,"noise",1))));
                    } else if (as_bool(logical_eq(link,2))) {
                        current_statement_begin__ = 717;
                        stan::math::assign(eta, elt_multiply(multiply(eta,aux),get_base1(noise,1,"noise",1)));
                    } else {
                        current_statement_begin__ = 718;
                        stan::math::assign(eta, add(add(eta,sqrt(aux)),sqrt(get_base1(noise,1,"noise",1))));
                    }
                }
                current_statement_begin__ = 720;
                stan::math::assign(nu, linkinv_count(eta,link, pstream__));
                current_statement_begin__ = 721;
                if (as_bool(logical_neq(family,2))) {
                    current_statement_begin__ = 721;
                    for (int n = 1; n <= N; ++n) {

                        current_statement_begin__ = 722;
                        if (as_bool(logical_lt(get_base1(nu,n,"nu",1),poisson_max))) {
                            current_statement_begin__ = 722;
                            stan::math::assign(mean_PPD, (mean_PPD + poisson_rng(get_base1(nu,n,"nu",1), base_rng__)));
                        } else {
                            current_statement_begin__ = 723;
                            stan::math::assign(mean_PPD, (mean_PPD + normal_rng(get_base1(nu,n,"nu",1),sqrt(get_base1(nu,n,"nu",1)), base_rng__)));
                        }
                    }
                } else {
                    current_statement_begin__ = 725;
                    for (int n = 1; n <= N; ++n) {
                        {
                            double gamma_temp(0.0);
                            (void) gamma_temp;  // dummy to suppress unused var warning

                            stan::math::initialize(gamma_temp, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(gamma_temp,DUMMY_VAR__);


                            current_statement_begin__ = 727;
                            if (as_bool(is_inf(aux))) {
                                current_statement_begin__ = 727;
                                stan::math::assign(gamma_temp, get_base1(nu,n,"nu",1));
                            } else {
                                current_statement_begin__ = 728;
                                stan::math::assign(gamma_temp, gamma_rng(aux,(aux / get_base1(nu,n,"nu",1)), base_rng__));
                            }
                            current_statement_begin__ = 729;
                            if (as_bool(logical_lt(gamma_temp,poisson_max))) {
                                current_statement_begin__ = 730;
                                stan::math::assign(mean_PPD, (mean_PPD + poisson_rng(gamma_temp, base_rng__)));
                            } else {
                                current_statement_begin__ = 731;
                                stan::math::assign(mean_PPD, (mean_PPD + normal_rng(gamma_temp,sqrt(gamma_temp), base_rng__)));
                            }
                        }
                    }
                }
                current_statement_begin__ = 733;
                stan::math::assign(mean_PPD, (mean_PPD / N));
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        // validate generated quantities

        // write generated quantities
        for (int k_0__ = 0; k_0__ < has_intercept; ++k_0__) {
            vars__.push_back(alpha[k_0__]);
        }
        vars__.push_back(mean_PPD);

    }

    template <typename RNG>
    void write_array(RNG& base_rng,
                     Eigen::Matrix<double,Eigen::Dynamic,1>& params_r,
                     Eigen::Matrix<double,Eigen::Dynamic,1>& vars,
                     bool include_tparams = true,
                     bool include_gqs = true,
                     std::ostream* pstream = 0) const {
      std::vector<double> params_r_vec(params_r.size());
      for (int i = 0; i < params_r.size(); ++i)
        params_r_vec[i] = params_r(i);
      std::vector<double> vars_vec;
      std::vector<int> params_i_vec;
      write_array(base_rng,params_r_vec,params_i_vec,vars_vec,include_tparams,include_gqs,pstream);
      vars.resize(vars_vec.size());
      for (int i = 0; i < vars.size(); ++i)
        vars(i) = vars_vec[i];
    }

    static std::string model_name() {
        return "model_count";
    }


    void constrained_param_names(std::vector<std::string>& param_names__,
                                 bool include_tparams__ = true,
                                 bool include_gqs__ = true) const {
        std::stringstream param_name_stream__;
        for (int k_0__ = 1; k_0__ <= has_intercept; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "gamma" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (logical_eq(prior_dist,7) ? sum(num_normals) : K ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_beta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= K_smooth; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_beta_smooth" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "smooth_sd_raw" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= hs; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "global" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_1__ = 1; k_1__ <= K; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= hs; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "local" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        for (int k_1__ = 1; k_1__ <= K; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))); ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "mix" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        for (int k_0__ = 1; k_0__ <= logical_eq(prior_dist,6); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "one_over_lambda" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= q; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_b" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_z_T; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_T" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_rho; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "rho" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_concentration; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "zeta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= t; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "tau" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= logical_gt(family,1); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "aux_unscaled" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_1__ = 1; k_1__ <= N; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= logical_eq(family,3); ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "noise" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }

        if (!include_gqs__ && !include_tparams__) return;
        param_name_stream__.str(std::string());
        param_name_stream__ << "aux";
        param_names__.push_back(param_name_stream__.str());
        for (int k_0__ = 1; k_0__ <= K; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "beta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= K_smooth; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "beta_smooth" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "smooth_sd" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= q; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "b" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_theta_L; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "theta_L" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__) return;
        for (int k_0__ = 1; k_0__ <= has_intercept; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "alpha" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        param_name_stream__.str(std::string());
        param_name_stream__ << "mean_PPD";
        param_names__.push_back(param_name_stream__.str());
    }


    void unconstrained_param_names(std::vector<std::string>& param_names__,
                                   bool include_tparams__ = true,
                                   bool include_gqs__ = true) const {
        std::stringstream param_name_stream__;
        for (int k_0__ = 1; k_0__ <= has_intercept; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "gamma" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (logical_eq(prior_dist,7) ? sum(num_normals) : K ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_beta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= K_smooth; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_beta_smooth" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "smooth_sd_raw" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= hs; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "global" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_1__ = 1; k_1__ <= K; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= hs; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "local" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        for (int k_1__ = 1; k_1__ <= K; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))); ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "mix" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        for (int k_0__ = 1; k_0__ <= logical_eq(prior_dist,6); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "one_over_lambda" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= q; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_b" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_z_T; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_T" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_rho; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "rho" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_concentration; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "zeta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= t; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "tau" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= logical_gt(family,1); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "aux_unscaled" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_1__ = 1; k_1__ <= N; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= logical_eq(family,3); ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "noise" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }

        if (!include_gqs__ && !include_tparams__) return;
        param_name_stream__.str(std::string());
        param_name_stream__ << "aux";
        param_names__.push_back(param_name_stream__.str());
        for (int k_0__ = 1; k_0__ <= K; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "beta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= K_smooth; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "beta_smooth" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (logical_gt(K_smooth,0) ? get_base1(smooth_map,K_smooth,"smooth_map",1) : 0 ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "smooth_sd" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= q; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "b" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= len_theta_L; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "theta_L" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__) return;
        for (int k_0__ = 1; k_0__ <= has_intercept; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "alpha" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        param_name_stream__.str(std::string());
        param_name_stream__ << "mean_PPD";
        param_names__.push_back(param_name_stream__.str());
    }

}; // model

}




// Code generated by Stan version 2.16.0

#include <stan/model/model_header.hpp>

namespace model_lm_namespace {

using std::istream;
using std::string;
using std::stringstream;
using std::vector;
using stan::io::dump;
using stan::math::lgamma;
using stan::model::prob_grad;
using namespace stan::math;

typedef Eigen::Matrix<double,Eigen::Dynamic,1> vector_d;
typedef Eigen::Matrix<double,1,Eigen::Dynamic> row_vector_d;
typedef Eigen::Matrix<double,Eigen::Dynamic,Eigen::Dynamic> matrix_d;

static int current_statement_begin__;

stan::io::program_reader prog_reader__() {
    stan::io::program_reader reader;
    reader.add_event(0, 0, "start", "model_lm");
    reader.add_event(133, 133, "end", "model_lm");
    return reader;
}

template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__, typename T_lp__, typename T_lp_accum__>
typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__, T_lp__>::type>::type
ll_mvn_ols_qr_lp(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& theta,
                     const Eigen::Matrix<T1__, Eigen::Dynamic,1>& b,
                     const T2__& intercept,
                     const T3__& ybar,
                     const T4__& SSR,
                     const T5__& sigma,
                     const int& N, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__, T_lp__>::type>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 38;
        lp_accum__.add((((-(0.5) * ((dot_self(subtract(theta,b)) + (N * square((intercept - ybar)))) + SSR)) / square(sigma)) - (N * (log(sigma) + 0.91893853320467267))));
        current_statement_begin__ = 42;
        return stan::math::promote_scalar<fun_return_scalar_t__>(get_lp(lp__, lp_accum__));
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct ll_mvn_ols_qr_lp_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__, typename T_lp__, typename T_lp_accum__>
        typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__, T_lp__>::type>::type
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& theta,
                     const Eigen::Matrix<T1__, Eigen::Dynamic,1>& b,
                     const T2__& intercept,
                     const T3__& ybar,
                     const T4__& SSR,
                     const T5__& sigma,
                     const int& N, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) const {
        return ll_mvn_ols_qr_lp(theta, b, intercept, ybar, SSR, sigma, N, lp__, lp_accum__, pstream__);
    }
};

class model_lm : public prob_grad {
private:
    int has_intercept;
    int prior_dist_for_intercept;
    double prior_scale_for_intercept;
    double prior_mean_for_intercept;
    int prior_dist;
    int prior_PD;
    double eta;
    int J;
    vector<int> N;
    int K;
    vector<vector_d> xbarR_inv;
    vector<double> ybar;
    double center_y;
    vector<double> s_Y;
    vector<vector_d> Rb;
    vector<double> SSR;
    vector<matrix_d> R_inv;
    double half_K;
    vector<double> sqrt_inv_N;
    vector<double> sqrt_Nm1;
public:
    model_lm(stan::io::var_context& context__,
        std::ostream* pstream__ = 0)
        : prob_grad(0) {
        ctor_body(context__, 0, pstream__);
    }

    model_lm(stan::io::var_context& context__,
        unsigned int random_seed__,
        std::ostream* pstream__ = 0)
        : prob_grad(0) {
        ctor_body(context__, random_seed__, pstream__);
    }

    void ctor_body(stan::io::var_context& context__,
                   unsigned int random_seed__,
                   std::ostream* pstream__) {
        boost::ecuyer1988 base_rng__ =
          stan::services::util::create_rng(random_seed__, 0);
        (void) base_rng__;  // suppress unused var warning

        current_statement_begin__ = -1;

        static const char* function__ = "model_lm_namespace::model_lm";
        (void) function__;  // dummy to suppress unused var warning
        size_t pos__;
        (void) pos__;  // dummy to suppress unused var warning
        std::vector<int> vals_i__;
        std::vector<double> vals_r__;
        double DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

        // initialize member variables
        context__.validate_dims("data initialization", "has_intercept", "int", context__.to_vec());
        has_intercept = int(0);
        vals_i__ = context__.vals_i("has_intercept");
        pos__ = 0;
        has_intercept = vals_i__[pos__++];
        context__.validate_dims("data initialization", "prior_dist_for_intercept", "int", context__.to_vec());
        prior_dist_for_intercept = int(0);
        vals_i__ = context__.vals_i("prior_dist_for_intercept");
        pos__ = 0;
        prior_dist_for_intercept = vals_i__[pos__++];
        context__.validate_dims("data initialization", "prior_scale_for_intercept", "double", context__.to_vec());
        prior_scale_for_intercept = double(0);
        vals_r__ = context__.vals_r("prior_scale_for_intercept");
        pos__ = 0;
        prior_scale_for_intercept = vals_r__[pos__++];
        context__.validate_dims("data initialization", "prior_mean_for_intercept", "double", context__.to_vec());
        prior_mean_for_intercept = double(0);
        vals_r__ = context__.vals_r("prior_mean_for_intercept");
        pos__ = 0;
        prior_mean_for_intercept = vals_r__[pos__++];
        context__.validate_dims("data initialization", "prior_dist", "int", context__.to_vec());
        prior_dist = int(0);
        vals_i__ = context__.vals_i("prior_dist");
        pos__ = 0;
        prior_dist = vals_i__[pos__++];
        context__.validate_dims("data initialization", "prior_PD", "int", context__.to_vec());
        prior_PD = int(0);
        vals_i__ = context__.vals_i("prior_PD");
        pos__ = 0;
        prior_PD = vals_i__[pos__++];
        context__.validate_dims("data initialization", "eta", "double", context__.to_vec());
        eta = double(0);
        vals_r__ = context__.vals_r("eta");
        pos__ = 0;
        eta = vals_r__[pos__++];
        context__.validate_dims("data initialization", "J", "int", context__.to_vec());
        J = int(0);
        vals_i__ = context__.vals_i("J");
        pos__ = 0;
        J = vals_i__[pos__++];
        validate_non_negative_index("N", "J", J);
        context__.validate_dims("data initialization", "N", "int", context__.to_vec(J));
        validate_non_negative_index("N", "J", J);
        N = std::vector<int>(J,int(0));
        vals_i__ = context__.vals_i("N");
        pos__ = 0;
        size_t N_limit_0__ = J;
        for (size_t i_0__ = 0; i_0__ < N_limit_0__; ++i_0__) {
            N[i_0__] = vals_i__[pos__++];
        }
        context__.validate_dims("data initialization", "K", "int", context__.to_vec());
        K = int(0);
        vals_i__ = context__.vals_i("K");
        pos__ = 0;
        K = vals_i__[pos__++];
        validate_non_negative_index("xbarR_inv", "J", J);
        validate_non_negative_index("xbarR_inv", "K", K);
        context__.validate_dims("data initialization", "xbarR_inv", "vector_d", context__.to_vec(J,K));
        validate_non_negative_index("xbarR_inv", "J", J);
        validate_non_negative_index("xbarR_inv", "K", K);
        xbarR_inv = std::vector<vector_d>(J,vector_d(static_cast<Eigen::VectorXd::Index>(K)));
        vals_r__ = context__.vals_r("xbarR_inv");
        pos__ = 0;
        size_t xbarR_inv_i_vec_lim__ = K;
        for (size_t i_vec__ = 0; i_vec__ < xbarR_inv_i_vec_lim__; ++i_vec__) {
            size_t xbarR_inv_limit_0__ = J;
            for (size_t i_0__ = 0; i_0__ < xbarR_inv_limit_0__; ++i_0__) {
                xbarR_inv[i_0__][i_vec__] = vals_r__[pos__++];
            }
        }
        validate_non_negative_index("ybar", "J", J);
        context__.validate_dims("data initialization", "ybar", "double", context__.to_vec(J));
        validate_non_negative_index("ybar", "J", J);
        ybar = std::vector<double>(J,double(0));
        vals_r__ = context__.vals_r("ybar");
        pos__ = 0;
        size_t ybar_limit_0__ = J;
        for (size_t i_0__ = 0; i_0__ < ybar_limit_0__; ++i_0__) {
            ybar[i_0__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "center_y", "double", context__.to_vec());
        center_y = double(0);
        vals_r__ = context__.vals_r("center_y");
        pos__ = 0;
        center_y = vals_r__[pos__++];
        validate_non_negative_index("s_Y", "J", J);
        context__.validate_dims("data initialization", "s_Y", "double", context__.to_vec(J));
        validate_non_negative_index("s_Y", "J", J);
        s_Y = std::vector<double>(J,double(0));
        vals_r__ = context__.vals_r("s_Y");
        pos__ = 0;
        size_t s_Y_limit_0__ = J;
        for (size_t i_0__ = 0; i_0__ < s_Y_limit_0__; ++i_0__) {
            s_Y[i_0__] = vals_r__[pos__++];
        }
        validate_non_negative_index("Rb", "J", J);
        validate_non_negative_index("Rb", "K", K);
        context__.validate_dims("data initialization", "Rb", "vector_d", context__.to_vec(J,K));
        validate_non_negative_index("Rb", "J", J);
        validate_non_negative_index("Rb", "K", K);
        Rb = std::vector<vector_d>(J,vector_d(static_cast<Eigen::VectorXd::Index>(K)));
        vals_r__ = context__.vals_r("Rb");
        pos__ = 0;
        size_t Rb_i_vec_lim__ = K;
        for (size_t i_vec__ = 0; i_vec__ < Rb_i_vec_lim__; ++i_vec__) {
            size_t Rb_limit_0__ = J;
            for (size_t i_0__ = 0; i_0__ < Rb_limit_0__; ++i_0__) {
                Rb[i_0__][i_vec__] = vals_r__[pos__++];
            }
        }
        validate_non_negative_index("SSR", "J", J);
        context__.validate_dims("data initialization", "SSR", "double", context__.to_vec(J));
        validate_non_negative_index("SSR", "J", J);
        SSR = std::vector<double>(J,double(0));
        vals_r__ = context__.vals_r("SSR");
        pos__ = 0;
        size_t SSR_limit_0__ = J;
        for (size_t i_0__ = 0; i_0__ < SSR_limit_0__; ++i_0__) {
            SSR[i_0__] = vals_r__[pos__++];
        }
        validate_non_negative_index("R_inv", "J", J);
        validate_non_negative_index("R_inv", "K", K);
        validate_non_negative_index("R_inv", "K", K);
        context__.validate_dims("data initialization", "R_inv", "matrix_d", context__.to_vec(J,K,K));
        validate_non_negative_index("R_inv", "J", J);
        validate_non_negative_index("R_inv", "K", K);
        validate_non_negative_index("R_inv", "K", K);
        R_inv = std::vector<matrix_d>(J,matrix_d(static_cast<Eigen::VectorXd::Index>(K),static_cast<Eigen::VectorXd::Index>(K)));
        vals_r__ = context__.vals_r("R_inv");
        pos__ = 0;
        size_t R_inv_m_mat_lim__ = K;
        size_t R_inv_n_mat_lim__ = K;
        for (size_t n_mat__ = 0; n_mat__ < R_inv_n_mat_lim__; ++n_mat__) {
            for (size_t m_mat__ = 0; m_mat__ < R_inv_m_mat_lim__; ++m_mat__) {
                size_t R_inv_limit_0__ = J;
                for (size_t i_0__ = 0; i_0__ < R_inv_limit_0__; ++i_0__) {
                    R_inv[i_0__](m_mat__,n_mat__) = vals_r__[pos__++];
            }
            }
        }

        // validate, data variables
        check_greater_or_equal(function__,"has_intercept",has_intercept,0);
        check_less_or_equal(function__,"has_intercept",has_intercept,1);
        check_greater_or_equal(function__,"prior_dist_for_intercept",prior_dist_for_intercept,0);
        check_less_or_equal(function__,"prior_dist_for_intercept",prior_dist_for_intercept,1);
        check_greater_or_equal(function__,"prior_scale_for_intercept",prior_scale_for_intercept,0);
        check_greater_or_equal(function__,"prior_dist",prior_dist,0);
        check_less_or_equal(function__,"prior_dist",prior_dist,1);
        check_greater_or_equal(function__,"prior_PD",prior_PD,0);
        check_less_or_equal(function__,"prior_PD",prior_PD,1);
        check_greater_or_equal(function__,"eta",eta,0);
        check_greater_or_equal(function__,"J",J,1);
        for (int k0__ = 0; k0__ < J; ++k0__) {
            check_greater_or_equal(function__,"N[k0__]",N[k0__],1);
        }
        check_greater_or_equal(function__,"K",K,1);
        check_less_or_equal(function__,"K",K,min(N));
        for (int k0__ = 0; k0__ < J; ++k0__) {
            check_greater_or_equal(function__,"s_Y[k0__]",s_Y[k0__],0);
        }
        for (int k0__ = 0; k0__ < J; ++k0__) {
            check_greater_or_equal(function__,"SSR[k0__]",SSR[k0__],0);
        }
        // initialize data variables
        half_K = double(0);
        stan::math::fill(half_K,DUMMY_VAR__);
        stan::math::assign(half_K,(0.5 * K));
        validate_non_negative_index("sqrt_inv_N", "J", J);
        sqrt_inv_N = std::vector<double>(J,double(0));
        stan::math::fill(sqrt_inv_N,DUMMY_VAR__);
        validate_non_negative_index("sqrt_Nm1", "J", J);
        sqrt_Nm1 = std::vector<double>(J,double(0));
        stan::math::fill(sqrt_Nm1,DUMMY_VAR__);

        try {
            current_statement_begin__ = 70;
            for (int j = 1; j <= J; ++j) {

                current_statement_begin__ = 71;
                stan::math::assign(get_base1_lhs(sqrt_inv_N,j,"sqrt_inv_N",1), sqrt((1.0 / get_base1(N,j,"N",1))));
                current_statement_begin__ = 72;
                stan::math::assign(get_base1_lhs(sqrt_Nm1,j,"sqrt_Nm1",1), sqrt((get_base1(N,j,"N",1) - 1.0)));
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        // validate transformed data

        // validate, set parameter ranges
        num_params_r__ = 0U;
        param_ranges_i__.clear();
        validate_non_negative_index("u", "K", K);
        validate_non_negative_index("u", "J", J);
        num_params_r__ += (K) * J;
        validate_non_negative_index("z_alpha", "(J * has_intercept)", (J * has_intercept));
        num_params_r__ += (J * has_intercept);
        validate_non_negative_index("R2", "J", J);
        num_params_r__ += J;
        validate_non_negative_index("log_omega", "(J * (1 - prior_PD))", (J * (1 - prior_PD)));
        num_params_r__ += (J * (1 - prior_PD));
    }

    ~model_lm() { }


    void transform_inits(const stan::io::var_context& context__,
                         std::vector<int>& params_i__,
                         std::vector<double>& params_r__,
                         std::ostream* pstream__) const {
        stan::io::writer<double> writer__(params_r__,params_i__);
        size_t pos__;
        (void) pos__; // dummy call to supress warning
        std::vector<double> vals_r__;
        std::vector<int> vals_i__;

        if (!(context__.contains_r("u")))
            throw std::runtime_error("variable u missing");
        vals_r__ = context__.vals_r("u");
        pos__ = 0U;
        validate_non_negative_index("u", "J", J);
        validate_non_negative_index("u", "K", K);
        context__.validate_dims("initialization", "u", "vector_d", context__.to_vec(J,K));
        // generate_declaration u
        std::vector<vector_d> u(J,vector_d(static_cast<Eigen::VectorXd::Index>(K)));
        for (int j1__ = 0U; j1__ < K; ++j1__)
            for (int i0__ = 0U; i0__ < J; ++i0__)
                u[i0__](j1__) = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < J; ++i0__)
            try {
            writer__.unit_vector_unconstrain(u[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable u: ") + e.what());
        }

        if (!(context__.contains_r("z_alpha")))
            throw std::runtime_error("variable z_alpha missing");
        vals_r__ = context__.vals_r("z_alpha");
        pos__ = 0U;
        validate_non_negative_index("z_alpha", "(J * has_intercept)", (J * has_intercept));
        context__.validate_dims("initialization", "z_alpha", "double", context__.to_vec((J * has_intercept)));
        // generate_declaration z_alpha
        std::vector<double> z_alpha((J * has_intercept),double(0));
        for (int i0__ = 0U; i0__ < (J * has_intercept); ++i0__)
            z_alpha[i0__] = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < (J * has_intercept); ++i0__)
            try {
            writer__.scalar_unconstrain(z_alpha[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable z_alpha: ") + e.what());
        }

        if (!(context__.contains_r("R2")))
            throw std::runtime_error("variable R2 missing");
        vals_r__ = context__.vals_r("R2");
        pos__ = 0U;
        validate_non_negative_index("R2", "J", J);
        context__.validate_dims("initialization", "R2", "double", context__.to_vec(J));
        // generate_declaration R2
        std::vector<double> R2(J,double(0));
        for (int i0__ = 0U; i0__ < J; ++i0__)
            R2[i0__] = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < J; ++i0__)
            try {
            writer__.scalar_lub_unconstrain(0,1,R2[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable R2: ") + e.what());
        }

        if (!(context__.contains_r("log_omega")))
            throw std::runtime_error("variable log_omega missing");
        vals_r__ = context__.vals_r("log_omega");
        pos__ = 0U;
        validate_non_negative_index("log_omega", "(J * (1 - prior_PD))", (J * (1 - prior_PD)));
        context__.validate_dims("initialization", "log_omega", "vector_d", context__.to_vec((J * (1 - prior_PD))));
        // generate_declaration log_omega
        vector_d log_omega(static_cast<Eigen::VectorXd::Index>((J * (1 - prior_PD))));
        for (int j1__ = 0U; j1__ < (J * (1 - prior_PD)); ++j1__)
            log_omega(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_unconstrain(log_omega);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable log_omega: ") + e.what());
        }

        params_r__ = writer__.data_r();
        params_i__ = writer__.data_i();
    }

    void transform_inits(const stan::io::var_context& context,
                         Eigen::Matrix<double,Eigen::Dynamic,1>& params_r,
                         std::ostream* pstream__) const {
      std::vector<double> params_r_vec;
      std::vector<int> params_i_vec;
      transform_inits(context, params_i_vec, params_r_vec, pstream__);
      params_r.resize(params_r_vec.size());
      for (int i = 0; i < params_r.size(); ++i)
        params_r(i) = params_r_vec[i];
    }


    template <bool propto__, bool jacobian__, typename T__>
    T__ log_prob(vector<T__>& params_r__,
                 vector<int>& params_i__,
                 std::ostream* pstream__ = 0) const {

        T__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

        T__ lp__(0.0);
        stan::math::accumulator<T__> lp_accum__;

        // model parameters
        stan::io::reader<T__> in__(params_r__,params_i__);

        vector<Eigen::Matrix<T__,Eigen::Dynamic,1> > u;
        size_t dim_u_0__ = J;
        u.reserve(dim_u_0__);
        for (size_t k_0__ = 0; k_0__ < dim_u_0__; ++k_0__) {
            if (jacobian__)
                u.push_back(in__.unit_vector_constrain(K,lp__));
            else
                u.push_back(in__.unit_vector_constrain(K));
        }

        vector<T__> z_alpha;
        size_t dim_z_alpha_0__ = (J * has_intercept);
        z_alpha.reserve(dim_z_alpha_0__);
        for (size_t k_0__ = 0; k_0__ < dim_z_alpha_0__; ++k_0__) {
            if (jacobian__)
                z_alpha.push_back(in__.scalar_constrain(lp__));
            else
                z_alpha.push_back(in__.scalar_constrain());
        }

        vector<T__> R2;
        size_t dim_R2_0__ = J;
        R2.reserve(dim_R2_0__);
        for (size_t k_0__ = 0; k_0__ < dim_R2_0__; ++k_0__) {
            if (jacobian__)
                R2.push_back(in__.scalar_lub_constrain(0,1,lp__));
            else
                R2.push_back(in__.scalar_lub_constrain(0,1));
        }

        Eigen::Matrix<T__,Eigen::Dynamic,1>  log_omega;
        (void) log_omega;  // dummy to suppress unused var warning
        if (jacobian__)
            log_omega = in__.vector_constrain((J * (1 - prior_PD)),lp__);
        else
            log_omega = in__.vector_constrain((J * (1 - prior_PD)));


        // transformed parameters
        validate_non_negative_index("alpha", "(J * has_intercept)", (J * has_intercept));
        vector<T__> alpha((J * has_intercept));
        stan::math::initialize(alpha, DUMMY_VAR__);
        stan::math::fill(alpha,DUMMY_VAR__);
        validate_non_negative_index("theta", "K", K);
        validate_non_negative_index("theta", "J", J);
        vector<Eigen::Matrix<T__,Eigen::Dynamic,1> > theta(J, (Eigen::Matrix<T__,Eigen::Dynamic,1> (static_cast<Eigen::VectorXd::Index>(K))));
        stan::math::initialize(theta, DUMMY_VAR__);
        stan::math::fill(theta,DUMMY_VAR__);
        validate_non_negative_index("sigma", "J", J);
        vector<T__> sigma(J);
        stan::math::initialize(sigma, DUMMY_VAR__);
        stan::math::fill(sigma,DUMMY_VAR__);


        try {
            current_statement_begin__ = 85;
            for (int j = 1; j <= J; ++j) {
                {
                    T__ Delta_y;
                    (void) Delta_y;  // dummy to suppress unused var warning

                    stan::math::initialize(Delta_y, DUMMY_VAR__);
                    stan::math::fill(Delta_y,DUMMY_VAR__);
                    stan::math::assign(Delta_y,(logical_eq(prior_PD,0) ? stan::math::promote_scalar<T__>((get_base1(s_Y,j,"s_Y",1) * exp(get_base1(log_omega,j,"log_omega",1)))) : stan::math::promote_scalar<T__>(1) ));


                    current_statement_begin__ = 90;
                    if (as_bool(logical_gt(K,1))) {
                        current_statement_begin__ = 90;
                        stan::math::assign(get_base1_lhs(theta,j,"theta",1), multiply(multiply(multiply(get_base1(u,j,"u",1),sqrt(get_base1(R2,j,"R2",1))),get_base1(sqrt_Nm1,j,"sqrt_Nm1",1)),Delta_y));
                    } else {
                        current_statement_begin__ = 91;
                        stan::math::assign(get_base1_lhs(get_base1_lhs(theta,j,"theta",1),1,"theta",2), (((get_base1(get_base1(u,j,"u",1),1,"u",2) * sqrt(get_base1(R2,j,"R2",1))) * get_base1(sqrt_Nm1,j,"sqrt_Nm1",1)) * Delta_y));
                    }
                    current_statement_begin__ = 93;
                    stan::math::assign(get_base1_lhs(sigma,j,"sigma",1), (Delta_y * sqrt((1 - get_base1(R2,j,"R2",1)))));
                    current_statement_begin__ = 95;
                    if (as_bool(logical_eq(has_intercept,1))) {

                        current_statement_begin__ = 96;
                        if (as_bool(logical_eq(prior_dist_for_intercept,0))) {
                            current_statement_begin__ = 97;
                            stan::math::assign(get_base1_lhs(alpha,j,"alpha",1), get_base1(z_alpha,j,"z_alpha",1));
                        } else if (as_bool(logical_eq(prior_scale_for_intercept,0))) {
                            current_statement_begin__ = 99;
                            stan::math::assign(get_base1_lhs(alpha,j,"alpha",1), (((get_base1(z_alpha,j,"z_alpha",1) * Delta_y) * get_base1(sqrt_inv_N,j,"sqrt_inv_N",1)) + prior_mean_for_intercept));
                        } else {
                            current_statement_begin__ = 101;
                            stan::math::assign(get_base1_lhs(alpha,j,"alpha",1), ((get_base1(z_alpha,j,"z_alpha",1) * prior_scale_for_intercept) + prior_mean_for_intercept));
                        }
                    }
                }
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        // validate transformed parameters
        for (int i0__ = 0; i0__ < (J * has_intercept); ++i0__) {
            if (stan::math::is_uninitialized(alpha[i0__])) {
                std::stringstream msg__;
                msg__ << "Undefined transformed parameter: alpha" << '[' << i0__ << ']';
                throw std::runtime_error(msg__.str());
            }
        }
        for (int i0__ = 0; i0__ < J; ++i0__) {
            for (int i1__ = 0; i1__ < K; ++i1__) {
                if (stan::math::is_uninitialized(theta[i0__](i1__))) {
                    std::stringstream msg__;
                    msg__ << "Undefined transformed parameter: theta" << '[' << i0__ << ']' << '[' << i1__ << ']';
                    throw std::runtime_error(msg__.str());
                }
            }
        }
        for (int i0__ = 0; i0__ < J; ++i0__) {
            if (stan::math::is_uninitialized(sigma[i0__])) {
                std::stringstream msg__;
                msg__ << "Undefined transformed parameter: sigma" << '[' << i0__ << ']';
                throw std::runtime_error(msg__.str());
            }
        }

        const char* function__ = "validate transformed params";
        (void) function__;  // dummy to suppress unused var warning
        for (int k0__ = 0; k0__ < J; ++k0__) {
            check_greater_or_equal(function__,"sigma[k0__]",sigma[k0__],0);
        }

        // model body
        try {

            current_statement_begin__ = 107;
            for (int j = 1; j <= J; ++j) {

                current_statement_begin__ = 108;
                if (as_bool(logical_eq(prior_PD,0))) {
                    {
                        T__ dummy;
                        (void) dummy;  // dummy to suppress unused var warning

                        stan::math::initialize(dummy, DUMMY_VAR__);
                        stan::math::fill(dummy,DUMMY_VAR__);
                        T__ shift;
                        (void) shift;  // dummy to suppress unused var warning

                        stan::math::initialize(shift, DUMMY_VAR__);
                        stan::math::fill(shift,DUMMY_VAR__);


                        current_statement_begin__ = 111;
                        stan::math::assign(shift, dot_product(get_base1(xbarR_inv,j,"xbarR_inv",1),get_base1(theta,j,"theta",1)));
                        current_statement_begin__ = 112;
                        stan::math::assign(dummy, ll_mvn_ols_qr_lp(get_base1(theta,j,"theta",1),get_base1(Rb,j,"Rb",1),(logical_eq(has_intercept,1) ? stan::math::promote_scalar<T__>((get_base1(alpha,j,"alpha",1) + shift)) : stan::math::promote_scalar<T__>(shift) ),get_base1(ybar,j,"ybar",1),get_base1(SSR,j,"SSR",1),get_base1(sigma,j,"sigma",1),get_base1(N,j,"N",1), lp__, lp_accum__, pstream__));
                    }
                }
            }
            current_statement_begin__ = 118;
            if (as_bool((primitive_value(logical_eq(has_intercept,1)) && primitive_value(logical_gt(prior_dist_for_intercept,0))))) {
                current_statement_begin__ = 119;
                lp_accum__.add(normal_log(z_alpha,0,1));
            }
            current_statement_begin__ = 120;
            if (as_bool(logical_eq(prior_dist,1))) {
                current_statement_begin__ = 120;
                lp_accum__.add(beta_log(R2,half_K,eta));
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        lp_accum__.add(lp__);
        return lp_accum__.sum();

    } // log_prob()

    template <bool propto, bool jacobian, typename T_>
    T_ log_prob(Eigen::Matrix<T_,Eigen::Dynamic,1>& params_r,
               std::ostream* pstream = 0) const {
      std::vector<T_> vec_params_r;
      vec_params_r.reserve(params_r.size());
      for (int i = 0; i < params_r.size(); ++i)
        vec_params_r.push_back(params_r(i));
      std::vector<int> vec_params_i;
      return log_prob<propto,jacobian,T_>(vec_params_r, vec_params_i, pstream);
    }


    void get_param_names(std::vector<std::string>& names__) const {
        names__.resize(0);
        names__.push_back("u");
        names__.push_back("z_alpha");
        names__.push_back("R2");
        names__.push_back("log_omega");
        names__.push_back("alpha");
        names__.push_back("theta");
        names__.push_back("sigma");
        names__.push_back("mean_PPD");
        names__.push_back("beta");
    }


    void get_dims(std::vector<std::vector<size_t> >& dimss__) const {
        dimss__.resize(0);
        std::vector<size_t> dims__;
        dims__.resize(0);
        dims__.push_back(J);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((J * has_intercept));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(J);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((J * (1 - prior_PD)));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((J * has_intercept));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(J);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(J);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(J);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(J);
        dims__.push_back(K);
        dimss__.push_back(dims__);
    }

    template <typename RNG>
    void write_array(RNG& base_rng__,
                     std::vector<double>& params_r__,
                     std::vector<int>& params_i__,
                     std::vector<double>& vars__,
                     bool include_tparams__ = true,
                     bool include_gqs__ = true,
                     std::ostream* pstream__ = 0) const {
        vars__.resize(0);
        stan::io::reader<double> in__(params_r__,params_i__);
        static const char* function__ = "model_lm_namespace::write_array";
        (void) function__;  // dummy to suppress unused var warning
        // read-transform, write parameters
        vector<vector_d> u;
        size_t dim_u_0__ = J;
        for (size_t k_0__ = 0; k_0__ < dim_u_0__; ++k_0__) {
            u.push_back(in__.unit_vector_constrain(K));
        }
        vector<double> z_alpha;
        size_t dim_z_alpha_0__ = (J * has_intercept);
        for (size_t k_0__ = 0; k_0__ < dim_z_alpha_0__; ++k_0__) {
            z_alpha.push_back(in__.scalar_constrain());
        }
        vector<double> R2;
        size_t dim_R2_0__ = J;
        for (size_t k_0__ = 0; k_0__ < dim_R2_0__; ++k_0__) {
            R2.push_back(in__.scalar_lub_constrain(0,1));
        }
        vector_d log_omega = in__.vector_constrain((J * (1 - prior_PD)));
        for (int k_1__ = 0; k_1__ < K; ++k_1__) {
            for (int k_0__ = 0; k_0__ < J; ++k_0__) {
                vars__.push_back(u[k_0__][k_1__]);
            }
        }
        for (int k_0__ = 0; k_0__ < (J * has_intercept); ++k_0__) {
            vars__.push_back(z_alpha[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < J; ++k_0__) {
            vars__.push_back(R2[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < (J * (1 - prior_PD)); ++k_0__) {
            vars__.push_back(log_omega[k_0__]);
        }

        if (!include_tparams__) return;
        // declare and define transformed parameters
        double lp__ = 0.0;
        (void) lp__;  // dummy to suppress unused var warning
        stan::math::accumulator<double> lp_accum__;

        double DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

        validate_non_negative_index("alpha", "(J * has_intercept)", (J * has_intercept));
        vector<double> alpha((J * has_intercept), 0.0);
        stan::math::initialize(alpha, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(alpha,DUMMY_VAR__);
        validate_non_negative_index("theta", "K", K);
        validate_non_negative_index("theta", "J", J);
        vector<vector_d> theta(J, (vector_d(static_cast<Eigen::VectorXd::Index>(K))));
        stan::math::initialize(theta, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(theta,DUMMY_VAR__);
        validate_non_negative_index("sigma", "J", J);
        vector<double> sigma(J, 0.0);
        stan::math::initialize(sigma, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(sigma,DUMMY_VAR__);


        try {
            current_statement_begin__ = 85;
            for (int j = 1; j <= J; ++j) {
                {
                    double Delta_y(0.0);
                    (void) Delta_y;  // dummy to suppress unused var warning

                    stan::math::initialize(Delta_y, std::numeric_limits<double>::quiet_NaN());
                    stan::math::fill(Delta_y,DUMMY_VAR__);
                    stan::math::assign(Delta_y,(logical_eq(prior_PD,0) ? stan::math::promote_scalar<double>((get_base1(s_Y,j,"s_Y",1) * exp(get_base1(log_omega,j,"log_omega",1)))) : stan::math::promote_scalar<double>(1) ));


                    current_statement_begin__ = 90;
                    if (as_bool(logical_gt(K,1))) {
                        current_statement_begin__ = 90;
                        stan::math::assign(get_base1_lhs(theta,j,"theta",1), multiply(multiply(multiply(get_base1(u,j,"u",1),sqrt(get_base1(R2,j,"R2",1))),get_base1(sqrt_Nm1,j,"sqrt_Nm1",1)),Delta_y));
                    } else {
                        current_statement_begin__ = 91;
                        stan::math::assign(get_base1_lhs(get_base1_lhs(theta,j,"theta",1),1,"theta",2), (((get_base1(get_base1(u,j,"u",1),1,"u",2) * sqrt(get_base1(R2,j,"R2",1))) * get_base1(sqrt_Nm1,j,"sqrt_Nm1",1)) * Delta_y));
                    }
                    current_statement_begin__ = 93;
                    stan::math::assign(get_base1_lhs(sigma,j,"sigma",1), (Delta_y * sqrt((1 - get_base1(R2,j,"R2",1)))));
                    current_statement_begin__ = 95;
                    if (as_bool(logical_eq(has_intercept,1))) {

                        current_statement_begin__ = 96;
                        if (as_bool(logical_eq(prior_dist_for_intercept,0))) {
                            current_statement_begin__ = 97;
                            stan::math::assign(get_base1_lhs(alpha,j,"alpha",1), get_base1(z_alpha,j,"z_alpha",1));
                        } else if (as_bool(logical_eq(prior_scale_for_intercept,0))) {
                            current_statement_begin__ = 99;
                            stan::math::assign(get_base1_lhs(alpha,j,"alpha",1), (((get_base1(z_alpha,j,"z_alpha",1) * Delta_y) * get_base1(sqrt_inv_N,j,"sqrt_inv_N",1)) + prior_mean_for_intercept));
                        } else {
                            current_statement_begin__ = 101;
                            stan::math::assign(get_base1_lhs(alpha,j,"alpha",1), ((get_base1(z_alpha,j,"z_alpha",1) * prior_scale_for_intercept) + prior_mean_for_intercept));
                        }
                    }
                }
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        // validate transformed parameters
        for (int k0__ = 0; k0__ < J; ++k0__) {
            check_greater_or_equal(function__,"sigma[k0__]",sigma[k0__],0);
        }

        // write transformed parameters
        for (int k_0__ = 0; k_0__ < (J * has_intercept); ++k_0__) {
            vars__.push_back(alpha[k_0__]);
        }
        for (int k_1__ = 0; k_1__ < K; ++k_1__) {
            for (int k_0__ = 0; k_0__ < J; ++k_0__) {
                vars__.push_back(theta[k_0__][k_1__]);
            }
        }
        for (int k_0__ = 0; k_0__ < J; ++k_0__) {
            vars__.push_back(sigma[k_0__]);
        }

        if (!include_gqs__) return;
        // declare and define generated quantities
        validate_non_negative_index("mean_PPD", "J", J);
        vector<double> mean_PPD(J, 0.0);
        stan::math::initialize(mean_PPD, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(mean_PPD,DUMMY_VAR__);
        validate_non_negative_index("beta", "K", K);
        validate_non_negative_index("beta", "J", J);
        vector<vector_d> beta(J, (vector_d(static_cast<Eigen::VectorXd::Index>(K))));
        stan::math::initialize(beta, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(beta,DUMMY_VAR__);


        try {
            current_statement_begin__ = 126;
            for (int j = 1; j <= J; ++j) {
                {
                    double shift(0.0);
                    (void) shift;  // dummy to suppress unused var warning

                    stan::math::initialize(shift, std::numeric_limits<double>::quiet_NaN());
                    stan::math::fill(shift,DUMMY_VAR__);


                    current_statement_begin__ = 128;
                    stan::math::assign(shift, dot_product(get_base1(xbarR_inv,j,"xbarR_inv",1),get_base1(theta,j,"theta",1)));
                    current_statement_begin__ = 129;
                    stan::math::assign(get_base1_lhs(mean_PPD,j,"mean_PPD",1), normal_rng((logical_eq(has_intercept,1) ? stan::math::promote_scalar<double>((get_base1(alpha,j,"alpha",1) + shift)) : stan::math::promote_scalar<double>(shift) ),(get_base1(sigma,j,"sigma",1) * get_base1(sqrt_inv_N,j,"sqrt_inv_N",1)), base_rng__));
                    current_statement_begin__ = 131;
                    stan::math::assign(get_base1_lhs(beta,j,"beta",1), multiply(get_base1(R_inv,j,"R_inv",1),get_base1(theta,j,"theta",1)));
                }
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        // validate generated quantities

        // write generated quantities
        for (int k_0__ = 0; k_0__ < J; ++k_0__) {
            vars__.push_back(mean_PPD[k_0__]);
        }
        for (int k_1__ = 0; k_1__ < K; ++k_1__) {
            for (int k_0__ = 0; k_0__ < J; ++k_0__) {
                vars__.push_back(beta[k_0__][k_1__]);
            }
        }

    }

    template <typename RNG>
    void write_array(RNG& base_rng,
                     Eigen::Matrix<double,Eigen::Dynamic,1>& params_r,
                     Eigen::Matrix<double,Eigen::Dynamic,1>& vars,
                     bool include_tparams = true,
                     bool include_gqs = true,
                     std::ostream* pstream = 0) const {
      std::vector<double> params_r_vec(params_r.size());
      for (int i = 0; i < params_r.size(); ++i)
        params_r_vec[i] = params_r(i);
      std::vector<double> vars_vec;
      std::vector<int> params_i_vec;
      write_array(base_rng,params_r_vec,params_i_vec,vars_vec,include_tparams,include_gqs,pstream);
      vars.resize(vars_vec.size());
      for (int i = 0; i < vars.size(); ++i)
        vars(i) = vars_vec[i];
    }

    static std::string model_name() {
        return "model_lm";
    }


    void constrained_param_names(std::vector<std::string>& param_names__,
                                 bool include_tparams__ = true,
                                 bool include_gqs__ = true) const {
        std::stringstream param_name_stream__;
        for (int k_1__ = 1; k_1__ <= K; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= J; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "u" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        for (int k_0__ = 1; k_0__ <= (J * has_intercept); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_alpha" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= J; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "R2" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (J * (1 - prior_PD)); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "log_omega" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__ && !include_tparams__) return;
        for (int k_0__ = 1; k_0__ <= (J * has_intercept); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "alpha" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_1__ = 1; k_1__ <= K; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= J; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "theta" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        for (int k_0__ = 1; k_0__ <= J; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "sigma" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__) return;
        for (int k_0__ = 1; k_0__ <= J; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "mean_PPD" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_1__ = 1; k_1__ <= K; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= J; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "beta" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }
    }


    void unconstrained_param_names(std::vector<std::string>& param_names__,
                                   bool include_tparams__ = true,
                                   bool include_gqs__ = true) const {
        std::stringstream param_name_stream__;
        for (int k_1__ = 1; k_1__ <= K; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= J; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "u" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        for (int k_0__ = 1; k_0__ <= (J * has_intercept); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_alpha" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= J; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "R2" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (J * (1 - prior_PD)); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "log_omega" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__ && !include_tparams__) return;
        for (int k_0__ = 1; k_0__ <= (J * has_intercept); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "alpha" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_1__ = 1; k_1__ <= K; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= J; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "theta" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        for (int k_0__ = 1; k_0__ <= J; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "sigma" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__) return;
        for (int k_0__ = 1; k_0__ <= J; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "mean_PPD" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_1__ = 1; k_1__ <= K; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= J; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "beta" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }
    }

}; // model

}




// Code generated by Stan version 2.16.0

#include <stan/model/model_header.hpp>

namespace model_polr_namespace {

using std::istream;
using std::string;
using std::stringstream;
using std::vector;
using stan::io::dump;
using stan::math::lgamma;
using stan::model::prob_grad;
using namespace stan::math;

typedef Eigen::Matrix<double,Eigen::Dynamic,1> vector_d;
typedef Eigen::Matrix<double,1,Eigen::Dynamic> row_vector_d;
typedef Eigen::Matrix<double,Eigen::Dynamic,Eigen::Dynamic> matrix_d;

static int current_statement_begin__;

stan::io::program_reader prog_reader__() {
    stan::io::program_reader reader;
    reader.add_event(0, 0, "start", "model_polr");
    reader.add_event(313, 313, "end", "model_polr");
    return reader;
}

template <typename T0__>
typename boost::math::tools::promote_args<T0__>::type
CDF_polr(const T0__& x,
             const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 34;
        if (as_bool(logical_eq(link,1))) {
            current_statement_begin__ = 34;
            return stan::math::promote_scalar<fun_return_scalar_t__>(inv_logit(x));
        } else if (as_bool(logical_eq(link,2))) {
            current_statement_begin__ = 35;
            return stan::math::promote_scalar<fun_return_scalar_t__>(Phi(x));
        } else if (as_bool(logical_eq(link,3))) {
            current_statement_begin__ = 36;
            return stan::math::promote_scalar<fun_return_scalar_t__>(gumbel_cdf(x,0,1));
        } else if (as_bool(logical_eq(link,4))) {
            current_statement_begin__ = 37;
            return stan::math::promote_scalar<fun_return_scalar_t__>(inv_cloglog(x));
        } else if (as_bool(logical_eq(link,5))) {
            current_statement_begin__ = 38;
            return stan::math::promote_scalar<fun_return_scalar_t__>(cauchy_cdf(x,0,1));
        } else {
            current_statement_begin__ = 39;
            std::stringstream errmsg_stream__;
            errmsg_stream__ << "Invalid link";
            throw std::domain_error(errmsg_stream__.str());
        }
        current_statement_begin__ = 39;
        current_statement_begin__ = 40;
        return stan::math::promote_scalar<fun_return_scalar_t__>(x);
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct CDF_polr_functor__ {
    template <typename T0__>
        typename boost::math::tools::promote_args<T0__>::type
    operator()(const T0__& x,
             const int& link, std::ostream* pstream__) const {
        return CDF_polr(x, link, pstream__);
    }
};

template <typename T1__, typename T2__, typename T4__>
Eigen::Matrix<typename boost::math::tools::promote_args<T1__, T2__, T4__>::type, Eigen::Dynamic,1>
pw_polr(const std::vector<int>& y,
            const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
            const Eigen::Matrix<T2__, Eigen::Dynamic,1>& cutpoints,
            const int& link,
            const T4__& alpha, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T1__, T2__, T4__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            int N(0);
            (void) N;  // dummy to suppress unused var warning

            stan::math::fill(N, std::numeric_limits<int>::min());
            stan::math::assign(N,rows(eta));
            int J(0);
            (void) J;  // dummy to suppress unused var warning

            stan::math::fill(J, std::numeric_limits<int>::min());
            stan::math::assign(J,(rows(cutpoints) + 1));
            validate_non_negative_index("ll", "N", N);
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  ll(static_cast<Eigen::VectorXd::Index>(N));
            (void) ll;  // dummy to suppress unused var warning

            stan::math::initialize(ll, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(ll,DUMMY_VAR__);


            current_statement_begin__ = 57;
            if (as_bool((primitive_value(logical_lt(link,1)) || primitive_value(logical_gt(link,5))))) {
                current_statement_begin__ = 58;
                std::stringstream errmsg_stream__;
                errmsg_stream__ << "Invalid link";
                throw std::domain_error(errmsg_stream__.str());
            }
            current_statement_begin__ = 58;
            current_statement_begin__ = 60;
            if (as_bool(logical_eq(alpha,1))) {
                current_statement_begin__ = 60;
                for (int n = 1; n <= N; ++n) {

                    current_statement_begin__ = 61;
                    if (as_bool(logical_eq(get_base1(y,n,"y",1),1))) {
                        current_statement_begin__ = 61;
                        stan::math::assign(get_base1_lhs(ll,n,"ll",1), CDF_polr((get_base1(cutpoints,1,"cutpoints",1) - get_base1(eta,n,"eta",1)),link, pstream__));
                    } else if (as_bool(logical_eq(get_base1(y,n,"y",1),J))) {
                        current_statement_begin__ = 62;
                        stan::math::assign(get_base1_lhs(ll,n,"ll",1), (1 - CDF_polr((get_base1(cutpoints,(J - 1),"cutpoints",1) - get_base1(eta,n,"eta",1)),link, pstream__)));
                    } else {
                        current_statement_begin__ = 63;
                        stan::math::assign(get_base1_lhs(ll,n,"ll",1), (CDF_polr((get_base1(cutpoints,get_base1(y,n,"y",1),"cutpoints",1) - get_base1(eta,n,"eta",1)),link, pstream__) - CDF_polr((get_base1(cutpoints,(get_base1(y,n,"y",1) - 1),"cutpoints",1) - get_base1(eta,n,"eta",1)),link, pstream__)));
                    }
                }
            } else {
                current_statement_begin__ = 66;
                for (int n = 1; n <= N; ++n) {

                    current_statement_begin__ = 67;
                    if (as_bool(logical_eq(get_base1(y,n,"y",1),1))) {
                        current_statement_begin__ = 67;
                        stan::math::assign(get_base1_lhs(ll,n,"ll",1), pow(CDF_polr((get_base1(cutpoints,1,"cutpoints",1) - get_base1(eta,n,"eta",1)),link, pstream__),alpha));
                    } else if (as_bool(logical_eq(get_base1(y,n,"y",1),J))) {
                        current_statement_begin__ = 68;
                        stan::math::assign(get_base1_lhs(ll,n,"ll",1), (1 - pow(CDF_polr((get_base1(cutpoints,(J - 1),"cutpoints",1) - get_base1(eta,n,"eta",1)),link, pstream__),alpha)));
                    } else {
                        current_statement_begin__ = 69;
                        std::stringstream errmsg_stream__;
                        errmsg_stream__ << "alpha not allowed with more than 2 outcome categories";
                        throw std::domain_error(errmsg_stream__.str());
                    }
                }
            }
            current_statement_begin__ = 71;
            return stan::math::promote_scalar<fun_return_scalar_t__>(log(ll));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct pw_polr_functor__ {
    template <typename T1__, typename T2__, typename T4__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T1__, T2__, T4__>::type, Eigen::Dynamic,1>
    operator()(const std::vector<int>& y,
            const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
            const Eigen::Matrix<T2__, Eigen::Dynamic,1>& cutpoints,
            const int& link,
            const T4__& alpha, std::ostream* pstream__) const {
        return pw_polr(y, eta, cutpoints, link, alpha, pstream__);
    }
};

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
make_cutpoints(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& probabilities,
                   const T1__& scale,
                   const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            int C(0);
            (void) C;  // dummy to suppress unused var warning

            stan::math::fill(C, std::numeric_limits<int>::min());
            stan::math::assign(C,(rows(probabilities) - 1));
            validate_non_negative_index("cutpoints", "C", C);
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  cutpoints(static_cast<Eigen::VectorXd::Index>(C));
            (void) cutpoints;  // dummy to suppress unused var warning

            stan::math::initialize(cutpoints, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(cutpoints,DUMMY_VAR__);
            fun_scalar_t__ running_sum;
            (void) running_sum;  // dummy to suppress unused var warning

            stan::math::initialize(running_sum, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(running_sum,DUMMY_VAR__);
            stan::math::assign(running_sum,0);


            current_statement_begin__ = 88;
            if (as_bool(logical_eq(link,1))) {
                current_statement_begin__ = 88;
                for (int c = 1; c <= C; ++c) {

                    current_statement_begin__ = 89;
                    stan::math::assign(running_sum, (running_sum + get_base1(probabilities,c,"probabilities",1)));
                    current_statement_begin__ = 90;
                    stan::math::assign(get_base1_lhs(cutpoints,c,"cutpoints",1), logit(running_sum));
                }
            } else if (as_bool(logical_eq(link,2))) {
                current_statement_begin__ = 92;
                for (int c = 1; c <= C; ++c) {

                    current_statement_begin__ = 93;
                    stan::math::assign(running_sum, (running_sum + get_base1(probabilities,c,"probabilities",1)));
                    current_statement_begin__ = 94;
                    stan::math::assign(get_base1_lhs(cutpoints,c,"cutpoints",1), inv_Phi(running_sum));
                }
            } else if (as_bool(logical_eq(link,3))) {
                current_statement_begin__ = 96;
                for (int c = 1; c <= C; ++c) {

                    current_statement_begin__ = 97;
                    stan::math::assign(running_sum, (running_sum + get_base1(probabilities,c,"probabilities",1)));
                    current_statement_begin__ = 98;
                    stan::math::assign(get_base1_lhs(cutpoints,c,"cutpoints",1), -(log(-(log(running_sum)))));
                }
            } else if (as_bool(logical_eq(link,4))) {
                current_statement_begin__ = 100;
                for (int c = 1; c <= C; ++c) {

                    current_statement_begin__ = 101;
                    stan::math::assign(running_sum, (running_sum + get_base1(probabilities,c,"probabilities",1)));
                    current_statement_begin__ = 102;
                    stan::math::assign(get_base1_lhs(cutpoints,c,"cutpoints",1), log(-(log1m(running_sum))));
                }
            } else if (as_bool(logical_eq(link,5))) {
                current_statement_begin__ = 104;
                for (int c = 1; c <= C; ++c) {

                    current_statement_begin__ = 105;
                    stan::math::assign(running_sum, (running_sum + get_base1(probabilities,c,"probabilities",1)));
                    current_statement_begin__ = 106;
                    stan::math::assign(get_base1_lhs(cutpoints,c,"cutpoints",1), tan((stan::math::pi() * (running_sum - 0.5))));
                }
            } else {
                current_statement_begin__ = 108;
                std::stringstream errmsg_stream__;
                errmsg_stream__ << "invalid link";
                throw std::domain_error(errmsg_stream__.str());
            }
            current_statement_begin__ = 108;
            current_statement_begin__ = 109;
            return stan::math::promote_scalar<fun_return_scalar_t__>(multiply(scale,cutpoints));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct make_cutpoints_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& probabilities,
                   const T1__& scale,
                   const int& link, std::ostream* pstream__) const {
        return make_cutpoints(probabilities, scale, link, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__, class RNG>
typename boost::math::tools::promote_args<T0__, T1__, T2__>::type
draw_ystar_rng(const T0__& lower,
                   const T1__& upper,
                   const T2__& eta,
                   const int& link, RNG& base_rng__, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            int iter(0);
            (void) iter;  // dummy to suppress unused var warning

            stan::math::fill(iter, std::numeric_limits<int>::min());
            stan::math::assign(iter,0);
            fun_scalar_t__ ystar;
            (void) ystar;  // dummy to suppress unused var warning

            stan::math::initialize(ystar, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(ystar,DUMMY_VAR__);
            stan::math::assign(ystar,stan::math::not_a_number());


            current_statement_begin__ = 124;
            if (as_bool(logical_gte(lower,upper))) {
                current_statement_begin__ = 125;
                std::stringstream errmsg_stream__;
                errmsg_stream__ << "lower must be less than upper";
                throw std::domain_error(errmsg_stream__.str());
            }
            current_statement_begin__ = 125;
            current_statement_begin__ = 129;
            if (as_bool(logical_eq(link,1))) {
                current_statement_begin__ = 129;
                while (as_bool(logical_negation((primitive_value(logical_gt(ystar,lower)) && primitive_value(logical_lt(ystar,upper)))))) {
                    current_statement_begin__ = 130;
                    stan::math::assign(ystar, logistic_rng(eta,1, base_rng__));
                }
            } else if (as_bool(logical_eq(link,2))) {
                current_statement_begin__ = 131;
                while (as_bool(logical_negation((primitive_value(logical_gt(ystar,lower)) && primitive_value(logical_lt(ystar,upper)))))) {
                    current_statement_begin__ = 132;
                    stan::math::assign(ystar, normal_rng(eta,1, base_rng__));
                }
            } else if (as_bool(logical_eq(link,3))) {
                current_statement_begin__ = 133;
                while (as_bool(logical_negation((primitive_value(logical_gt(ystar,lower)) && primitive_value(logical_lt(ystar,upper)))))) {
                    current_statement_begin__ = 134;
                    stan::math::assign(ystar, gumbel_rng(eta,1, base_rng__));
                }
            } else if (as_bool(logical_eq(link,4))) {
                current_statement_begin__ = 135;
                while (as_bool(logical_negation((primitive_value(logical_gt(ystar,lower)) && primitive_value(logical_lt(ystar,upper)))))) {
                    current_statement_begin__ = 136;
                    stan::math::assign(ystar, log(-(log1m(uniform_rng(0,1, base_rng__)))));
                }
            } else if (as_bool(logical_eq(link,5))) {
                current_statement_begin__ = 137;
                while (as_bool(logical_negation((primitive_value(logical_gt(ystar,lower)) && primitive_value(logical_lt(ystar,upper)))))) {
                    current_statement_begin__ = 138;
                    stan::math::assign(ystar, cauchy_rng(eta,1, base_rng__));
                }
            } else {
                current_statement_begin__ = 139;
                std::stringstream errmsg_stream__;
                errmsg_stream__ << "invalid link";
                throw std::domain_error(errmsg_stream__.str());
            }
            current_statement_begin__ = 139;
            current_statement_begin__ = 140;
            return stan::math::promote_scalar<fun_return_scalar_t__>(ystar);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct draw_ystar_rng_functor__ {
    template <typename T0__, typename T1__, typename T2__, class RNG>
        typename boost::math::tools::promote_args<T0__, T1__, T2__>::type
    operator()(const T0__& lower,
                   const T1__& upper,
                   const T2__& eta,
                   const int& link, RNG& base_rng__, std::ostream* pstream__) const {
        return draw_ystar_rng(lower, upper, eta, link, base_rng__, pstream__);
    }
};

class model_polr : public prob_grad {
private:
    int N;
    int K;
    vector_d xbar;
    int dense_X;
    vector<matrix_d> X;
    int nnz_X;
    vector_d w_X;
    vector<int> v_X;
    vector<int> u_X;
    int K_smooth;
    matrix_d S;
    vector<int> smooth_map;
    int J;
    vector<int> y;
    int prior_PD;
    int has_intercept;
    int family;
    int link;
    int prior_dist;
    int prior_dist_for_intercept;
    int prior_dist_for_aux;
    int prior_dist_for_smooth;
    int has_weights;
    vector_d weights;
    int has_offset;
    vector_d offset;
    double regularization;
    vector_d prior_counts;
    int is_skewed;
    double shape;
    double rate;
    int do_residuals;
    double half_K;
    double sqrt_Nm1;
    int is_constant;
    vector_d beta_smooth;
public:
    model_polr(stan::io::var_context& context__,
        std::ostream* pstream__ = 0)
        : prob_grad(0) {
        ctor_body(context__, 0, pstream__);
    }

    model_polr(stan::io::var_context& context__,
        unsigned int random_seed__,
        std::ostream* pstream__ = 0)
        : prob_grad(0) {
        ctor_body(context__, random_seed__, pstream__);
    }

    void ctor_body(stan::io::var_context& context__,
                   unsigned int random_seed__,
                   std::ostream* pstream__) {
        boost::ecuyer1988 base_rng__ =
          stan::services::util::create_rng(random_seed__, 0);
        (void) base_rng__;  // suppress unused var warning

        current_statement_begin__ = -1;

        static const char* function__ = "model_polr_namespace::model_polr";
        (void) function__;  // dummy to suppress unused var warning
        size_t pos__;
        (void) pos__;  // dummy to suppress unused var warning
        std::vector<int> vals_i__;
        std::vector<double> vals_r__;
        double DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

        // initialize member variables
        context__.validate_dims("data initialization", "N", "int", context__.to_vec());
        N = int(0);
        vals_i__ = context__.vals_i("N");
        pos__ = 0;
        N = vals_i__[pos__++];
        context__.validate_dims("data initialization", "K", "int", context__.to_vec());
        K = int(0);
        vals_i__ = context__.vals_i("K");
        pos__ = 0;
        K = vals_i__[pos__++];
        validate_non_negative_index("xbar", "K", K);
        context__.validate_dims("data initialization", "xbar", "vector_d", context__.to_vec(K));
        validate_non_negative_index("xbar", "K", K);
        xbar = vector_d(static_cast<Eigen::VectorXd::Index>(K));
        vals_r__ = context__.vals_r("xbar");
        pos__ = 0;
        size_t xbar_i_vec_lim__ = K;
        for (size_t i_vec__ = 0; i_vec__ < xbar_i_vec_lim__; ++i_vec__) {
            xbar[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "dense_X", "int", context__.to_vec());
        dense_X = int(0);
        vals_i__ = context__.vals_i("dense_X");
        pos__ = 0;
        dense_X = vals_i__[pos__++];
        validate_non_negative_index("X", "dense_X", dense_X);
        validate_non_negative_index("X", "N", N);
        validate_non_negative_index("X", "K", K);
        context__.validate_dims("data initialization", "X", "matrix_d", context__.to_vec(dense_X,N,K));
        validate_non_negative_index("X", "dense_X", dense_X);
        validate_non_negative_index("X", "N", N);
        validate_non_negative_index("X", "K", K);
        X = std::vector<matrix_d>(dense_X,matrix_d(static_cast<Eigen::VectorXd::Index>(N),static_cast<Eigen::VectorXd::Index>(K)));
        vals_r__ = context__.vals_r("X");
        pos__ = 0;
        size_t X_m_mat_lim__ = N;
        size_t X_n_mat_lim__ = K;
        for (size_t n_mat__ = 0; n_mat__ < X_n_mat_lim__; ++n_mat__) {
            for (size_t m_mat__ = 0; m_mat__ < X_m_mat_lim__; ++m_mat__) {
                size_t X_limit_0__ = dense_X;
                for (size_t i_0__ = 0; i_0__ < X_limit_0__; ++i_0__) {
                    X[i_0__](m_mat__,n_mat__) = vals_r__[pos__++];
            }
            }
        }
        context__.validate_dims("data initialization", "nnz_X", "int", context__.to_vec());
        nnz_X = int(0);
        vals_i__ = context__.vals_i("nnz_X");
        pos__ = 0;
        nnz_X = vals_i__[pos__++];
        validate_non_negative_index("w_X", "nnz_X", nnz_X);
        context__.validate_dims("data initialization", "w_X", "vector_d", context__.to_vec(nnz_X));
        validate_non_negative_index("w_X", "nnz_X", nnz_X);
        w_X = vector_d(static_cast<Eigen::VectorXd::Index>(nnz_X));
        vals_r__ = context__.vals_r("w_X");
        pos__ = 0;
        size_t w_X_i_vec_lim__ = nnz_X;
        for (size_t i_vec__ = 0; i_vec__ < w_X_i_vec_lim__; ++i_vec__) {
            w_X[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("v_X", "nnz_X", nnz_X);
        context__.validate_dims("data initialization", "v_X", "int", context__.to_vec(nnz_X));
        validate_non_negative_index("v_X", "nnz_X", nnz_X);
        v_X = std::vector<int>(nnz_X,int(0));
        vals_i__ = context__.vals_i("v_X");
        pos__ = 0;
        size_t v_X_limit_0__ = nnz_X;
        for (size_t i_0__ = 0; i_0__ < v_X_limit_0__; ++i_0__) {
            v_X[i_0__] = vals_i__[pos__++];
        }
        validate_non_negative_index("u_X", "(dense_X ? 0 : (N + 1) )", (dense_X ? 0 : (N + 1) ));
        context__.validate_dims("data initialization", "u_X", "int", context__.to_vec((dense_X ? 0 : (N + 1) )));
        validate_non_negative_index("u_X", "(dense_X ? 0 : (N + 1) )", (dense_X ? 0 : (N + 1) ));
        u_X = std::vector<int>((dense_X ? 0 : (N + 1) ),int(0));
        vals_i__ = context__.vals_i("u_X");
        pos__ = 0;
        size_t u_X_limit_0__ = (dense_X ? 0 : (N + 1) );
        for (size_t i_0__ = 0; i_0__ < u_X_limit_0__; ++i_0__) {
            u_X[i_0__] = vals_i__[pos__++];
        }
        context__.validate_dims("data initialization", "K_smooth", "int", context__.to_vec());
        K_smooth = int(0);
        vals_i__ = context__.vals_i("K_smooth");
        pos__ = 0;
        K_smooth = vals_i__[pos__++];
        validate_non_negative_index("S", "N", N);
        validate_non_negative_index("S", "K_smooth", K_smooth);
        context__.validate_dims("data initialization", "S", "matrix_d", context__.to_vec(N,K_smooth));
        validate_non_negative_index("S", "N", N);
        validate_non_negative_index("S", "K_smooth", K_smooth);
        S = matrix_d(static_cast<Eigen::VectorXd::Index>(N),static_cast<Eigen::VectorXd::Index>(K_smooth));
        vals_r__ = context__.vals_r("S");
        pos__ = 0;
        size_t S_m_mat_lim__ = N;
        size_t S_n_mat_lim__ = K_smooth;
        for (size_t n_mat__ = 0; n_mat__ < S_n_mat_lim__; ++n_mat__) {
            for (size_t m_mat__ = 0; m_mat__ < S_m_mat_lim__; ++m_mat__) {
                S(m_mat__,n_mat__) = vals_r__[pos__++];
            }
        }
        validate_non_negative_index("smooth_map", "K_smooth", K_smooth);
        context__.validate_dims("data initialization", "smooth_map", "int", context__.to_vec(K_smooth));
        validate_non_negative_index("smooth_map", "K_smooth", K_smooth);
        smooth_map = std::vector<int>(K_smooth,int(0));
        vals_i__ = context__.vals_i("smooth_map");
        pos__ = 0;
        size_t smooth_map_limit_0__ = K_smooth;
        for (size_t i_0__ = 0; i_0__ < smooth_map_limit_0__; ++i_0__) {
            smooth_map[i_0__] = vals_i__[pos__++];
        }
        context__.validate_dims("data initialization", "J", "int", context__.to_vec());
        J = int(0);
        vals_i__ = context__.vals_i("J");
        pos__ = 0;
        J = vals_i__[pos__++];
        validate_non_negative_index("y", "N", N);
        context__.validate_dims("data initialization", "y", "int", context__.to_vec(N));
        validate_non_negative_index("y", "N", N);
        y = std::vector<int>(N,int(0));
        vals_i__ = context__.vals_i("y");
        pos__ = 0;
        size_t y_limit_0__ = N;
        for (size_t i_0__ = 0; i_0__ < y_limit_0__; ++i_0__) {
            y[i_0__] = vals_i__[pos__++];
        }
        context__.validate_dims("data initialization", "prior_PD", "int", context__.to_vec());
        prior_PD = int(0);
        vals_i__ = context__.vals_i("prior_PD");
        pos__ = 0;
        prior_PD = vals_i__[pos__++];
        context__.validate_dims("data initialization", "has_intercept", "int", context__.to_vec());
        has_intercept = int(0);
        vals_i__ = context__.vals_i("has_intercept");
        pos__ = 0;
        has_intercept = vals_i__[pos__++];
        context__.validate_dims("data initialization", "family", "int", context__.to_vec());
        family = int(0);
        vals_i__ = context__.vals_i("family");
        pos__ = 0;
        family = vals_i__[pos__++];
        context__.validate_dims("data initialization", "link", "int", context__.to_vec());
        link = int(0);
        vals_i__ = context__.vals_i("link");
        pos__ = 0;
        link = vals_i__[pos__++];
        context__.validate_dims("data initialization", "prior_dist", "int", context__.to_vec());
        prior_dist = int(0);
        vals_i__ = context__.vals_i("prior_dist");
        pos__ = 0;
        prior_dist = vals_i__[pos__++];
        context__.validate_dims("data initialization", "prior_dist_for_intercept", "int", context__.to_vec());
        prior_dist_for_intercept = int(0);
        vals_i__ = context__.vals_i("prior_dist_for_intercept");
        pos__ = 0;
        prior_dist_for_intercept = vals_i__[pos__++];
        context__.validate_dims("data initialization", "prior_dist_for_aux", "int", context__.to_vec());
        prior_dist_for_aux = int(0);
        vals_i__ = context__.vals_i("prior_dist_for_aux");
        pos__ = 0;
        prior_dist_for_aux = vals_i__[pos__++];
        context__.validate_dims("data initialization", "prior_dist_for_smooth", "int", context__.to_vec());
        prior_dist_for_smooth = int(0);
        vals_i__ = context__.vals_i("prior_dist_for_smooth");
        pos__ = 0;
        prior_dist_for_smooth = vals_i__[pos__++];
        context__.validate_dims("data initialization", "has_weights", "int", context__.to_vec());
        has_weights = int(0);
        vals_i__ = context__.vals_i("has_weights");
        pos__ = 0;
        has_weights = vals_i__[pos__++];
        validate_non_negative_index("weights", "(has_weights ? N : 0 )", (has_weights ? N : 0 ));
        context__.validate_dims("data initialization", "weights", "vector_d", context__.to_vec((has_weights ? N : 0 )));
        validate_non_negative_index("weights", "(has_weights ? N : 0 )", (has_weights ? N : 0 ));
        weights = vector_d(static_cast<Eigen::VectorXd::Index>((has_weights ? N : 0 )));
        vals_r__ = context__.vals_r("weights");
        pos__ = 0;
        size_t weights_i_vec_lim__ = (has_weights ? N : 0 );
        for (size_t i_vec__ = 0; i_vec__ < weights_i_vec_lim__; ++i_vec__) {
            weights[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "has_offset", "int", context__.to_vec());
        has_offset = int(0);
        vals_i__ = context__.vals_i("has_offset");
        pos__ = 0;
        has_offset = vals_i__[pos__++];
        validate_non_negative_index("offset", "(has_offset ? N : 0 )", (has_offset ? N : 0 ));
        context__.validate_dims("data initialization", "offset", "vector_d", context__.to_vec((has_offset ? N : 0 )));
        validate_non_negative_index("offset", "(has_offset ? N : 0 )", (has_offset ? N : 0 ));
        offset = vector_d(static_cast<Eigen::VectorXd::Index>((has_offset ? N : 0 )));
        vals_r__ = context__.vals_r("offset");
        pos__ = 0;
        size_t offset_i_vec_lim__ = (has_offset ? N : 0 );
        for (size_t i_vec__ = 0; i_vec__ < offset_i_vec_lim__; ++i_vec__) {
            offset[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "regularization", "double", context__.to_vec());
        regularization = double(0);
        vals_r__ = context__.vals_r("regularization");
        pos__ = 0;
        regularization = vals_r__[pos__++];
        validate_non_negative_index("prior_counts", "J", J);
        context__.validate_dims("data initialization", "prior_counts", "vector_d", context__.to_vec(J));
        validate_non_negative_index("prior_counts", "J", J);
        prior_counts = vector_d(static_cast<Eigen::VectorXd::Index>(J));
        vals_r__ = context__.vals_r("prior_counts");
        pos__ = 0;
        size_t prior_counts_i_vec_lim__ = J;
        for (size_t i_vec__ = 0; i_vec__ < prior_counts_i_vec_lim__; ++i_vec__) {
            prior_counts[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "is_skewed", "int", context__.to_vec());
        is_skewed = int(0);
        vals_i__ = context__.vals_i("is_skewed");
        pos__ = 0;
        is_skewed = vals_i__[pos__++];
        context__.validate_dims("data initialization", "shape", "double", context__.to_vec());
        shape = double(0);
        vals_r__ = context__.vals_r("shape");
        pos__ = 0;
        shape = vals_r__[pos__++];
        context__.validate_dims("data initialization", "rate", "double", context__.to_vec());
        rate = double(0);
        vals_r__ = context__.vals_r("rate");
        pos__ = 0;
        rate = vals_r__[pos__++];
        context__.validate_dims("data initialization", "do_residuals", "int", context__.to_vec());
        do_residuals = int(0);
        vals_i__ = context__.vals_i("do_residuals");
        pos__ = 0;
        do_residuals = vals_i__[pos__++];

        // validate, data variables
        check_greater_or_equal(function__,"N",N,0);
        check_greater_or_equal(function__,"K",K,0);
        check_greater_or_equal(function__,"dense_X",dense_X,0);
        check_less_or_equal(function__,"dense_X",dense_X,1);
        check_greater_or_equal(function__,"nnz_X",nnz_X,0);
        for (int k0__ = 0; k0__ < nnz_X; ++k0__) {
            check_greater_or_equal(function__,"v_X[k0__]",v_X[k0__],0);
        }
        for (int k0__ = 0; k0__ < (dense_X ? 0 : (N + 1) ); ++k0__) {
            check_greater_or_equal(function__,"u_X[k0__]",u_X[k0__],0);
        }
        check_greater_or_equal(function__,"K_smooth",K_smooth,0);
        for (int k0__ = 0; k0__ < K_smooth; ++k0__) {
            check_greater_or_equal(function__,"smooth_map[k0__]",smooth_map[k0__],1);
        }
        check_greater_or_equal(function__,"J",J,2);
        for (int k0__ = 0; k0__ < N; ++k0__) {
            check_greater_or_equal(function__,"y[k0__]",y[k0__],1);
            check_less_or_equal(function__,"y[k0__]",y[k0__],J);
        }
        check_greater_or_equal(function__,"prior_PD",prior_PD,0);
        check_less_or_equal(function__,"prior_PD",prior_PD,1);
        check_greater_or_equal(function__,"has_intercept",has_intercept,0);
        check_less_or_equal(function__,"has_intercept",has_intercept,1);
        check_greater_or_equal(function__,"family",family,1);
        check_greater_or_equal(function__,"link",link,1);
        check_greater_or_equal(function__,"prior_dist",prior_dist,0);
        check_less_or_equal(function__,"prior_dist",prior_dist,7);
        check_greater_or_equal(function__,"prior_dist_for_intercept",prior_dist_for_intercept,0);
        check_less_or_equal(function__,"prior_dist_for_intercept",prior_dist_for_intercept,2);
        check_greater_or_equal(function__,"prior_dist_for_aux",prior_dist_for_aux,0);
        check_less_or_equal(function__,"prior_dist_for_aux",prior_dist_for_aux,3);
        check_greater_or_equal(function__,"prior_dist_for_smooth",prior_dist_for_smooth,0);
        check_less_or_equal(function__,"prior_dist_for_smooth",prior_dist_for_smooth,3);
        check_greater_or_equal(function__,"has_weights",has_weights,0);
        check_less_or_equal(function__,"has_weights",has_weights,1);
        check_greater_or_equal(function__,"has_offset",has_offset,0);
        check_less_or_equal(function__,"has_offset",has_offset,1);
        check_greater_or_equal(function__,"regularization",regularization,0);
        check_greater_or_equal(function__,"prior_counts",prior_counts,0);
        check_greater_or_equal(function__,"is_skewed",is_skewed,0);
        check_less_or_equal(function__,"is_skewed",is_skewed,1);
        check_greater_or_equal(function__,"shape",shape,0);
        check_greater_or_equal(function__,"rate",rate,0);
        check_greater_or_equal(function__,"do_residuals",do_residuals,0);
        check_less_or_equal(function__,"do_residuals",do_residuals,1);
        // initialize data variables
        half_K = double(0);
        stan::math::fill(half_K,DUMMY_VAR__);
        stan::math::assign(half_K,(0.5 * K));
        sqrt_Nm1 = double(0);
        stan::math::fill(sqrt_Nm1,DUMMY_VAR__);
        stan::math::assign(sqrt_Nm1,sqrt((N - 1.0)));
        is_constant = int(0);
        stan::math::fill(is_constant, std::numeric_limits<int>::min());
        stan::math::assign(is_constant,1);
        validate_non_negative_index("beta_smooth", "0", 0);
        beta_smooth = vector_d(static_cast<Eigen::VectorXd::Index>(0));
        stan::math::fill(beta_smooth,DUMMY_VAR__);

        try {
            current_statement_begin__ = 211;
            for (int j = 1; j <= J; ++j) {
                current_statement_begin__ = 211;
                if (as_bool(logical_neq(get_base1(prior_counts,j,"prior_counts",1),1))) {
                    current_statement_begin__ = 211;
                    stan::math::assign(is_constant, 0);
                }
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        // validate transformed data
        check_greater_or_equal(function__,"half_K",half_K,0);
        check_greater_or_equal(function__,"sqrt_Nm1",sqrt_Nm1,0);
        check_greater_or_equal(function__,"is_constant",is_constant,0);
        check_less_or_equal(function__,"is_constant",is_constant,1);

        // validate, set parameter ranges
        num_params_r__ = 0U;
        param_ranges_i__.clear();
        validate_non_negative_index("pi", "J", J);
        num_params_r__ += (J - 1);
        validate_non_negative_index("u", "K", K);
        num_params_r__ += (K);
        ++num_params_r__;
        validate_non_negative_index("alpha", "is_skewed", is_skewed);
        num_params_r__ += is_skewed;
    }

    ~model_polr() { }


    void transform_inits(const stan::io::var_context& context__,
                         std::vector<int>& params_i__,
                         std::vector<double>& params_r__,
                         std::ostream* pstream__) const {
        stan::io::writer<double> writer__(params_r__,params_i__);
        size_t pos__;
        (void) pos__; // dummy call to supress warning
        std::vector<double> vals_r__;
        std::vector<int> vals_i__;

        if (!(context__.contains_r("pi")))
            throw std::runtime_error("variable pi missing");
        vals_r__ = context__.vals_r("pi");
        pos__ = 0U;
        validate_non_negative_index("pi", "J", J);
        context__.validate_dims("initialization", "pi", "vector_d", context__.to_vec(J));
        // generate_declaration pi
        vector_d pi(static_cast<Eigen::VectorXd::Index>(J));
        for (int j1__ = 0U; j1__ < J; ++j1__)
            pi(j1__) = vals_r__[pos__++];
        try {
            writer__.simplex_unconstrain(pi);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable pi: ") + e.what());
        }

        if (!(context__.contains_r("u")))
            throw std::runtime_error("variable u missing");
        vals_r__ = context__.vals_r("u");
        pos__ = 0U;
        validate_non_negative_index("u", "K", K);
        context__.validate_dims("initialization", "u", "vector_d", context__.to_vec(K));
        // generate_declaration u
        vector_d u(static_cast<Eigen::VectorXd::Index>(K));
        for (int j1__ = 0U; j1__ < K; ++j1__)
            u(j1__) = vals_r__[pos__++];
        try {
            writer__.unit_vector_unconstrain(u);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable u: ") + e.what());
        }

        if (!(context__.contains_r("R2")))
            throw std::runtime_error("variable R2 missing");
        vals_r__ = context__.vals_r("R2");
        pos__ = 0U;
        context__.validate_dims("initialization", "R2", "double", context__.to_vec());
        // generate_declaration R2
        double R2(0);
        R2 = vals_r__[pos__++];
        try {
            writer__.scalar_lub_unconstrain(0,1,R2);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable R2: ") + e.what());
        }

        if (!(context__.contains_r("alpha")))
            throw std::runtime_error("variable alpha missing");
        vals_r__ = context__.vals_r("alpha");
        pos__ = 0U;
        validate_non_negative_index("alpha", "is_skewed", is_skewed);
        context__.validate_dims("initialization", "alpha", "double", context__.to_vec(is_skewed));
        // generate_declaration alpha
        std::vector<double> alpha(is_skewed,double(0));
        for (int i0__ = 0U; i0__ < is_skewed; ++i0__)
            alpha[i0__] = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < is_skewed; ++i0__)
            try {
            writer__.scalar_lb_unconstrain(0,alpha[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable alpha: ") + e.what());
        }

        params_r__ = writer__.data_r();
        params_i__ = writer__.data_i();
    }

    void transform_inits(const stan::io::var_context& context,
                         Eigen::Matrix<double,Eigen::Dynamic,1>& params_r,
                         std::ostream* pstream__) const {
      std::vector<double> params_r_vec;
      std::vector<int> params_i_vec;
      transform_inits(context, params_i_vec, params_r_vec, pstream__);
      params_r.resize(params_r_vec.size());
      for (int i = 0; i < params_r.size(); ++i)
        params_r(i) = params_r_vec[i];
    }


    template <bool propto__, bool jacobian__, typename T__>
    T__ log_prob(vector<T__>& params_r__,
                 vector<int>& params_i__,
                 std::ostream* pstream__ = 0) const {

        T__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

        T__ lp__(0.0);
        stan::math::accumulator<T__> lp_accum__;

        // model parameters
        stan::io::reader<T__> in__(params_r__,params_i__);

        Eigen::Matrix<T__,Eigen::Dynamic,1>  pi;
        (void) pi;  // dummy to suppress unused var warning
        if (jacobian__)
            pi = in__.simplex_constrain(J,lp__);
        else
            pi = in__.simplex_constrain(J);

        Eigen::Matrix<T__,Eigen::Dynamic,1>  u;
        (void) u;  // dummy to suppress unused var warning
        if (jacobian__)
            u = in__.unit_vector_constrain(K,lp__);
        else
            u = in__.unit_vector_constrain(K);

        T__ R2;
        (void) R2;  // dummy to suppress unused var warning
        if (jacobian__)
            R2 = in__.scalar_lub_constrain(0,1,lp__);
        else
            R2 = in__.scalar_lub_constrain(0,1);

        vector<T__> alpha;
        size_t dim_alpha_0__ = is_skewed;
        alpha.reserve(dim_alpha_0__);
        for (size_t k_0__ = 0; k_0__ < dim_alpha_0__; ++k_0__) {
            if (jacobian__)
                alpha.push_back(in__.scalar_lb_constrain(0,lp__));
            else
                alpha.push_back(in__.scalar_lb_constrain(0));
        }


        // transformed parameters
        validate_non_negative_index("beta", "K", K);
        Eigen::Matrix<T__,Eigen::Dynamic,1>  beta(static_cast<Eigen::VectorXd::Index>(K));
        (void) beta;  // dummy to suppress unused var warning

        stan::math::initialize(beta, DUMMY_VAR__);
        stan::math::fill(beta,DUMMY_VAR__);
        validate_non_negative_index("cutpoints", "(J - 1)", (J - 1));
        Eigen::Matrix<T__,Eigen::Dynamic,1>  cutpoints(static_cast<Eigen::VectorXd::Index>((J - 1)));
        (void) cutpoints;  // dummy to suppress unused var warning

        stan::math::initialize(cutpoints, DUMMY_VAR__);
        stan::math::fill(cutpoints,DUMMY_VAR__);


        try {
            {
                T__ Delta_y;
                (void) Delta_y;  // dummy to suppress unused var warning

                stan::math::initialize(Delta_y, DUMMY_VAR__);
                stan::math::fill(Delta_y,DUMMY_VAR__);
                stan::math::assign(Delta_y,inv(sqrt((1 - R2))));


                current_statement_begin__ = 224;
                if (as_bool(logical_gt(K,1))) {
                    current_statement_begin__ = 225;
                    stan::math::assign(beta, multiply(multiply(multiply(u,sqrt(R2)),Delta_y),sqrt_Nm1));
                } else {
                    current_statement_begin__ = 226;
                    stan::math::assign(get_base1_lhs(beta,1,"beta",1), (((get_base1(u,1,"u",1) * sqrt(R2)) * Delta_y) * sqrt_Nm1));
                }
                current_statement_begin__ = 227;
                stan::math::assign(cutpoints, make_cutpoints(pi,Delta_y,link, pstream__));
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        // validate transformed parameters
        for (int i0__ = 0; i0__ < K; ++i0__) {
            if (stan::math::is_uninitialized(beta(i0__))) {
                std::stringstream msg__;
                msg__ << "Undefined transformed parameter: beta" << '[' << i0__ << ']';
                throw std::runtime_error(msg__.str());
            }
        }
        for (int i0__ = 0; i0__ < (J - 1); ++i0__) {
            if (stan::math::is_uninitialized(cutpoints(i0__))) {
                std::stringstream msg__;
                msg__ << "Undefined transformed parameter: cutpoints" << '[' << i0__ << ']';
                throw std::runtime_error(msg__.str());
            }
        }

        const char* function__ = "validate transformed params";
        (void) function__;  // dummy to suppress unused var warning

        // model body
        try {
            {
                validate_non_negative_index("eta", "N", N);
                Eigen::Matrix<T__,Eigen::Dynamic,1>  eta(static_cast<Eigen::VectorXd::Index>(N));
                (void) eta;  // dummy to suppress unused var warning

                stan::math::initialize(eta, DUMMY_VAR__);
                stan::math::fill(eta,DUMMY_VAR__);


                current_statement_begin__ = 233;
                if (as_bool(logical_gt(K,0))) {

                    current_statement_begin__ = 234;
                    if (as_bool(dense_X)) {
                        current_statement_begin__ = 234;
                        stan::math::assign(eta, multiply(get_base1(X,1,"X",1),beta));
                    } else {
                        current_statement_begin__ = 235;
                        stan::math::assign(eta, csr_matrix_times_vector(N,K,w_X,v_X,u_X,beta));
                    }
                } else {
                    current_statement_begin__ = 237;
                    stan::math::assign(eta, rep_vector(0.0,N));
                }
                current_statement_begin__ = 238;
                if (as_bool(logical_eq(has_offset,1))) {
                    current_statement_begin__ = 238;
                    stan::math::assign(eta, add(eta,offset));
                }
                current_statement_begin__ = 239;
                if (as_bool(K_smooth)) {
                    current_statement_begin__ = 239;
                    stan::math::assign(eta, add(eta,multiply(S,beta_smooth)));
                }
                current_statement_begin__ = 240;
                if (as_bool((primitive_value(logical_eq(has_weights,0)) && primitive_value(logical_eq(prior_PD,0))))) {

                    current_statement_begin__ = 241;
                    if (as_bool(logical_eq(is_skewed,0))) {
                        current_statement_begin__ = 242;
                        lp_accum__.add(pw_polr(y,eta,cutpoints,link,1.0, pstream__));
                    } else {
                        current_statement_begin__ = 243;
                        lp_accum__.add(pw_polr(y,eta,cutpoints,link,get_base1(alpha,1,"alpha",1), pstream__));
                    }
                } else if (as_bool(logical_eq(prior_PD,0))) {

                    current_statement_begin__ = 246;
                    if (as_bool(logical_eq(is_skewed,0))) {
                        current_statement_begin__ = 247;
                        lp_accum__.add(dot_product(weights,pw_polr(y,eta,cutpoints,link,1.0, pstream__)));
                    } else {
                        current_statement_begin__ = 248;
                        lp_accum__.add(dot_product(weights,pw_polr(y,eta,cutpoints,link,get_base1(alpha,1,"alpha",1), pstream__)));
                    }
                }
                current_statement_begin__ = 251;
                if (as_bool(logical_eq(is_constant,0))) {
                    current_statement_begin__ = 251;
                    lp_accum__.add(dirichlet_log(pi,prior_counts));
                }
                current_statement_begin__ = 253;
                if (as_bool(logical_eq(prior_dist,1))) {
                    current_statement_begin__ = 253;
                    lp_accum__.add(beta_log(R2,half_K,regularization));
                }
                current_statement_begin__ = 254;
                if (as_bool(logical_eq(is_skewed,1))) {
                    current_statement_begin__ = 254;
                    lp_accum__.add(gamma_log(alpha,shape,rate));
                }
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        lp_accum__.add(lp__);
        return lp_accum__.sum();

    } // log_prob()

    template <bool propto, bool jacobian, typename T_>
    T_ log_prob(Eigen::Matrix<T_,Eigen::Dynamic,1>& params_r,
               std::ostream* pstream = 0) const {
      std::vector<T_> vec_params_r;
      vec_params_r.reserve(params_r.size());
      for (int i = 0; i < params_r.size(); ++i)
        vec_params_r.push_back(params_r(i));
      std::vector<int> vec_params_i;
      return log_prob<propto,jacobian,T_>(vec_params_r, vec_params_i, pstream);
    }


    void get_param_names(std::vector<std::string>& names__) const {
        names__.resize(0);
        names__.push_back("pi");
        names__.push_back("u");
        names__.push_back("R2");
        names__.push_back("alpha");
        names__.push_back("beta");
        names__.push_back("cutpoints");
        names__.push_back("mean_PPD");
        names__.push_back("residuals");
        names__.push_back("zeta");
    }


    void get_dims(std::vector<std::vector<size_t> >& dimss__) const {
        dimss__.resize(0);
        std::vector<size_t> dims__;
        dims__.resize(0);
        dims__.push_back(J);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(is_skewed);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((J - 1));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((logical_gt(J,2) ? J : 1 ));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((do_residuals ? N : 0 ));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((J - 1));
        dimss__.push_back(dims__);
    }

    template <typename RNG>
    void write_array(RNG& base_rng__,
                     std::vector<double>& params_r__,
                     std::vector<int>& params_i__,
                     std::vector<double>& vars__,
                     bool include_tparams__ = true,
                     bool include_gqs__ = true,
                     std::ostream* pstream__ = 0) const {
        vars__.resize(0);
        stan::io::reader<double> in__(params_r__,params_i__);
        static const char* function__ = "model_polr_namespace::write_array";
        (void) function__;  // dummy to suppress unused var warning
        // read-transform, write parameters
        vector_d pi = in__.simplex_constrain(J);
        vector_d u = in__.unit_vector_constrain(K);
        double R2 = in__.scalar_lub_constrain(0,1);
        vector<double> alpha;
        size_t dim_alpha_0__ = is_skewed;
        for (size_t k_0__ = 0; k_0__ < dim_alpha_0__; ++k_0__) {
            alpha.push_back(in__.scalar_lb_constrain(0));
        }
        for (int k_0__ = 0; k_0__ < J; ++k_0__) {
            vars__.push_back(pi[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < K; ++k_0__) {
            vars__.push_back(u[k_0__]);
        }
        vars__.push_back(R2);
        for (int k_0__ = 0; k_0__ < is_skewed; ++k_0__) {
            vars__.push_back(alpha[k_0__]);
        }

        if (!include_tparams__) return;
        // declare and define transformed parameters
        double lp__ = 0.0;
        (void) lp__;  // dummy to suppress unused var warning
        stan::math::accumulator<double> lp_accum__;

        double DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

        validate_non_negative_index("beta", "K", K);
        vector_d beta(static_cast<Eigen::VectorXd::Index>(K));
        (void) beta;  // dummy to suppress unused var warning

        stan::math::initialize(beta, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(beta,DUMMY_VAR__);
        validate_non_negative_index("cutpoints", "(J - 1)", (J - 1));
        vector_d cutpoints(static_cast<Eigen::VectorXd::Index>((J - 1)));
        (void) cutpoints;  // dummy to suppress unused var warning

        stan::math::initialize(cutpoints, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(cutpoints,DUMMY_VAR__);


        try {
            {
                double Delta_y(0.0);
                (void) Delta_y;  // dummy to suppress unused var warning

                stan::math::initialize(Delta_y, std::numeric_limits<double>::quiet_NaN());
                stan::math::fill(Delta_y,DUMMY_VAR__);
                stan::math::assign(Delta_y,inv(sqrt((1 - R2))));


                current_statement_begin__ = 224;
                if (as_bool(logical_gt(K,1))) {
                    current_statement_begin__ = 225;
                    stan::math::assign(beta, multiply(multiply(multiply(u,sqrt(R2)),Delta_y),sqrt_Nm1));
                } else {
                    current_statement_begin__ = 226;
                    stan::math::assign(get_base1_lhs(beta,1,"beta",1), (((get_base1(u,1,"u",1) * sqrt(R2)) * Delta_y) * sqrt_Nm1));
                }
                current_statement_begin__ = 227;
                stan::math::assign(cutpoints, make_cutpoints(pi,Delta_y,link, pstream__));
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        // validate transformed parameters

        // write transformed parameters
        for (int k_0__ = 0; k_0__ < K; ++k_0__) {
            vars__.push_back(beta[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < (J - 1); ++k_0__) {
            vars__.push_back(cutpoints[k_0__]);
        }

        if (!include_gqs__) return;
        // declare and define generated quantities
        validate_non_negative_index("mean_PPD", "(logical_gt(J,2) ? J : 1 )", (logical_gt(J,2) ? J : 1 ));
        vector_d mean_PPD(static_cast<Eigen::VectorXd::Index>((logical_gt(J,2) ? J : 1 )));
        (void) mean_PPD;  // dummy to suppress unused var warning

        stan::math::initialize(mean_PPD, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(mean_PPD,DUMMY_VAR__);
        stan::math::assign(mean_PPD,rep_vector(0,(logical_gt(J,2) ? J : 1 )));
        validate_non_negative_index("residuals", "(do_residuals ? N : 0 )", (do_residuals ? N : 0 ));
        vector_d residuals(static_cast<Eigen::VectorXd::Index>((do_residuals ? N : 0 )));
        (void) residuals;  // dummy to suppress unused var warning

        stan::math::initialize(residuals, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(residuals,DUMMY_VAR__);
        validate_non_negative_index("zeta", "(J - 1)", (J - 1));
        vector_d zeta(static_cast<Eigen::VectorXd::Index>((J - 1)));
        (void) zeta;  // dummy to suppress unused var warning

        stan::math::initialize(zeta, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(zeta,DUMMY_VAR__);


        try {
            current_statement_begin__ = 262;
            if (as_bool(dense_X)) {
                current_statement_begin__ = 262;
                stan::math::assign(zeta, add(cutpoints,dot_product(xbar,beta)));
            } else {
                current_statement_begin__ = 263;
                stan::math::assign(zeta, cutpoints);
            }
            current_statement_begin__ = 264;
            if (as_bool(logical_eq(J,2))) {
                current_statement_begin__ = 264;
                stan::math::assign(zeta, minus(zeta));
            }
            {
                validate_non_negative_index("eta", "N", N);
                vector_d eta(static_cast<Eigen::VectorXd::Index>(N));
                (void) eta;  // dummy to suppress unused var warning

                stan::math::initialize(eta, std::numeric_limits<double>::quiet_NaN());
                stan::math::fill(eta,DUMMY_VAR__);


                current_statement_begin__ = 268;
                if (as_bool(logical_gt(K,0))) {

                    current_statement_begin__ = 269;
                    if (as_bool(dense_X)) {
                        current_statement_begin__ = 269;
                        stan::math::assign(eta, multiply(get_base1(X,1,"X",1),beta));
                    } else {
                        current_statement_begin__ = 270;
                        stan::math::assign(eta, csr_matrix_times_vector(N,K,w_X,v_X,u_X,beta));
                    }
                } else {
                    current_statement_begin__ = 272;
                    stan::math::assign(eta, rep_vector(0.0,N));
                }
                current_statement_begin__ = 273;
                if (as_bool(logical_eq(has_offset,1))) {
                    current_statement_begin__ = 273;
                    stan::math::assign(eta, add(eta,offset));
                }
                current_statement_begin__ = 274;
                if (as_bool(K_smooth)) {
                    current_statement_begin__ = 274;
                    stan::math::assign(eta, add(eta,multiply(S,beta_smooth)));
                }
                current_statement_begin__ = 275;
                for (int n = 1; n <= N; ++n) {
                    {
                        int y_tilde(0);
                        (void) y_tilde;  // dummy to suppress unused var warning

                        stan::math::fill(y_tilde, std::numeric_limits<int>::min());
                        validate_non_negative_index("theta", "J", J);
                        vector_d theta(static_cast<Eigen::VectorXd::Index>(J));
                        (void) theta;  // dummy to suppress unused var warning

                        stan::math::initialize(theta, std::numeric_limits<double>::quiet_NaN());
                        stan::math::fill(theta,DUMMY_VAR__);
                        double previous(0.0);
                        (void) previous;  // dummy to suppress unused var warning

                        stan::math::initialize(previous, std::numeric_limits<double>::quiet_NaN());
                        stan::math::fill(previous,DUMMY_VAR__);


                        current_statement_begin__ = 279;
                        stan::math::assign(get_base1_lhs(theta,1,"theta",1), CDF_polr((get_base1(cutpoints,1,"cutpoints",1) - get_base1(eta,n,"eta",1)),link, pstream__));
                        current_statement_begin__ = 280;
                        stan::math::assign(previous, get_base1(theta,1,"theta",1));
                        current_statement_begin__ = 281;
                        if (as_bool(is_skewed)) {
                            current_statement_begin__ = 281;
                            stan::math::assign(get_base1_lhs(theta,1,"theta",1), pow(get_base1(theta,1,"theta",1),get_base1(alpha,1,"alpha",1)));
                        }
                        current_statement_begin__ = 282;
                        for (int j = 2; j <= (J - 1); ++j) {
                            {
                                double current(0.0);
                                (void) current;  // dummy to suppress unused var warning

                                stan::math::initialize(current, std::numeric_limits<double>::quiet_NaN());
                                stan::math::fill(current,DUMMY_VAR__);


                                current_statement_begin__ = 284;
                                stan::math::assign(current, CDF_polr((get_base1(cutpoints,j,"cutpoints",1) - get_base1(eta,n,"eta",1)),link, pstream__));
                                current_statement_begin__ = 285;
                                stan::math::assign(get_base1_lhs(theta,j,"theta",1), (current - previous));
                                current_statement_begin__ = 286;
                                stan::math::assign(previous, current);
                            }
                        }
                        current_statement_begin__ = 288;
                        if (as_bool(logical_eq(is_skewed,0))) {
                            current_statement_begin__ = 288;
                            stan::math::assign(get_base1_lhs(theta,J,"theta",1), (1 - previous));
                        } else {
                            current_statement_begin__ = 289;
                            stan::math::assign(get_base1_lhs(theta,J,"theta",1), (1 - pow(previous,get_base1(alpha,1,"alpha",1))));
                        }
                        current_statement_begin__ = 290;
                        if (as_bool((primitive_value(logical_lte(previous,0)) || primitive_value(logical_gte(previous,1))))) {

                        } else if (as_bool(logical_eq(J,2))) {

                            current_statement_begin__ = 294;
                            stan::math::assign(get_base1_lhs(mean_PPD,1,"mean_PPD",1), (get_base1(mean_PPD,1,"mean_PPD",1) + bernoulli_rng(get_base1(theta,J,"theta",1), base_rng__)));
                        } else {

                            current_statement_begin__ = 297;
                            stan::math::assign(y_tilde, categorical_rng(theta, base_rng__));
                            current_statement_begin__ = 298;
                            stan::math::assign(get_base1_lhs(mean_PPD,y_tilde,"mean_PPD",1), (get_base1(mean_PPD,y_tilde,"mean_PPD",1) + 1));
                        }
                        current_statement_begin__ = 301;
                        if (as_bool(do_residuals)) {
                            {
                                double ystar(0.0);
                                (void) ystar;  // dummy to suppress unused var warning

                                stan::math::initialize(ystar, std::numeric_limits<double>::quiet_NaN());
                                stan::math::fill(ystar,DUMMY_VAR__);


                                current_statement_begin__ = 303;
                                if (as_bool(logical_eq(get_base1(y,n,"y",1),1))) {
                                    current_statement_begin__ = 304;
                                    stan::math::assign(ystar, draw_ystar_rng(stan::math::negative_infinity(),get_base1(cutpoints,1,"cutpoints",1),get_base1(eta,n,"eta",1),link, base_rng__, pstream__));
                                } else if (as_bool(logical_eq(get_base1(y,n,"y",1),J))) {
                                    current_statement_begin__ = 306;
                                    stan::math::assign(ystar, draw_ystar_rng(get_base1(cutpoints,(J - 1),"cutpoints",1),stan::math::positive_infinity(),get_base1(eta,n,"eta",1),link, base_rng__, pstream__));
                                } else {
                                    current_statement_begin__ = 307;
                                    stan::math::assign(ystar, draw_ystar_rng(get_base1(cutpoints,(get_base1(y,n,"y",1) - 1),"cutpoints",1),get_base1(cutpoints,get_base1(y,n,"y",1),"cutpoints",1),get_base1(eta,n,"eta",1),link, base_rng__, pstream__));
                                }
                                current_statement_begin__ = 308;
                                stan::math::assign(get_base1_lhs(residuals,n,"residuals",1), (ystar - get_base1(eta,n,"eta",1)));
                            }
                        }
                    }
                }
                current_statement_begin__ = 311;
                stan::math::assign(mean_PPD, divide(mean_PPD,N));
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        // validate generated quantities

        // write generated quantities
        for (int k_0__ = 0; k_0__ < (logical_gt(J,2) ? J : 1 ); ++k_0__) {
            vars__.push_back(mean_PPD[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < (do_residuals ? N : 0 ); ++k_0__) {
            vars__.push_back(residuals[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < (J - 1); ++k_0__) {
            vars__.push_back(zeta[k_0__]);
        }

    }

    template <typename RNG>
    void write_array(RNG& base_rng,
                     Eigen::Matrix<double,Eigen::Dynamic,1>& params_r,
                     Eigen::Matrix<double,Eigen::Dynamic,1>& vars,
                     bool include_tparams = true,
                     bool include_gqs = true,
                     std::ostream* pstream = 0) const {
      std::vector<double> params_r_vec(params_r.size());
      for (int i = 0; i < params_r.size(); ++i)
        params_r_vec[i] = params_r(i);
      std::vector<double> vars_vec;
      std::vector<int> params_i_vec;
      write_array(base_rng,params_r_vec,params_i_vec,vars_vec,include_tparams,include_gqs,pstream);
      vars.resize(vars_vec.size());
      for (int i = 0; i < vars.size(); ++i)
        vars(i) = vars_vec[i];
    }

    static std::string model_name() {
        return "model_polr";
    }


    void constrained_param_names(std::vector<std::string>& param_names__,
                                 bool include_tparams__ = true,
                                 bool include_gqs__ = true) const {
        std::stringstream param_name_stream__;
        for (int k_0__ = 1; k_0__ <= J; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "pi" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= K; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "u" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        param_name_stream__.str(std::string());
        param_name_stream__ << "R2";
        param_names__.push_back(param_name_stream__.str());
        for (int k_0__ = 1; k_0__ <= is_skewed; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "alpha" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__ && !include_tparams__) return;
        for (int k_0__ = 1; k_0__ <= K; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "beta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (J - 1); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "cutpoints" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__) return;
        for (int k_0__ = 1; k_0__ <= (logical_gt(J,2) ? J : 1 ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "mean_PPD" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (do_residuals ? N : 0 ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "residuals" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (J - 1); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "zeta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
    }


    void unconstrained_param_names(std::vector<std::string>& param_names__,
                                   bool include_tparams__ = true,
                                   bool include_gqs__ = true) const {
        std::stringstream param_name_stream__;
        for (int k_0__ = 1; k_0__ <= (J - 1); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "pi" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= K; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "u" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        param_name_stream__.str(std::string());
        param_name_stream__ << "R2";
        param_names__.push_back(param_name_stream__.str());
        for (int k_0__ = 1; k_0__ <= is_skewed; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "alpha" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__ && !include_tparams__) return;
        for (int k_0__ = 1; k_0__ <= K; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "beta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (J - 1); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "cutpoints" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__) return;
        for (int k_0__ = 1; k_0__ <= (logical_gt(J,2) ? J : 1 ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "mean_PPD" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (do_residuals ? N : 0 ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "residuals" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (J - 1); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "zeta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
    }

}; // model

}




// Code generated by Stan version 2.16.0

#include <stan/model/model_header.hpp>

namespace model_spatial_namespace {

using std::istream;
using std::string;
using std::stringstream;
using std::vector;
using stan::io::dump;
using stan::math::lgamma;
using stan::model::prob_grad;
using namespace stan::math;

typedef Eigen::Matrix<double,Eigen::Dynamic,1> vector_d;
typedef Eigen::Matrix<double,1,Eigen::Dynamic> row_vector_d;
typedef Eigen::Matrix<double,Eigen::Dynamic,Eigen::Dynamic> matrix_d;

static int current_statement_begin__;

stan::io::program_reader prog_reader__() {
    stan::io::program_reader reader;
    reader.add_event(0, 0, "start", "model_spatial");
    reader.add_event(968, 968, "end", "model_spatial");
    return reader;
}

template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
linkinv_gauss(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                  const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 31;
        if (as_bool(logical_eq(link,1))) {
            current_statement_begin__ = 31;
            return stan::math::promote_scalar<fun_return_scalar_t__>(eta);
        } else if (as_bool(logical_eq(link,2))) {
            current_statement_begin__ = 32;
            return stan::math::promote_scalar<fun_return_scalar_t__>(exp(eta));
        } else if (as_bool(logical_eq(link,3))) {
            current_statement_begin__ = 33;
            return stan::math::promote_scalar<fun_return_scalar_t__>(inv(eta));
        } else {
            current_statement_begin__ = 34;
            std::stringstream errmsg_stream__;
            errmsg_stream__ << "Invalid link";
            throw std::domain_error(errmsg_stream__.str());
        }
        current_statement_begin__ = 34;
        current_statement_begin__ = 35;
        return stan::math::promote_scalar<fun_return_scalar_t__>(eta);
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct linkinv_gauss_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                  const int& link, std::ostream* pstream__) const {
        return linkinv_gauss(eta, link, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
pw_gauss(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& y,
             const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
             const T2__& sigma,
             const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 46;
        return stan::math::promote_scalar<fun_return_scalar_t__>(subtract((-(0.5) * log((6.2831853071795862 * sigma))),multiply(0.5,square(divide(subtract(y,linkinv_gauss(eta,link, pstream__)),sigma)))));
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct pw_gauss_functor__ {
    template <typename T0__, typename T1__, typename T2__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& y,
             const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
             const T2__& sigma,
             const int& link, std::ostream* pstream__) const {
        return pw_gauss(y, eta, sigma, link, pstream__);
    }
};

template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
linkinv_gamma(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                  const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 58;
        if (as_bool(logical_eq(link,1))) {
            current_statement_begin__ = 58;
            return stan::math::promote_scalar<fun_return_scalar_t__>(eta);
        } else if (as_bool(logical_eq(link,2))) {
            current_statement_begin__ = 59;
            return stan::math::promote_scalar<fun_return_scalar_t__>(exp(eta));
        } else if (as_bool(logical_eq(link,3))) {
            current_statement_begin__ = 60;
            return stan::math::promote_scalar<fun_return_scalar_t__>(inv(eta));
        } else {
            current_statement_begin__ = 61;
            std::stringstream errmsg_stream__;
            errmsg_stream__ << "Invalid link";
            throw std::domain_error(errmsg_stream__.str());
        }
        current_statement_begin__ = 61;
        current_statement_begin__ = 62;
        return stan::math::promote_scalar<fun_return_scalar_t__>(eta);
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct linkinv_gamma_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                  const int& link, std::ostream* pstream__) const {
        return linkinv_gamma(eta, link, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__, typename T4__>
typename boost::math::tools::promote_args<T0__, T1__, T2__, T4__>::type
GammaReg(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& y,
             const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
             const T2__& shape,
             const int& link,
             const T4__& sum_log_y, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T4__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            fun_scalar_t__ ret;
            (void) ret;  // dummy to suppress unused var warning

            stan::math::initialize(ret, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(ret,DUMMY_VAR__);
            stan::math::assign(ret,((rows(y) * ((shape * log(shape)) - stan::math::lgamma(shape))) + ((shape - 1) * sum_log_y)));


            current_statement_begin__ = 79;
            if (as_bool(logical_eq(link,2))) {
                current_statement_begin__ = 80;
                stan::math::assign(ret, ((ret - (shape * sum(eta))) - (shape * sum(elt_divide(y,exp(eta))))));
            } else if (as_bool(logical_eq(link,1))) {
                current_statement_begin__ = 82;
                stan::math::assign(ret, ((ret - (shape * sum(log(eta)))) - (shape * sum(elt_divide(y,eta)))));
            } else if (as_bool(logical_eq(link,3))) {
                current_statement_begin__ = 84;
                stan::math::assign(ret, ((ret + (shape * sum(log(eta)))) - (shape * dot_product(eta,y))));
            } else {
                current_statement_begin__ = 85;
                std::stringstream errmsg_stream__;
                errmsg_stream__ << "Invalid link";
                throw std::domain_error(errmsg_stream__.str());
            }
            current_statement_begin__ = 85;
            current_statement_begin__ = 86;
            return stan::math::promote_scalar<fun_return_scalar_t__>(ret);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct GammaReg_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T4__>
        typename boost::math::tools::promote_args<T0__, T1__, T2__, T4__>::type
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& y,
             const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
             const T2__& shape,
             const int& link,
             const T4__& sum_log_y, std::ostream* pstream__) const {
        return GammaReg(y, eta, shape, link, sum_log_y, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
pw_gamma(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& y,
             const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
             const T2__& shape,
             const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            int N(0);
            (void) N;  // dummy to suppress unused var warning

            stan::math::fill(N, std::numeric_limits<int>::min());
            stan::math::assign(N,rows(eta));
            validate_non_negative_index("ll", "N", N);
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  ll(static_cast<Eigen::VectorXd::Index>(N));
            (void) ll;  // dummy to suppress unused var warning

            stan::math::initialize(ll, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(ll,DUMMY_VAR__);


            current_statement_begin__ = 100;
            if (as_bool(logical_eq(link,3))) {

                current_statement_begin__ = 101;
                for (int n = 1; n <= N; ++n) {

                    current_statement_begin__ = 102;
                    stan::math::assign(get_base1_lhs(ll,n,"ll",1), gamma_log(get_base1(y,n,"y",1),shape,(shape * get_base1(eta,n,"eta",1))));
                }
            } else if (as_bool(logical_eq(link,2))) {

                current_statement_begin__ = 106;
                for (int n = 1; n <= N; ++n) {

                    current_statement_begin__ = 107;
                    stan::math::assign(get_base1_lhs(ll,n,"ll",1), gamma_log(get_base1(y,n,"y",1),shape,(shape / exp(get_base1(eta,n,"eta",1)))));
                }
            } else if (as_bool(logical_eq(link,1))) {

                current_statement_begin__ = 111;
                for (int n = 1; n <= N; ++n) {

                    current_statement_begin__ = 112;
                    stan::math::assign(get_base1_lhs(ll,n,"ll",1), gamma_log(get_base1(y,n,"y",1),shape,(shape / get_base1(eta,n,"eta",1))));
                }
            } else {
                current_statement_begin__ = 115;
                std::stringstream errmsg_stream__;
                errmsg_stream__ << "Invalid link";
                throw std::domain_error(errmsg_stream__.str());
            }
            current_statement_begin__ = 115;
            current_statement_begin__ = 116;
            return stan::math::promote_scalar<fun_return_scalar_t__>(ll);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct pw_gamma_functor__ {
    template <typename T0__, typename T1__, typename T2__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& y,
             const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
             const T2__& shape,
             const int& link, std::ostream* pstream__) const {
        return pw_gamma(y, eta, shape, link, pstream__);
    }
};

template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
linkinv_inv_gaussian(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                         const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 127;
        if (as_bool(logical_eq(link,1))) {
            current_statement_begin__ = 127;
            return stan::math::promote_scalar<fun_return_scalar_t__>(eta);
        } else if (as_bool(logical_eq(link,2))) {
            current_statement_begin__ = 128;
            return stan::math::promote_scalar<fun_return_scalar_t__>(exp(eta));
        } else if (as_bool(logical_eq(link,3))) {
            current_statement_begin__ = 129;
            return stan::math::promote_scalar<fun_return_scalar_t__>(inv(eta));
        } else if (as_bool(logical_eq(link,4))) {
            current_statement_begin__ = 130;
            return stan::math::promote_scalar<fun_return_scalar_t__>(inv_sqrt(eta));
        } else {
            current_statement_begin__ = 131;
            std::stringstream errmsg_stream__;
            errmsg_stream__ << "Invalid link";
            throw std::domain_error(errmsg_stream__.str());
        }
        current_statement_begin__ = 131;
        current_statement_begin__ = 132;
        return stan::math::promote_scalar<fun_return_scalar_t__>(eta);
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct linkinv_inv_gaussian_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                         const int& link, std::ostream* pstream__) const {
        return linkinv_inv_gaussian(eta, link, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__>
typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type
inv_gaussian(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& y,
                 const Eigen::Matrix<T1__, Eigen::Dynamic,1>& mu,
                 const T2__& lambda,
                 const T3__& sum_log_y,
                 const Eigen::Matrix<T4__, Eigen::Dynamic,1>& sqrt_y, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 147;
        return stan::math::promote_scalar<fun_return_scalar_t__>(((((0.5 * rows(y)) * log((lambda / 6.2831853071795862))) - (1.5 * sum_log_y)) - ((0.5 * lambda) * dot_self(elt_divide(subtract(y,mu),elt_multiply(mu,sqrt_y))))));
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct inv_gaussian_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__>
        typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& y,
                 const Eigen::Matrix<T1__, Eigen::Dynamic,1>& mu,
                 const T2__& lambda,
                 const T3__& sum_log_y,
                 const Eigen::Matrix<T4__, Eigen::Dynamic,1>& sqrt_y, std::ostream* pstream__) const {
        return inv_gaussian(y, mu, lambda, sum_log_y, sqrt_y, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__, typename T4__, typename T5__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T4__, typename boost::math::tools::promote_args<T5__>::type>::type, Eigen::Dynamic,1>
pw_inv_gaussian(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& y,
                    const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
                    const T2__& lambda,
                    const int& link,
                    const Eigen::Matrix<T4__, Eigen::Dynamic,1>& log_y,
                    const Eigen::Matrix<T5__, Eigen::Dynamic,1>& sqrt_y, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T4__, typename boost::math::tools::promote_args<T5__>::type>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            validate_non_negative_index("mu", "rows(y)", rows(y));
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  mu(static_cast<Eigen::VectorXd::Index>(rows(y)));
            (void) mu;  // dummy to suppress unused var warning

            stan::math::initialize(mu, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(mu,DUMMY_VAR__);
            stan::math::assign(mu,linkinv_inv_gaussian(eta,link, pstream__));


            current_statement_begin__ = 166;
            return stan::math::promote_scalar<fun_return_scalar_t__>(subtract(add(multiply((-(0.5) * lambda),square(elt_divide(subtract(y,mu),elt_multiply(mu,sqrt_y)))),(0.5 * log((lambda / 6.2831853071795862)))),multiply(1.5,log_y)));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct pw_inv_gaussian_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T4__, typename T5__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T4__, typename boost::math::tools::promote_args<T5__>::type>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& y,
                    const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
                    const T2__& lambda,
                    const int& link,
                    const Eigen::Matrix<T4__, Eigen::Dynamic,1>& log_y,
                    const Eigen::Matrix<T5__, Eigen::Dynamic,1>& sqrt_y, std::ostream* pstream__) const {
        return pw_inv_gaussian(y, eta, lambda, link, log_y, sqrt_y, pstream__);
    }
};

template <typename T0__, typename T1__, class RNG>
typename boost::math::tools::promote_args<T0__, T1__>::type
inv_gaussian_rng(const T0__& mu,
                     const T1__& lambda, RNG& base_rng__, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            fun_scalar_t__ mu2;
            (void) mu2;  // dummy to suppress unused var warning

            stan::math::initialize(mu2, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(mu2,DUMMY_VAR__);
            stan::math::assign(mu2,square(mu));
            fun_scalar_t__ z;
            (void) z;  // dummy to suppress unused var warning

            stan::math::initialize(z, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(z,DUMMY_VAR__);
            stan::math::assign(z,uniform_rng(0,1, base_rng__));
            fun_scalar_t__ y;
            (void) y;  // dummy to suppress unused var warning

            stan::math::initialize(y, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(y,DUMMY_VAR__);
            stan::math::assign(y,square(normal_rng(0,1, base_rng__)));
            fun_scalar_t__ x;
            (void) x;  // dummy to suppress unused var warning

            stan::math::initialize(x, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(x,DUMMY_VAR__);
            stan::math::assign(x,(mu + (((mu2 * y) - (mu * sqrt(((((4 * mu) * lambda) * y) + (mu2 * square(y)))))) / (2 * lambda))));


            current_statement_begin__ = 185;
            if (as_bool(logical_lte(z,(mu / (mu + x))))) {
                current_statement_begin__ = 185;
                return stan::math::promote_scalar<fun_return_scalar_t__>(x);
            } else {
                current_statement_begin__ = 186;
                return stan::math::promote_scalar<fun_return_scalar_t__>((mu2 / x));
            }
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct inv_gaussian_rng_functor__ {
    template <typename T0__, typename T1__, class RNG>
        typename boost::math::tools::promote_args<T0__, T1__>::type
    operator()(const T0__& mu,
                     const T1__& lambda, RNG& base_rng__, std::ostream* pstream__) const {
        return inv_gaussian_rng(mu, lambda, base_rng__, pstream__);
    }
};

template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
linkinv_beta(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                 const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 197;
        if (as_bool(logical_eq(link,1))) {
            current_statement_begin__ = 197;
            return stan::math::promote_scalar<fun_return_scalar_t__>(inv_logit(eta));
        } else if (as_bool(logical_eq(link,2))) {
            current_statement_begin__ = 198;
            return stan::math::promote_scalar<fun_return_scalar_t__>(Phi(eta));
        } else if (as_bool(logical_eq(link,3))) {
            current_statement_begin__ = 199;
            return stan::math::promote_scalar<fun_return_scalar_t__>(inv_cloglog(eta));
        } else if (as_bool(logical_eq(link,4))) {
            current_statement_begin__ = 200;
            return stan::math::promote_scalar<fun_return_scalar_t__>(add(0.5,divide(atan(eta),stan::math::pi())));
        } else if (as_bool(logical_eq(link,5))) {
            current_statement_begin__ = 201;
            return stan::math::promote_scalar<fun_return_scalar_t__>(exp(eta));
        } else if (as_bool(logical_eq(link,6))) {
            current_statement_begin__ = 202;
            return stan::math::promote_scalar<fun_return_scalar_t__>(subtract(1,inv_cloglog(minus(eta))));
        } else {
            current_statement_begin__ = 203;
            std::stringstream errmsg_stream__;
            errmsg_stream__ << "invalid link";
            throw std::domain_error(errmsg_stream__.str());
        }
        current_statement_begin__ = 203;
        current_statement_begin__ = 204;
        return stan::math::promote_scalar<fun_return_scalar_t__>(eta);
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct linkinv_beta_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                 const int& link, std::ostream* pstream__) const {
        return linkinv_beta(eta, link, pstream__);
    }
};

template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
linkinv_beta_z(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                   const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 215;
        if (as_bool(logical_eq(link,1))) {
            current_statement_begin__ = 215;
            return stan::math::promote_scalar<fun_return_scalar_t__>(exp(eta));
        } else if (as_bool(logical_eq(link,2))) {
            current_statement_begin__ = 216;
            return stan::math::promote_scalar<fun_return_scalar_t__>(eta);
        } else if (as_bool(logical_eq(link,3))) {
            current_statement_begin__ = 217;
            return stan::math::promote_scalar<fun_return_scalar_t__>(square(eta));
        } else {
            current_statement_begin__ = 218;
            std::stringstream errmsg_stream__;
            errmsg_stream__ << "Invalid link";
            throw std::domain_error(errmsg_stream__.str());
        }
        current_statement_begin__ = 219;
        return stan::math::promote_scalar<fun_return_scalar_t__>(eta);
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct linkinv_beta_z_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                   const int& link, std::ostream* pstream__) const {
        return linkinv_beta_z(eta, link, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
pw_beta(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& y,
            const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
            const T2__& dispersion,
            const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            validate_non_negative_index("ll", "rows(y)", rows(y));
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  ll(static_cast<Eigen::VectorXd::Index>(rows(y)));
            (void) ll;  // dummy to suppress unused var warning

            stan::math::initialize(ll, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(ll,DUMMY_VAR__);
            validate_non_negative_index("mu", "rows(y)", rows(y));
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  mu(static_cast<Eigen::VectorXd::Index>(rows(y)));
            (void) mu;  // dummy to suppress unused var warning

            stan::math::initialize(mu, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(mu,DUMMY_VAR__);
            stan::math::assign(mu,linkinv_beta(eta,link, pstream__));


            current_statement_begin__ = 234;
            for (int n = 1; n <= rows(y); ++n) {

                current_statement_begin__ = 235;
                stan::math::assign(get_base1_lhs(ll,n,"ll",1), beta_log(get_base1(y,n,"y",1),(get_base1(mu,n,"mu",1) * dispersion),((1 - get_base1(mu,n,"mu",1)) * dispersion)));
            }
            current_statement_begin__ = 237;
            return stan::math::promote_scalar<fun_return_scalar_t__>(ll);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct pw_beta_functor__ {
    template <typename T0__, typename T1__, typename T2__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& y,
            const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
            const T2__& dispersion,
            const int& link, std::ostream* pstream__) const {
        return pw_beta(y, eta, dispersion, link, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
pw_beta_z(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& y,
              const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
              const Eigen::Matrix<T2__, Eigen::Dynamic,1>& eta_z,
              const int& link,
              const int& link_phi, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            validate_non_negative_index("ll", "rows(y)", rows(y));
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  ll(static_cast<Eigen::VectorXd::Index>(rows(y)));
            (void) ll;  // dummy to suppress unused var warning

            stan::math::initialize(ll, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(ll,DUMMY_VAR__);
            validate_non_negative_index("mu", "rows(y)", rows(y));
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  mu(static_cast<Eigen::VectorXd::Index>(rows(y)));
            (void) mu;  // dummy to suppress unused var warning

            stan::math::initialize(mu, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(mu,DUMMY_VAR__);
            stan::math::assign(mu,linkinv_beta(eta,link, pstream__));
            validate_non_negative_index("mu_z", "rows(y)", rows(y));
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  mu_z(static_cast<Eigen::VectorXd::Index>(rows(y)));
            (void) mu_z;  // dummy to suppress unused var warning

            stan::math::initialize(mu_z, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(mu_z,DUMMY_VAR__);
            stan::math::assign(mu_z,linkinv_beta_z(eta_z,link_phi, pstream__));


            current_statement_begin__ = 254;
            for (int n = 1; n <= rows(y); ++n) {

                current_statement_begin__ = 255;
                stan::math::assign(get_base1_lhs(ll,n,"ll",1), beta_log(get_base1(y,n,"y",1),(get_base1(mu,n,"mu",1) * get_base1(mu_z,n,"mu_z",1)),((1 - get_base1(mu,n,"mu",1)) * get_base1(mu_z,n,"mu_z",1))));
            }
            current_statement_begin__ = 257;
            return stan::math::promote_scalar<fun_return_scalar_t__>(ll);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct pw_beta_z_functor__ {
    template <typename T0__, typename T1__, typename T2__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& y,
              const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
              const Eigen::Matrix<T2__, Eigen::Dynamic,1>& eta_z,
              const int& link,
              const int& link_phi, std::ostream* pstream__) const {
        return pw_beta_z(y, eta, eta_z, link, link_phi, pstream__);
    }
};

template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
linkinv_binom(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                  const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 268;
        if (as_bool(logical_eq(link,1))) {
            current_statement_begin__ = 268;
            return stan::math::promote_scalar<fun_return_scalar_t__>(inv_logit(eta));
        } else if (as_bool(logical_eq(link,2))) {
            current_statement_begin__ = 269;
            return stan::math::promote_scalar<fun_return_scalar_t__>(Phi(eta));
        } else if (as_bool(logical_eq(link,3))) {
            current_statement_begin__ = 270;
            return stan::math::promote_scalar<fun_return_scalar_t__>(add(divide(atan(eta),stan::math::pi()),0.5));
        } else if (as_bool(logical_eq(link,4))) {
            current_statement_begin__ = 271;
            return stan::math::promote_scalar<fun_return_scalar_t__>(exp(eta));
        } else if (as_bool(logical_eq(link,5))) {
            current_statement_begin__ = 272;
            return stan::math::promote_scalar<fun_return_scalar_t__>(inv_cloglog(eta));
        } else {
            current_statement_begin__ = 273;
            std::stringstream errmsg_stream__;
            errmsg_stream__ << "Invalid link";
            throw std::domain_error(errmsg_stream__.str());
        }
        current_statement_begin__ = 273;
        current_statement_begin__ = 274;
        return stan::math::promote_scalar<fun_return_scalar_t__>(eta);
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct linkinv_binom_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                  const int& link, std::ostream* pstream__) const {
        return linkinv_binom(eta, link, pstream__);
    }
};

template <typename T2__, typename T_lp__, typename T_lp_accum__>
typename boost::math::tools::promote_args<T2__, T_lp__>::type
ll_binom_lp(const std::vector<int>& y,
                const std::vector<int>& trials,
                const Eigen::Matrix<T2__, Eigen::Dynamic,1>& eta,
                const int& link, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T2__, T_lp__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 286;
        if (as_bool(logical_eq(link,1))) {
            current_statement_begin__ = 286;
            lp_accum__.add(binomial_logit_log(y,trials,eta));
        } else if (as_bool(logical_lt(link,4))) {
            current_statement_begin__ = 287;
            lp_accum__.add(binomial_log(y,trials,linkinv_binom(eta,link, pstream__)));
        } else if (as_bool(logical_eq(link,4))) {

            current_statement_begin__ = 289;
            for (int n = 1; n <= num_elements(y); ++n) {

                current_statement_begin__ = 290;
                lp_accum__.add((get_base1(y,n,"y",1) * get_base1(eta,n,"eta",1)));
                current_statement_begin__ = 291;
                lp_accum__.add(((get_base1(trials,n,"trials",1) - get_base1(y,n,"y",1)) * log1m_exp(get_base1(eta,n,"eta",1))));
                current_statement_begin__ = 292;
                lp_accum__.add(binomial_coefficient_log(get_base1(trials,n,"trials",1),get_base1(y,n,"y",1)));
            }
        } else if (as_bool(logical_eq(link,5))) {

            current_statement_begin__ = 296;
            for (int n = 1; n <= num_elements(y); ++n) {
                {
                    fun_scalar_t__ neg_exp_eta;
                    (void) neg_exp_eta;  // dummy to suppress unused var warning

                    stan::math::initialize(neg_exp_eta, std::numeric_limits<double>::quiet_NaN());
                    stan::math::fill(neg_exp_eta,DUMMY_VAR__);
                    stan::math::assign(neg_exp_eta,-(exp(get_base1(eta,n,"eta",1))));


                    current_statement_begin__ = 298;
                    lp_accum__.add((get_base1(y,n,"y",1) * log1m_exp(neg_exp_eta)));
                    current_statement_begin__ = 299;
                    lp_accum__.add(((get_base1(trials,n,"trials",1) - get_base1(y,n,"y",1)) * neg_exp_eta));
                    current_statement_begin__ = 300;
                    lp_accum__.add(binomial_coefficient_log(get_base1(trials,n,"trials",1),get_base1(y,n,"y",1)));
                }
            }
        } else {
            current_statement_begin__ = 303;
            std::stringstream errmsg_stream__;
            errmsg_stream__ << "Invalid link";
            throw std::domain_error(errmsg_stream__.str());
        }
        current_statement_begin__ = 303;
        current_statement_begin__ = 304;
        return stan::math::promote_scalar<fun_return_scalar_t__>(get_lp(lp__, lp_accum__));
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct ll_binom_lp_functor__ {
    template <typename T2__, typename T_lp__, typename T_lp_accum__>
        typename boost::math::tools::promote_args<T2__, T_lp__>::type
    operator()(const std::vector<int>& y,
                const std::vector<int>& trials,
                const Eigen::Matrix<T2__, Eigen::Dynamic,1>& eta,
                const int& link, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) const {
        return ll_binom_lp(y, trials, eta, link, lp__, lp_accum__, pstream__);
    }
};

template <typename T2__>
Eigen::Matrix<typename boost::math::tools::promote_args<T2__>::type, Eigen::Dynamic,1>
pw_binom(const std::vector<int>& y,
             const std::vector<int>& trials,
             const Eigen::Matrix<T2__, Eigen::Dynamic,1>& eta,
             const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T2__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            int N(0);
            (void) N;  // dummy to suppress unused var warning

            stan::math::fill(N, std::numeric_limits<int>::min());
            stan::math::assign(N,rows(eta));
            validate_non_negative_index("ll", "N", N);
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  ll(static_cast<Eigen::VectorXd::Index>(N));
            (void) ll;  // dummy to suppress unused var warning

            stan::math::initialize(ll, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(ll,DUMMY_VAR__);


            current_statement_begin__ = 317;
            if (as_bool(logical_eq(link,1))) {

                current_statement_begin__ = 318;
                for (int n = 1; n <= N; ++n) {
                    current_statement_begin__ = 319;
                    stan::math::assign(get_base1_lhs(ll,n,"ll",1), binomial_logit_log(get_base1(y,n,"y",1),get_base1(trials,n,"trials",1),get_base1(eta,n,"eta",1)));
                }
            } else if (as_bool(logical_lte(link,5))) {
                {
                    validate_non_negative_index("pi", "N", N);
                    Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  pi(static_cast<Eigen::VectorXd::Index>(N));
                    (void) pi;  // dummy to suppress unused var warning

                    stan::math::initialize(pi, std::numeric_limits<double>::quiet_NaN());
                    stan::math::fill(pi,DUMMY_VAR__);
                    stan::math::assign(pi,linkinv_binom(eta,link, pstream__));


                    current_statement_begin__ = 323;
                    for (int n = 1; n <= N; ++n) {
                        current_statement_begin__ = 323;
                        stan::math::assign(get_base1_lhs(ll,n,"ll",1), binomial_log(get_base1(y,n,"y",1),get_base1(trials,n,"trials",1),get_base1(pi,n,"pi",1)));
                    }
                }
            } else {
                current_statement_begin__ = 325;
                std::stringstream errmsg_stream__;
                errmsg_stream__ << "Invalid link";
                throw std::domain_error(errmsg_stream__.str());
            }
            current_statement_begin__ = 325;
            current_statement_begin__ = 326;
            return stan::math::promote_scalar<fun_return_scalar_t__>(ll);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct pw_binom_functor__ {
    template <typename T2__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T2__>::type, Eigen::Dynamic,1>
    operator()(const std::vector<int>& y,
             const std::vector<int>& trials,
             const Eigen::Matrix<T2__, Eigen::Dynamic,1>& eta,
             const int& link, std::ostream* pstream__) const {
        return pw_binom(y, trials, eta, link, pstream__);
    }
};

template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
linkinv_count(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                  const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 338;
        if (as_bool(logical_eq(link,1))) {
            current_statement_begin__ = 338;
            return stan::math::promote_scalar<fun_return_scalar_t__>(exp(eta));
        } else if (as_bool(logical_eq(link,2))) {
            current_statement_begin__ = 339;
            return stan::math::promote_scalar<fun_return_scalar_t__>(eta);
        } else if (as_bool(logical_eq(link,3))) {
            current_statement_begin__ = 340;
            return stan::math::promote_scalar<fun_return_scalar_t__>(square(eta));
        } else {
            current_statement_begin__ = 341;
            std::stringstream errmsg_stream__;
            errmsg_stream__ << "Invalid link";
            throw std::domain_error(errmsg_stream__.str());
        }
        current_statement_begin__ = 341;
        current_statement_begin__ = 342;
        return stan::math::promote_scalar<fun_return_scalar_t__>(eta);
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct linkinv_count_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                  const int& link, std::ostream* pstream__) const {
        return linkinv_count(eta, link, pstream__);
    }
};

template <typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T1__>::type, Eigen::Dynamic,1>
pw_pois(const std::vector<int>& y,
            const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
            const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T1__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            int N(0);
            (void) N;  // dummy to suppress unused var warning

            stan::math::fill(N, std::numeric_limits<int>::min());
            stan::math::assign(N,rows(eta));
            validate_non_negative_index("ll", "N", N);
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  ll(static_cast<Eigen::VectorXd::Index>(N));
            (void) ll;  // dummy to suppress unused var warning

            stan::math::initialize(ll, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(ll,DUMMY_VAR__);


            current_statement_begin__ = 356;
            if (as_bool(logical_eq(link,1))) {
                current_statement_begin__ = 357;
                for (int n = 1; n <= N; ++n) {
                    current_statement_begin__ = 357;
                    stan::math::assign(get_base1_lhs(ll,n,"ll",1), poisson_log_log(get_base1(y,n,"y",1),get_base1(eta,n,"eta",1)));
                }
            } else if (as_bool(logical_lte(link,3))) {
                {
                    validate_non_negative_index("phi", "N", N);
                    Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  phi(static_cast<Eigen::VectorXd::Index>(N));
                    (void) phi;  // dummy to suppress unused var warning

                    stan::math::initialize(phi, std::numeric_limits<double>::quiet_NaN());
                    stan::math::fill(phi,DUMMY_VAR__);
                    stan::math::assign(phi,linkinv_count(eta,link, pstream__));


                    current_statement_begin__ = 360;
                    for (int n = 1; n <= N; ++n) {
                        current_statement_begin__ = 360;
                        stan::math::assign(get_base1_lhs(ll,n,"ll",1), poisson_log(get_base1(y,n,"y",1),get_base1(phi,n,"phi",1)));
                    }
                }
            } else {
                current_statement_begin__ = 362;
                std::stringstream errmsg_stream__;
                errmsg_stream__ << "Invalid link";
                throw std::domain_error(errmsg_stream__.str());
            }
            current_statement_begin__ = 362;
            current_statement_begin__ = 363;
            return stan::math::promote_scalar<fun_return_scalar_t__>(ll);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct pw_pois_functor__ {
    template <typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T1__>::type, Eigen::Dynamic,1>
    operator()(const std::vector<int>& y,
            const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
            const int& link, std::ostream* pstream__) const {
        return pw_pois(y, eta, link, pstream__);
    }
};

template <typename T1__, typename T2__>
Eigen::Matrix<typename boost::math::tools::promote_args<T1__, T2__>::type, Eigen::Dynamic,1>
pw_nb(const std::vector<int>& y,
          const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
          const T2__& theta,
          const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T1__, T2__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            int N(0);
            (void) N;  // dummy to suppress unused var warning

            stan::math::fill(N, std::numeric_limits<int>::min());
            stan::math::assign(N,rows(eta));
            validate_non_negative_index("rho", "N", N);
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  rho(static_cast<Eigen::VectorXd::Index>(N));
            (void) rho;  // dummy to suppress unused var warning

            stan::math::initialize(rho, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(rho,DUMMY_VAR__);
            stan::math::assign(rho,linkinv_count(eta,link, pstream__));
            validate_non_negative_index("ll", "N", N);
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  ll(static_cast<Eigen::VectorXd::Index>(N));
            (void) ll;  // dummy to suppress unused var warning

            stan::math::initialize(ll, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(ll,DUMMY_VAR__);


            current_statement_begin__ = 379;
            for (int n = 1; n <= N; ++n) {
                current_statement_begin__ = 379;
                stan::math::assign(get_base1_lhs(ll,n,"ll",1), neg_binomial_2_log(get_base1(y,n,"y",1),get_base1(rho,n,"rho",1),theta));
            }
            current_statement_begin__ = 380;
            return stan::math::promote_scalar<fun_return_scalar_t__>(ll);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct pw_nb_functor__ {
    template <typename T1__, typename T2__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T1__, T2__>::type, Eigen::Dynamic,1>
    operator()(const std::vector<int>& y,
          const Eigen::Matrix<T1__, Eigen::Dynamic,1>& eta,
          const T2__& theta,
          const int& link, std::ostream* pstream__) const {
        return pw_nb(y, eta, theta, link, pstream__);
    }
};

template <typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T7__>
Eigen::Matrix<typename boost::math::tools::promote_args<T2__, T3__, T4__, T5__, typename boost::math::tools::promote_args<T6__, T7__>::type>::type, Eigen::Dynamic,1>
make_theta_L(const int& len_theta_L,
                 const std::vector<int>& p,
                 const T2__& dispersion,
                 const Eigen::Matrix<T3__, Eigen::Dynamic,1>& tau,
                 const Eigen::Matrix<T4__, Eigen::Dynamic,1>& scale,
                 const Eigen::Matrix<T5__, Eigen::Dynamic,1>& zeta,
                 const Eigen::Matrix<T6__, Eigen::Dynamic,1>& rho,
                 const Eigen::Matrix<T7__, Eigen::Dynamic,1>& z_T, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T2__, T3__, T4__, T5__, typename boost::math::tools::promote_args<T6__, T7__>::type>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            validate_non_negative_index("theta_L", "len_theta_L", len_theta_L);
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  theta_L(static_cast<Eigen::VectorXd::Index>(len_theta_L));
            (void) theta_L;  // dummy to suppress unused var warning

            stan::math::initialize(theta_L, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(theta_L,DUMMY_VAR__);
            int zeta_mark(0);
            (void) zeta_mark;  // dummy to suppress unused var warning

            stan::math::fill(zeta_mark, std::numeric_limits<int>::min());
            stan::math::assign(zeta_mark,1);
            int rho_mark(0);
            (void) rho_mark;  // dummy to suppress unused var warning

            stan::math::fill(rho_mark, std::numeric_limits<int>::min());
            stan::math::assign(rho_mark,1);
            int z_T_mark(0);
            (void) z_T_mark;  // dummy to suppress unused var warning

            stan::math::fill(z_T_mark, std::numeric_limits<int>::min());
            stan::math::assign(z_T_mark,1);
            int theta_L_mark(0);
            (void) theta_L_mark;  // dummy to suppress unused var warning

            stan::math::fill(theta_L_mark, std::numeric_limits<int>::min());
            stan::math::assign(theta_L_mark,1);


            current_statement_begin__ = 411;
            for (int i = 1; i <= size(p); ++i) {
                {
                    int nc(0);
                    (void) nc;  // dummy to suppress unused var warning

                    stan::math::fill(nc, std::numeric_limits<int>::min());
                    stan::math::assign(nc,get_base1(p,i,"p",1));


                    current_statement_begin__ = 413;
                    if (as_bool(logical_eq(nc,1))) {

                        current_statement_begin__ = 414;
                        stan::math::assign(get_base1_lhs(theta_L,theta_L_mark,"theta_L",1), ((get_base1(tau,i,"tau",1) * get_base1(scale,i,"scale",1)) * dispersion));
                        current_statement_begin__ = 416;
                        stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                    } else {
                        {
                            validate_non_negative_index("T_i", "nc", nc);
                            validate_non_negative_index("T_i", "nc", nc);
                            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,Eigen::Dynamic>  T_i(static_cast<Eigen::VectorXd::Index>(nc),static_cast<Eigen::VectorXd::Index>(nc));
                            (void) T_i;  // dummy to suppress unused var warning

                            stan::math::initialize(T_i, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(T_i,DUMMY_VAR__);
                            fun_scalar_t__ std_dev;
                            (void) std_dev;  // dummy to suppress unused var warning

                            stan::math::initialize(std_dev, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(std_dev,DUMMY_VAR__);
                            fun_scalar_t__ T21;
                            (void) T21;  // dummy to suppress unused var warning

                            stan::math::initialize(T21, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(T21,DUMMY_VAR__);
                            fun_scalar_t__ trace_T_i;
                            (void) trace_T_i;  // dummy to suppress unused var warning

                            stan::math::initialize(trace_T_i, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(trace_T_i,DUMMY_VAR__);
                            stan::math::assign(trace_T_i,(square(((get_base1(tau,i,"tau",1) * get_base1(scale,i,"scale",1)) * dispersion)) * nc));
                            validate_non_negative_index("pi", "nc", nc);
                            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  pi(static_cast<Eigen::VectorXd::Index>(nc));
                            (void) pi;  // dummy to suppress unused var warning

                            stan::math::initialize(pi, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(pi,DUMMY_VAR__);
                            stan::math::assign(pi,segment(zeta,zeta_mark,nc));


                            current_statement_begin__ = 424;
                            stan::math::assign(pi, divide(pi,sum(pi)));
                            current_statement_begin__ = 427;
                            stan::math::assign(zeta_mark, (zeta_mark + nc));
                            current_statement_begin__ = 428;
                            stan::math::assign(std_dev, sqrt((get_base1(pi,1,"pi",1) * trace_T_i)));
                            current_statement_begin__ = 429;
                            stan::math::assign(get_base1_lhs(T_i,1,1,"T_i",1), std_dev);
                            current_statement_begin__ = 432;
                            stan::math::assign(std_dev, sqrt((get_base1(pi,2,"pi",1) * trace_T_i)));
                            current_statement_begin__ = 433;
                            stan::math::assign(T21, ((2.0 * get_base1(rho,rho_mark,"rho",1)) - 1.0));
                            current_statement_begin__ = 434;
                            stan::math::assign(rho_mark, (rho_mark + 1));
                            current_statement_begin__ = 435;
                            stan::math::assign(get_base1_lhs(T_i,2,2,"T_i",1), (std_dev * sqrt((1.0 - square(T21)))));
                            current_statement_begin__ = 436;
                            stan::math::assign(get_base1_lhs(T_i,2,1,"T_i",1), (std_dev * T21));
                            current_statement_begin__ = 438;
                            for (int r = 2; r <= (nc - 1); ++r) {
                                {
                                    int rp1(0);
                                    (void) rp1;  // dummy to suppress unused var warning

                                    stan::math::fill(rp1, std::numeric_limits<int>::min());
                                    stan::math::assign(rp1,(r + 1));
                                    validate_non_negative_index("T_row", "r", r);
                                    Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  T_row(static_cast<Eigen::VectorXd::Index>(r));
                                    (void) T_row;  // dummy to suppress unused var warning

                                    stan::math::initialize(T_row, std::numeric_limits<double>::quiet_NaN());
                                    stan::math::fill(T_row,DUMMY_VAR__);
                                    stan::math::assign(T_row,segment(z_T,z_T_mark,r));
                                    fun_scalar_t__ scale_factor;
                                    (void) scale_factor;  // dummy to suppress unused var warning

                                    stan::math::initialize(scale_factor, std::numeric_limits<double>::quiet_NaN());
                                    stan::math::fill(scale_factor,DUMMY_VAR__);
                                    stan::math::assign(scale_factor,(sqrt((get_base1(rho,rho_mark,"rho",1) / dot_self(T_row))) * std_dev));


                                    current_statement_begin__ = 442;
                                    stan::math::assign(z_T_mark, (z_T_mark + r));
                                    current_statement_begin__ = 443;
                                    stan::math::assign(std_dev, sqrt((get_base1(pi,rp1,"pi",1) * trace_T_i)));
                                    current_statement_begin__ = 444;
                                    for (int c = 1; c <= r; ++c) {
                                        current_statement_begin__ = 444;
                                        stan::math::assign(get_base1_lhs(T_i,rp1,c,"T_i",1), (get_base1(T_row,c,"T_row",1) * scale_factor));
                                    }
                                    current_statement_begin__ = 445;
                                    stan::math::assign(get_base1_lhs(T_i,rp1,rp1,"T_i",1), (sqrt((1.0 - get_base1(rho,rho_mark,"rho",1))) * std_dev));
                                    current_statement_begin__ = 446;
                                    stan::math::assign(rho_mark, (rho_mark + 1));
                                }
                            }
                            current_statement_begin__ = 450;
                            for (int c = 1; c <= nc; ++c) {
                                current_statement_begin__ = 450;
                                for (int r = c; r <= nc; ++r) {

                                    current_statement_begin__ = 451;
                                    stan::math::assign(get_base1_lhs(theta_L,theta_L_mark,"theta_L",1), get_base1(T_i,r,c,"T_i",1));
                                    current_statement_begin__ = 452;
                                    stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                                }
                            }
                        }
                    }
                }
            }
            current_statement_begin__ = 456;
            return stan::math::promote_scalar<fun_return_scalar_t__>(theta_L);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct make_theta_L_functor__ {
    template <typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T7__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T2__, T3__, T4__, T5__, typename boost::math::tools::promote_args<T6__, T7__>::type>::type, Eigen::Dynamic,1>
    operator()(const int& len_theta_L,
                 const std::vector<int>& p,
                 const T2__& dispersion,
                 const Eigen::Matrix<T3__, Eigen::Dynamic,1>& tau,
                 const Eigen::Matrix<T4__, Eigen::Dynamic,1>& scale,
                 const Eigen::Matrix<T5__, Eigen::Dynamic,1>& zeta,
                 const Eigen::Matrix<T6__, Eigen::Dynamic,1>& rho,
                 const Eigen::Matrix<T7__, Eigen::Dynamic,1>& z_T, std::ostream* pstream__) const {
        return make_theta_L(len_theta_L, p, dispersion, tau, scale, zeta, rho, z_T, pstream__);
    }
};

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
make_b(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_b,
           const Eigen::Matrix<T1__, Eigen::Dynamic,1>& theta_L,
           const std::vector<int>& p,
           const std::vector<int>& l, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            validate_non_negative_index("b", "rows(z_b)", rows(z_b));
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  b(static_cast<Eigen::VectorXd::Index>(rows(z_b)));
            (void) b;  // dummy to suppress unused var warning

            stan::math::initialize(b, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(b,DUMMY_VAR__);
            int b_mark(0);
            (void) b_mark;  // dummy to suppress unused var warning

            stan::math::fill(b_mark, std::numeric_limits<int>::min());
            stan::math::assign(b_mark,1);
            int theta_L_mark(0);
            (void) theta_L_mark;  // dummy to suppress unused var warning

            stan::math::fill(theta_L_mark, std::numeric_limits<int>::min());
            stan::math::assign(theta_L_mark,1);


            current_statement_begin__ = 474;
            for (int i = 1; i <= size(p); ++i) {
                {
                    int nc(0);
                    (void) nc;  // dummy to suppress unused var warning

                    stan::math::fill(nc, std::numeric_limits<int>::min());
                    stan::math::assign(nc,get_base1(p,i,"p",1));


                    current_statement_begin__ = 476;
                    if (as_bool(logical_eq(nc,1))) {
                        {
                            fun_scalar_t__ theta_L_start;
                            (void) theta_L_start;  // dummy to suppress unused var warning

                            stan::math::initialize(theta_L_start, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(theta_L_start,DUMMY_VAR__);
                            stan::math::assign(theta_L_start,get_base1(theta_L,theta_L_mark,"theta_L",1));


                            current_statement_begin__ = 478;
                            for (int s = b_mark; s <= ((b_mark + get_base1(l,i,"l",1)) - 1); ++s) {
                                current_statement_begin__ = 479;
                                stan::math::assign(get_base1_lhs(b,s,"b",1), (theta_L_start * get_base1(z_b,s,"z_b",1)));
                            }
                            current_statement_begin__ = 480;
                            stan::math::assign(b_mark, (b_mark + get_base1(l,i,"l",1)));
                            current_statement_begin__ = 481;
                            stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                        }
                    } else {
                        {
                            validate_non_negative_index("T_i", "nc", nc);
                            validate_non_negative_index("T_i", "nc", nc);
                            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,Eigen::Dynamic>  T_i(static_cast<Eigen::VectorXd::Index>(nc),static_cast<Eigen::VectorXd::Index>(nc));
                            (void) T_i;  // dummy to suppress unused var warning

                            stan::math::initialize(T_i, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(T_i,DUMMY_VAR__);
                            stan::math::assign(T_i,rep_matrix(0,nc,nc));


                            current_statement_begin__ = 485;
                            for (int c = 1; c <= nc; ++c) {

                                current_statement_begin__ = 486;
                                stan::math::assign(get_base1_lhs(T_i,c,c,"T_i",1), get_base1(theta_L,theta_L_mark,"theta_L",1));
                                current_statement_begin__ = 487;
                                stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                                current_statement_begin__ = 488;
                                for (int r = (c + 1); r <= nc; ++r) {

                                    current_statement_begin__ = 489;
                                    stan::math::assign(get_base1_lhs(T_i,r,c,"T_i",1), get_base1(theta_L,theta_L_mark,"theta_L",1));
                                    current_statement_begin__ = 490;
                                    stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                                }
                            }
                            current_statement_begin__ = 493;
                            for (int j = 1; j <= get_base1(l,i,"l",1); ++j) {
                                {
                                    validate_non_negative_index("temp", "nc", nc);
                                    Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  temp(static_cast<Eigen::VectorXd::Index>(nc));
                                    (void) temp;  // dummy to suppress unused var warning

                                    stan::math::initialize(temp, std::numeric_limits<double>::quiet_NaN());
                                    stan::math::fill(temp,DUMMY_VAR__);
                                    stan::math::assign(temp,multiply(T_i,segment(z_b,b_mark,nc)));


                                    current_statement_begin__ = 495;
                                    stan::math::assign(b_mark, (b_mark - 1));
                                    current_statement_begin__ = 496;
                                    for (int s = 1; s <= nc; ++s) {
                                        current_statement_begin__ = 496;
                                        stan::math::assign(get_base1_lhs(b,(b_mark + s),"b",1), get_base1(temp,s,"temp",1));
                                    }
                                    current_statement_begin__ = 497;
                                    stan::math::assign(b_mark, ((b_mark + nc) + 1));
                                }
                            }
                        }
                    }
                }
            }
            current_statement_begin__ = 501;
            return stan::math::promote_scalar<fun_return_scalar_t__>(b);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct make_b_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_b,
           const Eigen::Matrix<T1__, Eigen::Dynamic,1>& theta_L,
           const std::vector<int>& p,
           const std::vector<int>& l, std::ostream* pstream__) const {
        return make_b(z_b, theta_L, p, l, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T7__, typename T_lp__, typename T_lp_accum__>
void
decov_lp(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_b,
             const Eigen::Matrix<T1__, Eigen::Dynamic,1>& z_T,
             const Eigen::Matrix<T2__, Eigen::Dynamic,1>& rho,
             const Eigen::Matrix<T3__, Eigen::Dynamic,1>& zeta,
             const Eigen::Matrix<T4__, Eigen::Dynamic,1>& tau,
             const std::vector<T5__>& regularization,
             const std::vector<T6__>& delta,
             const Eigen::Matrix<T7__, Eigen::Dynamic,1>& shape,
             const int& t,
             const std::vector<int>& p, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__, T6__, T7__, T_lp__>::type>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            int pos_reg(0);
            (void) pos_reg;  // dummy to suppress unused var warning

            stan::math::fill(pos_reg, std::numeric_limits<int>::min());
            stan::math::assign(pos_reg,1);
            int pos_rho(0);
            (void) pos_rho;  // dummy to suppress unused var warning

            stan::math::fill(pos_rho, std::numeric_limits<int>::min());
            stan::math::assign(pos_rho,1);


            current_statement_begin__ = 524;
            lp_accum__.add(normal_log(z_b,0,1));
            current_statement_begin__ = 525;
            lp_accum__.add(normal_log(z_T,0,1));
            current_statement_begin__ = 526;
            for (int i = 1; i <= t; ++i) {
                current_statement_begin__ = 526;
                if (as_bool(logical_gt(get_base1(p,i,"p",1),1))) {
                    {
                        validate_non_negative_index("shape1", "(get_base1(p,i,\"p\",1) - 1)", (get_base1(p,i,"p",1) - 1));
                        Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  shape1(static_cast<Eigen::VectorXd::Index>((get_base1(p,i,"p",1) - 1)));
                        (void) shape1;  // dummy to suppress unused var warning

                        stan::math::initialize(shape1, std::numeric_limits<double>::quiet_NaN());
                        stan::math::fill(shape1,DUMMY_VAR__);
                        validate_non_negative_index("shape2", "(get_base1(p,i,\"p\",1) - 1)", (get_base1(p,i,"p",1) - 1));
                        Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  shape2(static_cast<Eigen::VectorXd::Index>((get_base1(p,i,"p",1) - 1)));
                        (void) shape2;  // dummy to suppress unused var warning

                        stan::math::initialize(shape2, std::numeric_limits<double>::quiet_NaN());
                        stan::math::fill(shape2,DUMMY_VAR__);
                        fun_scalar_t__ nu;
                        (void) nu;  // dummy to suppress unused var warning

                        stan::math::initialize(nu, std::numeric_limits<double>::quiet_NaN());
                        stan::math::fill(nu,DUMMY_VAR__);
                        stan::math::assign(nu,(get_base1(regularization,pos_reg,"regularization",1) + (0.5 * (get_base1(p,i,"p",1) - 2))));


                        current_statement_begin__ = 530;
                        stan::math::assign(pos_reg, (pos_reg + 1));
                        current_statement_begin__ = 531;
                        stan::math::assign(get_base1_lhs(shape1,1,"shape1",1), nu);
                        current_statement_begin__ = 532;
                        stan::math::assign(get_base1_lhs(shape2,1,"shape2",1), nu);
                        current_statement_begin__ = 533;
                        for (int j = 2; j <= (get_base1(p,i,"p",1) - 1); ++j) {

                            current_statement_begin__ = 534;
                            stan::math::assign(nu, (nu - 0.5));
                            current_statement_begin__ = 535;
                            stan::math::assign(get_base1_lhs(shape1,j,"shape1",1), (0.5 * j));
                            current_statement_begin__ = 536;
                            stan::math::assign(get_base1_lhs(shape2,j,"shape2",1), nu);
                        }
                        current_statement_begin__ = 538;
                        lp_accum__.add(beta_log(stan::model::rvalue(rho, stan::model::cons_list(stan::model::index_min_max(pos_rho, ((pos_rho + get_base1(p,i,"p",1)) - 2)), stan::model::nil_index_list()), "rho"),shape1,shape2));
                        current_statement_begin__ = 539;
                        stan::math::assign(pos_rho, ((pos_rho + get_base1(p,i,"p",1)) - 1));
                    }
                }
            }
            current_statement_begin__ = 541;
            lp_accum__.add(gamma_log(zeta,delta,1));
            current_statement_begin__ = 542;
            lp_accum__.add(gamma_log(tau,shape,1));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct decov_lp_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T7__, typename T_lp__, typename T_lp_accum__>
        void
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_b,
             const Eigen::Matrix<T1__, Eigen::Dynamic,1>& z_T,
             const Eigen::Matrix<T2__, Eigen::Dynamic,1>& rho,
             const Eigen::Matrix<T3__, Eigen::Dynamic,1>& zeta,
             const Eigen::Matrix<T4__, Eigen::Dynamic,1>& tau,
             const std::vector<T5__>& regularization,
             const std::vector<T6__>& delta,
             const Eigen::Matrix<T7__, Eigen::Dynamic,1>& shape,
             const int& t,
             const std::vector<int>& p, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) const {
        return decov_lp(z_b, z_T, rho, zeta, tau, regularization, delta, shape, t, p, lp__, lp_accum__, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type, Eigen::Dynamic,1>
hs_prior(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_beta,
             const std::vector<T1__>& global,
             const std::vector<Eigen::Matrix<T2__, Eigen::Dynamic,1> >& local,
             const T3__& global_prior_scale,
             const T4__& error_scale, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            validate_non_negative_index("lambda", "rows(z_beta)", rows(z_beta));
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  lambda(static_cast<Eigen::VectorXd::Index>(rows(z_beta)));
            (void) lambda;  // dummy to suppress unused var warning

            stan::math::initialize(lambda, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(lambda,DUMMY_VAR__);
            int K(0);
            (void) K;  // dummy to suppress unused var warning

            stan::math::fill(K, std::numeric_limits<int>::min());


            current_statement_begin__ = 559;
            stan::math::assign(K, rows(z_beta));
            current_statement_begin__ = 560;
            for (int k = 1; k <= K; ++k) {
                current_statement_begin__ = 560;
                stan::math::assign(get_base1_lhs(lambda,k,"lambda",1), (get_base1(get_base1(local,1,"local",1),k,"local",2) * sqrt(get_base1(get_base1(local,2,"local",1),k,"local",2))));
            }
            current_statement_begin__ = 561;
            return stan::math::promote_scalar<fun_return_scalar_t__>(multiply(multiply(multiply(multiply(elt_multiply(z_beta,lambda),get_base1(global,1,"global",1)),sqrt(get_base1(global,2,"global",1))),global_prior_scale),error_scale));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct hs_prior_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_beta,
             const std::vector<T1__>& global,
             const std::vector<Eigen::Matrix<T2__, Eigen::Dynamic,1> >& local,
             const T3__& global_prior_scale,
             const T4__& error_scale, std::ostream* pstream__) const {
        return hs_prior(z_beta, global, local, global_prior_scale, error_scale, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type, Eigen::Dynamic,1>
hsplus_prior(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_beta,
                 const std::vector<T1__>& global,
                 const std::vector<Eigen::Matrix<T2__, Eigen::Dynamic,1> >& local,
                 const T3__& global_prior_scale,
                 const T4__& error_scale, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 577;
        return stan::math::promote_scalar<fun_return_scalar_t__>(multiply(multiply(multiply(multiply(elt_multiply(elt_multiply(z_beta,elt_multiply(get_base1(local,1,"local",1),sqrt(get_base1(local,2,"local",1)))),elt_multiply(get_base1(local,3,"local",1),sqrt(get_base1(local,4,"local",1)))),get_base1(global,1,"global",1)),sqrt(get_base1(global,2,"global",1))),global_prior_scale),error_scale));
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct hsplus_prior_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__>::type>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_beta,
                 const std::vector<T1__>& global,
                 const std::vector<Eigen::Matrix<T2__, Eigen::Dynamic,1> >& local,
                 const T3__& global_prior_scale,
                 const T4__& error_scale, std::ostream* pstream__) const {
        return hsplus_prior(z_beta, global, local, global_prior_scale, error_scale, pstream__);
    }
};

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
divide_real_by_vector(const T0__& x,
                          const Eigen::Matrix<T1__, Eigen::Dynamic,1>& y, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            int K(0);
            (void) K;  // dummy to suppress unused var warning

            stan::math::fill(K, std::numeric_limits<int>::min());
            stan::math::assign(K,rows(y));
            validate_non_negative_index("ret", "K", K);
            Eigen::Matrix<fun_scalar_t__,Eigen::Dynamic,1>  ret(static_cast<Eigen::VectorXd::Index>(K));
            (void) ret;  // dummy to suppress unused var warning

            stan::math::initialize(ret, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(ret,DUMMY_VAR__);


            current_statement_begin__ = 592;
            for (int k = 1; k <= K; ++k) {
                current_statement_begin__ = 592;
                stan::math::assign(get_base1_lhs(ret,k,"ret",1), (x / get_base1(y,k,"y",1)));
            }
            current_statement_begin__ = 593;
            return stan::math::promote_scalar<fun_return_scalar_t__>(ret);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct divide_real_by_vector_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
    operator()(const T0__& x,
                          const Eigen::Matrix<T1__, Eigen::Dynamic,1>& y, std::ostream* pstream__) const {
        return divide_real_by_vector(x, y, pstream__);
    }
};

template <typename T0__, typename T1__>
typename boost::math::tools::promote_args<T0__, T1__>::type
CFt(const T0__& z,
        const T1__& df, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            fun_scalar_t__ z2;
            (void) z2;  // dummy to suppress unused var warning

            stan::math::initialize(z2, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(z2,DUMMY_VAR__);
            stan::math::assign(z2,square(z));
            fun_scalar_t__ z3;
            (void) z3;  // dummy to suppress unused var warning

            stan::math::initialize(z3, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(z3,DUMMY_VAR__);
            stan::math::assign(z3,(z2 * z));
            fun_scalar_t__ z5;
            (void) z5;  // dummy to suppress unused var warning

            stan::math::initialize(z5, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(z5,DUMMY_VAR__);
            stan::math::assign(z5,(z2 * z3));
            fun_scalar_t__ z7;
            (void) z7;  // dummy to suppress unused var warning

            stan::math::initialize(z7, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(z7,DUMMY_VAR__);
            stan::math::assign(z7,(z2 * z5));
            fun_scalar_t__ z9;
            (void) z9;  // dummy to suppress unused var warning

            stan::math::initialize(z9, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(z9,DUMMY_VAR__);
            stan::math::assign(z9,(z2 * z7));
            fun_scalar_t__ df2;
            (void) df2;  // dummy to suppress unused var warning

            stan::math::initialize(df2, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(df2,DUMMY_VAR__);
            stan::math::assign(df2,square(df));
            fun_scalar_t__ df3;
            (void) df3;  // dummy to suppress unused var warning

            stan::math::initialize(df3, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(df3,DUMMY_VAR__);
            stan::math::assign(df3,(df2 * df));
            fun_scalar_t__ df4;
            (void) df4;  // dummy to suppress unused var warning

            stan::math::initialize(df4, std::numeric_limits<double>::quiet_NaN());
            stan::math::fill(df4,DUMMY_VAR__);
            stan::math::assign(df4,(df2 * df2));


            current_statement_begin__ = 615;
            return stan::math::promote_scalar<fun_return_scalar_t__>(((((z + ((z3 + z) / (4 * df))) + ((((5 * z5) + (16 * z3)) + (3 * z)) / (96 * df2))) + (((((3 * z7) + (19 * z5)) + (17 * z3)) - (15 * z)) / (384 * df3))) + ((((((79 * z9) + (776 * z7)) + (1482 * z5)) - (1920 * z3)) - (945 * z)) / (92160 * df4))));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct CFt_functor__ {
    template <typename T0__, typename T1__>
        typename boost::math::tools::promote_args<T0__, T1__>::type
    operator()(const T0__& z,
        const T1__& df, std::ostream* pstream__) const {
        return CFt(z, df, pstream__);
    }
};

std::vector<std::vector<int> >
make_V(const int& N,
           const int& t,
           const std::vector<int>& v, std::ostream* pstream__) {
    typedef double fun_scalar_t__;
    typedef int fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
            validate_non_negative_index("V", "t", t);
            validate_non_negative_index("V", "N", N);
            vector<vector<int> > V(t, (vector<int>(N, 0)));
            stan::math::fill(V, std::numeric_limits<int>::min());
            int pos(0);
            (void) pos;  // dummy to suppress unused var warning

            stan::math::fill(pos, std::numeric_limits<int>::min());
            stan::math::assign(pos,1);


            current_statement_begin__ = 630;
            if (as_bool(logical_gt(t,0))) {
                current_statement_begin__ = 630;
                for (int j = 1; j <= N; ++j) {
                    current_statement_begin__ = 630;
                    for (int i = 1; i <= t; ++i) {

                        current_statement_begin__ = 631;
                        stan::math::assign(get_base1_lhs(get_base1_lhs(V,i,"V",1),j,"V",2), get_base1(v,pos,"v",1));
                        current_statement_begin__ = 632;
                        stan::math::assign(pos, (pos + 1));
                    }
                }
            }
            current_statement_begin__ = 634;
            return stan::math::promote_scalar<fun_return_scalar_t__>(V);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct make_V_functor__ {
            std::vector<std::vector<int> >
    operator()(const int& N,
           const int& t,
           const std::vector<int>& v, std::ostream* pstream__) const {
        return make_V(N, t, v, pstream__);
    }
};

double
make_lower(const int& family,
               const int& link, std::ostream* pstream__) {
    typedef double fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 645;
        if (as_bool(logical_eq(family,1))) {
            current_statement_begin__ = 645;
            return stan::math::promote_scalar<fun_return_scalar_t__>(stan::math::negative_infinity());
        }
        current_statement_begin__ = 646;
        if (as_bool(logical_eq(family,5))) {

            current_statement_begin__ = 647;
            if (as_bool(logical_eq(link,2))) {
                current_statement_begin__ = 647;
                return stan::math::promote_scalar<fun_return_scalar_t__>(stan::math::negative_infinity());
            }
            current_statement_begin__ = 648;
            return stan::math::promote_scalar<fun_return_scalar_t__>(0);
        }
        current_statement_begin__ = 650;
        if (as_bool((primitive_value(logical_eq(family,2)) || primitive_value(logical_eq(family,3))))) {

            current_statement_begin__ = 651;
            if (as_bool(logical_eq(link,1))) {
                current_statement_begin__ = 651;
                return stan::math::promote_scalar<fun_return_scalar_t__>(stan::math::negative_infinity());
            }
            current_statement_begin__ = 652;
            return stan::math::promote_scalar<fun_return_scalar_t__>(0.0);
        }
        current_statement_begin__ = 654;
        return stan::math::promote_scalar<fun_return_scalar_t__>(stan::math::negative_infinity());
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct make_lower_functor__ {
            double
    operator()(const int& family,
               const int& link, std::ostream* pstream__) const {
        return make_lower(family, link, pstream__);
    }
};

double
make_upper(const int& family,
               const int& link, std::ostream* pstream__) {
    typedef double fun_scalar_t__;
    typedef fun_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        fun_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 665;
        if (as_bool((primitive_value(logical_eq(family,4)) && primitive_value(logical_eq(link,4))))) {
            current_statement_begin__ = 665;
            return stan::math::promote_scalar<fun_return_scalar_t__>(0.0);
        }
        current_statement_begin__ = 666;
        return stan::math::promote_scalar<fun_return_scalar_t__>(stan::math::positive_infinity());
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct make_upper_functor__ {
            double
    operator()(const int& family,
               const int& link, std::ostream* pstream__) const {
        return make_upper(family, link, pstream__);
    }
};

class model_spatial : public prob_grad {
private:
    int N;
    int K;
    matrix_d X;
    int family;
    int link;
    int is_continuous;
    int has_aux;
    int model_type;
    int has_intercept;
    vector_d xbar;
    vector<int> trials;
    vector<int> y_int;
    vector_d y_real;
    int E_n;
    vector<vector<int> > edges;
    int order;
    vector<int> Q_n;
    vector_d w;
    vector<int> v;
    vector<int> u;
    int prior_dist_rho;
    double prior_mean_rho;
    double prior_scale_rho;
    double prior_df_rho;
    double shape1_rho;
    double shape2_rho;
    double scaling_factor;
    int prior_dist_for_intercept;
    int prior_dist;
    int prior_dist_tau;
    double prior_mean_for_intercept;
    double prior_scale_for_intercept;
    double prior_df_for_intercept;
    vector_d prior_mean;
    vector_d prior_scale;
    vector_d prior_df;
    double prior_mean_tau;
    double prior_scale_tau;
    double prior_df_tau;
    double global_prior_df;
    double global_prior_scale;
    vector<int> num_normals;
    int prior_dist_for_aux;
    double prior_mean_for_aux;
    double prior_scale_for_aux;
    double prior_df_for_aux;
    double poisson_max;
    int hs;
    double sum_log_y;
public:
    model_spatial(stan::io::var_context& context__,
        std::ostream* pstream__ = 0)
        : prob_grad(0) {
        ctor_body(context__, 0, pstream__);
    }

    model_spatial(stan::io::var_context& context__,
        unsigned int random_seed__,
        std::ostream* pstream__ = 0)
        : prob_grad(0) {
        ctor_body(context__, random_seed__, pstream__);
    }

    void ctor_body(stan::io::var_context& context__,
                   unsigned int random_seed__,
                   std::ostream* pstream__) {
        boost::ecuyer1988 base_rng__ =
          stan::services::util::create_rng(random_seed__, 0);
        (void) base_rng__;  // suppress unused var warning

        current_statement_begin__ = -1;

        static const char* function__ = "model_spatial_namespace::model_spatial";
        (void) function__;  // dummy to suppress unused var warning
        size_t pos__;
        (void) pos__;  // dummy to suppress unused var warning
        std::vector<int> vals_i__;
        std::vector<double> vals_r__;
        double DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

        // initialize member variables
        context__.validate_dims("data initialization", "N", "int", context__.to_vec());
        N = int(0);
        vals_i__ = context__.vals_i("N");
        pos__ = 0;
        N = vals_i__[pos__++];
        context__.validate_dims("data initialization", "K", "int", context__.to_vec());
        K = int(0);
        vals_i__ = context__.vals_i("K");
        pos__ = 0;
        K = vals_i__[pos__++];
        validate_non_negative_index("X", "N", N);
        validate_non_negative_index("X", "K", K);
        context__.validate_dims("data initialization", "X", "matrix_d", context__.to_vec(N,K));
        validate_non_negative_index("X", "N", N);
        validate_non_negative_index("X", "K", K);
        X = matrix_d(static_cast<Eigen::VectorXd::Index>(N),static_cast<Eigen::VectorXd::Index>(K));
        vals_r__ = context__.vals_r("X");
        pos__ = 0;
        size_t X_m_mat_lim__ = N;
        size_t X_n_mat_lim__ = K;
        for (size_t n_mat__ = 0; n_mat__ < X_n_mat_lim__; ++n_mat__) {
            for (size_t m_mat__ = 0; m_mat__ < X_m_mat_lim__; ++m_mat__) {
                X(m_mat__,n_mat__) = vals_r__[pos__++];
            }
        }
        context__.validate_dims("data initialization", "family", "int", context__.to_vec());
        family = int(0);
        vals_i__ = context__.vals_i("family");
        pos__ = 0;
        family = vals_i__[pos__++];
        context__.validate_dims("data initialization", "link", "int", context__.to_vec());
        link = int(0);
        vals_i__ = context__.vals_i("link");
        pos__ = 0;
        link = vals_i__[pos__++];
        context__.validate_dims("data initialization", "is_continuous", "int", context__.to_vec());
        is_continuous = int(0);
        vals_i__ = context__.vals_i("is_continuous");
        pos__ = 0;
        is_continuous = vals_i__[pos__++];
        context__.validate_dims("data initialization", "has_aux", "int", context__.to_vec());
        has_aux = int(0);
        vals_i__ = context__.vals_i("has_aux");
        pos__ = 0;
        has_aux = vals_i__[pos__++];
        context__.validate_dims("data initialization", "model_type", "int", context__.to_vec());
        model_type = int(0);
        vals_i__ = context__.vals_i("model_type");
        pos__ = 0;
        model_type = vals_i__[pos__++];
        context__.validate_dims("data initialization", "has_intercept", "int", context__.to_vec());
        has_intercept = int(0);
        vals_i__ = context__.vals_i("has_intercept");
        pos__ = 0;
        has_intercept = vals_i__[pos__++];
        validate_non_negative_index("xbar", "K", K);
        context__.validate_dims("data initialization", "xbar", "vector_d", context__.to_vec(K));
        validate_non_negative_index("xbar", "K", K);
        xbar = vector_d(static_cast<Eigen::VectorXd::Index>(K));
        vals_r__ = context__.vals_r("xbar");
        pos__ = 0;
        size_t xbar_i_vec_lim__ = K;
        for (size_t i_vec__ = 0; i_vec__ < xbar_i_vec_lim__; ++i_vec__) {
            xbar[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("trials", "(logical_eq(family,4) ? N : 0 )", (logical_eq(family,4) ? N : 0 ));
        context__.validate_dims("data initialization", "trials", "int", context__.to_vec((logical_eq(family,4) ? N : 0 )));
        validate_non_negative_index("trials", "(logical_eq(family,4) ? N : 0 )", (logical_eq(family,4) ? N : 0 ));
        trials = std::vector<int>((logical_eq(family,4) ? N : 0 ),int(0));
        vals_i__ = context__.vals_i("trials");
        pos__ = 0;
        size_t trials_limit_0__ = (logical_eq(family,4) ? N : 0 );
        for (size_t i_0__ = 0; i_0__ < trials_limit_0__; ++i_0__) {
            trials[i_0__] = vals_i__[pos__++];
        }
        validate_non_negative_index("y_int", "(logical_eq(is_continuous,1) ? 0 : N )", (logical_eq(is_continuous,1) ? 0 : N ));
        context__.validate_dims("data initialization", "y_int", "int", context__.to_vec((logical_eq(is_continuous,1) ? 0 : N )));
        validate_non_negative_index("y_int", "(logical_eq(is_continuous,1) ? 0 : N )", (logical_eq(is_continuous,1) ? 0 : N ));
        y_int = std::vector<int>((logical_eq(is_continuous,1) ? 0 : N ),int(0));
        vals_i__ = context__.vals_i("y_int");
        pos__ = 0;
        size_t y_int_limit_0__ = (logical_eq(is_continuous,1) ? 0 : N );
        for (size_t i_0__ = 0; i_0__ < y_int_limit_0__; ++i_0__) {
            y_int[i_0__] = vals_i__[pos__++];
        }
        validate_non_negative_index("y_real", "(logical_eq(is_continuous,1) ? N : 0 )", (logical_eq(is_continuous,1) ? N : 0 ));
        context__.validate_dims("data initialization", "y_real", "vector_d", context__.to_vec((logical_eq(is_continuous,1) ? N : 0 )));
        validate_non_negative_index("y_real", "(logical_eq(is_continuous,1) ? N : 0 )", (logical_eq(is_continuous,1) ? N : 0 ));
        y_real = vector_d(static_cast<Eigen::VectorXd::Index>((logical_eq(is_continuous,1) ? N : 0 )));
        vals_r__ = context__.vals_r("y_real");
        pos__ = 0;
        size_t y_real_i_vec_lim__ = (logical_eq(is_continuous,1) ? N : 0 );
        for (size_t i_vec__ = 0; i_vec__ < y_real_i_vec_lim__; ++i_vec__) {
            y_real[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "E_n", "int", context__.to_vec());
        E_n = int(0);
        vals_i__ = context__.vals_i("E_n");
        pos__ = 0;
        E_n = vals_i__[pos__++];
        validate_non_negative_index("edges", "E_n", E_n);
        validate_non_negative_index("edges", "2", 2);
        context__.validate_dims("data initialization", "edges", "int", context__.to_vec(E_n,2));
        validate_non_negative_index("edges", "E_n", E_n);
        validate_non_negative_index("edges", "2", 2);
        edges = std::vector<std::vector<int> >(E_n,std::vector<int>(2,int(0)));
        vals_i__ = context__.vals_i("edges");
        pos__ = 0;
        size_t edges_limit_1__ = 2;
        for (size_t i_1__ = 0; i_1__ < edges_limit_1__; ++i_1__) {
            size_t edges_limit_0__ = E_n;
            for (size_t i_0__ = 0; i_0__ < edges_limit_0__; ++i_0__) {
                edges[i_0__][i_1__] = vals_i__[pos__++];
            }
        }
        context__.validate_dims("data initialization", "order", "int", context__.to_vec());
        order = int(0);
        vals_i__ = context__.vals_i("order");
        pos__ = 0;
        order = vals_i__[pos__++];
        validate_non_negative_index("Q_n", "logical_eq(order,2)", logical_eq(order,2));
        context__.validate_dims("data initialization", "Q_n", "int", context__.to_vec(logical_eq(order,2)));
        validate_non_negative_index("Q_n", "logical_eq(order,2)", logical_eq(order,2));
        Q_n = std::vector<int>(logical_eq(order,2),int(0));
        vals_i__ = context__.vals_i("Q_n");
        pos__ = 0;
        size_t Q_n_limit_0__ = logical_eq(order,2);
        for (size_t i_0__ = 0; i_0__ < Q_n_limit_0__; ++i_0__) {
            Q_n[i_0__] = vals_i__[pos__++];
        }
        validate_non_negative_index("w", "(logical_eq(order,2) ? get_base1(Q_n,1,\"Q_n\",1) : 0 )", (logical_eq(order,2) ? get_base1(Q_n,1,"Q_n",1) : 0 ));
        context__.validate_dims("data initialization", "w", "vector_d", context__.to_vec((logical_eq(order,2) ? get_base1(Q_n,1,"Q_n",1) : 0 )));
        validate_non_negative_index("w", "(logical_eq(order,2) ? get_base1(Q_n,1,\"Q_n\",1) : 0 )", (logical_eq(order,2) ? get_base1(Q_n,1,"Q_n",1) : 0 ));
        w = vector_d(static_cast<Eigen::VectorXd::Index>((logical_eq(order,2) ? get_base1(Q_n,1,"Q_n",1) : 0 )));
        vals_r__ = context__.vals_r("w");
        pos__ = 0;
        size_t w_i_vec_lim__ = (logical_eq(order,2) ? get_base1(Q_n,1,"Q_n",1) : 0 );
        for (size_t i_vec__ = 0; i_vec__ < w_i_vec_lim__; ++i_vec__) {
            w[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("v", "(logical_eq(order,2) ? get_base1(Q_n,1,\"Q_n\",1) : 0 )", (logical_eq(order,2) ? get_base1(Q_n,1,"Q_n",1) : 0 ));
        context__.validate_dims("data initialization", "v", "int", context__.to_vec((logical_eq(order,2) ? get_base1(Q_n,1,"Q_n",1) : 0 )));
        validate_non_negative_index("v", "(logical_eq(order,2) ? get_base1(Q_n,1,\"Q_n\",1) : 0 )", (logical_eq(order,2) ? get_base1(Q_n,1,"Q_n",1) : 0 ));
        v = std::vector<int>((logical_eq(order,2) ? get_base1(Q_n,1,"Q_n",1) : 0 ),int(0));
        vals_i__ = context__.vals_i("v");
        pos__ = 0;
        size_t v_limit_0__ = (logical_eq(order,2) ? get_base1(Q_n,1,"Q_n",1) : 0 );
        for (size_t i_0__ = 0; i_0__ < v_limit_0__; ++i_0__) {
            v[i_0__] = vals_i__[pos__++];
        }
        validate_non_negative_index("u", "(logical_eq(order,2) ? (N + 1) : 0 )", (logical_eq(order,2) ? (N + 1) : 0 ));
        context__.validate_dims("data initialization", "u", "int", context__.to_vec((logical_eq(order,2) ? (N + 1) : 0 )));
        validate_non_negative_index("u", "(logical_eq(order,2) ? (N + 1) : 0 )", (logical_eq(order,2) ? (N + 1) : 0 ));
        u = std::vector<int>((logical_eq(order,2) ? (N + 1) : 0 ),int(0));
        vals_i__ = context__.vals_i("u");
        pos__ = 0;
        size_t u_limit_0__ = (logical_eq(order,2) ? (N + 1) : 0 );
        for (size_t i_0__ = 0; i_0__ < u_limit_0__; ++i_0__) {
            u[i_0__] = vals_i__[pos__++];
        }
        context__.validate_dims("data initialization", "prior_dist_rho", "int", context__.to_vec());
        prior_dist_rho = int(0);
        vals_i__ = context__.vals_i("prior_dist_rho");
        pos__ = 0;
        prior_dist_rho = vals_i__[pos__++];
        context__.validate_dims("data initialization", "prior_mean_rho", "double", context__.to_vec());
        prior_mean_rho = double(0);
        vals_r__ = context__.vals_r("prior_mean_rho");
        pos__ = 0;
        prior_mean_rho = vals_r__[pos__++];
        context__.validate_dims("data initialization", "prior_scale_rho", "double", context__.to_vec());
        prior_scale_rho = double(0);
        vals_r__ = context__.vals_r("prior_scale_rho");
        pos__ = 0;
        prior_scale_rho = vals_r__[pos__++];
        context__.validate_dims("data initialization", "prior_df_rho", "double", context__.to_vec());
        prior_df_rho = double(0);
        vals_r__ = context__.vals_r("prior_df_rho");
        pos__ = 0;
        prior_df_rho = vals_r__[pos__++];
        context__.validate_dims("data initialization", "shape1_rho", "double", context__.to_vec());
        shape1_rho = double(0);
        vals_r__ = context__.vals_r("shape1_rho");
        pos__ = 0;
        shape1_rho = vals_r__[pos__++];
        context__.validate_dims("data initialization", "shape2_rho", "double", context__.to_vec());
        shape2_rho = double(0);
        vals_r__ = context__.vals_r("shape2_rho");
        pos__ = 0;
        shape2_rho = vals_r__[pos__++];
        context__.validate_dims("data initialization", "scaling_factor", "double", context__.to_vec());
        scaling_factor = double(0);
        vals_r__ = context__.vals_r("scaling_factor");
        pos__ = 0;
        scaling_factor = vals_r__[pos__++];
        context__.validate_dims("data initialization", "prior_dist_for_intercept", "int", context__.to_vec());
        prior_dist_for_intercept = int(0);
        vals_i__ = context__.vals_i("prior_dist_for_intercept");
        pos__ = 0;
        prior_dist_for_intercept = vals_i__[pos__++];
        context__.validate_dims("data initialization", "prior_dist", "int", context__.to_vec());
        prior_dist = int(0);
        vals_i__ = context__.vals_i("prior_dist");
        pos__ = 0;
        prior_dist = vals_i__[pos__++];
        context__.validate_dims("data initialization", "prior_dist_tau", "int", context__.to_vec());
        prior_dist_tau = int(0);
        vals_i__ = context__.vals_i("prior_dist_tau");
        pos__ = 0;
        prior_dist_tau = vals_i__[pos__++];
        context__.validate_dims("data initialization", "prior_mean_for_intercept", "double", context__.to_vec());
        prior_mean_for_intercept = double(0);
        vals_r__ = context__.vals_r("prior_mean_for_intercept");
        pos__ = 0;
        prior_mean_for_intercept = vals_r__[pos__++];
        context__.validate_dims("data initialization", "prior_scale_for_intercept", "double", context__.to_vec());
        prior_scale_for_intercept = double(0);
        vals_r__ = context__.vals_r("prior_scale_for_intercept");
        pos__ = 0;
        prior_scale_for_intercept = vals_r__[pos__++];
        context__.validate_dims("data initialization", "prior_df_for_intercept", "double", context__.to_vec());
        prior_df_for_intercept = double(0);
        vals_r__ = context__.vals_r("prior_df_for_intercept");
        pos__ = 0;
        prior_df_for_intercept = vals_r__[pos__++];
        validate_non_negative_index("prior_mean", "K", K);
        context__.validate_dims("data initialization", "prior_mean", "vector_d", context__.to_vec(K));
        validate_non_negative_index("prior_mean", "K", K);
        prior_mean = vector_d(static_cast<Eigen::VectorXd::Index>(K));
        vals_r__ = context__.vals_r("prior_mean");
        pos__ = 0;
        size_t prior_mean_i_vec_lim__ = K;
        for (size_t i_vec__ = 0; i_vec__ < prior_mean_i_vec_lim__; ++i_vec__) {
            prior_mean[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("prior_scale", "K", K);
        context__.validate_dims("data initialization", "prior_scale", "vector_d", context__.to_vec(K));
        validate_non_negative_index("prior_scale", "K", K);
        prior_scale = vector_d(static_cast<Eigen::VectorXd::Index>(K));
        vals_r__ = context__.vals_r("prior_scale");
        pos__ = 0;
        size_t prior_scale_i_vec_lim__ = K;
        for (size_t i_vec__ = 0; i_vec__ < prior_scale_i_vec_lim__; ++i_vec__) {
            prior_scale[i_vec__] = vals_r__[pos__++];
        }
        validate_non_negative_index("prior_df", "K", K);
        context__.validate_dims("data initialization", "prior_df", "vector_d", context__.to_vec(K));
        validate_non_negative_index("prior_df", "K", K);
        prior_df = vector_d(static_cast<Eigen::VectorXd::Index>(K));
        vals_r__ = context__.vals_r("prior_df");
        pos__ = 0;
        size_t prior_df_i_vec_lim__ = K;
        for (size_t i_vec__ = 0; i_vec__ < prior_df_i_vec_lim__; ++i_vec__) {
            prior_df[i_vec__] = vals_r__[pos__++];
        }
        context__.validate_dims("data initialization", "prior_mean_tau", "double", context__.to_vec());
        prior_mean_tau = double(0);
        vals_r__ = context__.vals_r("prior_mean_tau");
        pos__ = 0;
        prior_mean_tau = vals_r__[pos__++];
        context__.validate_dims("data initialization", "prior_scale_tau", "double", context__.to_vec());
        prior_scale_tau = double(0);
        vals_r__ = context__.vals_r("prior_scale_tau");
        pos__ = 0;
        prior_scale_tau = vals_r__[pos__++];
        context__.validate_dims("data initialization", "prior_df_tau", "double", context__.to_vec());
        prior_df_tau = double(0);
        vals_r__ = context__.vals_r("prior_df_tau");
        pos__ = 0;
        prior_df_tau = vals_r__[pos__++];
        context__.validate_dims("data initialization", "global_prior_df", "double", context__.to_vec());
        global_prior_df = double(0);
        vals_r__ = context__.vals_r("global_prior_df");
        pos__ = 0;
        global_prior_df = vals_r__[pos__++];
        context__.validate_dims("data initialization", "global_prior_scale", "double", context__.to_vec());
        global_prior_scale = double(0);
        vals_r__ = context__.vals_r("global_prior_scale");
        pos__ = 0;
        global_prior_scale = vals_r__[pos__++];
        validate_non_negative_index("num_normals", "(logical_eq(prior_dist,7) ? K : 0 )", (logical_eq(prior_dist,7) ? K : 0 ));
        context__.validate_dims("data initialization", "num_normals", "int", context__.to_vec((logical_eq(prior_dist,7) ? K : 0 )));
        validate_non_negative_index("num_normals", "(logical_eq(prior_dist,7) ? K : 0 )", (logical_eq(prior_dist,7) ? K : 0 ));
        num_normals = std::vector<int>((logical_eq(prior_dist,7) ? K : 0 ),int(0));
        vals_i__ = context__.vals_i("num_normals");
        pos__ = 0;
        size_t num_normals_limit_0__ = (logical_eq(prior_dist,7) ? K : 0 );
        for (size_t i_0__ = 0; i_0__ < num_normals_limit_0__; ++i_0__) {
            num_normals[i_0__] = vals_i__[pos__++];
        }
        context__.validate_dims("data initialization", "prior_dist_for_aux", "int", context__.to_vec());
        prior_dist_for_aux = int(0);
        vals_i__ = context__.vals_i("prior_dist_for_aux");
        pos__ = 0;
        prior_dist_for_aux = vals_i__[pos__++];
        context__.validate_dims("data initialization", "prior_mean_for_aux", "double", context__.to_vec());
        prior_mean_for_aux = double(0);
        vals_r__ = context__.vals_r("prior_mean_for_aux");
        pos__ = 0;
        prior_mean_for_aux = vals_r__[pos__++];
        context__.validate_dims("data initialization", "prior_scale_for_aux", "double", context__.to_vec());
        prior_scale_for_aux = double(0);
        vals_r__ = context__.vals_r("prior_scale_for_aux");
        pos__ = 0;
        prior_scale_for_aux = vals_r__[pos__++];
        context__.validate_dims("data initialization", "prior_df_for_aux", "double", context__.to_vec());
        prior_df_for_aux = double(0);
        vals_r__ = context__.vals_r("prior_df_for_aux");
        pos__ = 0;
        prior_df_for_aux = vals_r__[pos__++];

        // validate, data variables
        check_greater_or_equal(function__,"N",N,0);
        check_greater_or_equal(function__,"K",K,0);
        check_greater_or_equal(function__,"family",family,1);
        check_less_or_equal(function__,"family",family,5);
        check_greater_or_equal(function__,"is_continuous",is_continuous,0);
        check_less_or_equal(function__,"is_continuous",is_continuous,1);
        check_greater_or_equal(function__,"has_aux",has_aux,0);
        check_less_or_equal(function__,"has_aux",has_aux,1);
        check_greater_or_equal(function__,"model_type",model_type,1);
        check_less_or_equal(function__,"model_type",model_type,3);
        check_greater_or_equal(function__,"has_intercept",has_intercept,0);
        check_less_or_equal(function__,"has_intercept",has_intercept,1);
        for (int k0__ = 0; k0__ < (logical_eq(family,4) ? N : 0 ); ++k0__) {
            check_greater_or_equal(function__,"trials[k0__]",trials[k0__],0);
        }
        check_greater_or_equal(function__,"order",order,1);
        check_less_or_equal(function__,"order",order,2);
        for (int k0__ = 0; k0__ < logical_eq(order,2); ++k0__) {
            check_greater_or_equal(function__,"Q_n[k0__]",Q_n[k0__],0);
        }
        check_greater_or_equal(function__,"prior_dist_rho",prior_dist_rho,0);
        check_less_or_equal(function__,"prior_dist_rho",prior_dist_rho,1);
        check_greater_or_equal(function__,"prior_scale_rho",prior_scale_rho,0);
        check_greater_or_equal(function__,"prior_df_rho",prior_df_rho,0);
        check_greater_or_equal(function__,"shape1_rho",shape1_rho,0);
        check_greater_or_equal(function__,"shape2_rho",shape2_rho,0);
        check_greater_or_equal(function__,"prior_dist_for_intercept",prior_dist_for_intercept,0);
        check_greater_or_equal(function__,"prior_dist",prior_dist,0);
        check_greater_or_equal(function__,"prior_dist_tau",prior_dist_tau,0);
        check_greater_or_equal(function__,"prior_scale_for_intercept",prior_scale_for_intercept,0);
        check_greater_or_equal(function__,"prior_df_for_intercept",prior_df_for_intercept,0);
        check_greater_or_equal(function__,"prior_scale",prior_scale,0);
        check_greater_or_equal(function__,"prior_df",prior_df,0);
        check_greater_or_equal(function__,"prior_scale_tau",prior_scale_tau,0);
        check_greater_or_equal(function__,"prior_df_tau",prior_df_tau,0);
        check_greater_or_equal(function__,"global_prior_df",global_prior_df,0);
        check_greater_or_equal(function__,"global_prior_scale",global_prior_scale,0);
        for (int k0__ = 0; k0__ < (logical_eq(prior_dist,7) ? K : 0 ); ++k0__) {
            check_greater_or_equal(function__,"num_normals[k0__]",num_normals[k0__],2);
        }
        check_greater_or_equal(function__,"prior_dist_for_aux",prior_dist_for_aux,0);
        check_less_or_equal(function__,"prior_dist_for_aux",prior_dist_for_aux,3);
        check_greater_or_equal(function__,"prior_mean_for_aux",prior_mean_for_aux,0);
        check_greater_or_equal(function__,"prior_scale_for_aux",prior_scale_for_aux,0);
        check_greater_or_equal(function__,"prior_df_for_aux",prior_df_for_aux,0);
        // initialize data variables
        poisson_max = double(0);
        stan::math::fill(poisson_max,DUMMY_VAR__);
        stan::math::assign(poisson_max,pow(2.0,30.0));
        hs = int(0);
        stan::math::fill(hs, std::numeric_limits<int>::min());
        sum_log_y = double(0);
        stan::math::fill(sum_log_y,DUMMY_VAR__);
        stan::math::assign(sum_log_y,(logical_eq(family,1) ? stan::math::not_a_number() : sum(log(y_real)) ));

        try {
            current_statement_begin__ = 724;
            if (as_bool(logical_lte(prior_dist,2))) {
                current_statement_begin__ = 724;
                stan::math::assign(hs, 0);
            } else if (as_bool(logical_eq(prior_dist,3))) {
                current_statement_begin__ = 725;
                stan::math::assign(hs, 2);
            } else if (as_bool(logical_eq(prior_dist,4))) {
                current_statement_begin__ = 726;
                stan::math::assign(hs, 4);
            } else {
                current_statement_begin__ = 727;
                stan::math::assign(hs, 0);
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        // validate transformed data
        check_greater_or_equal(function__,"hs",hs,0);

        // validate, set parameter ranges
        num_params_r__ = 0U;
        param_ranges_i__.clear();
        validate_non_negative_index("gamma", "has_intercept", has_intercept);
        num_params_r__ += has_intercept;
        validate_non_negative_index("z_beta", "K", K);
        num_params_r__ += K;
        validate_non_negative_index("theta_raw", "(logical_eq(model_type,1) ? 0 : N )", (logical_eq(model_type,1) ? 0 : N ));
        num_params_r__ += (logical_eq(model_type,1) ? 0 : N );
        validate_non_negative_index("phi_raw", "(N - 1)", (N - 1));
        num_params_r__ += (N - 1);
        validate_non_negative_index("rho", "logical_neq(model_type,1)", logical_neq(model_type,1));
        num_params_r__ += logical_neq(model_type,1);
        ++num_params_r__;
        validate_non_negative_index("global", "hs", hs);
        num_params_r__ += hs;
        validate_non_negative_index("local", "K", K);
        validate_non_negative_index("local", "hs", hs);
        num_params_r__ += K * hs;
        validate_non_negative_index("mix", "K", K);
        validate_non_negative_index("mix", "(primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6)))", (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))));
        num_params_r__ += K * (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6)));
        validate_non_negative_index("aux_unscaled", "has_aux", has_aux);
        num_params_r__ += has_aux;
        validate_non_negative_index("one_over_lambda", "logical_eq(prior_dist,6)", logical_eq(prior_dist,6));
        num_params_r__ += logical_eq(prior_dist,6);
    }

    ~model_spatial() { }


    void transform_inits(const stan::io::var_context& context__,
                         std::vector<int>& params_i__,
                         std::vector<double>& params_r__,
                         std::ostream* pstream__) const {
        stan::io::writer<double> writer__(params_r__,params_i__);
        size_t pos__;
        (void) pos__; // dummy call to supress warning
        std::vector<double> vals_r__;
        std::vector<int> vals_i__;

        if (!(context__.contains_r("gamma")))
            throw std::runtime_error("variable gamma missing");
        vals_r__ = context__.vals_r("gamma");
        pos__ = 0U;
        validate_non_negative_index("gamma", "has_intercept", has_intercept);
        context__.validate_dims("initialization", "gamma", "double", context__.to_vec(has_intercept));
        // generate_declaration gamma
        std::vector<double> gamma(has_intercept,double(0));
        for (int i0__ = 0U; i0__ < has_intercept; ++i0__)
            gamma[i0__] = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < has_intercept; ++i0__)
            try {
            writer__.scalar_lub_unconstrain(make_lower(family,link, pstream__),make_upper(family,link, pstream__),gamma[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable gamma: ") + e.what());
        }

        if (!(context__.contains_r("z_beta")))
            throw std::runtime_error("variable z_beta missing");
        vals_r__ = context__.vals_r("z_beta");
        pos__ = 0U;
        validate_non_negative_index("z_beta", "K", K);
        context__.validate_dims("initialization", "z_beta", "vector_d", context__.to_vec(K));
        // generate_declaration z_beta
        vector_d z_beta(static_cast<Eigen::VectorXd::Index>(K));
        for (int j1__ = 0U; j1__ < K; ++j1__)
            z_beta(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_unconstrain(z_beta);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable z_beta: ") + e.what());
        }

        if (!(context__.contains_r("theta_raw")))
            throw std::runtime_error("variable theta_raw missing");
        vals_r__ = context__.vals_r("theta_raw");
        pos__ = 0U;
        validate_non_negative_index("theta_raw", "(logical_eq(model_type,1) ? 0 : N )", (logical_eq(model_type,1) ? 0 : N ));
        context__.validate_dims("initialization", "theta_raw", "vector_d", context__.to_vec((logical_eq(model_type,1) ? 0 : N )));
        // generate_declaration theta_raw
        vector_d theta_raw(static_cast<Eigen::VectorXd::Index>((logical_eq(model_type,1) ? 0 : N )));
        for (int j1__ = 0U; j1__ < (logical_eq(model_type,1) ? 0 : N ); ++j1__)
            theta_raw(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_unconstrain(theta_raw);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable theta_raw: ") + e.what());
        }

        if (!(context__.contains_r("phi_raw")))
            throw std::runtime_error("variable phi_raw missing");
        vals_r__ = context__.vals_r("phi_raw");
        pos__ = 0U;
        validate_non_negative_index("phi_raw", "(N - 1)", (N - 1));
        context__.validate_dims("initialization", "phi_raw", "vector_d", context__.to_vec((N - 1)));
        // generate_declaration phi_raw
        vector_d phi_raw(static_cast<Eigen::VectorXd::Index>((N - 1)));
        for (int j1__ = 0U; j1__ < (N - 1); ++j1__)
            phi_raw(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_unconstrain(phi_raw);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable phi_raw: ") + e.what());
        }

        if (!(context__.contains_r("rho")))
            throw std::runtime_error("variable rho missing");
        vals_r__ = context__.vals_r("rho");
        pos__ = 0U;
        validate_non_negative_index("rho", "logical_neq(model_type,1)", logical_neq(model_type,1));
        context__.validate_dims("initialization", "rho", "double", context__.to_vec(logical_neq(model_type,1)));
        // generate_declaration rho
        std::vector<double> rho(logical_neq(model_type,1),double(0));
        for (int i0__ = 0U; i0__ < logical_neq(model_type,1); ++i0__)
            rho[i0__] = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < logical_neq(model_type,1); ++i0__)
            try {
            writer__.scalar_lub_unconstrain(0,(logical_eq(model_type,3) ? stan::math::promote_scalar<double>(1) : stan::math::promote_scalar<double>(stan::math::positive_infinity()) ),rho[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable rho: ") + e.what());
        }

        if (!(context__.contains_r("tau")))
            throw std::runtime_error("variable tau missing");
        vals_r__ = context__.vals_r("tau");
        pos__ = 0U;
        context__.validate_dims("initialization", "tau", "double", context__.to_vec());
        // generate_declaration tau
        double tau(0);
        tau = vals_r__[pos__++];
        try {
            writer__.scalar_lb_unconstrain(0,tau);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable tau: ") + e.what());
        }

        if (!(context__.contains_r("global")))
            throw std::runtime_error("variable global missing");
        vals_r__ = context__.vals_r("global");
        pos__ = 0U;
        validate_non_negative_index("global", "hs", hs);
        context__.validate_dims("initialization", "global", "double", context__.to_vec(hs));
        // generate_declaration global
        std::vector<double> global(hs,double(0));
        for (int i0__ = 0U; i0__ < hs; ++i0__)
            global[i0__] = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < hs; ++i0__)
            try {
            writer__.scalar_lb_unconstrain(0,global[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable global: ") + e.what());
        }

        if (!(context__.contains_r("local")))
            throw std::runtime_error("variable local missing");
        vals_r__ = context__.vals_r("local");
        pos__ = 0U;
        validate_non_negative_index("local", "hs", hs);
        validate_non_negative_index("local", "K", K);
        context__.validate_dims("initialization", "local", "vector_d", context__.to_vec(hs,K));
        // generate_declaration local
        std::vector<vector_d> local(hs,vector_d(static_cast<Eigen::VectorXd::Index>(K)));
        for (int j1__ = 0U; j1__ < K; ++j1__)
            for (int i0__ = 0U; i0__ < hs; ++i0__)
                local[i0__](j1__) = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < hs; ++i0__)
            try {
            writer__.vector_lb_unconstrain(0,local[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable local: ") + e.what());
        }

        if (!(context__.contains_r("mix")))
            throw std::runtime_error("variable mix missing");
        vals_r__ = context__.vals_r("mix");
        pos__ = 0U;
        validate_non_negative_index("mix", "(primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6)))", (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))));
        validate_non_negative_index("mix", "K", K);
        context__.validate_dims("initialization", "mix", "vector_d", context__.to_vec((primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))),K));
        // generate_declaration mix
        std::vector<vector_d> mix((primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))),vector_d(static_cast<Eigen::VectorXd::Index>(K)));
        for (int j1__ = 0U; j1__ < K; ++j1__)
            for (int i0__ = 0U; i0__ < (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))); ++i0__)
                mix[i0__](j1__) = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))); ++i0__)
            try {
            writer__.vector_lb_unconstrain(0,mix[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable mix: ") + e.what());
        }

        if (!(context__.contains_r("aux_unscaled")))
            throw std::runtime_error("variable aux_unscaled missing");
        vals_r__ = context__.vals_r("aux_unscaled");
        pos__ = 0U;
        validate_non_negative_index("aux_unscaled", "has_aux", has_aux);
        context__.validate_dims("initialization", "aux_unscaled", "double", context__.to_vec(has_aux));
        // generate_declaration aux_unscaled
        std::vector<double> aux_unscaled(has_aux,double(0));
        for (int i0__ = 0U; i0__ < has_aux; ++i0__)
            aux_unscaled[i0__] = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < has_aux; ++i0__)
            try {
            writer__.scalar_lb_unconstrain(0,aux_unscaled[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable aux_unscaled: ") + e.what());
        }

        if (!(context__.contains_r("one_over_lambda")))
            throw std::runtime_error("variable one_over_lambda missing");
        vals_r__ = context__.vals_r("one_over_lambda");
        pos__ = 0U;
        validate_non_negative_index("one_over_lambda", "logical_eq(prior_dist,6)", logical_eq(prior_dist,6));
        context__.validate_dims("initialization", "one_over_lambda", "double", context__.to_vec(logical_eq(prior_dist,6)));
        // generate_declaration one_over_lambda
        std::vector<double> one_over_lambda(logical_eq(prior_dist,6),double(0));
        for (int i0__ = 0U; i0__ < logical_eq(prior_dist,6); ++i0__)
            one_over_lambda[i0__] = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < logical_eq(prior_dist,6); ++i0__)
            try {
            writer__.scalar_lb_unconstrain(0,one_over_lambda[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable one_over_lambda: ") + e.what());
        }

        params_r__ = writer__.data_r();
        params_i__ = writer__.data_i();
    }

    void transform_inits(const stan::io::var_context& context,
                         Eigen::Matrix<double,Eigen::Dynamic,1>& params_r,
                         std::ostream* pstream__) const {
      std::vector<double> params_r_vec;
      std::vector<int> params_i_vec;
      transform_inits(context, params_i_vec, params_r_vec, pstream__);
      params_r.resize(params_r_vec.size());
      for (int i = 0; i < params_r.size(); ++i)
        params_r(i) = params_r_vec[i];
    }


    template <bool propto__, bool jacobian__, typename T__>
    T__ log_prob(vector<T__>& params_r__,
                 vector<int>& params_i__,
                 std::ostream* pstream__ = 0) const {

        T__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

        T__ lp__(0.0);
        stan::math::accumulator<T__> lp_accum__;

        // model parameters
        stan::io::reader<T__> in__(params_r__,params_i__);

        vector<T__> gamma;
        size_t dim_gamma_0__ = has_intercept;
        gamma.reserve(dim_gamma_0__);
        for (size_t k_0__ = 0; k_0__ < dim_gamma_0__; ++k_0__) {
            if (jacobian__)
                gamma.push_back(in__.scalar_lub_constrain(make_lower(family,link, pstream__),make_upper(family,link, pstream__),lp__));
            else
                gamma.push_back(in__.scalar_lub_constrain(make_lower(family,link, pstream__),make_upper(family,link, pstream__)));
        }

        Eigen::Matrix<T__,Eigen::Dynamic,1>  z_beta;
        (void) z_beta;  // dummy to suppress unused var warning
        if (jacobian__)
            z_beta = in__.vector_constrain(K,lp__);
        else
            z_beta = in__.vector_constrain(K);

        Eigen::Matrix<T__,Eigen::Dynamic,1>  theta_raw;
        (void) theta_raw;  // dummy to suppress unused var warning
        if (jacobian__)
            theta_raw = in__.vector_constrain((logical_eq(model_type,1) ? 0 : N ),lp__);
        else
            theta_raw = in__.vector_constrain((logical_eq(model_type,1) ? 0 : N ));

        Eigen::Matrix<T__,Eigen::Dynamic,1>  phi_raw;
        (void) phi_raw;  // dummy to suppress unused var warning
        if (jacobian__)
            phi_raw = in__.vector_constrain((N - 1),lp__);
        else
            phi_raw = in__.vector_constrain((N - 1));

        vector<T__> rho;
        size_t dim_rho_0__ = logical_neq(model_type,1);
        rho.reserve(dim_rho_0__);
        for (size_t k_0__ = 0; k_0__ < dim_rho_0__; ++k_0__) {
            if (jacobian__)
                rho.push_back(in__.scalar_lub_constrain(0,(logical_eq(model_type,3) ? stan::math::promote_scalar<double>(1) : stan::math::promote_scalar<double>(stan::math::positive_infinity()) ),lp__));
            else
                rho.push_back(in__.scalar_lub_constrain(0,(logical_eq(model_type,3) ? stan::math::promote_scalar<double>(1) : stan::math::promote_scalar<double>(stan::math::positive_infinity()) )));
        }

        T__ tau;
        (void) tau;  // dummy to suppress unused var warning
        if (jacobian__)
            tau = in__.scalar_lb_constrain(0,lp__);
        else
            tau = in__.scalar_lb_constrain(0);

        vector<T__> global;
        size_t dim_global_0__ = hs;
        global.reserve(dim_global_0__);
        for (size_t k_0__ = 0; k_0__ < dim_global_0__; ++k_0__) {
            if (jacobian__)
                global.push_back(in__.scalar_lb_constrain(0,lp__));
            else
                global.push_back(in__.scalar_lb_constrain(0));
        }

        vector<Eigen::Matrix<T__,Eigen::Dynamic,1> > local;
        size_t dim_local_0__ = hs;
        local.reserve(dim_local_0__);
        for (size_t k_0__ = 0; k_0__ < dim_local_0__; ++k_0__) {
            if (jacobian__)
                local.push_back(in__.vector_lb_constrain(0,K,lp__));
            else
                local.push_back(in__.vector_lb_constrain(0,K));
        }

        vector<Eigen::Matrix<T__,Eigen::Dynamic,1> > mix;
        size_t dim_mix_0__ = (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6)));
        mix.reserve(dim_mix_0__);
        for (size_t k_0__ = 0; k_0__ < dim_mix_0__; ++k_0__) {
            if (jacobian__)
                mix.push_back(in__.vector_lb_constrain(0,K,lp__));
            else
                mix.push_back(in__.vector_lb_constrain(0,K));
        }

        vector<T__> aux_unscaled;
        size_t dim_aux_unscaled_0__ = has_aux;
        aux_unscaled.reserve(dim_aux_unscaled_0__);
        for (size_t k_0__ = 0; k_0__ < dim_aux_unscaled_0__; ++k_0__) {
            if (jacobian__)
                aux_unscaled.push_back(in__.scalar_lb_constrain(0,lp__));
            else
                aux_unscaled.push_back(in__.scalar_lb_constrain(0));
        }

        vector<T__> one_over_lambda;
        size_t dim_one_over_lambda_0__ = logical_eq(prior_dist,6);
        one_over_lambda.reserve(dim_one_over_lambda_0__);
        for (size_t k_0__ = 0; k_0__ < dim_one_over_lambda_0__; ++k_0__) {
            if (jacobian__)
                one_over_lambda.push_back(in__.scalar_lb_constrain(0,lp__));
            else
                one_over_lambda.push_back(in__.scalar_lb_constrain(0));
        }


        // transformed parameters
        validate_non_negative_index("beta", "K", K);
        Eigen::Matrix<T__,Eigen::Dynamic,1>  beta(static_cast<Eigen::VectorXd::Index>(K));
        (void) beta;  // dummy to suppress unused var warning

        stan::math::initialize(beta, DUMMY_VAR__);
        stan::math::fill(beta,DUMMY_VAR__);
        T__ aux;
        (void) aux;  // dummy to suppress unused var warning

        stan::math::initialize(aux, DUMMY_VAR__);
        stan::math::fill(aux,DUMMY_VAR__);
        stan::math::assign(aux,(logical_eq(has_aux,0) ? stan::math::promote_scalar<T__>(0) : stan::math::promote_scalar<T__>((logical_eq(prior_dist_for_aux,0) ? stan::math::promote_scalar<T__>(get_base1(aux_unscaled,1,"aux_unscaled",1)) : stan::math::promote_scalar<T__>((logical_lte(prior_dist_for_aux,2) ? stan::math::promote_scalar<T__>(((prior_scale_for_aux * get_base1(aux_unscaled,1,"aux_unscaled",1)) + prior_mean_for_aux)) : stan::math::promote_scalar<T__>((prior_scale_for_aux * get_base1(aux_unscaled,1,"aux_unscaled",1))) )) )) ));
        validate_non_negative_index("phi", "N", N);
        Eigen::Matrix<T__,Eigen::Dynamic,1>  phi(static_cast<Eigen::VectorXd::Index>(N));
        (void) phi;  // dummy to suppress unused var warning

        stan::math::initialize(phi, DUMMY_VAR__);
        stan::math::fill(phi,DUMMY_VAR__);
        validate_non_negative_index("psi", "N", N);
        Eigen::Matrix<T__,Eigen::Dynamic,1>  psi(static_cast<Eigen::VectorXd::Index>(N));
        (void) psi;  // dummy to suppress unused var warning

        stan::math::initialize(psi, DUMMY_VAR__);
        stan::math::fill(psi,DUMMY_VAR__);


        try {
            current_statement_begin__ = 751;
            stan::model::assign(phi, 
                        stan::model::cons_list(stan::model::index_min_max(1, (N - 1)), stan::model::nil_index_list()), 
                        phi_raw, 
                        "assigning variable phi");
            current_statement_begin__ = 752;
            stan::math::assign(get_base1_lhs(phi,N,"phi",1), -(sum(phi_raw)));
            current_statement_begin__ = 761;
            if (as_bool(logical_eq(model_type,1))) {
                current_statement_begin__ = 762;
                stan::math::assign(psi, multiply(phi,tau));
            } else if (as_bool(logical_eq(model_type,2))) {
                current_statement_begin__ = 764;
                stan::math::assign(psi, add(multiply(phi,get_base1(rho,1,"rho",1)),multiply(theta_raw,tau)));
            } else if (as_bool(logical_eq(model_type,3))) {
                current_statement_begin__ = 766;
                stan::math::assign(psi, multiply(tau,add(multiply(sqrt((1 - get_base1(rho,1,"rho",1))),theta_raw),multiply(sqrt((get_base1(rho,1,"rho",1) / scaling_factor)),phi))));
            }
            current_statement_begin__ = 769;
            if (as_bool(logical_eq(prior_dist,0))) {
                current_statement_begin__ = 769;
                stan::math::assign(beta, z_beta);
            } else if (as_bool(logical_eq(prior_dist,1))) {
                current_statement_begin__ = 770;
                stan::math::assign(beta, add(elt_multiply(z_beta,prior_scale),prior_mean));
            } else if (as_bool(logical_eq(prior_dist,2))) {
                current_statement_begin__ = 771;
                for (int k = 1; k <= K; ++k) {

                    current_statement_begin__ = 772;
                    stan::math::assign(get_base1_lhs(beta,k,"beta",1), ((CFt(get_base1(z_beta,k,"z_beta",1),get_base1(prior_df,k,"prior_df",1), pstream__) * get_base1(prior_scale,k,"prior_scale",1)) + get_base1(prior_mean,k,"prior_mean",1)));
                }
            } else if (as_bool(logical_eq(prior_dist,3))) {

                current_statement_begin__ = 775;
                if (as_bool((primitive_value(logical_eq(is_continuous,1)) && primitive_value(logical_eq(family,1))))) {
                    current_statement_begin__ = 776;
                    stan::math::assign(beta, hs_prior(z_beta,global,local,global_prior_scale,aux, pstream__));
                } else {
                    current_statement_begin__ = 777;
                    stan::math::assign(beta, hs_prior(z_beta,global,local,global_prior_scale,1, pstream__));
                }
            } else if (as_bool(logical_eq(prior_dist,4))) {

                current_statement_begin__ = 780;
                if (as_bool((primitive_value(logical_eq(is_continuous,1)) && primitive_value(logical_eq(family,1))))) {
                    current_statement_begin__ = 781;
                    stan::math::assign(beta, hsplus_prior(z_beta,global,local,global_prior_scale,aux, pstream__));
                } else {
                    current_statement_begin__ = 782;
                    stan::math::assign(beta, hsplus_prior(z_beta,global,local,global_prior_scale,1, pstream__));
                }
            } else if (as_bool(logical_eq(prior_dist,5))) {
                current_statement_begin__ = 785;
                stan::math::assign(beta, add(prior_mean,elt_multiply(elt_multiply(prior_scale,sqrt(multiply(2,get_base1(mix,1,"mix",1)))),z_beta)));
            } else if (as_bool(logical_eq(prior_dist,6))) {
                current_statement_begin__ = 787;
                stan::math::assign(beta, add(prior_mean,elt_multiply(elt_multiply(multiply(get_base1(one_over_lambda,1,"one_over_lambda",1),prior_scale),sqrt(multiply(2,get_base1(mix,1,"mix",1)))),z_beta)));
            } else if (as_bool(logical_eq(prior_dist,7))) {
                {
                    int z_pos(0);
                    (void) z_pos;  // dummy to suppress unused var warning

                    stan::math::fill(z_pos, std::numeric_limits<int>::min());
                    stan::math::assign(z_pos,1);


                    current_statement_begin__ = 790;
                    for (int k = 1; k <= K; ++k) {

                        current_statement_begin__ = 791;
                        stan::math::assign(get_base1_lhs(beta,k,"beta",1), get_base1(z_beta,z_pos,"z_beta",1));
                        current_statement_begin__ = 792;
                        stan::math::assign(z_pos, (z_pos + 1));
                        current_statement_begin__ = 793;
                        for (int n = 2; n <= get_base1(num_normals,k,"num_normals",1); ++n) {

                            current_statement_begin__ = 794;
                            stan::math::assign(get_base1_lhs(beta,k,"beta",1), (get_base1(beta,k,"beta",1) * get_base1(z_beta,z_pos,"z_beta",1)));
                            current_statement_begin__ = 795;
                            stan::math::assign(z_pos, (z_pos + 1));
                        }
                        current_statement_begin__ = 797;
                        stan::math::assign(get_base1_lhs(beta,k,"beta",1), ((get_base1(beta,k,"beta",1) * pow(get_base1(prior_scale,k,"prior_scale",1),get_base1(num_normals,k,"num_normals",1))) + get_base1(prior_mean,k,"prior_mean",1)));
                    }
                }
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        // validate transformed parameters
        for (int i0__ = 0; i0__ < K; ++i0__) {
            if (stan::math::is_uninitialized(beta(i0__))) {
                std::stringstream msg__;
                msg__ << "Undefined transformed parameter: beta" << '[' << i0__ << ']';
                throw std::runtime_error(msg__.str());
            }
        }
        if (stan::math::is_uninitialized(aux)) {
            std::stringstream msg__;
            msg__ << "Undefined transformed parameter: aux";
            throw std::runtime_error(msg__.str());
        }
        for (int i0__ = 0; i0__ < N; ++i0__) {
            if (stan::math::is_uninitialized(phi(i0__))) {
                std::stringstream msg__;
                msg__ << "Undefined transformed parameter: phi" << '[' << i0__ << ']';
                throw std::runtime_error(msg__.str());
            }
        }
        for (int i0__ = 0; i0__ < N; ++i0__) {
            if (stan::math::is_uninitialized(psi(i0__))) {
                std::stringstream msg__;
                msg__ << "Undefined transformed parameter: psi" << '[' << i0__ << ']';
                throw std::runtime_error(msg__.str());
            }
        }

        const char* function__ = "validate transformed params";
        (void) function__;  // dummy to suppress unused var warning

        // model body
        try {
            {
                validate_non_negative_index("eta", "N", N);
                Eigen::Matrix<T__,Eigen::Dynamic,1>  eta(static_cast<Eigen::VectorXd::Index>(N));
                (void) eta;  // dummy to suppress unused var warning

                stan::math::initialize(eta, DUMMY_VAR__);
                stan::math::fill(eta,DUMMY_VAR__);


                current_statement_begin__ = 804;
                if (as_bool(logical_eq(has_intercept,1))) {
                    current_statement_begin__ = 805;
                    stan::math::assign(eta, add(add(get_base1(gamma,1,"gamma",1),multiply(X,beta)),psi));
                } else {
                    current_statement_begin__ = 807;
                    stan::math::assign(eta, add(multiply(X,beta),psi));
                }
                current_statement_begin__ = 809;
                if (as_bool(logical_eq(family,1))) {

                    current_statement_begin__ = 810;
                    stan::math::assign(eta, linkinv_gauss(eta,link, pstream__));
                    current_statement_begin__ = 811;
                    lp_accum__.add(normal_log(y_real,eta,aux));
                } else if (as_bool(logical_eq(family,2))) {

                    current_statement_begin__ = 814;
                    stan::math::assign(eta, linkinv_count(eta,link, pstream__));
                    current_statement_begin__ = 815;
                    lp_accum__.add(poisson_log(y_int,eta));
                } else if (as_bool(logical_eq(family,3))) {

                    current_statement_begin__ = 818;
                    stan::math::assign(eta, linkinv_count(eta,link, pstream__));
                    current_statement_begin__ = 819;
                    lp_accum__.add(neg_binomial_2_log(y_int,eta,aux));
                } else if (as_bool(logical_eq(family,4))) {

                    current_statement_begin__ = 822;
                    stan::math::assign(eta, linkinv_binom(eta,link, pstream__));
                    current_statement_begin__ = 823;
                    lp_accum__.add(binomial_log(y_int,trials,eta));
                } else if (as_bool(logical_eq(family,5))) {

                    current_statement_begin__ = 826;
                    lp_accum__.add(GammaReg(y_real,eta,aux,link,sum_log_y, pstream__));
                }
                current_statement_begin__ = 829;
                if (as_bool(logical_eq(order,1))) {
                    current_statement_begin__ = 830;
                    lp_accum__.add((-(0.5) * dot_self(subtract(stan::model::rvalue(phi, stan::model::cons_list(stan::model::index_multi(stan::model::rvalue(edges, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list())), "edges")), stan::model::nil_index_list()), "phi"),stan::model::rvalue(phi, stan::model::cons_list(stan::model::index_multi(stan::model::rvalue(edges, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(2), stan::model::nil_index_list())), "edges")), stan::model::nil_index_list()), "phi")))));
                } else if (as_bool(logical_eq(order,2))) {
                    current_statement_begin__ = 832;
                    lp_accum__.add((-(0.5) * dot_product(phi,csr_matrix_times_vector(N,N,w,v,u,phi))));
                }
                current_statement_begin__ = 836;
                if (as_bool(logical_eq(prior_dist,1))) {
                    current_statement_begin__ = 836;
                    lp_accum__.add(normal_log(z_beta,0,1));
                } else if (as_bool(logical_eq(prior_dist,2))) {
                    current_statement_begin__ = 837;
                    lp_accum__.add(normal_log(z_beta,0,1));
                } else if (as_bool(logical_eq(prior_dist,3))) {
                    {
                        T__ log_half;
                        (void) log_half;  // dummy to suppress unused var warning

                        stan::math::initialize(log_half, DUMMY_VAR__);
                        stan::math::fill(log_half,DUMMY_VAR__);
                        stan::math::assign(log_half,-(0.6931471805599454));


                        current_statement_begin__ = 840;
                        lp_accum__.add(normal_log(z_beta,0,1));
                        current_statement_begin__ = 841;
                        lp_accum__.add((normal_log(get_base1(local,1,"local",1),0,1) - log_half));
                        current_statement_begin__ = 842;
                        lp_accum__.add(inv_gamma_log(get_base1(local,2,"local",1),multiply(0.5,prior_df),multiply(0.5,prior_df)));
                        current_statement_begin__ = 843;
                        lp_accum__.add((normal_log(get_base1(global,1,"global",1),0,1) - log_half));
                        current_statement_begin__ = 844;
                        lp_accum__.add(inv_gamma_log(get_base1(global,2,"global",1),(0.5 * global_prior_df),(0.5 * global_prior_df)));
                    }
                } else if (as_bool(logical_eq(prior_dist,4))) {
                    {
                        T__ log_half;
                        (void) log_half;  // dummy to suppress unused var warning

                        stan::math::initialize(log_half, DUMMY_VAR__);
                        stan::math::fill(log_half,DUMMY_VAR__);
                        stan::math::assign(log_half,-(0.6931471805599454));


                        current_statement_begin__ = 848;
                        lp_accum__.add(normal_log(z_beta,0,1));
                        current_statement_begin__ = 849;
                        lp_accum__.add((normal_log(get_base1(local,1,"local",1),0,1) - log_half));
                        current_statement_begin__ = 850;
                        lp_accum__.add(inv_gamma_log(get_base1(local,2,"local",1),multiply(0.5,prior_df),multiply(0.5,prior_df)));
                        current_statement_begin__ = 851;
                        lp_accum__.add((normal_log(get_base1(local,3,"local",1),0,1) - log_half));
                        current_statement_begin__ = 853;
                        lp_accum__.add(inv_gamma_log(get_base1(local,4,"local",1),multiply(0.5,prior_scale),multiply(0.5,prior_scale)));
                        current_statement_begin__ = 854;
                        lp_accum__.add((normal_log(get_base1(global,1,"global",1),0,1) - log_half));
                        current_statement_begin__ = 855;
                        lp_accum__.add(inv_gamma_log(get_base1(global,2,"global",1),(0.5 * global_prior_df),(0.5 * global_prior_df)));
                    }
                } else if (as_bool(logical_eq(prior_dist,5))) {

                    current_statement_begin__ = 858;
                    lp_accum__.add(normal_log(z_beta,0,1));
                    current_statement_begin__ = 859;
                    lp_accum__.add(exponential_log(get_base1(mix,1,"mix",1),1));
                } else if (as_bool(logical_eq(prior_dist,6))) {

                    current_statement_begin__ = 862;
                    lp_accum__.add(normal_log(z_beta,0,1));
                    current_statement_begin__ = 863;
                    lp_accum__.add(exponential_log(get_base1(mix,1,"mix",1),1));
                    current_statement_begin__ = 864;
                    lp_accum__.add(chi_square_log(get_base1(one_over_lambda,1,"one_over_lambda",1),get_base1(prior_df,1,"prior_df",1)));
                } else if (as_bool(logical_eq(prior_dist,7))) {

                    current_statement_begin__ = 867;
                    lp_accum__.add(normal_log(z_beta,0,1));
                }
                current_statement_begin__ = 872;
                if (as_bool(logical_eq(has_intercept,1))) {

                    current_statement_begin__ = 873;
                    if (as_bool(logical_eq(prior_dist_for_intercept,1))) {
                        current_statement_begin__ = 874;
                        lp_accum__.add(normal_log(gamma,prior_mean_for_intercept,prior_scale_for_intercept));
                    } else if (as_bool(logical_eq(prior_dist_for_intercept,2))) {
                        current_statement_begin__ = 876;
                        lp_accum__.add(student_t_log(gamma,prior_df_for_intercept,prior_mean_for_intercept,prior_scale_for_intercept));
                    }
                }
                current_statement_begin__ = 881;
                if (as_bool(logical_eq(model_type,2))) {

                    current_statement_begin__ = 882;
                    lp_accum__.add(normal_log(theta_raw,0,1));
                    current_statement_begin__ = 884;
                    if (as_bool(logical_eq(prior_dist_rho,1))) {
                        current_statement_begin__ = 885;
                        lp_accum__.add(normal_log(get_base1(rho,1,"rho",1),prior_mean_rho,prior_scale_rho));
                    } else if (as_bool(logical_eq(prior_dist_rho,2))) {
                        current_statement_begin__ = 887;
                        lp_accum__.add(student_t_log(get_base1(rho,1,"rho",1),prior_df_rho,prior_mean_rho,prior_scale_rho));
                    } else if (as_bool(logical_eq(prior_dist_rho,3))) {
                        current_statement_begin__ = 889;
                        lp_accum__.add(exponential_log(get_base1(rho,1,"rho",1),prior_scale_rho));
                    }
                } else if (as_bool(logical_eq(model_type,3))) {

                    current_statement_begin__ = 893;
                    lp_accum__.add(normal_log(theta_raw,0,1));
                    current_statement_begin__ = 894;
                    if (as_bool(logical_eq(prior_dist_rho,1))) {
                        current_statement_begin__ = 895;
                        lp_accum__.add(beta_log(get_base1(rho,1,"rho",1),shape1_rho,shape2_rho));
                    }
                }
                current_statement_begin__ = 899;
                if (as_bool(logical_eq(prior_dist_tau,1))) {
                    current_statement_begin__ = 900;
                    lp_accum__.add(normal_log(tau,prior_mean_tau,prior_scale_tau));
                } else if (as_bool(logical_eq(prior_dist_tau,2))) {
                    current_statement_begin__ = 902;
                    lp_accum__.add(student_t_log(tau,prior_df_tau,prior_mean_tau,prior_scale_tau));
                } else if (as_bool(logical_eq(prior_dist_tau,3))) {
                    current_statement_begin__ = 904;
                    lp_accum__.add(exponential_log(tau,prior_scale_tau));
                }
                current_statement_begin__ = 907;
                if (as_bool(logical_eq(has_aux,1))) {

                    current_statement_begin__ = 910;
                    if (as_bool((primitive_value(logical_gt(prior_dist_for_aux,0)) && primitive_value(logical_gt(prior_scale_for_aux,0))))) {
                        {
                            T__ log_half;
                            (void) log_half;  // dummy to suppress unused var warning

                            stan::math::initialize(log_half, DUMMY_VAR__);
                            stan::math::fill(log_half,DUMMY_VAR__);
                            stan::math::assign(log_half,-(0.6931471805599454));


                            current_statement_begin__ = 912;
                            if (as_bool(logical_eq(prior_dist_for_aux,1))) {
                                current_statement_begin__ = 913;
                                lp_accum__.add((normal_log(aux_unscaled,0,1) - log_half));
                            } else if (as_bool(logical_eq(prior_dist_for_aux,2))) {
                                current_statement_begin__ = 915;
                                lp_accum__.add((student_t_log(aux_unscaled,prior_df_for_aux,0,1) - log_half));
                            } else {
                                current_statement_begin__ = 917;
                                lp_accum__.add(exponential_log(aux_unscaled,1));
                            }
                        }
                    }
                }
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        lp_accum__.add(lp__);
        return lp_accum__.sum();

    } // log_prob()

    template <bool propto, bool jacobian, typename T_>
    T_ log_prob(Eigen::Matrix<T_,Eigen::Dynamic,1>& params_r,
               std::ostream* pstream = 0) const {
      std::vector<T_> vec_params_r;
      vec_params_r.reserve(params_r.size());
      for (int i = 0; i < params_r.size(); ++i)
        vec_params_r.push_back(params_r(i));
      std::vector<int> vec_params_i;
      return log_prob<propto,jacobian,T_>(vec_params_r, vec_params_i, pstream);
    }


    void get_param_names(std::vector<std::string>& names__) const {
        names__.resize(0);
        names__.push_back("gamma");
        names__.push_back("z_beta");
        names__.push_back("theta_raw");
        names__.push_back("phi_raw");
        names__.push_back("rho");
        names__.push_back("tau");
        names__.push_back("global");
        names__.push_back("local");
        names__.push_back("mix");
        names__.push_back("aux_unscaled");
        names__.push_back("one_over_lambda");
        names__.push_back("beta");
        names__.push_back("aux");
        names__.push_back("phi");
        names__.push_back("psi");
        names__.push_back("mean_PPD");
        names__.push_back("alpha");
    }


    void get_dims(std::vector<std::vector<size_t> >& dimss__) const {
        dimss__.resize(0);
        std::vector<size_t> dims__;
        dims__.resize(0);
        dims__.push_back(has_intercept);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((logical_eq(model_type,1) ? 0 : N ));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((N - 1));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(logical_neq(model_type,1));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(hs);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(hs);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))));
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(has_aux);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(logical_eq(prior_dist,6));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(N);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(N);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(has_intercept);
        dimss__.push_back(dims__);
    }

    template <typename RNG>
    void write_array(RNG& base_rng__,
                     std::vector<double>& params_r__,
                     std::vector<int>& params_i__,
                     std::vector<double>& vars__,
                     bool include_tparams__ = true,
                     bool include_gqs__ = true,
                     std::ostream* pstream__ = 0) const {
        vars__.resize(0);
        stan::io::reader<double> in__(params_r__,params_i__);
        static const char* function__ = "model_spatial_namespace::write_array";
        (void) function__;  // dummy to suppress unused var warning
        // read-transform, write parameters
        vector<double> gamma;
        size_t dim_gamma_0__ = has_intercept;
        for (size_t k_0__ = 0; k_0__ < dim_gamma_0__; ++k_0__) {
            gamma.push_back(in__.scalar_lub_constrain(make_lower(family,link, pstream__),make_upper(family,link, pstream__)));
        }
        vector_d z_beta = in__.vector_constrain(K);
        vector_d theta_raw = in__.vector_constrain((logical_eq(model_type,1) ? 0 : N ));
        vector_d phi_raw = in__.vector_constrain((N - 1));
        vector<double> rho;
        size_t dim_rho_0__ = logical_neq(model_type,1);
        for (size_t k_0__ = 0; k_0__ < dim_rho_0__; ++k_0__) {
            rho.push_back(in__.scalar_lub_constrain(0,(logical_eq(model_type,3) ? stan::math::promote_scalar<double>(1) : stan::math::promote_scalar<double>(stan::math::positive_infinity()) )));
        }
        double tau = in__.scalar_lb_constrain(0);
        vector<double> global;
        size_t dim_global_0__ = hs;
        for (size_t k_0__ = 0; k_0__ < dim_global_0__; ++k_0__) {
            global.push_back(in__.scalar_lb_constrain(0));
        }
        vector<vector_d> local;
        size_t dim_local_0__ = hs;
        for (size_t k_0__ = 0; k_0__ < dim_local_0__; ++k_0__) {
            local.push_back(in__.vector_lb_constrain(0,K));
        }
        vector<vector_d> mix;
        size_t dim_mix_0__ = (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6)));
        for (size_t k_0__ = 0; k_0__ < dim_mix_0__; ++k_0__) {
            mix.push_back(in__.vector_lb_constrain(0,K));
        }
        vector<double> aux_unscaled;
        size_t dim_aux_unscaled_0__ = has_aux;
        for (size_t k_0__ = 0; k_0__ < dim_aux_unscaled_0__; ++k_0__) {
            aux_unscaled.push_back(in__.scalar_lb_constrain(0));
        }
        vector<double> one_over_lambda;
        size_t dim_one_over_lambda_0__ = logical_eq(prior_dist,6);
        for (size_t k_0__ = 0; k_0__ < dim_one_over_lambda_0__; ++k_0__) {
            one_over_lambda.push_back(in__.scalar_lb_constrain(0));
        }
        for (int k_0__ = 0; k_0__ < has_intercept; ++k_0__) {
            vars__.push_back(gamma[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < K; ++k_0__) {
            vars__.push_back(z_beta[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < (logical_eq(model_type,1) ? 0 : N ); ++k_0__) {
            vars__.push_back(theta_raw[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < (N - 1); ++k_0__) {
            vars__.push_back(phi_raw[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < logical_neq(model_type,1); ++k_0__) {
            vars__.push_back(rho[k_0__]);
        }
        vars__.push_back(tau);
        for (int k_0__ = 0; k_0__ < hs; ++k_0__) {
            vars__.push_back(global[k_0__]);
        }
        for (int k_1__ = 0; k_1__ < K; ++k_1__) {
            for (int k_0__ = 0; k_0__ < hs; ++k_0__) {
                vars__.push_back(local[k_0__][k_1__]);
            }
        }
        for (int k_1__ = 0; k_1__ < K; ++k_1__) {
            for (int k_0__ = 0; k_0__ < (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))); ++k_0__) {
                vars__.push_back(mix[k_0__][k_1__]);
            }
        }
        for (int k_0__ = 0; k_0__ < has_aux; ++k_0__) {
            vars__.push_back(aux_unscaled[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < logical_eq(prior_dist,6); ++k_0__) {
            vars__.push_back(one_over_lambda[k_0__]);
        }

        if (!include_tparams__) return;
        // declare and define transformed parameters
        double lp__ = 0.0;
        (void) lp__;  // dummy to suppress unused var warning
        stan::math::accumulator<double> lp_accum__;

        double DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

        validate_non_negative_index("beta", "K", K);
        vector_d beta(static_cast<Eigen::VectorXd::Index>(K));
        (void) beta;  // dummy to suppress unused var warning

        stan::math::initialize(beta, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(beta,DUMMY_VAR__);
        double aux(0.0);
        (void) aux;  // dummy to suppress unused var warning

        stan::math::initialize(aux, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(aux,DUMMY_VAR__);
        stan::math::assign(aux,(logical_eq(has_aux,0) ? stan::math::promote_scalar<double>(0) : stan::math::promote_scalar<double>((logical_eq(prior_dist_for_aux,0) ? stan::math::promote_scalar<double>(get_base1(aux_unscaled,1,"aux_unscaled",1)) : stan::math::promote_scalar<double>((logical_lte(prior_dist_for_aux,2) ? stan::math::promote_scalar<double>(((prior_scale_for_aux * get_base1(aux_unscaled,1,"aux_unscaled",1)) + prior_mean_for_aux)) : stan::math::promote_scalar<double>((prior_scale_for_aux * get_base1(aux_unscaled,1,"aux_unscaled",1))) )) )) ));
        validate_non_negative_index("phi", "N", N);
        vector_d phi(static_cast<Eigen::VectorXd::Index>(N));
        (void) phi;  // dummy to suppress unused var warning

        stan::math::initialize(phi, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(phi,DUMMY_VAR__);
        validate_non_negative_index("psi", "N", N);
        vector_d psi(static_cast<Eigen::VectorXd::Index>(N));
        (void) psi;  // dummy to suppress unused var warning

        stan::math::initialize(psi, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(psi,DUMMY_VAR__);


        try {
            current_statement_begin__ = 751;
            stan::model::assign(phi, 
                        stan::model::cons_list(stan::model::index_min_max(1, (N - 1)), stan::model::nil_index_list()), 
                        phi_raw, 
                        "assigning variable phi");
            current_statement_begin__ = 752;
            stan::math::assign(get_base1_lhs(phi,N,"phi",1), -(sum(phi_raw)));
            current_statement_begin__ = 761;
            if (as_bool(logical_eq(model_type,1))) {
                current_statement_begin__ = 762;
                stan::math::assign(psi, multiply(phi,tau));
            } else if (as_bool(logical_eq(model_type,2))) {
                current_statement_begin__ = 764;
                stan::math::assign(psi, add(multiply(phi,get_base1(rho,1,"rho",1)),multiply(theta_raw,tau)));
            } else if (as_bool(logical_eq(model_type,3))) {
                current_statement_begin__ = 766;
                stan::math::assign(psi, multiply(tau,add(multiply(sqrt((1 - get_base1(rho,1,"rho",1))),theta_raw),multiply(sqrt((get_base1(rho,1,"rho",1) / scaling_factor)),phi))));
            }
            current_statement_begin__ = 769;
            if (as_bool(logical_eq(prior_dist,0))) {
                current_statement_begin__ = 769;
                stan::math::assign(beta, z_beta);
            } else if (as_bool(logical_eq(prior_dist,1))) {
                current_statement_begin__ = 770;
                stan::math::assign(beta, add(elt_multiply(z_beta,prior_scale),prior_mean));
            } else if (as_bool(logical_eq(prior_dist,2))) {
                current_statement_begin__ = 771;
                for (int k = 1; k <= K; ++k) {

                    current_statement_begin__ = 772;
                    stan::math::assign(get_base1_lhs(beta,k,"beta",1), ((CFt(get_base1(z_beta,k,"z_beta",1),get_base1(prior_df,k,"prior_df",1), pstream__) * get_base1(prior_scale,k,"prior_scale",1)) + get_base1(prior_mean,k,"prior_mean",1)));
                }
            } else if (as_bool(logical_eq(prior_dist,3))) {

                current_statement_begin__ = 775;
                if (as_bool((primitive_value(logical_eq(is_continuous,1)) && primitive_value(logical_eq(family,1))))) {
                    current_statement_begin__ = 776;
                    stan::math::assign(beta, hs_prior(z_beta,global,local,global_prior_scale,aux, pstream__));
                } else {
                    current_statement_begin__ = 777;
                    stan::math::assign(beta, hs_prior(z_beta,global,local,global_prior_scale,1, pstream__));
                }
            } else if (as_bool(logical_eq(prior_dist,4))) {

                current_statement_begin__ = 780;
                if (as_bool((primitive_value(logical_eq(is_continuous,1)) && primitive_value(logical_eq(family,1))))) {
                    current_statement_begin__ = 781;
                    stan::math::assign(beta, hsplus_prior(z_beta,global,local,global_prior_scale,aux, pstream__));
                } else {
                    current_statement_begin__ = 782;
                    stan::math::assign(beta, hsplus_prior(z_beta,global,local,global_prior_scale,1, pstream__));
                }
            } else if (as_bool(logical_eq(prior_dist,5))) {
                current_statement_begin__ = 785;
                stan::math::assign(beta, add(prior_mean,elt_multiply(elt_multiply(prior_scale,sqrt(multiply(2,get_base1(mix,1,"mix",1)))),z_beta)));
            } else if (as_bool(logical_eq(prior_dist,6))) {
                current_statement_begin__ = 787;
                stan::math::assign(beta, add(prior_mean,elt_multiply(elt_multiply(multiply(get_base1(one_over_lambda,1,"one_over_lambda",1),prior_scale),sqrt(multiply(2,get_base1(mix,1,"mix",1)))),z_beta)));
            } else if (as_bool(logical_eq(prior_dist,7))) {
                {
                    int z_pos(0);
                    (void) z_pos;  // dummy to suppress unused var warning

                    stan::math::fill(z_pos, std::numeric_limits<int>::min());
                    stan::math::assign(z_pos,1);


                    current_statement_begin__ = 790;
                    for (int k = 1; k <= K; ++k) {

                        current_statement_begin__ = 791;
                        stan::math::assign(get_base1_lhs(beta,k,"beta",1), get_base1(z_beta,z_pos,"z_beta",1));
                        current_statement_begin__ = 792;
                        stan::math::assign(z_pos, (z_pos + 1));
                        current_statement_begin__ = 793;
                        for (int n = 2; n <= get_base1(num_normals,k,"num_normals",1); ++n) {

                            current_statement_begin__ = 794;
                            stan::math::assign(get_base1_lhs(beta,k,"beta",1), (get_base1(beta,k,"beta",1) * get_base1(z_beta,z_pos,"z_beta",1)));
                            current_statement_begin__ = 795;
                            stan::math::assign(z_pos, (z_pos + 1));
                        }
                        current_statement_begin__ = 797;
                        stan::math::assign(get_base1_lhs(beta,k,"beta",1), ((get_base1(beta,k,"beta",1) * pow(get_base1(prior_scale,k,"prior_scale",1),get_base1(num_normals,k,"num_normals",1))) + get_base1(prior_mean,k,"prior_mean",1)));
                    }
                }
            }
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        // validate transformed parameters

        // write transformed parameters
        for (int k_0__ = 0; k_0__ < K; ++k_0__) {
            vars__.push_back(beta[k_0__]);
        }
        vars__.push_back(aux);
        for (int k_0__ = 0; k_0__ < N; ++k_0__) {
            vars__.push_back(phi[k_0__]);
        }
        for (int k_0__ = 0; k_0__ < N; ++k_0__) {
            vars__.push_back(psi[k_0__]);
        }

        if (!include_gqs__) return;
        // declare and define generated quantities
        double mean_PPD(0.0);
        (void) mean_PPD;  // dummy to suppress unused var warning

        stan::math::initialize(mean_PPD, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(mean_PPD,DUMMY_VAR__);
        stan::math::assign(mean_PPD,0);
        validate_non_negative_index("alpha", "has_intercept", has_intercept);
        vector<double> alpha(has_intercept, 0.0);
        stan::math::initialize(alpha, std::numeric_limits<double>::quiet_NaN());
        stan::math::fill(alpha,DUMMY_VAR__);


        try {
            current_statement_begin__ = 924;
            if (as_bool(has_intercept)) {
                current_statement_begin__ = 925;
                stan::math::assign(get_base1_lhs(alpha,1,"alpha",1), (get_base1(gamma,1,"gamma",1) - dot_product(beta,xbar)));
            }
            {
                validate_non_negative_index("eta", "N", N);
                vector_d eta(static_cast<Eigen::VectorXd::Index>(N));
                (void) eta;  // dummy to suppress unused var warning

                stan::math::initialize(eta, std::numeric_limits<double>::quiet_NaN());
                stan::math::fill(eta,DUMMY_VAR__);


                current_statement_begin__ = 928;
                if (as_bool(logical_eq(has_intercept,1))) {

                    current_statement_begin__ = 929;
                    stan::math::assign(eta, add(add(get_base1(alpha,1,"alpha",1),multiply(X,beta)),psi));
                } else {

                    current_statement_begin__ = 932;
                    stan::math::assign(eta, add(multiply(X,beta),psi));
                }
                current_statement_begin__ = 934;
                if (as_bool(logical_eq(family,1))) {

                    current_statement_begin__ = 935;
                    stan::math::assign(eta, linkinv_gauss(eta,link, pstream__));
                    current_statement_begin__ = 936;
                    for (int n = 1; n <= N; ++n) {
                        current_statement_begin__ = 936;
                        stan::math::assign(mean_PPD, (mean_PPD + normal_rng(get_base1(eta,n,"eta",1),aux, base_rng__)));
                    }
                } else if (as_bool(logical_eq(family,2))) {

                    current_statement_begin__ = 939;
                    stan::math::assign(eta, linkinv_count(eta,link, pstream__));
                    current_statement_begin__ = 940;
                    for (int n = 1; n <= N; ++n) {

                        current_statement_begin__ = 941;
                        if (as_bool(logical_lt(get_base1(eta,n,"eta",1),poisson_max))) {
                            current_statement_begin__ = 942;
                            stan::math::assign(mean_PPD, (mean_PPD + poisson_rng(get_base1(eta,n,"eta",1), base_rng__)));
                        } else {
                            current_statement_begin__ = 944;
                            stan::math::assign(mean_PPD, (mean_PPD + normal_rng(get_base1(eta,n,"eta",1),sqrt(get_base1(eta,n,"eta",1)), base_rng__)));
                        }
                    }
                } else if (as_bool(logical_eq(family,3))) {

                    current_statement_begin__ = 948;
                    stan::math::assign(eta, linkinv_count(eta,link, pstream__));
                    current_statement_begin__ = 949;
                    for (int n = 1; n <= N; ++n) {
                        {
                            double gamma_temp(0.0);
                            (void) gamma_temp;  // dummy to suppress unused var warning

                            stan::math::initialize(gamma_temp, std::numeric_limits<double>::quiet_NaN());
                            stan::math::fill(gamma_temp,DUMMY_VAR__);


                            current_statement_begin__ = 951;
                            if (as_bool(is_inf(aux))) {
                                current_statement_begin__ = 951;
                                stan::math::assign(gamma_temp, get_base1(eta,n,"eta",1));
                            } else {
                                current_statement_begin__ = 952;
                                stan::math::assign(gamma_temp, gamma_rng(aux,(aux / get_base1(eta,n,"eta",1)), base_rng__));
                            }
                            current_statement_begin__ = 953;
                            if (as_bool(logical_lt(gamma_temp,poisson_max))) {
                                current_statement_begin__ = 954;
                                stan::math::assign(mean_PPD, (mean_PPD + poisson_rng(gamma_temp, base_rng__)));
                            } else {
                                current_statement_begin__ = 955;
                                stan::math::assign(mean_PPD, (mean_PPD + normal_rng(gamma_temp,sqrt(gamma_temp), base_rng__)));
                            }
                        }
                    }
                } else if (as_bool(logical_eq(family,4))) {

                    current_statement_begin__ = 959;
                    stan::math::assign(eta, linkinv_binom(eta,link, pstream__));
                    current_statement_begin__ = 960;
                    for (int n = 1; n <= N; ++n) {
                        current_statement_begin__ = 960;
                        stan::math::assign(mean_PPD, (mean_PPD + binomial_rng(get_base1(trials,n,"trials",1),inv_logit(get_base1(eta,n,"eta",1)), base_rng__)));
                    }
                } else if (as_bool(logical_eq(family,5))) {

                    current_statement_begin__ = 963;
                    if (as_bool(logical_gt(link,1))) {
                        current_statement_begin__ = 963;
                        stan::math::assign(eta, linkinv_gamma(eta,link, pstream__));
                    }
                    current_statement_begin__ = 964;
                    for (int n = 1; n <= N; ++n) {
                        current_statement_begin__ = 964;
                        stan::math::assign(mean_PPD, (mean_PPD + gamma_rng(aux,(aux / get_base1(eta,n,"eta",1)), base_rng__)));
                    }
                }
            }
            current_statement_begin__ = 967;
            stan::math::assign(mean_PPD, (mean_PPD / N));
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        // validate generated quantities

        // write generated quantities
        vars__.push_back(mean_PPD);
        for (int k_0__ = 0; k_0__ < has_intercept; ++k_0__) {
            vars__.push_back(alpha[k_0__]);
        }

    }

    template <typename RNG>
    void write_array(RNG& base_rng,
                     Eigen::Matrix<double,Eigen::Dynamic,1>& params_r,
                     Eigen::Matrix<double,Eigen::Dynamic,1>& vars,
                     bool include_tparams = true,
                     bool include_gqs = true,
                     std::ostream* pstream = 0) const {
      std::vector<double> params_r_vec(params_r.size());
      for (int i = 0; i < params_r.size(); ++i)
        params_r_vec[i] = params_r(i);
      std::vector<double> vars_vec;
      std::vector<int> params_i_vec;
      write_array(base_rng,params_r_vec,params_i_vec,vars_vec,include_tparams,include_gqs,pstream);
      vars.resize(vars_vec.size());
      for (int i = 0; i < vars.size(); ++i)
        vars(i) = vars_vec[i];
    }

    static std::string model_name() {
        return "model_spatial";
    }


    void constrained_param_names(std::vector<std::string>& param_names__,
                                 bool include_tparams__ = true,
                                 bool include_gqs__ = true) const {
        std::stringstream param_name_stream__;
        for (int k_0__ = 1; k_0__ <= has_intercept; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "gamma" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= K; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_beta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (logical_eq(model_type,1) ? 0 : N ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "theta_raw" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (N - 1); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "phi_raw" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= logical_neq(model_type,1); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "rho" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        param_name_stream__.str(std::string());
        param_name_stream__ << "tau";
        param_names__.push_back(param_name_stream__.str());
        for (int k_0__ = 1; k_0__ <= hs; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "global" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_1__ = 1; k_1__ <= K; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= hs; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "local" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        for (int k_1__ = 1; k_1__ <= K; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))); ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "mix" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        for (int k_0__ = 1; k_0__ <= has_aux; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "aux_unscaled" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= logical_eq(prior_dist,6); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "one_over_lambda" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__ && !include_tparams__) return;
        for (int k_0__ = 1; k_0__ <= K; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "beta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        param_name_stream__.str(std::string());
        param_name_stream__ << "aux";
        param_names__.push_back(param_name_stream__.str());
        for (int k_0__ = 1; k_0__ <= N; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "phi" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= N; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "psi" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__) return;
        param_name_stream__.str(std::string());
        param_name_stream__ << "mean_PPD";
        param_names__.push_back(param_name_stream__.str());
        for (int k_0__ = 1; k_0__ <= has_intercept; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "alpha" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
    }


    void unconstrained_param_names(std::vector<std::string>& param_names__,
                                   bool include_tparams__ = true,
                                   bool include_gqs__ = true) const {
        std::stringstream param_name_stream__;
        for (int k_0__ = 1; k_0__ <= has_intercept; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "gamma" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= K; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_beta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (logical_eq(model_type,1) ? 0 : N ); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "theta_raw" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= (N - 1); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "phi_raw" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= logical_neq(model_type,1); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "rho" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        param_name_stream__.str(std::string());
        param_name_stream__ << "tau";
        param_names__.push_back(param_name_stream__.str());
        for (int k_0__ = 1; k_0__ <= hs; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "global" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_1__ = 1; k_1__ <= K; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= hs; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "local" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        for (int k_1__ = 1; k_1__ <= K; ++k_1__) {
            for (int k_0__ = 1; k_0__ <= (primitive_value(logical_eq(prior_dist,5)) || primitive_value(logical_eq(prior_dist,6))); ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "mix" << '.' << k_0__ << '.' << k_1__;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        for (int k_0__ = 1; k_0__ <= has_aux; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "aux_unscaled" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= logical_eq(prior_dist,6); ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "one_over_lambda" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__ && !include_tparams__) return;
        for (int k_0__ = 1; k_0__ <= K; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "beta" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        param_name_stream__.str(std::string());
        param_name_stream__ << "aux";
        param_names__.push_back(param_name_stream__.str());
        for (int k_0__ = 1; k_0__ <= N; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "phi" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= N; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "psi" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__) return;
        param_name_stream__.str(std::string());
        param_name_stream__ << "mean_PPD";
        param_names__.push_back(param_name_stream__.str());
        for (int k_0__ = 1; k_0__ <= has_intercept; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "alpha" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
    }

}; // model

}




#endif
