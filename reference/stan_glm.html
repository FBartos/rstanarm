<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Bayesian generalized linear models via Stan — stan_glm • rstanarm</title>

<!-- favicons -->
<link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png" />
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png" />
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png" />
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png" />

<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
<!-- Bootstrap -->
<link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous" />


<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/all.min.css" integrity="sha256-nAmazAk6vS34Xqo0BSrTb+abbtFlgsFK7NKSi6o7Y78=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/v4-shims.min.css" integrity="sha256-6qHlizsOWFskGlwVOKuns+D1nB6ssZrHQrNj1wGplHc=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script>

<!-- headroom.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/headroom.min.js" integrity="sha256-DJFC1kqIhelURkuza0AvYal5RxMtpzLjFhsnVIeuk+U=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>




<meta property="og:title" content="Bayesian generalized linear models via Stan — stan_glm" />
<meta property="og:description" content="
Generalized linear modeling with optional prior distributions for the
coefficients, intercept, and auxiliary parameters." />
<meta property="og:image" content="https://mc-stan.org/rstanarm/logo.png" />
<meta name="twitter:card" content="summary" />




<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->



  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">rstanarm</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">2.19.2</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../articles/index.html">Vignettes</a>
</li>
<li>
  <a href="../reference/index.html">Functions</a>
</li>
<li>
  <a href="../dev-notes/index.html">Develop</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Other Packages
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="https://mc-stan.org/rstan">rstan</a>
    </li>
    <li>
      <a href="https://mc-stan.org/bayesplot">bayesplot</a>
    </li>
    <li>
      <a href="https://mc-stan.org/shinystan">shinystan</a>
    </li>
    <li>
      <a href="https://mc-stan.org/loo">loo</a>
    </li>
    <li>
      <a href="https://mc-stan.org/projpred">projpred</a>
    </li>
    <li>
      <a href="https://mc-stan.org/rstantools">rstantools</a>
    </li>
  </ul>
</li>
<li>
  <a href="https://mc-stan.org">Stan</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://twitter.com/mcmc_stan">
    <span class="fa fa-twitter"></span>
     
  </a>
</li>
<li>
  <a href="https://github.com/stan-dev/rstanarm">
    <span class="fa fa-github"></span>
     
  </a>
</li>
<li>
  <a href="https://discourse.mc-stan.org/">
    <span class="fa fa-users"></span>
     
  </a>
</li>
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Bayesian generalized linear models via Stan</h1>
    
    <div class="hidden name"><code>stan_glm.Rd</code></div>
    </div>

    <div class="ref-description">
    <p><img src='figures/stanlogo.png' width="25px" alt="http://mc-stan.org/about/logo/" />
Generalized linear modeling with optional prior distributions for the
coefficients, intercept, and auxiliary parameters.</p>
    </div>

    <pre class="usage"><span class='fu'>stan_glm</span>(<span class='no'>formula</span>, <span class='kw'>family</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/stats/family.html'>gaussian</a></span>(), <span class='no'>data</span>, <span class='no'>weights</span>, <span class='no'>subset</span>,
  <span class='kw'>na.action</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>offset</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>model</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>, <span class='kw'>x</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>,
  <span class='kw'>y</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>, <span class='kw'>contrasts</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='no'>...</span>, <span class='kw'>prior</span> <span class='kw'>=</span> <span class='fu'><a href='priors.html'>normal</a></span>(),
  <span class='kw'>prior_intercept</span> <span class='kw'>=</span> <span class='fu'><a href='priors.html'>normal</a></span>(), <span class='kw'>prior_aux</span> <span class='kw'>=</span> <span class='fu'><a href='priors.html'>exponential</a></span>(),
  <span class='kw'>prior_PD</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>algorithm</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='st'>"sampling"</span>, <span class='st'>"optimizing"</span>,
  <span class='st'>"meanfield"</span>, <span class='st'>"fullrank"</span>), <span class='kw'>mean_PPD</span> <span class='kw'>=</span> <span class='no'>algorithm</span> <span class='kw'>!=</span> <span class='st'>"optimizing"</span>,
  <span class='kw'>adapt_delta</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>QR</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>sparse</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)

<span class='fu'>stan_glm.nb</span>(<span class='no'>formula</span>, <span class='no'>data</span>, <span class='no'>weights</span>, <span class='no'>subset</span>, <span class='kw'>na.action</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>offset</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>model</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>, <span class='kw'>x</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>y</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>,
  <span class='kw'>contrasts</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>link</span> <span class='kw'>=</span> <span class='st'>"log"</span>, <span class='no'>...</span>, <span class='kw'>prior</span> <span class='kw'>=</span> <span class='fu'><a href='priors.html'>normal</a></span>(),
  <span class='kw'>prior_intercept</span> <span class='kw'>=</span> <span class='fu'><a href='priors.html'>normal</a></span>(), <span class='kw'>prior_aux</span> <span class='kw'>=</span> <span class='fu'><a href='priors.html'>exponential</a></span>(),
  <span class='kw'>prior_PD</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>algorithm</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='st'>"sampling"</span>, <span class='st'>"optimizing"</span>,
  <span class='st'>"meanfield"</span>, <span class='st'>"fullrank"</span>), <span class='kw'>mean_PPD</span> <span class='kw'>=</span> <span class='no'>algorithm</span> <span class='kw'>!=</span> <span class='st'>"optimizing"</span>,
  <span class='kw'>adapt_delta</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>QR</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)

<span class='fu'>stan_glm.fit</span>(<span class='no'>x</span>, <span class='no'>y</span>, <span class='kw'>weights</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/rep.html'>rep</a></span>(<span class='fl'>1</span>, <span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>NROW</a></span>(<span class='no'>y</span>)), <span class='kw'>offset</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/rep.html'>rep</a></span>(<span class='fl'>0</span>, <span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>NROW</a></span>(<span class='no'>y</span>)),
  <span class='kw'>family</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/stats/family.html'>gaussian</a></span>(), <span class='no'>...</span>, <span class='kw'>prior</span> <span class='kw'>=</span> <span class='fu'><a href='priors.html'>normal</a></span>(),
  <span class='kw'>prior_intercept</span> <span class='kw'>=</span> <span class='fu'><a href='priors.html'>normal</a></span>(), <span class='kw'>prior_aux</span> <span class='kw'>=</span> <span class='fu'><a href='priors.html'>exponential</a></span>(),
  <span class='kw'>prior_smooth</span> <span class='kw'>=</span> <span class='fu'><a href='priors.html'>exponential</a></span>(<span class='kw'>autoscale</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>), <span class='kw'>prior_ops</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>group</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span>(), <span class='kw'>prior_PD</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>algorithm</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='st'>"sampling"</span>,
  <span class='st'>"optimizing"</span>, <span class='st'>"meanfield"</span>, <span class='st'>"fullrank"</span>), <span class='kw'>mean_PPD</span> <span class='kw'>=</span> <span class='no'>algorithm</span> <span class='kw'>!=</span>
  <span class='st'>"optimizing"</span>, <span class='kw'>adapt_delta</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>QR</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>sparse</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>,
  <span class='kw'>importance_resampling</span> <span class='kw'>=</span> <span class='no'>algorithm</span> <span class='kw'>!=</span> <span class='st'>"sampling"</span>,
  <span class='kw'>keep_every</span> <span class='kw'>=</span> <span class='no'>algorithm</span> <span class='kw'>!=</span> <span class='st'>"sampling"</span>)</pre>

    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>formula, data, subset</th>
      <td><p>Same as <code><a href='https://rdrr.io/r/stats/glm.html'>glm</a></code>, 
but <em>we strongly advise against omitting the <code>data</code>
argument</em>. Unless <code>data</code> is specified (and is a data frame) many
post-estimation functions (including <code>update</code>, <code>loo</code>,
<code>kfold</code>) are not guaranteed to work properly.</p></td>
    </tr>
    <tr>
      <th>family</th>
      <td><p>Same as <code><a href='https://rdrr.io/r/stats/glm.html'>glm</a></code>, except negative binomial GLMs
are also possible using the <code><a href='neg_binomial_2.html'>neg_binomial_2</a></code> family object.</p></td>
    </tr>
    <tr>
      <th>na.action, contrasts</th>
      <td><p>Same as <code><a href='https://rdrr.io/r/stats/glm.html'>glm</a></code>, but
rarely specified.</p></td>
    </tr>
    <tr>
      <th>model, offset, weights</th>
      <td><p>Same as <code><a href='https://rdrr.io/r/stats/glm.html'>glm</a></code>.</p></td>
    </tr>
    <tr>
      <th>x</th>
      <td><p>In <code>stan_glm</code>, logical scalar indicating whether to
return the design matrix. In <code>stan_glm.fit</code>, usually a design matrix
but can also be a list of design matrices with the same number of rows, in
which case the first element of the list is interpreted as the primary design
matrix and the remaining list elements collectively constitute a basis for a
smooth nonlinear function of the predictors indicated by the <code>formula</code>
argument to <code><a href='stan_gamm4.html'>stan_gamm4</a></code>.</p></td>
    </tr>
    <tr>
      <th>y</th>
      <td><p>In <code>stan_glm</code>, logical scalar indicating whether to
return the response vector. In <code>stan_glm.fit</code>, a response vector.</p></td>
    </tr>
    <tr>
      <th>...</th>
      <td><p>Further arguments passed to the function in the <span class="pkg">rstan</span> 
package (<code><a href='https://rdrr.io/pkg/rstan/man/stanmodel-method-sampling.html'>sampling</a></code>, <code><a href='https://rdrr.io/pkg/rstan/man/stanmodel-method-vb.html'>vb</a></code>, or 
<code><a href='https://rdrr.io/pkg/rstan/man/stanmodel-method-optimizing.html'>optimizing</a></code>), corresponding to the estimation method 
named by <code>algorithm</code>. For example, if <code>algorithm</code> is
<code>"sampling"</code> it is possibly to specify <code>iter</code>, <code>chains</code>,
<code>cores</code>, <code>refresh</code>, etc.</p></td>
    </tr>
    <tr>
      <th>prior</th>
      <td><p>The prior distribution for the regression coefficients. 
<code>prior</code> should be a call to one of the various functions provided by 
<span class="pkg">rstanarm</span> for specifying priors. The subset of these functions that 
can be used for the prior on the coefficients can be grouped into several 
"families":</p>
<table class='table'>
<tr><td><strong>Family</strong></td><td><strong>Functions</strong></td></tr>
<tr><td><em>Student t family</em></td><td><code>normal</code>, <code>student_t</code>, <code>cauchy</code></td></tr>
<tr><td><em>Hierarchical shrinkage family</em></td><td><code>hs</code>, <code>hs_plus</code></td></tr>
<tr><td><em>Laplace family</em></td><td><code>laplace</code>, <code>lasso</code></td></tr>
<tr><td><em>Product normal family</em></td><td><code>product_normal</code></td></tr>
</table>


<p>See the <a href='priors.html'>priors help page</a> for details on the families and 
how to specify the arguments for all of the functions in the table above.
To omit a prior ---i.e., to use a flat (improper) uniform prior---
<code>prior</code> can be set to <code>NULL</code>, although this is rarely a good
idea.</p>
<p><strong>Note:</strong> Unless <code>QR=TRUE</code>, if <code>prior</code> is from the Student t
family or Laplace family, and if the <code>autoscale</code> argument to the 
function used to specify the prior (e.g. <code><a href='priors.html'>normal</a></code>) is left at 
its default and recommended value of <code>TRUE</code>, then the default or 
user-specified prior scale(s) may be adjusted internally based on the
scales of the predictors. See the <a href='priors.html'>priors help page</a> and the
<em>Prior Distributions</em> vignette for details on the rescaling and the
<code><a href='prior_summary.stanreg.html'>prior_summary</a></code> function for a summary of the priors used for a
particular model.</p></td>
    </tr>
    <tr>
      <th>prior_intercept</th>
      <td><p>The prior distribution for the intercept. 
<code>prior_intercept</code> can be a call to <code>normal</code>, <code>student_t</code> or 
<code>cauchy</code>. See the <a href='priors.html'>priors help page</a> for details on 
these functions. To omit a prior on the intercept ---i.e., to use a flat
(improper) uniform prior--- <code>prior_intercept</code> can be set to
<code>NULL</code>.</p>
<p><strong>Note:</strong> If using a dense representation of the design matrix
---i.e., if the <code>sparse</code> argument is left at its default value of
<code>FALSE</code>--- then the prior distribution for the intercept is set so it
applies to the value <em>when all predictors are centered</em>. If you prefer
to specify a prior on the intercept without the predictors being
auto-centered, then you have to omit the intercept from the
<code><a href='https://rdrr.io/r/stats/formula.html'>formula</a></code> and include a column of ones as a predictor,
in which case some element of <code>prior</code> specifies the prior on it,
rather than <code>prior_intercept</code>. Regardless of how
<code>prior_intercept</code> is specified, the reported <em>estimates</em> of the
intercept always correspond to a parameterization without centered
predictors (i.e., same as in <code>glm</code>).</p></td>
    </tr>
    <tr>
      <th>prior_aux</th>
      <td><p>The prior distribution for the "auxiliary" parameter (if
applicable). The "auxiliary" parameter refers to a different parameter 
depending on the <code>family</code>. For Gaussian models <code>prior_aux</code> 
controls <code>"sigma"</code>, the error 
standard deviation. For negative binomial models <code>prior_aux</code> controls 
<code>"reciprocal_dispersion"</code>, which is similar to the 
<code>"size"</code> parameter of <code><a href='https://rdrr.io/r/stats/NegBinomial.html'>rnbinom</a></code>:
smaller values of <code>"reciprocal_dispersion"</code> correspond to 
greater dispersion. For gamma models <code>prior_aux</code> sets the prior on 
to the <code>"shape"</code> parameter (see e.g., 
<code><a href='https://rdrr.io/r/stats/GammaDist.html'>rgamma</a></code>), and for inverse-Gaussian models it is the 
so-called <code>"lambda"</code> parameter (which is essentially the reciprocal of
a scale parameter). Binomial and Poisson models do not have auxiliary 
parameters.</p>
<p><code>prior_aux</code> can be a call to <code>exponential</code> to 
use an exponential distribution, or <code>normal</code>, <code>student_t</code> or 
<code>cauchy</code>, which results in a half-normal, half-t, or half-Cauchy 
prior. See <code><a href='priors.html'>priors</a></code> for details on these functions. To omit a 
prior ---i.e., to use a flat (improper) uniform prior--- set 
<code>prior_aux</code> to <code>NULL</code>.</p></td>
    </tr>
    <tr>
      <th>prior_PD</th>
      <td><p>A logical scalar (defaulting to <code>FALSE</code>) indicating
whether to draw from the prior predictive distribution instead of
conditioning on the outcome.</p></td>
    </tr>
    <tr>
      <th>algorithm</th>
      <td><p>A string (possibly abbreviated) indicating the 
estimation approach to use. Can be <code>"sampling"</code> for MCMC (the
default), <code>"optimizing"</code> for optimization, <code>"meanfield"</code> for
variational inference with independent normal distributions, or
<code>"fullrank"</code> for variational inference with a multivariate normal
distribution. See <code><a href='rstanarm-package.html'>rstanarm-package</a></code> for more details on the
estimation algorithms. NOTE: not all fitting functions support all four
algorithms.</p></td>
    </tr>
    <tr>
      <th>mean_PPD</th>
      <td><p>A logical value indicating whether the sample mean of the
posterior predictive distribution of the outcome should be calculated in
the <code>generated quantities</code> block. If <code>TRUE</code> then <code>mean_PPD</code>
is computed and displayed as a diagnostic in the
<a href='print.stanreg.html'>printed output</a>. The default is <code>TRUE</code> except if
<code>algorithm=="optimizing"</code>. A useful heuristic is to check if
<code>mean_PPD</code> is plausible when compared to <code><a href='https://rdrr.io/r/base/mean.html'>mean(y)</a></code>. If it is
plausible then this does <em>not</em> mean that the model is good in general
(only that it can reproduce the sample mean), but if <code>mean_PPD</code> is
implausible then there may be something wrong, e.g., severe model
misspecification, problems with the data and/or priors, computational
issues, etc.</p></td>
    </tr>
    <tr>
      <th>adapt_delta</th>
      <td><p>Only relevant if <code>algorithm="sampling"</code>. See 
the <a href='adapt_delta.html'>adapt_delta</a> help page for details.</p></td>
    </tr>
    <tr>
      <th>QR</th>
      <td><p>A logical scalar defaulting to <code>FALSE</code>, but if <code>TRUE</code>
applies a scaled <code><a href='https://rdrr.io/r/base/qr.html'>qr</a></code> decomposition to the design matrix. The
transformation does not change the likelihood of the data but is
recommended for computational reasons when there are multiple predictors.
See the <a href='QR-argument.html'>QR-argument</a> documentation page for details on how
<span class="pkg">rstanarm</span> does the transformation and important information about how
to interpret the prior distributions of the model parameters when using
<code>QR=TRUE</code>.</p></td>
    </tr>
    <tr>
      <th>sparse</th>
      <td><p>A logical scalar (defaulting to <code>FALSE</code>) indicating
whether to use a sparse representation of the design (X) matrix. 
If <code>TRUE</code>, the the design matrix is not centered (since that would 
destroy the sparsity) and likewise it is not possible to specify both 
<code>QR = TRUE</code> and <code>sparse = TRUE</code>. Depending on how many zeros
there are in the design matrix, setting <code>sparse = TRUE</code> may make
the code run faster and can consume much less RAM.</p></td>
    </tr>
    <tr>
      <th>link</th>
      <td><p>For <code>stan_glm.nb</code> only, the link function to use. See 
<code><a href='neg_binomial_2.html'>neg_binomial_2</a></code>.</p></td>
    </tr>
    <tr>
      <th>prior_smooth</th>
      <td><p>The prior distribution for the hyperparameters in GAMs,
with lower values yielding less flexible smooth functions.</p> 
<p><code>prior_smooth</code> can be a call to <code>exponential</code> to 
use an exponential distribution, or <code>normal</code>, <code>student_t</code> or 
<code>cauchy</code>, which results in a half-normal, half-t, or half-Cauchy 
prior. See <code><a href='priors.html'>priors</a></code> for details on these functions. To omit a 
prior ---i.e., to use a flat (improper) uniform prior--- set 
<code>prior_smooth</code> to <code>NULL</code>. The number of hyperparameters depends
on the model specification but a scalar prior will be recylced as necessary
to the appropriate length.</p></td>
    </tr>
    <tr>
      <th>prior_ops</th>
      <td><p>Deprecated. See <a href='rstanarm-deprecated.html'>rstanarm-deprecated</a> for details.</p></td>
    </tr>
    <tr>
      <th>group</th>
      <td><p>A list, possibly of length zero (the default), but otherwise
having the structure of that produced by <code><a href='https://rdrr.io/pkg/lme4/man/mkReTrms.html'>mkReTrms</a></code> to
indicate the group-specific part of the model. In addition, this list must
have elements for the <code>regularization</code>, <code>concentration</code> 
<code>shape</code>, and <code>scale</code> components of a <code><a href='priors.html'>decov</a></code>
prior for the covariance matrices among the group-specific coefficients.</p></td>
    </tr>
    <tr>
      <th>importance_resampling</th>
      <td><p>Logical scalar indicating whether to use 
importance resampling when approximating the posterior distribution with
a multivariate normal around the posterior mode, which only applies
when <code>algorithm</code> is <code>"optimizing"</code> but defaults to <code>TRUE</code>
in that case</p></td>
    </tr>
    <tr>
      <th>keep_every</th>
      <td><p>Positive integer, which defaults to 1, but can be higher
in order to "thin" the importance sampling realizations. Applies only
when <code>importance_resampling=TRUE</code>.</p></td>
    </tr>
    </table>

    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>A <a href='stanreg-objects.html'>stanreg</a> object is returned 
for <code>stan_glm, stan_glm.nb</code>.</p>
<p>A stanfit object (or a slightly modified 
  stanfit object) is returned if <code>stan_glm.fit</code> is called directly.</p>
    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p>The <code>stan_glm</code> function is similar in syntax to 
  <code><a href='https://rdrr.io/r/stats/glm.html'>glm</a></code> but rather than performing maximum likelihood 
  estimation of generalized linear models, full Bayesian estimation is 
  performed (if <code>algorithm</code> is <code>"sampling"</code>) via MCMC. The Bayesian
  model adds priors (independent by default) on the coefficients of the GLM.
  The <code>stan_glm</code> function calls the workhorse <code>stan_glm.fit</code>
  function, but it is also possible to call the latter directly.</p>  
<p>The <code>stan_glm.nb</code> function, which takes the extra argument 
  <code>link</code>, is a wrapper for <code>stan_glm</code> with <code>family = 
  <a href='neg_binomial_2.html'>neg_binomial_2</a>(link)</code>.</p>
    <h2 class="hasAnchor" id="references"><a class="anchor" href="#references"></a>References</h2>

    <p>Gelman, A. and Hill, J. (2007). <em>Data Analysis Using
  Regression and Multilevel/Hierarchical Models.</em> Cambridge University Press,
  Cambridge, UK. (Ch. 3-6)</p>
<p>Muth, C., Oravecz, Z., and Gabry, J. (2018)
User-friendly Bayesian regression modeling: A tutorial with rstanarm and shinystan.
<em>The Quantitative Methods for Psychology</em>. 14(2), 99--119.
<a href='https://www.tqmp.org/RegularArticles/vol14-2/p099/p099.pdf'>https://www.tqmp.org/RegularArticles/vol14-2/p099/p099.pdf</a></p>
    <h2 class="hasAnchor" id="see-also"><a class="anchor" href="#see-also"></a>See also</h2>

    <div class='dont-index'><p><code><a href='stanreg-methods.html'>stanreg-methods</a></code> and 
<code><a href='https://rdrr.io/r/stats/glm.html'>glm</a></code>.</p>
<p>The various vignettes for <code>stan_glm</code> at
  <a href='http://mc-stan.org/rstanarm/articles/'>http://mc-stan.org/rstanarm/articles/</a>.</p></div>

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='kw'>if</span> (!<span class='fu'><a href='https://rdrr.io/r/base/grep.html'>grepl</a></span>(<span class='st'>"^sparc"</span>,  <span class='no'>R.version</span>$<span class='no'>platform</span>)) {
<span class='co'>### Linear regression</span>
<span class='no'>mtcars</span>$<span class='no'>mpg10</span> <span class='kw'>&lt;-</span> <span class='no'>mtcars</span>$<span class='no'>mpg</span> / <span class='fl'>10</span>
<span class='no'>fit</span> <span class='kw'>&lt;-</span> <span class='fu'>stan_glm</span>(
  <span class='no'>mpg10</span> ~ <span class='no'>wt</span> + <span class='no'>cyl</span> + <span class='no'>am</span>,
  <span class='kw'>data</span> <span class='kw'>=</span> <span class='no'>mtcars</span>,
  <span class='kw'>QR</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>,
  <span class='co'># for speed of example only (default is "sampling")</span>
  <span class='kw'>algorithm</span> <span class='kw'>=</span> <span class='st'>"fullrank"</span>
 )

<span class='fu'><a href='https://rdrr.io/r/graphics/plot.html'>plot</a></span>(<span class='no'>fit</span>, <span class='kw'>prob</span> <span class='kw'>=</span> <span class='fl'>0.5</span>)
<span class='fu'><a href='https://rdrr.io/r/graphics/plot.html'>plot</a></span>(<span class='no'>fit</span>, <span class='kw'>prob</span> <span class='kw'>=</span> <span class='fl'>0.5</span>, <span class='kw'>pars</span> <span class='kw'>=</span> <span class='st'>"beta"</span>)
<span class='fu'><a href='https://rdrr.io/r/graphics/plot.html'>plot</a></span>(<span class='no'>fit</span>, <span class='st'>"hist"</span>, <span class='kw'>pars</span> <span class='kw'>=</span> <span class='st'>"sigma"</span>)
}</div><div class='output co'>#&gt; Chain 1: ------------------------------------------------------------
#&gt; Chain 1: EXPERIMENTAL ALGORITHM:
#&gt; Chain 1:   This procedure has not been thoroughly tested and may be unstable
#&gt; Chain 1:   or buggy. The interface is subject to change.
#&gt; Chain 1: ------------------------------------------------------------
#&gt; Chain 1: 
#&gt; Chain 1: 
#&gt; Chain 1: 
#&gt; Chain 1: Gradient evaluation took 2.1e-05 seconds
#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds.
#&gt; Chain 1: Adjust your expectations accordingly!
#&gt; Chain 1: 
#&gt; Chain 1: 
#&gt; Chain 1: Begin eta adaptation.
#&gt; Chain 1: Iteration:   1 / 250 [  0%]  (Adaptation)
#&gt; Chain 1: Iteration:  50 / 250 [ 20%]  (Adaptation)
#&gt; Chain 1: Iteration: 100 / 250 [ 40%]  (Adaptation)
#&gt; Chain 1: Iteration: 150 / 250 [ 60%]  (Adaptation)
#&gt; Chain 1: Iteration: 200 / 250 [ 80%]  (Adaptation)
#&gt; Chain 1: Iteration: 250 / 250 [100%]  (Adaptation)
#&gt; Chain 1: Success! Found best value [eta = 0.1].
#&gt; Chain 1: 
#&gt; Chain 1: Begin stochastic gradient ascent.
#&gt; Chain 1:   iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes 
#&gt; Chain 1:    100          -87.982             1.000            1.000
#&gt; Chain 1:    200          -69.794             0.630            1.000
#&gt; Chain 1:    300          -51.556             0.538            0.354
#&gt; Chain 1:    400          -36.132             0.510            0.427
#&gt; Chain 1:    500          -27.959             0.467            0.354
#&gt; Chain 1:    600          -21.958             0.434            0.354
#&gt; Chain 1:    700          -19.017             0.395            0.292
#&gt; Chain 1:    800          -19.311             0.347            0.292
#&gt; Chain 1:    900          -18.849             0.311            0.273
#&gt; Chain 1:   1000          -18.489             0.282            0.273
#&gt; Chain 1:   1100          -18.706             0.183            0.261
#&gt; Chain 1:   1200          -19.304             0.160            0.155
#&gt; Chain 1:   1300          -18.624             0.129            0.037
#&gt; Chain 1:   1400          -19.590             0.091            0.037
#&gt; Chain 1:   1500          -18.562             0.067            0.037
#&gt; Chain 1:   1600          -18.590             0.040            0.031
#&gt; Chain 1:   1700          -18.453             0.025            0.025
#&gt; Chain 1:   1800          -19.001             0.027            0.029
#&gt; Chain 1:   1900          -18.730             0.026            0.029
#&gt; Chain 1:   2000          -18.877             0.024            0.029
#&gt; Chain 1:   2100          -18.691             0.024            0.029
#&gt; Chain 1:   2200          -18.341             0.023            0.019
#&gt; Chain 1:   2300          -18.550             0.020            0.014
#&gt; Chain 1:   2400          -18.684             0.016            0.011
#&gt; Chain 1:   2500          -18.439             0.012            0.011
#&gt; Chain 1:   2600          -18.514             0.012            0.011
#&gt; Chain 1:   2700          -18.471             0.012            0.011
#&gt; Chain 1:   2800          -18.584             0.010            0.010
#&gt; Chain 1:   2900          -18.556             0.008            0.008
#&gt; Chain 1:   3000          -18.517             0.008            0.007
#&gt; Chain 1:   3100          -18.568             0.007            0.006
#&gt; Chain 1:   3200          -18.692             0.006            0.006
#&gt; Chain 1:   3300          -18.297             0.007            0.006
#&gt; Chain 1:   3400          -18.691             0.008            0.006
#&gt; Chain 1:   3500          -18.516             0.008            0.006
#&gt; Chain 1:   3600          -18.322             0.008            0.007
#&gt; Chain 1:   3700          -18.540             0.009            0.009
#&gt; Chain 1:   3800          -19.078             0.012            0.011
#&gt; Chain 1:   3900          -18.437             0.015            0.012
#&gt; Chain 1:   4000          -18.458             0.015            0.012
#&gt; Chain 1:   4100          -18.250             0.016            0.012
#&gt; Chain 1:   4200          -18.128             0.016            0.012
#&gt; Chain 1:   4300          -18.700             0.017            0.012
#&gt; Chain 1:   4400          -18.705             0.014            0.011
#&gt; Chain 1:   4500          -18.572             0.014            0.011
#&gt; Chain 1:   4600          -18.652             0.014            0.011
#&gt; Chain 1:   4700          -18.709             0.013            0.007
#&gt; Chain 1:   4800          -18.466             0.011            0.007
#&gt; Chain 1:   4900          -18.325             0.009            0.007
#&gt; Chain 1:   5000          -18.445             0.009            0.007
#&gt; Chain 1:   5100          -18.280             0.009            0.007
#&gt; Chain 1:   5200          -18.558             0.010            0.008
#&gt; Chain 1:   5300          -18.356             0.008            0.008
#&gt; Chain 1:   5400          -18.755             0.010            0.009
#&gt; Chain 1:   5500          -18.464             0.011            0.011
#&gt; Chain 1:   5600          -18.534             0.011            0.011
#&gt; Chain 1:   5700          -18.353             0.011            0.011
#&gt; Chain 1:   5800          -18.364             0.010            0.010
#&gt; Chain 1:   5900          -18.330             0.009            0.010
#&gt; Chain 1:   6000          -18.526             0.010            0.011
#&gt; Chain 1:   6100          -18.493             0.009            0.011
#&gt; Chain 1:   6200          -18.719             0.009            0.011
#&gt; Chain 1:   6300          -18.634             0.008            0.010
#&gt; Chain 1:   6400          -18.621             0.006            0.005
#&gt; Chain 1:   6500          -18.519             0.005            0.005
#&gt; Chain 1:   6600          -19.155             0.008            0.006
#&gt; Chain 1:   6700          -18.575             0.010            0.006
#&gt; Chain 1:   6800          -18.401             0.011            0.009
#&gt; Chain 1:   6900          -18.552             0.012            0.009
#&gt; Chain 1:   7000          -18.187             0.013            0.009
#&gt; Chain 1:   7100          -18.348             0.013            0.009
#&gt; Chain 1:   7200          -18.078             0.014            0.009
#&gt; Chain 1:   7300          -18.435             0.015            0.015
#&gt; Chain 1:   7400          -18.546             0.016            0.015
#&gt; Chain 1:   7500          -18.349             0.016            0.015
#&gt; Chain 1:   7600          -18.262             0.013            0.011
#&gt; Chain 1:   7700          -18.269             0.010            0.009
#&gt; Chain 1:   7800          -18.960             0.013            0.011
#&gt; Chain 1:   7900          -18.494             0.015            0.015
#&gt; Chain 1:   8000          -17.917             0.016            0.015
#&gt; Chain 1:   8100          -17.980             0.015            0.015
#&gt; Chain 1:   8200          -18.340             0.016            0.019
#&gt; Chain 1:   8300          -18.974             0.017            0.020
#&gt; Chain 1:   8400          -18.147             0.021            0.025
#&gt; Chain 1:   8500          -18.137             0.020            0.025
#&gt; Chain 1:   8600          -18.555             0.022            0.025
#&gt; Chain 1:   8700          -18.251             0.024            0.025
#&gt; Chain 1:   8800          -18.643             0.022            0.023
#&gt; Chain 1:   8900          -18.626             0.020            0.021
#&gt; Chain 1:   9000          -18.155             0.019            0.021
#&gt; Chain 1:   9100          -18.653             0.021            0.023
#&gt; Chain 1:   9200          -18.256             0.022            0.023
#&gt; Chain 1:   9300          -18.269             0.018            0.022
#&gt; Chain 1:   9400          -18.668             0.016            0.021
#&gt; Chain 1:   9500          -18.608             0.016            0.021
#&gt; Chain 1:   9600          -18.354             0.015            0.021
#&gt; Chain 1:   9700          -18.624             0.015            0.021
#&gt; Chain 1:   9800          -18.731             0.013            0.014
#&gt; Chain 1:   9900          -18.676             0.014            0.014
#&gt; Chain 1:   10000          -18.770             0.012            0.014
#&gt; Chain 1: Informational Message: The maximum number of iterations is reached! The algorithm may not have converged.
#&gt; Chain 1: This variational approximation is not guaranteed to be meaningful.
#&gt; Chain 1: 
#&gt; Chain 1: Drawing a sample of size 1000 from the approximate posterior... 
#&gt; Chain 1: COMPLETED.</div><div class='output co'>#&gt; <span class='message'>`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</span></div><div class='img'><img src='stan_glm-1.png' alt='' width='700' height='433' /></div><div class='input'><span class='co'># \donttest{</span>
<span class='co'>### Logistic regression</span>
<span class='fu'><a href='https://rdrr.io/r/utils/head.html'>head</a></span>(<span class='no'>wells</span>)</div><div class='output co'>#&gt;   switch arsenic   dist assoc educ
#&gt; 1      1    2.36 16.826     0    0
#&gt; 2      1    0.71 47.322     0    0
#&gt; 3      0    2.07 20.967     0   10
#&gt; 4      1    1.15 21.486     0   12
#&gt; 5      1    1.10 40.874     1   14
#&gt; 6      1    3.90 69.518     1    9</div><div class='input'><span class='no'>wells</span>$<span class='no'>dist100</span> <span class='kw'>&lt;-</span> <span class='no'>wells</span>$<span class='no'>dist</span> / <span class='fl'>100</span>
<span class='no'>fit2</span> <span class='kw'>&lt;-</span> <span class='fu'>stan_glm</span>(
  <span class='no'>switch</span> ~ <span class='no'>dist100</span> + <span class='no'>arsenic</span>,
  <span class='kw'>data</span> <span class='kw'>=</span> <span class='no'>wells</span>,
  <span class='kw'>family</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/stats/family.html'>binomial</a></span>(<span class='kw'>link</span> <span class='kw'>=</span> <span class='st'>"logit"</span>),
  <span class='kw'>prior_intercept</span> <span class='kw'>=</span> <span class='fu'><a href='priors.html'>normal</a></span>(<span class='fl'>0</span>, <span class='fl'>10</span>),
  <span class='kw'>QR</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>,
  <span class='co'># for speed of example only</span>
  <span class='kw'>chains</span> <span class='kw'>=</span> <span class='fl'>2</span>, <span class='kw'>iter</span> <span class='kw'>=</span> <span class='fl'>200</span>
)</div><div class='output co'>#&gt; 
#&gt; SAMPLING FOR MODEL 'bernoulli' NOW (CHAIN 1).
#&gt; Chain 1: 
#&gt; Chain 1: Gradient evaluation took 9.3e-05 seconds
#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.93 seconds.
#&gt; Chain 1: Adjust your expectations accordingly!
#&gt; Chain 1: 
#&gt; Chain 1: 
#&gt; Chain 1: WARNING: There aren't enough warmup iterations to fit the
#&gt; Chain 1:          three stages of adaptation as currently configured.
#&gt; Chain 1:          Reducing each adaptation stage to 15%/75%/10% of
#&gt; Chain 1:          the given number of warmup iterations:
#&gt; Chain 1:            init_buffer = 15
#&gt; Chain 1:            adapt_window = 75
#&gt; Chain 1:            term_buffer = 10
#&gt; Chain 1: 
#&gt; Chain 1: Iteration:   1 / 200 [  0%]  (Warmup)
#&gt; Chain 1: Iteration:  20 / 200 [ 10%]  (Warmup)
#&gt; Chain 1: Iteration:  40 / 200 [ 20%]  (Warmup)
#&gt; Chain 1: Iteration:  60 / 200 [ 30%]  (Warmup)
#&gt; Chain 1: Iteration:  80 / 200 [ 40%]  (Warmup)
#&gt; Chain 1: Iteration: 100 / 200 [ 50%]  (Warmup)
#&gt; Chain 1: Iteration: 101 / 200 [ 50%]  (Sampling)
#&gt; Chain 1: Iteration: 120 / 200 [ 60%]  (Sampling)
#&gt; Chain 1: Iteration: 140 / 200 [ 70%]  (Sampling)
#&gt; Chain 1: Iteration: 160 / 200 [ 80%]  (Sampling)
#&gt; Chain 1: Iteration: 180 / 200 [ 90%]  (Sampling)
#&gt; Chain 1: Iteration: 200 / 200 [100%]  (Sampling)
#&gt; Chain 1: 
#&gt; Chain 1:  Elapsed Time: 0.05362 seconds (Warm-up)
#&gt; Chain 1:                0.066983 seconds (Sampling)
#&gt; Chain 1:                0.120603 seconds (Total)
#&gt; Chain 1: 
#&gt; 
#&gt; SAMPLING FOR MODEL 'bernoulli' NOW (CHAIN 2).
#&gt; Chain 2: 
#&gt; Chain 2: Gradient evaluation took 0.000109 seconds
#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 1.09 seconds.
#&gt; Chain 2: Adjust your expectations accordingly!
#&gt; Chain 2: 
#&gt; Chain 2: 
#&gt; Chain 2: WARNING: There aren't enough warmup iterations to fit the
#&gt; Chain 2:          three stages of adaptation as currently configured.
#&gt; Chain 2:          Reducing each adaptation stage to 15%/75%/10% of
#&gt; Chain 2:          the given number of warmup iterations:
#&gt; Chain 2:            init_buffer = 15
#&gt; Chain 2:            adapt_window = 75
#&gt; Chain 2:            term_buffer = 10
#&gt; Chain 2: 
#&gt; Chain 2: Iteration:   1 / 200 [  0%]  (Warmup)
#&gt; Chain 2: Iteration:  20 / 200 [ 10%]  (Warmup)
#&gt; Chain 2: Iteration:  40 / 200 [ 20%]  (Warmup)
#&gt; Chain 2: Iteration:  60 / 200 [ 30%]  (Warmup)
#&gt; Chain 2: Iteration:  80 / 200 [ 40%]  (Warmup)
#&gt; Chain 2: Iteration: 100 / 200 [ 50%]  (Warmup)
#&gt; Chain 2: Iteration: 101 / 200 [ 50%]  (Sampling)
#&gt; Chain 2: Iteration: 120 / 200 [ 60%]  (Sampling)
#&gt; Chain 2: Iteration: 140 / 200 [ 70%]  (Sampling)
#&gt; Chain 2: Iteration: 160 / 200 [ 80%]  (Sampling)
#&gt; Chain 2: Iteration: 180 / 200 [ 90%]  (Sampling)
#&gt; Chain 2: Iteration: 200 / 200 [100%]  (Sampling)
#&gt; Chain 2: 
#&gt; Chain 2:  Elapsed Time: 0.056518 seconds (Warm-up)
#&gt; Chain 2:                0.068286 seconds (Sampling)
#&gt; Chain 2:                0.124804 seconds (Total)
#&gt; Chain 2: </div><div class='output co'>#&gt; <span class='warning'>Warning: The largest R-hat is 1.06, indicating chains have not mixed.</span>
#&gt; <span class='warning'>Running the chains for more iterations may help. See</span>
#&gt; <span class='warning'>http://mc-stan.org/misc/warnings.html#r-hat</span></div><div class='output co'>#&gt; <span class='warning'>Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.</span>
#&gt; <span class='warning'>Running the chains for more iterations may help. See</span>
#&gt; <span class='warning'>http://mc-stan.org/misc/warnings.html#bulk-ess</span></div><div class='output co'>#&gt; <span class='warning'>Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.</span>
#&gt; <span class='warning'>Running the chains for more iterations may help. See</span>
#&gt; <span class='warning'>http://mc-stan.org/misc/warnings.html#tail-ess</span></div><div class='input'><span class='fu'><a href='https://rdrr.io/r/base/print.html'>print</a></span>(<span class='no'>fit2</span>)</div><div class='output co'>#&gt; stan_glm
#&gt;  family:       binomial [logit]
#&gt;  formula:      switch ~ dist100 + arsenic
#&gt;  observations: 3020
#&gt;  predictors:   3
#&gt; ------
#&gt;             Median MAD_SD
#&gt; (Intercept)  0.0    0.1  
#&gt; dist100     -0.9    0.1  
#&gt; arsenic      0.5    0.0  
#&gt; 
#&gt; ------
#&gt; * For help interpreting the printed output see ?print.stanreg
#&gt; * For info on the priors used see ?prior_summary.stanreg</div><div class='input'><span class='fu'><a href='prior_summary.stanreg.html'>prior_summary</a></span>(<span class='no'>fit2</span>)</div><div class='output co'>#&gt; Priors for model 'fit2' 
#&gt; ------
#&gt; Intercept (after predictors centered)
#&gt;  ~ normal(location = 0, scale = 10)
#&gt; 
#&gt; Coefficients (in Q-space)
#&gt;  ~ normal(location = [0,0], scale = [2.5,2.5])
#&gt; ------
#&gt; See help('prior_summary.stanreg') for more details</div><div class='input'>
<span class='co'># ?bayesplot::mcmc_areas</span>
<span class='fu'><a href='https://rdrr.io/r/graphics/plot.html'>plot</a></span>(<span class='no'>fit2</span>, <span class='kw'>plotfun</span> <span class='kw'>=</span> <span class='st'>"areas"</span>, <span class='kw'>prob</span> <span class='kw'>=</span> <span class='fl'>0.9</span>,
     <span class='kw'>pars</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='st'>"(Intercept)"</span>, <span class='st'>"arsenic"</span>))</div><div class='img'><img src='stan_glm-2.png' alt='' width='700' height='433' /></div><div class='input'>
<span class='co'># ?bayesplot::ppc_error_binned</span>
<span class='fu'><a href='pp_check.stanreg.html'>pp_check</a></span>(<span class='no'>fit2</span>, <span class='kw'>plotfun</span> <span class='kw'>=</span> <span class='st'>"error_binned"</span>)</div><div class='img'><img src='stan_glm-3.png' alt='' width='700' height='433' /></div><div class='input'>

<span class='co'>### Poisson regression (example from help("glm")) </span>
<span class='no'>count_data</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/data.frame.html'>data.frame</a></span>(
 <span class='kw'>counts</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>18</span>,<span class='fl'>17</span>,<span class='fl'>15</span>,<span class='fl'>20</span>,<span class='fl'>10</span>,<span class='fl'>20</span>,<span class='fl'>25</span>,<span class='fl'>13</span>,<span class='fl'>12</span>),
 <span class='kw'>outcome</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/gl.html'>gl</a></span>(<span class='fl'>3</span>,<span class='fl'>1</span>,<span class='fl'>9</span>),
 <span class='kw'>treatment</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/gl.html'>gl</a></span>(<span class='fl'>3</span>,<span class='fl'>3</span>)
)
<span class='no'>fit3</span> <span class='kw'>&lt;-</span> <span class='fu'>stan_glm</span>(
  <span class='no'>counts</span> ~ <span class='no'>outcome</span> + <span class='no'>treatment</span>,
  <span class='kw'>data</span> <span class='kw'>=</span> <span class='no'>count_data</span>,
  <span class='kw'>family</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/stats/family.html'>poisson</a></span>(<span class='kw'>link</span><span class='kw'>=</span><span class='st'>"log"</span>),
  <span class='kw'>prior</span> <span class='kw'>=</span> <span class='fu'><a href='priors.html'>normal</a></span>(<span class='fl'>0</span>, <span class='fl'>2</span>, <span class='kw'>autoscale</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>),
  <span class='co'># for speed of example only</span>
  <span class='kw'>chains</span> <span class='kw'>=</span> <span class='fl'>2</span>, <span class='kw'>iter</span> <span class='kw'>=</span> <span class='fl'>250</span>
)</div><div class='output co'>#&gt; 
#&gt; SAMPLING FOR MODEL 'count' NOW (CHAIN 1).
#&gt; Chain 1: 
#&gt; Chain 1: Gradient evaluation took 1.7e-05 seconds
#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.
#&gt; Chain 1: Adjust your expectations accordingly!
#&gt; Chain 1: 
#&gt; Chain 1: 
#&gt; Chain 1: WARNING: There aren't enough warmup iterations to fit the
#&gt; Chain 1:          three stages of adaptation as currently configured.
#&gt; Chain 1:          Reducing each adaptation stage to 15%/75%/10% of
#&gt; Chain 1:          the given number of warmup iterations:
#&gt; Chain 1:            init_buffer = 18
#&gt; Chain 1:            adapt_window = 95
#&gt; Chain 1:            term_buffer = 12
#&gt; Chain 1: 
#&gt; Chain 1: Iteration:   1 / 250 [  0%]  (Warmup)
#&gt; Chain 1: Iteration:  25 / 250 [ 10%]  (Warmup)
#&gt; Chain 1: Iteration:  50 / 250 [ 20%]  (Warmup)
#&gt; Chain 1: Iteration:  75 / 250 [ 30%]  (Warmup)
#&gt; Chain 1: Iteration: 100 / 250 [ 40%]  (Warmup)
#&gt; Chain 1: Iteration: 125 / 250 [ 50%]  (Warmup)
#&gt; Chain 1: Iteration: 126 / 250 [ 50%]  (Sampling)
#&gt; Chain 1: Iteration: 150 / 250 [ 60%]  (Sampling)
#&gt; Chain 1: Iteration: 175 / 250 [ 70%]  (Sampling)
#&gt; Chain 1: Iteration: 200 / 250 [ 80%]  (Sampling)
#&gt; Chain 1: Iteration: 225 / 250 [ 90%]  (Sampling)
#&gt; Chain 1: Iteration: 250 / 250 [100%]  (Sampling)
#&gt; Chain 1: 
#&gt; Chain 1:  Elapsed Time: 0.005866 seconds (Warm-up)
#&gt; Chain 1:                0.006603 seconds (Sampling)
#&gt; Chain 1:                0.012469 seconds (Total)
#&gt; Chain 1: 
#&gt; 
#&gt; SAMPLING FOR MODEL 'count' NOW (CHAIN 2).
#&gt; Chain 2: 
#&gt; Chain 2: Gradient evaluation took 1.2e-05 seconds
#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds.
#&gt; Chain 2: Adjust your expectations accordingly!
#&gt; Chain 2: 
#&gt; Chain 2: 
#&gt; Chain 2: WARNING: There aren't enough warmup iterations to fit the
#&gt; Chain 2:          three stages of adaptation as currently configured.
#&gt; Chain 2:          Reducing each adaptation stage to 15%/75%/10% of
#&gt; Chain 2:          the given number of warmup iterations:
#&gt; Chain 2:            init_buffer = 18
#&gt; Chain 2:            adapt_window = 95
#&gt; Chain 2:            term_buffer = 12
#&gt; Chain 2: 
#&gt; Chain 2: Iteration:   1 / 250 [  0%]  (Warmup)
#&gt; Chain 2: Iteration:  25 / 250 [ 10%]  (Warmup)
#&gt; Chain 2: Iteration:  50 / 250 [ 20%]  (Warmup)
#&gt; Chain 2: Iteration:  75 / 250 [ 30%]  (Warmup)
#&gt; Chain 2: Iteration: 100 / 250 [ 40%]  (Warmup)
#&gt; Chain 2: Iteration: 125 / 250 [ 50%]  (Warmup)
#&gt; Chain 2: Iteration: 126 / 250 [ 50%]  (Sampling)
#&gt; Chain 2: Iteration: 150 / 250 [ 60%]  (Sampling)
#&gt; Chain 2: Iteration: 175 / 250 [ 70%]  (Sampling)
#&gt; Chain 2: Iteration: 200 / 250 [ 80%]  (Sampling)
#&gt; Chain 2: Iteration: 225 / 250 [ 90%]  (Sampling)
#&gt; Chain 2: Iteration: 250 / 250 [100%]  (Sampling)
#&gt; Chain 2: 
#&gt; Chain 2:  Elapsed Time: 0.005589 seconds (Warm-up)
#&gt; Chain 2:                0.005192 seconds (Sampling)
#&gt; Chain 2:                0.010781 seconds (Total)
#&gt; Chain 2: </div><div class='output co'>#&gt; <span class='warning'>Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.</span>
#&gt; <span class='warning'>Running the chains for more iterations may help. See</span>
#&gt; <span class='warning'>http://mc-stan.org/misc/warnings.html#bulk-ess</span></div><div class='output co'>#&gt; <span class='warning'>Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.</span>
#&gt; <span class='warning'>Running the chains for more iterations may help. See</span>
#&gt; <span class='warning'>http://mc-stan.org/misc/warnings.html#tail-ess</span></div><div class='input'><span class='fu'><a href='https://rdrr.io/r/base/print.html'>print</a></span>(<span class='no'>fit3</span>)</div><div class='output co'>#&gt; stan_glm
#&gt;  family:       poisson [log]
#&gt;  formula:      counts ~ outcome + treatment
#&gt;  observations: 9
#&gt;  predictors:   5
#&gt; ------
#&gt;             Median MAD_SD
#&gt; (Intercept)  3.0    0.2  
#&gt; outcome2    -0.5    0.2  
#&gt; outcome3    -0.3    0.2  
#&gt; treatment2   0.0    0.2  
#&gt; treatment3   0.0    0.2  
#&gt; 
#&gt; ------
#&gt; * For help interpreting the printed output see ?print.stanreg
#&gt; * For info on the priors used see ?prior_summary.stanreg</div><div class='input'>
<span class='kw pkg'>bayesplot</span><span class='kw ns'>::</span><span class='fu'><a href='https://mc-stan.org/bayesplot/reference/bayesplot-colors.html'>color_scheme_set</a></span>(<span class='st'>"viridis"</span>)
<span class='fu'><a href='https://rdrr.io/r/graphics/plot.html'>plot</a></span>(<span class='no'>fit3</span>)</div><div class='img'><img src='stan_glm-4.png' alt='' width='700' height='433' /></div><div class='input'><span class='fu'><a href='https://rdrr.io/r/graphics/plot.html'>plot</a></span>(<span class='no'>fit3</span>, <span class='kw'>regex_pars</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='st'>"outcome"</span>, <span class='st'>"treatment"</span>))</div><div class='img'><img src='stan_glm-5.png' alt='' width='700' height='433' /></div><div class='input'><span class='fu'><a href='https://rdrr.io/r/graphics/plot.html'>plot</a></span>(<span class='no'>fit3</span>, <span class='kw'>plotfun</span> <span class='kw'>=</span> <span class='st'>"combo"</span>, <span class='kw'>regex_pars</span> <span class='kw'>=</span> <span class='st'>"treatment"</span>) <span class='co'># ?bayesplot::mcmc_combo</span></div><div class='img'><img src='stan_glm-6.png' alt='' width='700' height='433' /></div><div class='input'><span class='fu'><a href='posterior_vs_prior.html'>posterior_vs_prior</a></span>(<span class='no'>fit3</span>, <span class='kw'>regex_pars</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='st'>"outcome"</span>, <span class='st'>"treatment"</span>))</div><div class='output co'>#&gt; <span class='message'></span>
#&gt; <span class='message'>Drawing from prior...</span></div><div class='img'><img src='stan_glm-7.png' alt='' width='700' height='433' /></div><div class='input'>
<span class='co'>### Gamma regression (example from help("glm"))</span>
<span class='no'>clotting</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/data.frame.html'>data.frame</a></span>(<span class='kw'>log_u</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>5</span>,<span class='fl'>10</span>,<span class='fl'>15</span>,<span class='fl'>20</span>,<span class='fl'>30</span>,<span class='fl'>40</span>,<span class='fl'>60</span>,<span class='fl'>80</span>,<span class='fl'>100</span>)),
                       <span class='kw'>lot1</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>118</span>,<span class='fl'>58</span>,<span class='fl'>42</span>,<span class='fl'>35</span>,<span class='fl'>27</span>,<span class='fl'>25</span>,<span class='fl'>21</span>,<span class='fl'>19</span>,<span class='fl'>18</span>),
                       <span class='kw'>lot2</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>69</span>,<span class='fl'>35</span>,<span class='fl'>26</span>,<span class='fl'>21</span>,<span class='fl'>18</span>,<span class='fl'>16</span>,<span class='fl'>13</span>,<span class='fl'>12</span>,<span class='fl'>12</span>))
<span class='no'>fit4</span> <span class='kw'>&lt;-</span> <span class='fu'>stan_glm</span>(
  <span class='no'>lot1</span> ~ <span class='no'>log_u</span>,
  <span class='kw'>data</span> <span class='kw'>=</span> <span class='no'>clotting</span>,
  <span class='kw'>family</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/stats/family.html'>Gamma</a></span>(<span class='kw'>link</span><span class='kw'>=</span><span class='st'>"log"</span>),
  <span class='kw'>iter</span> <span class='kw'>=</span> <span class='fl'>500</span> <span class='co'># for speed of example only </span>
 )</div><div class='output co'>#&gt; 
#&gt; SAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).
#&gt; Chain 1: 
#&gt; Chain 1: Gradient evaluation took 2.6e-05 seconds
#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.26 seconds.
#&gt; Chain 1: Adjust your expectations accordingly!
#&gt; Chain 1: 
#&gt; Chain 1: 
#&gt; Chain 1: Iteration:   1 / 500 [  0%]  (Warmup)
#&gt; Chain 1: Iteration:  50 / 500 [ 10%]  (Warmup)
#&gt; Chain 1: Iteration: 100 / 500 [ 20%]  (Warmup)
#&gt; Chain 1: Iteration: 150 / 500 [ 30%]  (Warmup)
#&gt; Chain 1: Iteration: 200 / 500 [ 40%]  (Warmup)
#&gt; Chain 1: Iteration: 250 / 500 [ 50%]  (Warmup)
#&gt; Chain 1: Iteration: 251 / 500 [ 50%]  (Sampling)
#&gt; Chain 1: Iteration: 300 / 500 [ 60%]  (Sampling)
#&gt; Chain 1: Iteration: 350 / 500 [ 70%]  (Sampling)
#&gt; Chain 1: Iteration: 400 / 500 [ 80%]  (Sampling)
#&gt; Chain 1: Iteration: 450 / 500 [ 90%]  (Sampling)
#&gt; Chain 1: Iteration: 500 / 500 [100%]  (Sampling)
#&gt; Chain 1: 
#&gt; Chain 1:  Elapsed Time: 0.024445 seconds (Warm-up)
#&gt; Chain 1:                0.009355 seconds (Sampling)
#&gt; Chain 1:                0.0338 seconds (Total)
#&gt; Chain 1: 
#&gt; 
#&gt; SAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).
#&gt; Chain 2: 
#&gt; Chain 2: Gradient evaluation took 1e-05 seconds
#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds.
#&gt; Chain 2: Adjust your expectations accordingly!
#&gt; Chain 2: 
#&gt; Chain 2: 
#&gt; Chain 2: Iteration:   1 / 500 [  0%]  (Warmup)
#&gt; Chain 2: Iteration:  50 / 500 [ 10%]  (Warmup)
#&gt; Chain 2: Iteration: 100 / 500 [ 20%]  (Warmup)
#&gt; Chain 2: Iteration: 150 / 500 [ 30%]  (Warmup)
#&gt; Chain 2: Iteration: 200 / 500 [ 40%]  (Warmup)
#&gt; Chain 2: Iteration: 250 / 500 [ 50%]  (Warmup)
#&gt; Chain 2: Iteration: 251 / 500 [ 50%]  (Sampling)
#&gt; Chain 2: Iteration: 300 / 500 [ 60%]  (Sampling)
#&gt; Chain 2: Iteration: 350 / 500 [ 70%]  (Sampling)
#&gt; Chain 2: Iteration: 400 / 500 [ 80%]  (Sampling)
#&gt; Chain 2: Iteration: 450 / 500 [ 90%]  (Sampling)
#&gt; Chain 2: Iteration: 500 / 500 [100%]  (Sampling)
#&gt; Chain 2: 
#&gt; Chain 2:  Elapsed Time: 0.015312 seconds (Warm-up)
#&gt; Chain 2:                0.012285 seconds (Sampling)
#&gt; Chain 2:                0.027597 seconds (Total)
#&gt; Chain 2: 
#&gt; 
#&gt; SAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).
#&gt; Chain 3: 
#&gt; Chain 3: Gradient evaluation took 1.1e-05 seconds
#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.11 seconds.
#&gt; Chain 3: Adjust your expectations accordingly!
#&gt; Chain 3: 
#&gt; Chain 3: 
#&gt; Chain 3: Iteration:   1 / 500 [  0%]  (Warmup)
#&gt; Chain 3: Iteration:  50 / 500 [ 10%]  (Warmup)
#&gt; Chain 3: Iteration: 100 / 500 [ 20%]  (Warmup)
#&gt; Chain 3: Iteration: 150 / 500 [ 30%]  (Warmup)
#&gt; Chain 3: Iteration: 200 / 500 [ 40%]  (Warmup)
#&gt; Chain 3: Iteration: 250 / 500 [ 50%]  (Warmup)
#&gt; Chain 3: Iteration: 251 / 500 [ 50%]  (Sampling)
#&gt; Chain 3: Iteration: 300 / 500 [ 60%]  (Sampling)
#&gt; Chain 3: Iteration: 350 / 500 [ 70%]  (Sampling)
#&gt; Chain 3: Iteration: 400 / 500 [ 80%]  (Sampling)
#&gt; Chain 3: Iteration: 450 / 500 [ 90%]  (Sampling)
#&gt; Chain 3: Iteration: 500 / 500 [100%]  (Sampling)
#&gt; Chain 3: 
#&gt; Chain 3:  Elapsed Time: 0.014631 seconds (Warm-up)
#&gt; Chain 3:                0.010485 seconds (Sampling)
#&gt; Chain 3:                0.025116 seconds (Total)
#&gt; Chain 3: 
#&gt; 
#&gt; SAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).
#&gt; Chain 4: 
#&gt; Chain 4: Gradient evaluation took 1.5e-05 seconds
#&gt; Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.
#&gt; Chain 4: Adjust your expectations accordingly!
#&gt; Chain 4: 
#&gt; Chain 4: 
#&gt; Chain 4: Iteration:   1 / 500 [  0%]  (Warmup)
#&gt; Chain 4: Iteration:  50 / 500 [ 10%]  (Warmup)
#&gt; Chain 4: Iteration: 100 / 500 [ 20%]  (Warmup)
#&gt; Chain 4: Iteration: 150 / 500 [ 30%]  (Warmup)
#&gt; Chain 4: Iteration: 200 / 500 [ 40%]  (Warmup)
#&gt; Chain 4: Iteration: 250 / 500 [ 50%]  (Warmup)
#&gt; Chain 4: Iteration: 251 / 500 [ 50%]  (Sampling)
#&gt; Chain 4: Iteration: 300 / 500 [ 60%]  (Sampling)
#&gt; Chain 4: Iteration: 350 / 500 [ 70%]  (Sampling)
#&gt; Chain 4: Iteration: 400 / 500 [ 80%]  (Sampling)
#&gt; Chain 4: Iteration: 450 / 500 [ 90%]  (Sampling)
#&gt; Chain 4: Iteration: 500 / 500 [100%]  (Sampling)
#&gt; Chain 4: 
#&gt; Chain 4:  Elapsed Time: 0.014871 seconds (Warm-up)
#&gt; Chain 4:                0.010353 seconds (Sampling)
#&gt; Chain 4:                0.025224 seconds (Total)
#&gt; Chain 4: </div><div class='output co'>#&gt; <span class='warning'>Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.</span>
#&gt; <span class='warning'>Running the chains for more iterations may help. See</span>
#&gt; <span class='warning'>http://mc-stan.org/misc/warnings.html#tail-ess</span></div><div class='input'><span class='fu'><a href='https://rdrr.io/r/base/print.html'>print</a></span>(<span class='no'>fit4</span>, <span class='kw'>digits</span> <span class='kw'>=</span> <span class='fl'>2</span>)</div><div class='output co'>#&gt; stan_glm
#&gt;  family:       Gamma [log]
#&gt;  formula:      lot1 ~ log_u
#&gt;  observations: 9
#&gt;  predictors:   2
#&gt; ------
#&gt;             Median MAD_SD
#&gt; (Intercept)  5.55   0.58 
#&gt; log_u       -0.61   0.16 
#&gt; 
#&gt; Auxiliary parameter(s):
#&gt;       Median MAD_SD
#&gt; shape 4.06   1.91  
#&gt; 
#&gt; ------
#&gt; * For help interpreting the printed output see ?print.stanreg
#&gt; * For info on the priors used see ?prior_summary.stanreg</div><div class='input'>
<span class='no'>fit5</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/update.html'>update</a></span>(<span class='no'>fit4</span>, <span class='kw'>formula</span> <span class='kw'>=</span> <span class='no'>lot2</span> ~ <span class='no'>log_u</span>)</div><div class='output co'>#&gt; 
#&gt; SAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).
#&gt; Chain 1: 
#&gt; Chain 1: Gradient evaluation took 2.2e-05 seconds
#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.22 seconds.
#&gt; Chain 1: Adjust your expectations accordingly!
#&gt; Chain 1: 
#&gt; Chain 1: 
#&gt; Chain 1: Iteration:   1 / 500 [  0%]  (Warmup)
#&gt; Chain 1: Iteration:  50 / 500 [ 10%]  (Warmup)
#&gt; Chain 1: Iteration: 100 / 500 [ 20%]  (Warmup)
#&gt; Chain 1: Iteration: 150 / 500 [ 30%]  (Warmup)
#&gt; Chain 1: Iteration: 200 / 500 [ 40%]  (Warmup)
#&gt; Chain 1: Iteration: 250 / 500 [ 50%]  (Warmup)
#&gt; Chain 1: Iteration: 251 / 500 [ 50%]  (Sampling)
#&gt; Chain 1: Iteration: 300 / 500 [ 60%]  (Sampling)
#&gt; Chain 1: Iteration: 350 / 500 [ 70%]  (Sampling)
#&gt; Chain 1: Iteration: 400 / 500 [ 80%]  (Sampling)
#&gt; Chain 1: Iteration: 450 / 500 [ 90%]  (Sampling)
#&gt; Chain 1: Iteration: 500 / 500 [100%]  (Sampling)
#&gt; Chain 1: 
#&gt; Chain 1:  Elapsed Time: 0.014737 seconds (Warm-up)
#&gt; Chain 1:                0.010768 seconds (Sampling)
#&gt; Chain 1:                0.025505 seconds (Total)
#&gt; Chain 1: 
#&gt; 
#&gt; SAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).
#&gt; Chain 2: 
#&gt; Chain 2: Gradient evaluation took 1.3e-05 seconds
#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.13 seconds.
#&gt; Chain 2: Adjust your expectations accordingly!
#&gt; Chain 2: 
#&gt; Chain 2: 
#&gt; Chain 2: Iteration:   1 / 500 [  0%]  (Warmup)
#&gt; Chain 2: Iteration:  50 / 500 [ 10%]  (Warmup)
#&gt; Chain 2: Iteration: 100 / 500 [ 20%]  (Warmup)
#&gt; Chain 2: Iteration: 150 / 500 [ 30%]  (Warmup)
#&gt; Chain 2: Iteration: 200 / 500 [ 40%]  (Warmup)
#&gt; Chain 2: Iteration: 250 / 500 [ 50%]  (Warmup)
#&gt; Chain 2: Iteration: 251 / 500 [ 50%]  (Sampling)
#&gt; Chain 2: Iteration: 300 / 500 [ 60%]  (Sampling)
#&gt; Chain 2: Iteration: 350 / 500 [ 70%]  (Sampling)
#&gt; Chain 2: Iteration: 400 / 500 [ 80%]  (Sampling)
#&gt; Chain 2: Iteration: 450 / 500 [ 90%]  (Sampling)
#&gt; Chain 2: Iteration: 500 / 500 [100%]  (Sampling)
#&gt; Chain 2: 
#&gt; Chain 2:  Elapsed Time: 0.015018 seconds (Warm-up)
#&gt; Chain 2:                0.00885 seconds (Sampling)
#&gt; Chain 2:                0.023868 seconds (Total)
#&gt; Chain 2: 
#&gt; 
#&gt; SAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).
#&gt; Chain 3: 
#&gt; Chain 3: Gradient evaluation took 1e-05 seconds
#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds.
#&gt; Chain 3: Adjust your expectations accordingly!
#&gt; Chain 3: 
#&gt; Chain 3: 
#&gt; Chain 3: Iteration:   1 / 500 [  0%]  (Warmup)
#&gt; Chain 3: Iteration:  50 / 500 [ 10%]  (Warmup)
#&gt; Chain 3: Iteration: 100 / 500 [ 20%]  (Warmup)
#&gt; Chain 3: Iteration: 150 / 500 [ 30%]  (Warmup)
#&gt; Chain 3: Iteration: 200 / 500 [ 40%]  (Warmup)
#&gt; Chain 3: Iteration: 250 / 500 [ 50%]  (Warmup)
#&gt; Chain 3: Iteration: 251 / 500 [ 50%]  (Sampling)
#&gt; Chain 3: Iteration: 300 / 500 [ 60%]  (Sampling)
#&gt; Chain 3: Iteration: 350 / 500 [ 70%]  (Sampling)
#&gt; Chain 3: Iteration: 400 / 500 [ 80%]  (Sampling)
#&gt; Chain 3: Iteration: 450 / 500 [ 90%]  (Sampling)
#&gt; Chain 3: Iteration: 500 / 500 [100%]  (Sampling)
#&gt; Chain 3: 
#&gt; Chain 3:  Elapsed Time: 0.013373 seconds (Warm-up)
#&gt; Chain 3:                0.014626 seconds (Sampling)
#&gt; Chain 3:                0.027999 seconds (Total)
#&gt; Chain 3: 
#&gt; 
#&gt; SAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).
#&gt; Chain 4: 
#&gt; Chain 4: Gradient evaluation took 1e-05 seconds
#&gt; Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds.
#&gt; Chain 4: Adjust your expectations accordingly!
#&gt; Chain 4: 
#&gt; Chain 4: 
#&gt; Chain 4: Iteration:   1 / 500 [  0%]  (Warmup)
#&gt; Chain 4: Iteration:  50 / 500 [ 10%]  (Warmup)
#&gt; Chain 4: Iteration: 100 / 500 [ 20%]  (Warmup)
#&gt; Chain 4: Iteration: 150 / 500 [ 30%]  (Warmup)
#&gt; Chain 4: Iteration: 200 / 500 [ 40%]  (Warmup)
#&gt; Chain 4: Iteration: 250 / 500 [ 50%]  (Warmup)
#&gt; Chain 4: Iteration: 251 / 500 [ 50%]  (Sampling)
#&gt; Chain 4: Iteration: 300 / 500 [ 60%]  (Sampling)
#&gt; Chain 4: Iteration: 350 / 500 [ 70%]  (Sampling)
#&gt; Chain 4: Iteration: 400 / 500 [ 80%]  (Sampling)
#&gt; Chain 4: Iteration: 450 / 500 [ 90%]  (Sampling)
#&gt; Chain 4: Iteration: 500 / 500 [100%]  (Sampling)
#&gt; Chain 4: 
#&gt; Chain 4:  Elapsed Time: 0.015733 seconds (Warm-up)
#&gt; Chain 4:                0.010458 seconds (Sampling)
#&gt; Chain 4:                0.026191 seconds (Total)
#&gt; Chain 4: </div><div class='input'>
<span class='co'># ?bayesplot::ppc_dens_overlay</span>
<span class='kw pkg'>bayesplot</span><span class='kw ns'>::</span><span class='fu'><a href='https://mc-stan.org/bayesplot/reference/bayesplot_grid.html'>bayesplot_grid</a></span>(
  <span class='fu'><a href='pp_check.stanreg.html'>pp_check</a></span>(<span class='no'>fit4</span>, <span class='kw'>seed</span> <span class='kw'>=</span> <span class='fl'>123</span>),
  <span class='fu'><a href='pp_check.stanreg.html'>pp_check</a></span>(<span class='no'>fit5</span>, <span class='kw'>seed</span> <span class='kw'>=</span> <span class='fl'>123</span>),
  <span class='kw'>titles</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='st'>"lot1"</span>, <span class='st'>"lot2"</span>)
)</div><div class='img'><img src='stan_glm-8.png' alt='' width='700' height='433' /></div><div class='input'>

<span class='co'>### Negative binomial regression</span>
<span class='no'>fit6</span> <span class='kw'>&lt;-</span> <span class='fu'>stan_glm.nb</span>(<span class='no'>Days</span> ~ <span class='no'>Sex</span>/(<span class='no'>Age</span> + <span class='no'>Eth</span>*<span class='no'>Lrn</span>), <span class='kw'>data</span> <span class='kw'>=</span> <span class='kw pkg'>MASS</span><span class='kw ns'>::</span><span class='no'><a href='https://rdrr.io/pkg/MASS/man/quine.html'>quine</a></span>,
                    <span class='kw'>link</span> <span class='kw'>=</span> <span class='st'>"log"</span>, <span class='kw'>prior_aux</span> <span class='kw'>=</span> <span class='fu'><a href='priors.html'>exponential</a></span>(<span class='fl'>1.5</span>),
                    <span class='kw'>chains</span> <span class='kw'>=</span> <span class='fl'>2</span>, <span class='kw'>iter</span> <span class='kw'>=</span> <span class='fl'>200</span>) <span class='co'># for speed of example only</span></div><div class='output co'>#&gt; 
#&gt; SAMPLING FOR MODEL 'count' NOW (CHAIN 1).
#&gt; Chain 1: 
#&gt; Chain 1: Gradient evaluation took 4.2e-05 seconds
#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.42 seconds.
#&gt; Chain 1: Adjust your expectations accordingly!
#&gt; Chain 1: 
#&gt; Chain 1: 
#&gt; Chain 1: WARNING: There aren't enough warmup iterations to fit the
#&gt; Chain 1:          three stages of adaptation as currently configured.
#&gt; Chain 1:          Reducing each adaptation stage to 15%/75%/10% of
#&gt; Chain 1:          the given number of warmup iterations:
#&gt; Chain 1:            init_buffer = 15
#&gt; Chain 1:            adapt_window = 75
#&gt; Chain 1:            term_buffer = 10
#&gt; Chain 1: 
#&gt; Chain 1: Iteration:   1 / 200 [  0%]  (Warmup)
#&gt; Chain 1: Iteration:  20 / 200 [ 10%]  (Warmup)
#&gt; Chain 1: Iteration:  40 / 200 [ 20%]  (Warmup)
#&gt; Chain 1: Iteration:  60 / 200 [ 30%]  (Warmup)
#&gt; Chain 1: Iteration:  80 / 200 [ 40%]  (Warmup)
#&gt; Chain 1: Iteration: 100 / 200 [ 50%]  (Warmup)
#&gt; Chain 1: Iteration: 101 / 200 [ 50%]  (Sampling)
#&gt; Chain 1: Iteration: 120 / 200 [ 60%]  (Sampling)
#&gt; Chain 1: Iteration: 140 / 200 [ 70%]  (Sampling)
#&gt; Chain 1: Iteration: 160 / 200 [ 80%]  (Sampling)
#&gt; Chain 1: Iteration: 180 / 200 [ 90%]  (Sampling)
#&gt; Chain 1: Iteration: 200 / 200 [100%]  (Sampling)
#&gt; Chain 1: 
#&gt; Chain 1:  Elapsed Time: 0.072875 seconds (Warm-up)
#&gt; Chain 1:                0.06739 seconds (Sampling)
#&gt; Chain 1:                0.140265 seconds (Total)
#&gt; Chain 1: 
#&gt; 
#&gt; SAMPLING FOR MODEL 'count' NOW (CHAIN 2).
#&gt; Chain 2: 
#&gt; Chain 2: Gradient evaluation took 3.9e-05 seconds
#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.39 seconds.
#&gt; Chain 2: Adjust your expectations accordingly!
#&gt; Chain 2: 
#&gt; Chain 2: 
#&gt; Chain 2: WARNING: There aren't enough warmup iterations to fit the
#&gt; Chain 2:          three stages of adaptation as currently configured.
#&gt; Chain 2:          Reducing each adaptation stage to 15%/75%/10% of
#&gt; Chain 2:          the given number of warmup iterations:
#&gt; Chain 2:            init_buffer = 15
#&gt; Chain 2:            adapt_window = 75
#&gt; Chain 2:            term_buffer = 10
#&gt; Chain 2: 
#&gt; Chain 2: Iteration:   1 / 200 [  0%]  (Warmup)
#&gt; Chain 2: Iteration:  20 / 200 [ 10%]  (Warmup)
#&gt; Chain 2: Iteration:  40 / 200 [ 20%]  (Warmup)
#&gt; Chain 2: Iteration:  60 / 200 [ 30%]  (Warmup)
#&gt; Chain 2: Iteration:  80 / 200 [ 40%]  (Warmup)
#&gt; Chain 2: Iteration: 100 / 200 [ 50%]  (Warmup)
#&gt; Chain 2: Iteration: 101 / 200 [ 50%]  (Sampling)
#&gt; Chain 2: Iteration: 120 / 200 [ 60%]  (Sampling)
#&gt; Chain 2: Iteration: 140 / 200 [ 70%]  (Sampling)
#&gt; Chain 2: Iteration: 160 / 200 [ 80%]  (Sampling)
#&gt; Chain 2: Iteration: 180 / 200 [ 90%]  (Sampling)
#&gt; Chain 2: Iteration: 200 / 200 [100%]  (Sampling)
#&gt; Chain 2: 
#&gt; Chain 2:  Elapsed Time: 0.056908 seconds (Warm-up)
#&gt; Chain 2:                0.073774 seconds (Sampling)
#&gt; Chain 2:                0.130682 seconds (Total)
#&gt; Chain 2: </div><div class='output co'>#&gt; <span class='warning'>Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.</span>
#&gt; <span class='warning'>Running the chains for more iterations may help. See</span>
#&gt; <span class='warning'>http://mc-stan.org/misc/warnings.html#bulk-ess</span></div><div class='output co'>#&gt; <span class='warning'>Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.</span>
#&gt; <span class='warning'>Running the chains for more iterations may help. See</span>
#&gt; <span class='warning'>http://mc-stan.org/misc/warnings.html#tail-ess</span></div><div class='input'>
<span class='fu'><a href='prior_summary.stanreg.html'>prior_summary</a></span>(<span class='no'>fit6</span>)</div><div class='output co'>#&gt; Priors for model 'fit6' 
#&gt; ------
#&gt; Intercept (after predictors centered)
#&gt;  ~ normal(location = 0, scale = 10)
#&gt; 
#&gt; Coefficients
#&gt;  ~ normal(location = [0,0,0,...], scale = [2.5,2.5,2.5,...])
#&gt; 
#&gt; Auxiliary (reciprocal_dispersion)
#&gt;  ~ exponential(rate = 1.5)
#&gt; ------
#&gt; See help('prior_summary.stanreg') for more details</div><div class='input'><span class='kw pkg'>bayesplot</span><span class='kw ns'>::</span><span class='fu'><a href='https://mc-stan.org/bayesplot/reference/bayesplot-colors.html'>color_scheme_set</a></span>(<span class='st'>"brightblue"</span>)
<span class='fu'><a href='https://rdrr.io/r/graphics/plot.html'>plot</a></span>(<span class='no'>fit6</span>)</div><div class='img'><img src='stan_glm-9.png' alt='' width='700' height='433' /></div><div class='input'><span class='fu'><a href='pp_check.stanreg.html'>pp_check</a></span>(<span class='no'>fit6</span>, <span class='kw'>plotfun</span> <span class='kw'>=</span> <span class='st'>"hist"</span>, <span class='kw'>nreps</span> <span class='kw'>=</span> <span class='fl'>5</span>) <span class='co'># ?bayesplot::ppc_hist</span></div><div class='output co'>#&gt; <span class='message'>`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</span></div><div class='img'><img src='stan_glm-10.png' alt='' width='700' height='433' /></div><div class='input'>
<span class='co'># 80% interval of estimated reciprocal_dispersion parameter</span>
<span class='fu'><a href='posterior_interval.stanreg.html'>posterior_interval</a></span>(<span class='no'>fit6</span>, <span class='kw'>pars</span> <span class='kw'>=</span> <span class='st'>"reciprocal_dispersion"</span>, <span class='kw'>prob</span> <span class='kw'>=</span> <span class='fl'>0.8</span>)</div><div class='output co'>#&gt;                            10%      90%
#&gt; reciprocal_dispersion 1.181574 1.621397</div><div class='input'><span class='fu'><a href='https://rdrr.io/r/graphics/plot.html'>plot</a></span>(<span class='no'>fit6</span>, <span class='st'>"areas"</span>, <span class='kw'>pars</span> <span class='kw'>=</span> <span class='st'>"reciprocal_dispersion"</span>, <span class='kw'>prob</span> <span class='kw'>=</span> <span class='fl'>0.8</span>)</div><div class='img'><img src='stan_glm-11.png' alt='' width='700' height='433' /></div><div class='input'># }

</div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      <li><a href="#value">Value</a></li>
      <li><a href="#details">Details</a></li>
      <li><a href="#references">References</a></li>
      <li><a href="#see-also">See also</a></li>
      <li><a href="#examples">Examples</a></li>
    </ul>

  </div>
</div>


      <footer>
      <div class="copyright">
  <p>Developed by Jonah Gabry, Ben Goodrich.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.4.1.</p>
</div>

      </footer>
   </div>

  


  </body>
</html>


